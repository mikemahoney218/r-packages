From Achim.Zeileis at wu-wien.ac.at  Wed Jan  6 17:40:46 2010
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 6 Jan 2010 17:40:46 +0100 (CET)
Subject: [R-pkgs] fortunes: 250th fortune
Message-ID: <alpine.DEB.2.00.1001061730340.6635@paninaro.stat-math.wu-wien.ac.at>

Dear useRs,

it's a new year and time for a new CRAN-version of the "fortunes" package. 
Version 1.3-7 is now online at

   http://CRAN.R-project.org/package=fortunes

which contains the 250th fortune:

R> fortune(250)

As Obi-Wan Kenobi may have said in Star Wars: "Use the source, Luke!"
    -- Barry Rowlingson (answering a question on the documentation of some
       implementation details)
       R-devel (January 2010)

Actually there is also the 251st...

Thanks to all that have contributed to the "fortunes" package in the form 
of creating these nice quote or submitting them to the package.

Best wishes,
Z


From nkraemer at cs.tu-berlin.de  Wed Jan  6 18:12:13 2010
From: nkraemer at cs.tu-berlin.de (=?ISO-8859-15?Q?Nicole_Kr=E4mer?=)
Date: Wed, 06 Jan 2010 18:12:13 +0100
Subject: [R-pkgs] parcor 0.2-2 - Regularized Partial Correlation Matrices
 with (adaptive) Lasso, PLS, and Ridge Regression
Message-ID: <4B44C46D.2000705@cs.tu-berlin.de>

Dear R-users,

we are happy to announce the release of our R package parcor.

The package contains tools to estimate the matrix of partial 
correlations based on different regularized regression methods: Lasso, 
adaptive Lasso, PLS, and Ridge Regression. In addition, parcor provides 
cross-validation based model selection for Lasso, adaptive Lasso and 
Ridge Regression.

More details can be found in the accompanying article

Nicole Kr?mer, Juliane Sch?fer, Anne-Laure Boulesteix.
Regularized Estimation of Large Scale Gene Association Networks using 
Gaussian Graphical Models
BMC Bioinformatics, 10:384, 2009.

http://www.biomedcentral.com/1471-2105/10/384

Please send an email to nkraemer at cs.tu-berlin.de for any comments, 
suggestions, or bug reports.

Best regards,

Nicole & Juliane

-- 
Dr. Nicole Kr?mer
TU Berlin
Machine Learning/Intelligent Data Analysis	fon: (+49) 30 314 78627
Franklinstr. 28/29, 10587 Berlin, Germany	fax: (+49) 30 314 78622

web: http://ml.cs.tu-berlin.de/~nkraemer


From Roger.Bivand at nhh.no  Wed Jan 13 19:58:17 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 13 Jan 2010 19:58:17 +0100 (CET)
Subject: [R-pkgs] New sp release
Message-ID: <alpine.LRH.2.00.1001131949130.25617@reclus.nhh.no>

The sp package provides class definitions for spatial data, and utilities 
for spatial data handling and manipulation.

The release of sp version 0.9-56 introduces changes in the ways in which 
Polygon, Polygons, and SpatialPolygons objects are created, moving from R 
code to compiled C code. Because of these changes, it is possible that 
users will see changed output. The package maintainers have tested as far 
as possible, and a beta release has been checked by some users, without 
any problems coming to light.

Further details are given in:

https://stat.ethz.ch/pipermail/r-sig-geo/2010-January/007377.html

Should anyone see problems following this change, please contact me 
directly with a reproducible example.

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From stephen.b.weston at gmail.com  Thu Jan 14 22:39:59 2010
From: stephen.b.weston at gmail.com (Stephen Weston)
Date: Thu, 14 Jan 2010 16:39:59 -0500
Subject: [R-pkgs] itertools 0.1-1
Message-ID: <57e838141001141339k70a47a26p39f4785844df0df1@mail.gmail.com>

I'd like to announce the availability of the new "itertools" package,
which provides a variety of functions used to create iterators, as
defined by REvolution Computing's "iterators" package.  The package has
been uploaded to CRAN and is now available under the GPL-2 license.

The "itertools" package is strongly inspired by the Python itertools
module, and includes a number of functions of the same name.  There are
a variety of functions that create iterators for splitting, chunking,
repeating, recycling, zipping, and filtering your data.  There is also
an "ihasNext" function, written by Hadley Wickham, that adds a "hasNext"
method to any iterator, making it easier to get values from an iterator
without the use of the "foreach" function.  Hadley also contributed some
utility functions for writing your own iterators.

- Steve Weston


From stephen.b.weston at gmail.com  Thu Jan 14 22:42:26 2010
From: stephen.b.weston at gmail.com (Stephen Weston)
Date: Thu, 14 Jan 2010 16:42:26 -0500
Subject: [R-pkgs] doMPI 0.1-4
Message-ID: <57e838141001141342o27b89b03i570e1838f7102c06@mail.gmail.com>

I'd like to announce the availability of version 0.1-4 of the "doMPI"
package, a parallel backend for the "foreach" package, which acts as an
adaptor to the "Rmpi" package.  The package has been uploaded to CRAN
and is now available under the GPL-2 license.

In addition to fixing a few problems in version 0.1-3, the main new
feature of this release is the backend-specific "initEnvirMaster"
option, which specifies an R function that is executed in the master
process at the beginning of the foreach loop.  It is intended to be used
in conjunction with the "initEnvir" option, which specifies an R
function that is executed by the cluster workers.  By using both
together, MPI collective communication functions can be executed to
initialize the cluster workers.  This is particularly useful for sending
large matrices to each of the workers, since it allows the matrix to be
broadcast using the mpi.bcast function without calling the R "serialize"
function.  An example of this technique is in the new "rforest.R" file,
a parallel random forest benchmark which is included in the "benchmark"
directory of the doMPI distribution.

- Steve Weston


From barret at barretschloerke.com  Thu Jan 21 20:37:24 2010
From: barret at barretschloerke.com (Barret Schloerke)
Date: Thu, 21 Jan 2010 13:37:24 -0600
Subject: [R-pkgs] GGally - Plot Matrix Extension for GGplot2
Message-ID: <4e2dfc531001211137r2f1f58cldad1ffd8e7ca9a14@mail.gmail.com>

GGally:  a companion to GGplot2.

GGally is a package built to produce plot matrices without the hassle
of making viewports and labels yourself.  GGally is built upon the
GGplot2 framework.  Keeping the functionality and feel of ggplot,
GGally has shortened common function calls and added a few new ones.

ggpairs, the main function within GGally, will take your data set and
produce a plots according to the data types given. ggpairs will
produce four different types of plots: continuous-continuous,
continuous-discrete, discrete-continuous, discrete-discrete.  The
function will determine which type is needed and produce a plot
according the the specified type given.  General aesthetics can be
applied to the whole plot matrix.

This package was developed as an add on package to keep the base
functionality of GGplot2 separate.

Examples:
  #plot matrix of all five variables in iris
  ggpairs(iris)

  # Make a ggpairs object with
  #  the upper triangle containing 2D density plots and box plots,
  #  the lower triangle containing scatter plots and dod plots,
  #  the diagonal containing histograms.
  # The color of each plot, if applicable, will be done accordingly to "cut"
  #
  diamondMatrix <- ggpairs(	
    diamonds[,1:3], 	
    upper = list(continuous = "density", combo = "box"), 	
    lower = list(continuous = "points", combo = "dot"), 	
    diag = list(continuous = "bar", discrete = "bar"),
    color = "cut",
    filled = TRUE,
    title = "Diamonds"
  )
  # print the plot matrix
  diamondMatrix

- Barret Schloerke, Dianne Cook, Heike Hofmann, Hadley Wickham


From RossBoylan at stanfordalumni.org  Thu Jan 21 20:46:27 2010
From: RossBoylan at stanfordalumni.org (Ross Boylan)
Date: Thu, 21 Jan 2010 11:46:27 -0800
Subject: [R-pkgs] [ANN] mspath analyzes transitions between multiple state
	with	history dependence
Message-ID: <1264103187.6220.108.camel@corn.betterworld.us>

Now available on CRAN.
Package: mspath
Title: Multi-state Path-Dependent Models in Discrete Time
Description:  Functions for fitting path-dependent (non-Markov)
 multi-state models to categorical processes observed at arbitrary
 times,  optionally with misclassified responses, and covariates on
 transition  or misclassification rates.  Uses discrete-time
 approximation.  Based on the Jackson's msm package v 0.3.1, with an
 interface as compatible as  possible.


From jens.oehlschlaegel at truecluster.com  Fri Jan 22 17:49:10 2010
From: jens.oehlschlaegel at truecluster.com (=?iso-8859-15?Q?Jens_Oehlschl=E4gel?=)
Date: Fri, 22 Jan 2010 17:49:10 +0100
Subject: [R-pkgs] New version of package ff
Message-ID: <1477909486@web.de>

Dear R community,

Package bit version 1.1-3 and ff version 2.1.2 is available on CRAN and should be useful to handle large datasets.

It adds convenient utilities for managing ff objects and files (see ?ffsave) and removes some performance bottlenecks. 

In case you experience unexpected performance problems with ff, here is a couple of recommendations based on FAQs:

1) Compare the size of data to be written at the same time to available RAM for your filesystem cache. 
   If the data exceeds available RAM, then consider using caching="mmeachflush" instead of caching="mmnoflush", this will make write operations predictably slower but prevent write storms stalling some systems (observed under NTFS win32+64).
   You can set ff's caching option 
   either with options(ffcaching="mmeachflush") before creating ff objects
   or create ff objects with ffobj <- ff(..., caching="mmeachflush") 
   or open your existing ff object with open(ffobj, caching="mmeachflush") (while it is closed)
   ff objects will remember this setting

2) If you use caching="mmnoflush": check the writeback cache configuration of your filesystem (e.g. set data=writeback for ext3, tune limits for dirty pages, consider different filesystem, consider different OS). 

3) Choose a reasonable size for options("ffbatchbytes"), which limits the amount of RAM used for one chunk. 
   With too small chunks you pay more performance overhead. 
   Note that bigger chunks are not always better, for example if you distribute chunked processing on many cores or if some operation involved does not scale well with chunk size. 

Final remark: testing ff access functionality  on a Core i7 920 (4 cores, 8 cores with HT) shows that hyperthreading with 8 parallel processes (snowfall, sockets) gives about 5x the performance of a single process, but already 7 processes with HT perform worse than 4 processes without HT. Conclusion: if a machine is dedicated to R for RAM-critical applications, try switching hyperthreading off. 

Hope you find this useful. We appreciate any feedback.


Jens & Daniel


From mfay at niaid.nih.gov  Thu Jan 28 01:59:09 2010
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 27 Jan 2010 19:59:09 -0500
Subject: [R-pkgs] exactci package gives exact binomial and poisson tests and
 matching CI
Message-ID: <E71B6F8FD9DA77498BED796B4E35362C023825B6F1@NIHMLBX01.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100127/2f5de288/attachment.pl>

From mfay at niaid.nih.gov  Thu Jan 28 01:59:50 2010
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 27 Jan 2010 19:59:50 -0500
Subject: [R-pkgs] Update to exact2x2 package: Exact McNemar's test
Message-ID: <E71B6F8FD9DA77498BED796B4E35362C023825B6F2@NIHMLBX01.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100127/3328bbdf/attachment.pl>

From Benjamin.Hofner at imbe.med.uni-erlangen.de  Tue Feb  2 10:19:42 2010
From: Benjamin.Hofner at imbe.med.uni-erlangen.de (Benjamin Hofner)
Date: Tue, 02 Feb 2010 10:19:42 +0100
Subject: [R-pkgs] Major update: mboost 2.0-0 released
Message-ID: <4B67EE2E.4000301@imbe.med.uni-erlangen.de>

Dear useRs,

we are happy to announce the release of mboost 2.0-0 on CRAN:

http://cran.r-project.org/package=mboost

This version contains major updates and changes to the implementation of 
the main algorithm. Some slight changes to the user-interface where 
necessary. Please consult the manual and the list of CHANGES below.

The package 'mboost' (Model-based Boosting) implements boosting for 
optimizing general risk functions utilizing component-wise (penalized) 
least squares estimates or regression trees as base-learners for fitting 
generalized linear, additive and interaction models to potentially 
high-dimensional data.

A big variety of models can be investigated using 'mboost' including 
survival models, expectile regression models, ordinal regression models 
as well as standard models such as simple linear models. In all cases, 
the predictor can be specified very flexible using linear, smooth, 
random and spatial effects as well as decision trees or an arbitrary 
combination suiting the intention of the researcher.

For more details and a nice example showing some of the functionality of 
'mboost' see ?mboost-package.

We appreciate any feedback.

    mboost development team

___________


                 CHANGES in `mboost' VERSION 2.0-0 (2010-02-01)

   o  generic implementation of component-wise functional gradient
      boosting in `mboost_fit', specialized code for linear,
      additive and interaction models removed

   o  new families available for ordinal, expectile and censored
      regression

   o  computations potentially based on package Matrix
      (reduces memory usage)

   o  various speed improvements

   o  added interface to extract selected base-learners (selected())

   o  added interface for parallel computations in cvrisk with
      arbitrary packages (e.g. multicore, snow)

   o  added "which" argument in predict and coef functions and improved
      usability of "which" in plot-function. Users can specify "which" as
      numeric value or as a character string

   o  added function cv() to generate matrices for k-fold
      cross-validation, subsampling and bootstrap

   o  new function stabsel() for stability selection with error control

   o  added function model.weights() to extract the weights

   o  added interface to expand model by increasing mstop in
      model[mstop]

   o  alternative definition of degrees of freedom available

   o  Interface changes:

      - class definition / Family() arguments changed
      - changed behavior of subset method (model[mstop]). Object
        is directly altered and not duplicated
      - argument "center" in bols replaced with "intercept"
      - argument "z" in base-learners replaced with "by"
      - bns and bss deprecated


-- 
******************************************************************************
Dipl.-Stat. Benjamin Hofner

Institut f?r Medizininformatik, Biometrie und Epidemiologie
Friedrich-Alexander-Universit?t Erlangen-N?rnberg
Waldstr. 6 - 91054 Erlangen - Germany

benjamin.hofner at imbe.med.uni-erlangen.de

http://www.imbe.med.uni-erlangen.de/~hofnerb/
http://www.benjaminhofner.de


From racinej at mcmaster.ca  Wed Feb  3 17:10:21 2010
From: racinej at mcmaster.ca (Jeffrey Racine)
Date: Wed, 3 Feb 2010 11:10:21 -0500
Subject: [R-pkgs] Package np update (0.30-6) adds nonparametric entropy test
	functionality...
Message-ID: <2141CA57-3FF9-474B-8FC2-6ECE4D06E6A4@mcmaster.ca>

Dear R users,

Version 0.30-6 of the np package has been uploaded to CRAN. See

http://cran.r-project.org/package=np

Note that the cubature package is now required in addition to the boot package. The recent updates in 0.30-4 through 0.30-6 provides additional functionality in the form of five new functions that incorporate frequently requested nonparametric entropy-based testing methods to the np package.

The new functions are:

- npdeneqtest
- npsymtest
- npdeptest
- npsdeptest
- b.star

A brief description of each:

npdeneqtest implements a consistent integrated squared difference test for equality of densities as described in Li, Q. and E. Maasoumi and J.S. Racine (2009), ?A Nonparametric Test for Equality of Distributions with Mixed Categorical and Continuous Data,? Journal of Econometrics, 148, pp 186-200.

npsymtest implements a consistent entropy-based test for asymmetry as described in Maasoumi, E. and J.S. Racine (2009), ?A robust entropy-based test of asymmetry for discrete and continuous processes,? Econometric Reviews, 28, 246-261.

npdeptest implements a consistent entropy-based test for pairwise independence as described in Maasoumi, E. and J.S. Racine (2002), ?Entropy and Predictability of Stock Market Returns,? Journal of Econometrics, 107, 2, pp 291-312.

npsdeptest implements a consistent entropy-based test for serial nonlinear dependence as described in Granger, C.W. and E. Maasoumi and J.S. Racine (2004), ?A dependence metric for possibly nonlinear processes?, Journal of Time Series Analysis, 25, 649-669.

b.star is a function which computes the optimal block length for a continuous variable using the method described in Politis, D.N. and H. White (2004), ?Automatic block-length selection for the dependent bootstrap?, Econometric Reviews 23(1), 53-70 and Patton, A. and D.N. Politis and H. White (2009), ?CORRECTION TO "Automatic block-length selection for the dependent bootstrap" by D. Politis and H. White?, Econometric Reviews 28(4), 372-375.

The function b.star is now used throughout the np package for automated block length selection for the stationary bootstrap (via the `l = ' argument in tsboot from the boot package).

Examples are provided for each function at the end of the respective man pages. We hope you find the functions to be easy to use. Kindly report any bugs, suggested improvements and the like to racinej at mcmaster.ca

-- Jeff

Professor J. S. Racine         Phone:  (905) 525 9140 x 23825
Department of Economics        FAX:    (905) 521-8232
McMaster University            e-mail: racinej at mcmaster.ca
1280 Main St. W.,Hamilton,     URL: http://www.economics.mcmaster.ca/racine/
Ontario, Canada. L8S 4M4

`The generation of random numbers is too important to be left to chance'


From mfay at niaid.nih.gov  Thu Feb  4 22:39:48 2010
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Thu, 4 Feb 2010 16:39:48 -0500
Subject: [R-pkgs] Update of interval package
Message-ID: <E71B6F8FD9DA77498BED796B4E35362C0239271C20@NIHMLBX01.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100204/0c9be857/attachment.pl>

From tlumley at u.washington.edu  Tue Feb  9 22:34:34 2010
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 9 Feb 2010 13:34:34 -0800 (PST)
Subject: [R-pkgs] survey 3.20
Message-ID: <alpine.LRH.2.01.1002091334340.22535@hymn33.u.washington.edu>



Version 3.20 of the survey package is percolating through CRAN

The major additions since the last announcement on this list (3.18, in September) are
  
    - database-backed designs can now use replicate weights
    - some multivariate statistics: principal components, factor analysis.

The NEWS file has a more detailed list of additions and changes.

       -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From ajsaez at ujaen.es  Thu Feb 11 12:31:56 2010
From: ajsaez at ujaen.es (Antonio =?iso-8859-1?Q?Jos=E9_S=E1ez_Castillo?=)
Date: Thu, 11 Feb 2010 12:31:56 +0100 (CET)
Subject: [R-pkgs] GWRM package
Message-ID: <182650dc012510ce5c9ebd81a8564bb2.squirrel@webmail.ujaen.es>

I'd like to announce the availability of the "GWRM" package. It provides a
set of functions for fitting Generalized Waring Regression Models. It also
includes the dataset and the example of Rodriguez-Avi, J; Conde-Sanchez,
A; Saez-Castillo, A.J., Olmo-Jimenez, M. J. and Martinez Rodriguez, A.
M.(2009). A generalized Waring regression model for count data.
Computational Statistics and Data Analysis, 53, pp. 3717-3725. The package
has been uploaded to CRAN and is now available under the GPL-2 license.

Antonio Jose Saez-Castillo, Ph.D.


From hadley at rice.edu  Fri Feb 19 20:44:30 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 19 Feb 2010 13:44:30 -0600
Subject: [R-pkgs] ggplot2: version 0.8.6
Message-ID: <f8e6ff051002191144l4db7bf79s45b14e684bb3120d@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

To install or update, run:
install.packages(c("ggplot2", "plyr"))

Find out more at http://had.co.nz/ggplot2, and check out the nearly 500
examples of ggplot in use.  If you're interested, you can also sign up to
the ggplot2 mailing list at http://groups.google.com/group/ggplot2, or track
development at  http://github.com/hadley/ggplot2

ggplot2 0.8.6 (2010-02-07) ----------------------------------------

New features

* trans_log1p: new log + 1 transformer contributed by Jean-Olivier Irisson

Bug fixes

* aesthetics: fixed bug when overriding aesthetics with NULL
* annotate: adds layers with legend = FALSE
* coord_equal: correctly place tick marks (Fixes #61)
* documentation: usage statements should now be spread over multiple lines
* fortify.SpatialPolygonsDataFrame: fixed bug when region variable had
missing values
* legend: don't try and display legend when unnecessary scale added
* legend: text labels now correctly left-aligned when non-numeric
* order aesthetic now correctly affects position adjustments  (Fixes #70)
* qplot loads facetting variables from global environment more correctly
* scale_date and scale_date_time now work with infinite positions
* scale_date and scale_date_time now take expand argument
* scales were not getting automatically added in many situations (Fixes #69)
* scale_manual was not returning labels in the correct format and so legends
  were not getting merged correctly
* stat_contour: fix error if x or y coordinates were negative
* stat_bin: now copes with bars of zero height (Fixes #72)
* stat_qq: always use sorted data (rather than interpolated quantiles)
on sample axis.  This makes it behave more like qqnorm
* stat_quantile: correctly group results
* xlim now works with datetimes

* all plyr functions prefixed with their namespace to avoid clashes
with other packages (thanks to Steve Lianoglou)

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From jjdonald at indiana.edu  Sat Feb 20 00:10:54 2010
From: jjdonald at indiana.edu (Justin Donaldson)
Date: Fri, 19 Feb 2010 18:10:54 -0500
Subject: [R-pkgs] "tsne" package for t-SNE dimensionality reduction
Message-ID: <eda626a31002191510p343070bbje58e5a96a53ccebc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100219/0082cd62/attachment.pl>

From Matthias.Kohl at stamats.de  Sat Feb 20 09:31:35 2010
From: Matthias.Kohl at stamats.de (Dr. Matthias Kohl)
Date: Sat, 20 Feb 2010 09:31:35 +0100
Subject: [R-pkgs] new package RFLPtools
In-Reply-To: <4B7A73DC.7010006@uni-bayreuth.de>
References: <4B7A73DC.7010006@uni-bayreuth.de>
Message-ID: <4B7F9DE7.3090603@stamats.de>

The new package RFLPtools is available on CRAN.

RFLPtools provides analysis functions for DNA fragment molecular weights 
(e.g.\ derived from RFLP-analysis) and nucleotide sequence similarities. 
It aims mainly at the identification of similar or identical fragment 
patterns to evaluate the amount of different genotypes gained from
environmental samples during diversity studies and at further analysis 
of similarities of nucleotide sequences derived from pairwise sequence 
alignments (e.g.\ derived from standalone BLAST). Additionally, 
functions to check the data quality of molecular fingerprints are 
available. To identify the organisms represented by the extracted 
fragment patterns (e.g.\ RFLP genotypes), RFLPtools includes a function 
to compare samples with fragment patterns stored in a reference dataset, 
from which the taxonomic affiliations are already known. To identify 
unknown samples in scientific projects, DNA sequences are used, and the 
gained DNA sequences are compared to existing sequence data via 
alignments tools, as standalone BLAST.
RFLPtools offers tools to generate groups based on tabular report files 
of sequence comparison of pairwise nucleotide sequence alignment.

To get a first impression try:

vignette("RFLPtools")

as well as

library(RFLPtools)
example("RFLPplot")
example("RFLPrefplot")

Best regards,
Fabienne
Alexandra
Matthias

-- 
Dr. Matthias Kohl
www.stamats.de


From oscar.perpinan at upm.es  Fri Feb 12 15:50:12 2010
From: oscar.perpinan at upm.es (Oscar =?UTF-8?B?UGVycGnDsWFu?= Lamigueiro)
Date: Fri, 12 Feb 2010 15:50:12 +0100
Subject: [R-pkgs] New solaR package
Message-ID: <20100212155012.6af74732@upm.es>

Hello.

I'd like to announce the availability of version 0.14 of the "solaR" package. It provides a set of calculation methods of solar radiation and performance of photovoltaic systems. The package has been uploaded to CRAN and is now available under the GPL-3 license. 

Moreover, I have designed some GUIs with gWidgets. They are still far from elegant so I have not included them in the package. They are available at my blog: http://procomun.wordpress.com/software/solar/

An introduction to the package can be found in the vignette (in Spanish): http://cran.r-project.org/web/packages/solaR/vignettes/solaR.pdf. A handbook of photovoltaic systems (in Spanish) is available at http://procomun.wordpress.com/documentos/libroesf/.

Best regards.

Oscar Perpi??n Lamigueiro.


From f.harrell at Vanderbilt.Edu  Wed Feb 24 19:38:50 2010
From: f.harrell at Vanderbilt.Edu (Frank E Harrell Jr)
Date: Wed, 24 Feb 2010 12:38:50 -0600
Subject: [R-pkgs] New version of rms package now on CRAN
Message-ID: <4B85723A.1070500@vanderbilt.edu>

Version 2.2-0 of the rms package is now available.  This is a somewhat 
major update.  One major change is not downward compatible: Instead of 
specifying predictor=. or predictor=NA to Predict, summary, nomogram, 
survplot, gendata, you just specify the name of the predictor.  For 
example, to get predictions for the default range of x1 and for just 2 
values of x2 you might specify Predict(fit, x1, x2=c(1,3)).  The next 
major change is the use of lattice graphics in bplot, so that now you 
can easily make multi-panel 3-D displays of effects in the fitted model.

The package's web site is http://biostat.mc.vanderbilt.edu/rms

Here is what's new:

    * Added levels.only option to survplot.* to remove variablename= 
from curve labels
    * Added digits argument to calibrate.default
    * Added new ref in val.prob help page
    * Corrected location of dataset in residuals.lrm help page (thanks 
frederic.holzwarth at bgc-jena.mpg.de)
    * Fixed latex.rms to latex-escape percent signs inside value labels
    * Added scat1d.opts to plot.Predict
    * Changed method of specifying variables to vary by not requiring an 
equals sign and a dot after the variable name, for Predict, summary, 
nomogram, gendata, survplot.rms
    * Added factors argument to Predict to handle the above for survplot
    * Made gendata a non-generic function, changed the order of its 
arguments, removed editor options, relying on R de function always
    * Thanks to Kevin Thorpe <kevin.thorpe at utoronto.ca> to make 
latex.summary.rms and latex.anova.rms respect the table.env argument
    * Fixed bug in calibrate.default related to digits argument
    * Re-wrote bplot to use lattice graphics (e.g., levelplot 
contourplot wireframe), allowing for multiple panels for 3-d plots
    * Changed all Rd files to use {arg1,arg2,...} instead of having empty {}

-- 
Frank E Harrell Jr   Professor and Chairman        School of Medicine
                      Department of Biostatistics   Vanderbilt University


From ronggui.huang at gmail.com  Mon Mar  1 05:24:31 2010
From: ronggui.huang at gmail.com (Wincent)
Date: Mon, 1 Mar 2010 12:24:31 +0800
Subject: [R-pkgs] RQDA 0.1-9 is on CRAN now
Message-ID: <38b9f0351002282024n3b62a98am4e75faf3b4e7d896@mail.gmail.com>

Dear all,

RQDA is a R package for computer-aided qualitative data analysis
(CAQDA). It is an easy-to-use tool to assist in the analysis of
textual data.

RQDA 0.1-9 is a major upgrade with the following changes:
* widgets are enabled only if they are usable.
* Better code categories management system and various improvements of GUI.
* Click-handler for second half of code-mark.
* Better default color scheme for code mark.
* New function of and().
* New option "both" in "type of retrieval".
* New option of subset in GetAtrr().
* It can handle ' correctly now.
* Various bugfixes.

As always, feedbacks and suggestions are more than welcome.

Regars

-- 
Wincent Ronggui HUANG
Doctoral Candidate
Dept of Public and Social Administration
City University of Hong Kong
http://asrr.r-forge.r-project.org/rghuang.html


From alexander.pilhoefer at gmx.de  Mon Mar  1 12:11:20 2010
From: alexander.pilhoefer at gmx.de (=?iso-8859-1?Q?=22Alexander_Pilh=F6fer=22?=)
Date: Mon, 01 Mar 2010 12:11:20 +0100
Subject: [R-pkgs] NEW: extracat - a package for the visualization of
	categorical data
Message-ID: <20100301111120.7510@gmx.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100301/6f212e63/attachment.pl>

From matthieu.stigler at gmail.com  Tue Mar  2 09:45:56 2010
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Tue, 02 Mar 2010 09:45:56 +0100
Subject: [R-pkgs] Version 1.4.7 of package vars
Message-ID: <4B8CD044.3060702@gmail.com>

Dear useRs,

The package vars, implementing multivariate time series models VAR and 
VECM, has been updated to version 1.4.7

The new changes are:

-the compatibility with the sandwich/lmtest package, which allows to use 
heteroskedasticity consistent (HC) covariance estimators, to do 
inference on the parameters taking into account heteroskedasticity of 
unknown form.

-Implementation of a heteroskedasticity robust Granger causality test 
with HC covariance and/or a wild bootstrap

Example:
library(vars)
data(Canada)
va<-VAR(Canada, p=2)
coeftest(va, vcov.=vcovHC)
causality(va, vcov.=vcovHC, boot=TRUE)

Best

Matthieu Stigler


From cgenolin at u-paris10.fr  Thu Mar  4 08:10:10 2010
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Thu, 04 Mar 2010 08:10:10 +0100
Subject: [R-pkgs] KmL 1.1.1
Message-ID: <4B8F5CD2.70001@u-paris10.fr>

?kml? is an implementation of k-means for longitudinal data (or 
trajectories). This algorithm is able to deal with missing value
and provides an easy way to re roll the algorithm several times, varying 
the starting conditions and/or the number of clusters looked for.

KmL 1.1.1 addition:
- 7 imputations methods for longitudinal data
- Calculus of three qualities criterion (Calinski&Harabatz, Ray&Turi, 
Davies&Bouldin)
- Implementation of the Frechet distance between two trajectories
- Calculus of the Frechet path
- Optimization of the function 'dist' for trajectories
- Possibility to use three different ways to define the starting conditions
- Correction of minor bugs


Christophe Genolini


From seth at userprimary.net  Wed Mar 10 18:43:41 2010
From: seth at userprimary.net (Seth Falcon)
Date: Wed, 10 Mar 2010 09:43:41 -0800
Subject: [R-pkgs] RSQLite 0.8-4 now on CRAN
Message-ID: <4B97DA4D.9060208@userprimary.net>

A new version of RSQLite (0.8-4) is now available on CRAN.  Highlights 
of this release:

Version 0.8-4

- Fix a memory leak in bound parameter management and resolve a
   missing PROTECT bug that caused spurious crashes when performing
   many prepared queries.

- There is now a fairly comprehensive example of using prepared
   queries in the man page for dbSendQuery-methods.

- Upgrade to SQLite 3.6.21 => 3.6.22 (minor bug fixes).

- Enable full-text search module by default.  See
   http://www.sqlite.org/fts3.html for details on this SQLite
   module.

- Add support for prepared queries that involve a SELECT.  This was
   previously unsupported.  SELECT queries can now be used with
   dbSendPreparedQuery.  The return value is the same as rbind'ing the
   results of the individual queries.  This means that parameters that
   return no results are ignored in the result.

Full NEWS items available here:
http://cran.r-project.org/web/packages/RSQLite/NEWS

+ seth

-- 
Seth Falcon | @sfalcon | http://userprimary.net/


From hadley at rice.edu  Sat Mar 13 01:42:15 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 12 Mar 2010 18:42:15 -0600
Subject: [R-pkgs] ggplot2: version 0.8.7
Message-ID: <f8e6ff051003121642n7a2fbdccida963bd1b65747d0@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

To install or update, run:
install.packages(c("ggplot2", "plyr"))

Find out more at http://had.co.nz/ggplot2, and check out the nearly 500
examples of ggplot in use.  If you're interested, you can also sign up to
the ggplot2 mailing list at http://groups.google.com/group/ggplot2, or track
development at  http://github.com/hadley/ggplot2

ggplot2 0.8.7 (2010-03-03) ----------------------------------------

* coord_map gains xlim and ylim arguments to control region of projection
* corrected label generation for computed aesthetics (..x..) and special
  names (`x x`)
* fullseq: now always returns vector of length two, even when range is 0
* geom_point legend takes more care to ensure that fill colours will be shown
* legend: fixed scale merging bug when labels were set manually
* scale_area: gains a legend argument like all other scales
* scale_colour_brewer: gains na.colour argument to set colour of missing
  values
* stat_bin2d: fix typo in breaks calculation
* stat_bin: deals with floating point rounding issues using the same
  algorithm as base::hist
* stat_density2d: fixed bug when contour = FALSE (Thanks to Takahashi Kohske)


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From bwhitcher at gmail.com  Fri Mar 12 13:01:08 2010
From: bwhitcher at gmail.com (Brandon Whitcher)
Date: Fri, 12 Mar 2010 12:01:08 +0000
Subject: [R-pkgs] oro.dicom released (replaces DICOM)
Message-ID: <6a7001e11003120401m33780dd3g51713f306d507bc8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100312/126aa10d/attachment.pl>

From bwhitcher at gmail.com  Fri Mar 12 13:12:26 2010
From: bwhitcher at gmail.com (Brandon Whitcher)
Date: Fri, 12 Mar 2010 12:12:26 +0000
Subject: [R-pkgs] oro.nifti released (new package)
Message-ID: <6a7001e11003120412i460db188y533a0c4af9ea4682@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100312/dc60c0a6/attachment.pl>

From ian.fellows at stat.ucla.edu  Mon Mar 15 07:55:20 2010
From: ian.fellows at stat.ucla.edu (ian fellows)
Date: Sun, 14 Mar 2010 23:55:20 -0700
Subject: [R-pkgs] Deducer 0.2-3 and DeducerPlugInExample released
Message-ID: <24019E41-3EE3-4951-994A-FDE29489EDED@stat.ucla.edu>

I would like to announce the release of Deducer 0.2-3 and the new  
package DeducerPlugInExample.

-----------------------------------

Deducer is designed to be a free easy to use alternative to  
proprietary data analysis software such as SPSS, JMP, and Minitab. It  
has a menu system to do common data manipulation and analysis tasks,  
and an excel-like spreadsheet in which to view and edit data frames.

This new version of Deducer includes an easy to use API for creating  
new GUI dialogs for statistical analysis. These dialogs can be  
created using either Java, or purely in R. Documentation, which is  
currently under construction, is available at: http://www.deducer.org/ 
pmwiki/pmwiki.php?n=Main.Development

-----------------------------------

DeducerPlugInExample is a simple plug-in package illustrating dialog  
creation both from within R and from Java. It aims to be a good  
starting place for future plug-in projects.

-----------------------------------

I am very interested in community feedback regarding the API and  
Deducer in general. If you have a suggestion or question please feel  
free to join the discussion group at http://groups.google.com/group/ 
deducer

All the best,
Ian Fellows


From rhbc at imm.dtu.dk  Tue Mar 16 11:45:14 2010
From: rhbc at imm.dtu.dk (Rune Haubo)
Date: Tue, 16 Mar 2010 11:45:14 +0100
Subject: [R-pkgs] New package: ordinal
Message-ID: <4949c7e61003160345q19bc9ec7y732200fa09dac208@mail.gmail.com>

This is to announce the new R-package ?ordinal? that implements
cumulative link (mixed) models for ordinal (ordered categorical) data
(http://www.cran.r-project.org/package=ordinal/).

The main features are:
-	scale (multiplicative) as well as location (additive) effects
-	nominal effects for a subset of the predictors (denoted partial
proportional odds when the link is the logistic)
-	structured thresholds, e.g. assuming symmetry or equidistant thresholds
-	random effects via the Laplace approximation and adaptive
Gauss-Hermite quadrature in the location-part of the model.
-	a range of standard link functions
-	flexible link functions where an extra link function-parameter
bridges the log-log, probit and c-loglog links (log-gamma), and
cloglog and logistic links (Aranda-Ordaz)
-	a suite of optimizers including an efficient Newton scheme.
-	works for binomial observations (a special case of ordinal data).
-	a suite of methods including anova, addterm, dropterm, profile,
confint, plot.profile, predict, in addition to the standard print and
summary methods.
-	an important special case is the proportional odds model (with
random effects).
-	a range of examples illustrates how to use the functions.

Future additions will include:
-	more general random effect structures: multiple (crossed and nested)
and vector-valued random effects.
-	profile methods for variance parameters in mixed effect models.
-	helpful package vignettes.
-	implementation of core functions in C.

Comments, critique, suggestions, wishes and contributions are always
highly appreciated.

Kind regards
Rune

-- 
Rune Haubo Bojesen Christensen

PhD student, M.Sc. Eng.
Phone: (+45) 45 25 33 63
Mail: rhbc at imm.dtu.dk

DTU Informatics, Section for Statistics
Technical University of Denmark, Build. 305, Room 122,
DK-2800 Kgs. Lyngby, Denmark


From G.P.Nason at bristol.ac.uk  Wed Mar 17 15:29:00 2010
From: G.P.Nason at bristol.ac.uk (Guy Nason)
Date: Wed, 17 Mar 2010 14:29:00 +0000
Subject: [R-pkgs] wavethresh
Message-ID: <103B1DA6-2962-4BA2-87BC-917E4EB48808@bristol.ac.uk>

Dear all,

A new version of wavethresh has just been submitted to CRAN.

This is version 4.5

All best wishes,
Guy Nason


From g.p.nason at bristol.ac.uk  Wed Mar 17 15:31:45 2010
From: g.p.nason at bristol.ac.uk (Guy Nason)
Date: Wed, 17 Mar 2010 14:31:45 +0000
Subject: [R-pkgs] haarfisz
Message-ID: <84A68B94-206F-4975-926F-678E90F111A4@bristol.ac.uk>

Dear all,

The package haarfisz, for computing Haar-Fisz variance stabilization transforms for Poisson-like data has just been submitted to CRAN.

This was previously bundled with wavethresh, but has now been unbundled.

Best wishes,
Guy Nason


From g.p.nason at bristol.ac.uk  Wed Mar 17 15:32:33 2010
From: g.p.nason at bristol.ac.uk (Guy Nason)
Date: Wed, 17 Mar 2010 14:32:33 +0000
Subject: [R-pkgs] waveband
Message-ID: <FFB5F3FA-2DBE-4CF5-A60C-79D68C4D82EF@bristol.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100317/9422abb5/attachment.pl>

From g.p.nason at bristol.ac.uk  Wed Mar 17 15:33:04 2010
From: g.p.nason at bristol.ac.uk (Guy Nason)
Date: Wed, 17 Mar 2010 14:33:04 +0000
Subject: [R-pkgs] cthresh
Message-ID: <5B8606F9-E973-422B-AE7F-0D81CBAD028D@bristol.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100317/9cf9bfba/attachment.pl>

From g.p.nason at bristol.ac.uk  Wed Mar 17 15:34:59 2010
From: g.p.nason at bristol.ac.uk (Guy Nason)
Date: Wed, 17 Mar 2010 14:34:59 +0000
Subject: [R-pkgs] NORMT3
Message-ID: <1A0D7197-DFF7-4765-AE26-89AF66542457@bristol.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100317/2f0280c0/attachment.pl>

From Stefan.Wilhelm at financial.com  Tue Mar 16 15:12:02 2010
From: Stefan.Wilhelm at financial.com (Stefan Wilhelm)
Date: Tue, 16 Mar 2010 15:12:02 +0100
Subject: [R-pkgs] tmvtnorm: version 1.0-2
Message-ID: <51DB78F6E5F0E84DB1F28E85AC471F3F171A728868@OB1NWS302.financial.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100316/5eda189e/attachment.pl>

From kogalurshear at gmail.com  Wed Mar 17 18:47:02 2010
From: kogalurshear at gmail.com (Udaya B. Kogalur)
Date: Wed, 17 Mar 2010 13:47:02 -0400
Subject: [R-pkgs] spikeslab 1.0.0 now available on CRAN
Message-ID: <38c08c271003171047u5fe7cd3amd570f94636191574@mail.gmail.com>

Please find release 1.0.0 of the new CRAN package "spikeslab" now
available for download.  Thank you.

---------------------------------------------------------------------------------

RELEASE 1.0.0 is the first and initial release of this package.

Fits a rescaled spike and slab model using a continuous bimodal
prior. Can be used for prediction and variable selection in low and
high-dimensional linear regression models.

Key features include:

o Option for ultra-fast handling of high-dimensional data.

o Variable selection using the generalized elastic net (gnet).

o Grouping of variables with unique regularization (no limit on the number).

o Predict wrapper for predicting on test data.

o Sparse PC approach for multiclass analysis of gene expression data.

o Depends on the randomForest and lars R-packages.


---------------------------------------------------------------------------------

kogalurshear at gmail.com

Udaya B. Kogalur, Ph.D.
Adjunct Staff, Dept of Quantitative Health Sciences, Cleveland Clinic Foundation
President, Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012


From d.rizopoulos at erasmusmc.nl  Thu Mar 18 09:01:07 2010
From: d.rizopoulos at erasmusmc.nl (Dimitris Rizopoulos)
Date: Thu, 18 Mar 2010 09:01:07 +0100
Subject: [R-pkgs] package JM -- version 0.6-0
Message-ID: <4BA1DDC3.4090202@erasmusmc.nl>

Dear R-users,

I'd like to announce the release of the new version of package JM (soon 
available from CRAN) for the joint modelling of longitudinal and 
time-to-event data using shared parameter models. These models are 
applicable in mainly two settings. First, when focus is in the 
time-to-event outcome and we wish to account for the effect of a 
time-dependent covariate measured with error. Second, when focus is in 
the longitudinal outcome and we wish to correct for nonrandom dropout.

New features include:

* function survfitJM() has been added that calculates predictions of 
subject-specific survival probabilities given a history of longitudinal 
responses.

   * function dynC() has been added that calculates a dynamic 
concordance index for joint models. The function also returns 
time-dependent areas under the ROC curve.

   * method = "ch-GH" has been replaced by method = "spline-PH-GH" that 
fits a relative risk model with a B-spline-approximated baseline risk 
function. Similarly to method = "ch-GH", the plan is that the same 
relative risk model with a B-spline-approximated baseline risk will also 
replace method = "ch-Laplace".

   * method = "spline-PH-GH" allows for stratification, i.e., different 
spline coefficients are estimated for the different levels of a 
stratification factor. By default the knots positions are the same 
across strata -- this can be changed by either directly specifying the 
knots or by setting the control argument 'equal.strata.knots' to FALSE.

   * the new function wald.strata() can be used to test for equality of 
the spline coefficients among strata.

   * jointModel() has now the extra argument 'lag' that allows for 
lagged effects in the time-dependent covariate represented by the linear 
mixed model.

   * method = "ph-GH" that fits a relative risk with an unspecified 
baseline risk function has been renamed to method = "Cox-PH-GH".

   * a bug was corrected in joint models with piecewise constant 
baseline risk function. In particular, the 'xi' parameters were reported 
as double their actual value.


As always, any kind of feedback (e.g., questions, suggestions, 
bug-reports, etc.) is more than welcome.

Best,
Dimitris

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014


From marc_schwartz at me.com  Mon Mar 22 14:33:32 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 22 Mar 2010 08:33:32 -0500
Subject: [R-pkgs] WriteXLS - New Version 1.9.0
Message-ID: <B633EF1D-C0D3-4D4C-A823-46ADB3C8FBF2@me.com>

The updated package has been submitted to CRAN and has begun to propagate to CRAN mirrors.

Package: WriteXLS

Version: 1.9.0

Description: Cross-platform perl based R function to create Excel (XLS) files from one or more data frames. Each data frame will be written to a separate named worksheet in the Excel spreadsheet. The worksheet name will be the name of the data frame it contains or can be specified by the user.

Author(s): Marc Schwartz <marc_schwartz at me.com>
Maintainer: Marc Schwartz <marc_schwartz at me.com>

License: GPL (>=2)

URL:	http://r-forge.r-project.org/projects/writexls/


Key changes since version 1.8.1:

New arguments: 

1. 'AdjWidth' for approximate auto column width adjustments to the longest (widest) entry in each column. This is approximate because the built-in AutoFit functions are not accessible from Perl. The approximation used will typically result in a column width that is somewhat too wide rather than too narrow and is based upon using the default font of Arial 10. Default is FALSE.

2. 'AutoFilter' for setting up autofiltering for each column. Default is FALSE.

3. 'BoldHeaderRow' to add bold font to header row entries. Default is FALSE.

4. 'FreezeRow' and 'FreezeCol' to set up frozen panes in each worksheet. Default values are 0 and 0, where there are no frozen panes created.


The above new options will apply to ALL worksheets created in the XLS file.


Please note that after researching the potential for being able to append new worksheets to an existing XLS file, this does not appear to be a robust option via Perl. The combination of the required Perl packages Spreadsheet::ParseExcel and Spreadsheet::WriteExcel does not support the preservation of many pre-existing worksheet objects as noted in:

http://search.cpan.org/~jmcnamara/Spreadsheet-WriteExcel-2.37/lib/Spreadsheet/WriteExcel.pm#MODIFYING_AND_REWRITING_EXCEL_FILES

These include embedded graphics, cell formulae, macros, etc. which would be lost during the worksheet appending process. Via Perl, it appears that one cannot simply open an XLS file, add a new worksheet and then close the file. One has to open the existing file, read each existing worksheet, write the existing worksheets to a new file, append the new worksheets to the new file and then close both files. Thus, given this limitation using Perl and the potential for compromising the content of existing XLS files, there are no plans at present to add the ability to append new worksheets to an existing file to this package.


Thanks and regards,

Marc Schwartz


From tony.d.albano at gmail.com  Fri Mar 26 17:42:29 2010
From: tony.d.albano at gmail.com (Tony Albano)
Date: Fri, 26 Mar 2010 11:42:29 -0500
Subject: [R-pkgs]  New package: equate
Message-ID: <4BACE3F5.2040409@gmail.com>

The 'equate' package, designed for statistical equating (non-IRT) of 
test score distributions, is available on CRAN:
http://cran.r-project.org/package=equate

The package was developed for both research and teaching purposes, and 
will hopefully be useful for both. A vignette introduces the basic 
concepts and terminology of traditional equating, and demonstrates the 
functionality of the package.

Mean, linear, equipercentile, and circle-arc equating are supported and 
specific methods include Tucker, Levine observed score, Levine true 
score, Braun/Holland, frequency estimation, and chained equating (linear 
and nonlinear). Univariate and bivariate presmoothing are also 
supported, as is estimation of standard error via bootstrapping.

Additional info can be found at the rwiki:
http://rwiki.sciviews.org/doku.php?id=packages:cran:equate

Suggestions are much appreciated!
Thanks
Tony
____________________________________________
Tony Albano       

University of Minnesota
193 Education Sciences Building
56 East River Road
Minneapolis, MN 55455


From arne.henningsen at googlemail.com  Sat Mar 27 10:33:24 2010
From: arne.henningsen at googlemail.com (Arne Henningsen)
Date: Sat, 27 Mar 2010 10:33:24 +0100
Subject: [R-pkgs] micEcon split into micEconSNQP, micEconCES, and micEcon
Message-ID: <ee2a35a61003270233q2fb54a7dx3e0564e4560f19fd@mail.gmail.com>

In December, the packages "miscTools" and "micEconAids" were separated
from the "micEcon" package. Now, two further packages have been
separated from the micEcon package: "micEconSNQP" and "micEconCES".

The "micEconSNQP" package (version 0.6-2) provides tools for
production analysis with the Symmetric Normalized Quadratic (SNQ)
profit function (also known as the "Generalized McFadden" profit
function), e.g. snqProfitEst() for estimating the SNQ profit function,
snqProfitCalc() for calculating the endogenous variable of the SNQ
profit function, or snqProfitEla() for calculating price elasticities
of the SNQ profit function.

The "micEconCES" package (version 0.6-6) provides tools for estimating
the Constant Elasticity of Scale (CES) function. Function cesEst() has
been tremendously improved. It can estimate the CES function using
much more estimation methods (optimizers) now, e.g. the
Levenberg-Marquardt or the Differential Evolution algorithm.
Furthermore a "vignette" (supplementary documentation) "Estimating the
CES Function in R: Package micEconCES" (written by Geraldine
Henningsen and Arne Henningsen) [1] has been added.

The "micEcon" package (version 0.6-2) includes the remaining parts of
the "old" micEcon package, e.g. for economic analysis with
Cobb-Douglas functions, translog functions, quadratic functions, or
linearly homogeneous non-parametric functions.

All these packages are available on CRAN [2,3,4] and R-Forge [5].

[1] http://cran.r-project.org/web/packages/micEconCES/vignettes/CES.pdf
[2] http://cran.r-project.org/package=micEcon
[3] http://cran.r-project.org/package=micEconSNQP
[4] http://cran.r-project.org/package=micEconCES
[5] http://r-forge.r-project.org/projects/micecon/

Feedback is highly welcome!

/Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name


From hastie at stanford.edu  Sun Apr  4 23:46:09 2010
From: hastie at stanford.edu (Trevor Hastie)
Date: Sun, 4 Apr 2010 23:46:09 +0200
Subject: [R-pkgs] Major glmnet upgrade on CRAN
Message-ID: <3E69C62D-15F0-4DA1-87AB-5ABF3ABED679@stanford.edu>

glmnet_1.2 has been uploaded to CRAN. 

This is a major upgrade, with the following additional features:

* poisson family, with dense or sparse x
* Cox proportional hazards family, for dense x
* wide range of cross-validation features. All models have several criteria for cross-validation.  
  These include deviance, mean absolute error, misclassification error and "auc" for logistic or multinomial models. 
  Observation weights are incorporated.
* offset is allowed in fitting the model 

Here is the description of the package.

glmnet is a package that fits the regularization path for linear, two- and multi-class logistic regression
models, poisson regression and the Cox model, with "elastic net" regularization (tunable mixture of L1 and L2 penalties).
glmnet uses pathwise coordinate descent, and is very fast.

Some of the features of glmnet:

* by default it computes the path at 100 uniformly spaced (on the log scale) values of the regularization parameter
* glmnet appears to be faster than any of the packages that are freely available, in some cases by two orders of magnitude.
* recognizes and exploits sparse input matrices (ala Matrix package). Coefficient matrices are output in sparse matrix representation.
* penalty is (1-a)*||\beta||_2^2 +a*||beta||_1  where a is between 0 and 1;  a=0 is the Lasso penalty, a=1 is the ridge penalty.
  For many correlated predictors, a=.95 or thereabouts improves the performance of the lasso.
* convenient predict, plot, print, and coef methods
* variable-wise penalty modulation allows each variable to be penalized by a scalable amount; if zero that variable always enters
* glmnet uses a symmetric parametrization for multinomial, with constraints enforced by the penalization.
* a comprehensive set of cross-validation routines are provided for all models and several error measures
* offsets and weights can be provided for all models

 
Examples of glmnet speed trials:
Newsgroup data: N=11,000, p= 0.75 Million, two class logistic. 100 values along lasso path.   Time = 2mins
14 Class cancer data: N=144, p=16K, 14 class multinomial, 100 values along lasso path. Time = 30secs

Authors: Jerome Friedman, Trevor Hastie, Rob Tibshirani.

See our paper http://www-stat.stanford.edu/~hastie/Papers/glmnet.pdf for implementation details,
and comparisons with other related software.



-------------------------------------------------------------------
  Trevor Hastie                                   hastie at stanford.edu  
  Professor, Department of Statistics, Stanford University
  Phone: (650) 725-2231 (Statistics)          Fax: (650) 725-8977  
  (650) 498-5233 (Biostatistics)   Fax: (650) 725-6951
  URL: http://www-stat.stanford.edu/~hastie  
   address: room 104, Department of Statistics, Sequoia Hall
           390 Serra Mall, Stanford University, CA 94305-4065  


From Achim.Zeileis at R-project.org  Tue Apr  6 16:12:59 2010
From: Achim.Zeileis at R-project.org (Achim Zeileis)
Date: Tue, 6 Apr 2010 16:12:59 +0200 (CEST)
Subject: [R-pkgs] Formula 1.0-0: Model formulas with multiple parts and
	responses
Message-ID: <alpine.DEB.2.00.1004061605190.5535@paninaro.uibk.ac.at>

Dear useRs,

version 1.0-0 of the "Formula" package has just been released on CRAN

   http://CRAN.R-project.org/package=Formula

accompanied by an article in the Journal of Statistical Software

   http://www.jstatsoft.org/v34/i01/

It provides simple infrastructre for processing formulas like

   y ~ x1 + x2 | z1 + z2

where there are two groups of explanatory variables, e.g., pertaining to 
separation equations for mean and variance or to regressors and 
instruments etc. Furthermore formulas with multiple repsonses are 
supported such as

   y1 + y2 ~ x

which has a bivariate reponse with potentially different classes, e.g., 
factors, numeric, Survival etc.

Best wishes,
Z


From Achim.Zeileis at R-project.org  Tue Apr  6 16:22:01 2010
From: Achim.Zeileis at R-project.org (Achim Zeileis)
Date: Tue, 6 Apr 2010 16:22:01 +0200 (CEST)
Subject: [R-pkgs] betareg 2.2-2: Beta regression
Message-ID: <alpine.DEB.2.00.1004061616570.5535@paninaro.uibk.ac.at>

Dear useRs,

version 2.2-2 of the "betareg" package has just been released on CRAN

   http://CRAN.R-project.org/package=betareg

accompanied by an article in the Journal of Statistical Software

   http://www.jstatsoft.org/v34/i02/

The package provides beta regression for data in the unit interval (0, 1) 
such as rates and proportions. The manuscript replicates several practical 
applications from econometrics and psychometrics.

Best wishes,
Z


From bill.venables at gmail.com  Wed Apr  7 10:03:29 2010
From: bill.venables at gmail.com (William Venables)
Date: Wed, 7 Apr 2010 18:03:29 +1000
Subject: [R-pkgs] SOAR - Stored object caches for R
Message-ID: <r2hb38c58d21004070103jaf0448adk1cda8e0adbe1f9b0@mail.gmail.com>

I have just submitted SOAR version 0.99-2 to CRAN.? This replaces
version 0.99-1, submitted yesterday, in which a small bug was
discovered rather quickly (only affecting Windows, though).

This package is a small set of utilities for making and managing
'Stored Object Caches' for R.? These allow objects to be stored on the
disc rather than in memory, with automatic recall into R by the
delayedAssign mechanism.? It uses the same basic idea as the package
g.data of David Brahm, though the usage is rather different.

There are two main purposes: large objects can easily be managed so as
not to overload memory, and frequently used functions and datasets can
easily be made accessible to different R sessions.? The effect is
somewhat like that of the use of the .Data directory in S-PLUS, (a
program not unlike R), though somewhat more manually driven.

There is a vignette, "SOAR", which prospective users may care to read
first for a more complete discussion.

This package is the formal successor to an older package, ASOR, which
was never released on CRAN.? Users of the ASOR package may wish to
look first at Appendix C of the vignette, which lists the important
differences.? The transition from ASOR to SOAR, though, should be
almost transparent.

Bill Veanbles.

--
Bill Venables
Senior Research Scientist,
CSIRO, Cleveland Laboratories,
Queensland,
Australia.


From F.TE at gmx.net  Mon Apr 12 09:04:48 2010
From: F.TE at gmx.net (F Te)
Date: Mon, 12 Apr 2010 09:04:48 +0200
Subject: [R-pkgs] New package mvngGrAd
Message-ID: <4BC2C610.7030003@gmx.net>

Dear useRs,

I am glad to announce that that my package mvngGrAd (read: "moving 
grid") is now available on CRAN.

The package implements moving grid adjustment, which is a spatial method 
used in (unreplicated) plant breeding trials to adjust phenotypic values 
for environmental effects. The adjustment is done by using phenotypic 
information from nearest neighbors (NN) as a covariate. Unlike in other  
NN methods,  the NN in the moving grid adjustment are not determined by 
a measure of distance but by inclusion in a grid of certain size and shape.

If you're interested,  please see the included vignette for more details 
on moving grid adjustment and the package.

Best regards

Frank.


From Mark.Bravington at csiro.au  Wed Apr 14 02:42:07 2010
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Wed, 14 Apr 2010 10:42:07 +1000
Subject: [R-pkgs] mvbutils 2.5.1 on CRAN
Message-ID: <62C82B39B8A85E4B95A18F7F7B852F8705658B3325@exvic-mbx03.nexus.csiro.au>

Version 2.5.1 of 'mvbutils' is now on CRAN. This version offers improved support for easy package preparation and maintenance, plus minor changes required by the new version of the 'debug' package (see separate announcement). Package 'mvbutils' offers the following main features, as well as a number of miscellaneous goodies:

 - Hierarchical organization of projects (tasks) and sub-tasks, allowing switching within a single R session, searching and moving objects through the hierarchy, objects in ancestor tasks always visible from child (sub)tasks, etc.

 - Improved function & text-object editing facilities, plain-text documentation stored with function definition, and automatic backup.

 - Automated package construction, including production of Rd-format from plain text documentation. Packages can be edited & updated seamlessly while loaded, without needing to unload/quit/rebuild/reinstall. 
 
 - "Lazy loading" for individual objects, allowing fast and transparent access to collections of biggish objects where only a few objects are used at a time.

package?mvbutils will tell you more...

-- 
Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623


From Mark.Bravington at csiro.au  Wed Apr 14 02:45:18 2010
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Wed, 14 Apr 2010 10:45:18 +1000
Subject: [R-pkgs] debug 1.2.2 on CRAN
Message-ID: <62C82B39B8A85E4B95A18F7F7B852F8705658B3326@exvic-mbx03.nexus.csiro.au>

Version 1.2.2 of 'debug' is now on CRAN. The debugging facilities offered include code display, graceful error recovery, line-numbered conditional breakpoints, access to exit code, flow control, and full keyboard input. The new version supports debugging of code inside 'try', 'eval', 'evalq', and 'with' statements. See package?debug for more info.

-- 
Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623


From xie at yihui.name  Tue Apr 13 18:16:29 2010
From: xie at yihui.name (Yihui Xie)
Date: Tue, 13 Apr 2010 11:16:29 -0500
Subject: [R-pkgs] formatR: farewell to ugly R code
In-Reply-To: <q2jee281c151004130810gba7f787buad901abfcb9fff8a@mail.gmail.com>
References: <q2jee281c151004130810gba7f787buad901abfcb9fff8a@mail.gmail.com>
Message-ID: <j2v89b6b8c91004130916h4232a956o1ceb5f20aff212ff@mail.gmail.com>

This is an announcement of the release of an R package 'formatR',
which can help us format our R code to make it more human-readable. If
you have ugly (I mean unformatted) R code like this:

?# rotation of the word "Animation"
# in a loop; change the angle and color
# step by step
for (i in 1:360) {
?    # redraw the plot again and again
plot(1,ann=FALSE,type="n",axes=FALSE)
# rotate; use rainbow() colors
text(1,1,"Animation",srt=i,col=rainbow(360)[i],cex=7*i/360)
# pause for a while
Sys.sleep(0.01)}

There are no spaces, no appropriate indent... The package 'formatR'
provides a GUI (by gWidgets) to make messy R code clean and tidy, e.g.

# rotation of the word 'Animation'
# in a loop; change the angle and color
# step by step
for (i in 1:360) {
? ?# redraw the plot again and again
? ?plot(1, ann = FALSE, type = "n", axes = FALSE)
? ?# rotate; use rainbow() colors
? ?text(1, 1, "Animation", srt = i, col = rainbow(360)[i],
? ? ? ?cex = 7 * i/360)
? ?# pause for a while
? ?Sys.sleep(0.01)
}

The usage is simple:

# formatR depends on RGtk+; will be installed automatically
# better use the latest version of R (>=2.10.1)
install.packages('formatR')
library(formatR)
# or formatR()

Screen-shots can be found here:
http://yihui.name/en/2010/04/formatr-farewell-to-ugly-r-code/

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-6609 Web: http://yihui.name
Department of Statistics, Iowa State University
3211 Snedecor Hall, Ames, IA


From afs at fct.unl.pt  Tue Apr 20 13:12:17 2010
From: afs at fct.unl.pt (Adelino)
Date: Tue, 20 Apr 2010 12:12:17 +0100
Subject: [R-pkgs] cudaBayesreg update
Message-ID: <4BCD8C11.1090306@fct.unl.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100420/3f2ac9b7/attachment.pl>

From hastie at stanford.edu  Wed Apr 28 17:49:33 2010
From: hastie at stanford.edu (Trevor Hastie)
Date: Wed, 28 Apr 2010 17:49:33 +0200
Subject: [R-pkgs] New package for ICA uploaded to CRA
Message-ID: <804E417F-74CA-46BE-A365-CDD610EB7005@stanford.edu>

I have uploaded a new package to CRAN called ProDenICA.

This fits ICA models directly via product-density estimation
of the source densities. This package was promised on page 567 in the 
2nd edition of our book 'Elements of Statistical Learning' 
(Hastie, Tibshirani and Friedman, 2009, Springer) . Apologies that it is so late.

The method fits each source density by a tilted gaussian density, where
the log of the tilting function is modeled by a smoothing spline. This 
function is then used as a contrast function for computing the negentropy
measure for this source component. The estimation is achieved by fitting a poisson
GAM model for each component, with the log-gaussian as an offset.

The method was first described in
Hastie, T. and Tibshirani, R. (2003). Independent component analysis
through product density estimation, in S. T. S. Becker and K. Obermayer
(eds), Advances in Neural Information Processing Systems 15,
MIT Press, Cambridge, MA, pp. 649-656.



-------------------------------------------------------------------
  Trevor Hastie                                   hastie at stanford.edu  
  Professor, Department of Statistics, Stanford University
  Phone: (650) 725-2231 (Statistics)          Fax: (650) 725-8977  
  (650) 498-5233 (Biostatistics)   Fax: (650) 725-6951
  URL: http://www-stat.stanford.edu/~hastie  
   address: room 104, Department of Statistics, Sequoia Hall
           390 Serra Mall, Stanford University, CA 94305-4065  


From charles.dupont at Vanderbilt.Edu  Wed May  5 19:09:31 2010
From: charles.dupont at Vanderbilt.Edu (Charles Dupont)
Date: Wed, 5 May 2010 12:09:31 -0500
Subject: [R-pkgs] Hmisc version 3.8-0 now available on CRAN
Message-ID: <4BE1A64B.5040306@vanderbilt.edu>

Hmisc version 3.8-0 has been released and is now available on CRAN.

Primary improvement is compatibility with R 2.11.0.

Linux packages, Windows 32bit and 64bit binary packages, and Mac binary packages 
are built and are currently available on the http://cran.r-project.org/ repository.

Charles Dupont


From mdowle at mdowle.plus.com  Thu May  6 20:15:36 2010
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 06 May 2010 19:15:36 +0100
Subject: [R-pkgs] data.table 1.4.1 now on CRAN
Message-ID: <1273169736.27760.7.camel@Adam>

data.table is an enhanced data.frame with fast subset, fast
grouping and fast merge. It uses a short and flexible syntax
which extends existing R concepts.

Example:
    DT[a>3,sum(b*c),by=d]
where DT is a data.table with 4 columns (a,b,c,d).

data.table 1.4.1 :

* grouping is now 10+ times faster than tapply()
* extract is 100+ times faster than ==, as before
* 3 new vignettes: Intro, FAQ & Timings
* NEWS file contains further details

http://datatable.r-forge.r-project.org/

http://cran.r-project.org/web/packages/data.table/index.html

There is a new mailing list, datatable-help. Please do send comments,
feedback, problems and questions.

Matthew and Tom


From sb.pmlab at gmail.com  Thu May  6 14:36:49 2010
From: sb.pmlab at gmail.com (Sebastien Bihorel)
Date: Thu, 6 May 2010 08:36:49 -0400
Subject: [R-pkgs] Release of optimbase, optimsimplex and neldermead packages
Message-ID: <q2necd262691005060536t9fe54a59p594d928c5c4cfe84@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100506/4af42188/attachment.pl>

From sb.pmlab at gmail.com  Thu May  6 14:37:49 2010
From: sb.pmlab at gmail.com (Sebastien Bihorel)
Date: Thu, 6 May 2010 08:37:49 -0400
Subject: [R-pkgs] Release of the scaRabee package
Message-ID: <z2pecd262691005060537t2c878ec5ya12340faa0e73c24@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100506/d3c1610d/attachment.pl>

From seth at userprimary.net  Fri May  7 19:42:15 2010
From: seth at userprimary.net (Seth Falcon)
Date: Fri, 07 May 2010 10:42:15 -0700
Subject: [R-pkgs] Release announcement: RSQLite 0.9-0 now with more BLOBs
Message-ID: <4BE450F7.2090705@userprimary.net>

RSQLite is an R package conforming to the R DBI interface that allows 
for interaction with SQLite.

Version 0.9-0 highlights:

* Support for SQLite BLOBs using raw vectors in R

* New memory model for db connections allows for more familiar R 
semantics and no predefined limit to the number of connections you can 
have in an R session.

* Upgrade to SQLite 3.6.23.1

* Removed an unnecessary validity check on process ID for the manager 
handle.  This should make use of RSQLite with the multicore package easier.

* RSQLite now depends on R >= 2.10.0

You can read more details about these and other changes here:

    http://cran.r-project.org/web/packages/RSQLite/NEWS


+ seth


-- 
Seth Falcon | @sfalcon | http://userprimary.net/


From cbrown at opendatagroup.com  Fri May  7 18:19:15 2010
From: cbrown at opendatagroup.com (Christopher Brown)
Date: Fri, 7 May 2010 09:19:15 -0700
Subject: [R-pkgs] hash-2.0.0
Message-ID: <o2h5832a2d11005070919w7469aa85tda377d3a280b76de@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100507/140f151d/attachment.pl>

From jayemerson at gmail.com  Sun May  9 21:06:57 2010
From: jayemerson at gmail.com (Jay Emerson)
Date: Sun, 9 May 2010 15:06:57 -0400
Subject: [R-pkgs] "Bayesian change point" package bcp 2.2.0 available
Message-ID: <u2ud4588dec1005091206z3c660b21gc4d395d488981a81@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100509/4a72a578/attachment.pl>

From edd at debian.org  Mon May 17 17:19:03 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 17 May 2010 10:19:03 -0500
Subject: [R-pkgs] Rcpp 0.8.0 on CRAN
Message-ID: <19441.24167.442231.404310@ron.nulle.part>


===== Summary =====

Version 0.8.0 of the Rcpp package was released to CRAN today. This release
marks another milestone in the ongoing redesign of the package, and
underlying C++ library.


===== Overview =====

Rcpp is an R package and C++ library that facilitates integration of C++
code in R packages. 

The package features a set of C++ classes (Rcpp::IntegerVector,
Rcpp::Function, Rcpp::Environment, ...) that makes it easier to manipulate R
objects of matching types (integer vectors, functions, environments, etc
...).

Rcpp takes advantage of C++ language features such as the explicit
constructor/destructor lifecycle of objects to manage garbage collection
automatically and transparently. We believe this is a major improvement over
PROTECT/UNPROTECT. When an Rcpp object is created, it protects the underlying
SEXP so that the garbage collector does not attempt to reclaim the
memory. This protection is withdrawn when the object goes out of
scope. Moreover, users generally do not need to manage memory directly (via
calls to new / delete or malloc / free) as this is done by the Rcpp classes
or the corresponding STL containers.


===== API =====

Rcpp provides two APIs: an older set of classes we refer to the classic API
(see below for the section 'Backwards Compatibility) as well as second and
newer set of classes. 

Classes of the new Rcpp API belong to the Rcpp namespace. Each class is
associated to a given SEXP type and exposes an interface that allows
manipulation of the object that may feel more natural than the usual use of
macros and functions provided by the R API.

----------------------------------------------------------
SEXP type         |    Rcpp class                 
----------------------------------------------------------
INTSXP            |    Rcpp::IntegerVector        
REALSXP           |    Rcpp::NumericVector
RAWSXP            |    Rcpp::RawVector
LGLSXP            |    Rcpp::LogicalVector
CPLXSXP           |    Rcpp::ComplexVector 
STRSXP            |    Rcpp::CharacterVector
VECSXP            |    Rcpp::List
EXPRSXP           |    Rcpp::ExpressionVector
----------------------------------------------------------
ENVSXP            |    Rcpp::Environment
SYMSXP            |    Rcpp::Symbol
----------------------------------------------------------
CLOSXP            |
BUILTINSXP        |    Rcpp::Function
SPECIALSXP        |
----------------------------------------------------------
LANGSXP           |    Rcpp::Language
LISTSXP           |    Rcpp::Pairlist
----------------------------------------------------------
S4SXP             |    Rcpp::S4
----------------------------------------------------------
PROMSXP           |    Rcpp::Promise
WEAKREFSXP        |    Rcpp::WeakReference
EXTPTRSXP         |    template <typename T> Rcpp::XPtr
----------------------------------------------------------

Some SEXP types do not have dedicated Rcpp classes : NILSXP, DOTSXP, 
ANYSXP, BCODESXP and CHARSXP. 

Still missing are a few convenience classes such as Rcpp::Date or
Rcpp::Datetime which would map useful and frequently used R data types, but
which do not have an underlying SEXP type.


===== Data Interchange =====

Data interchange between R and C++ is managed by extensible and powerful yet
simple mechanisms.

Conversion of a C++ object is managed by the template function Rcpp::wrap. 
This function currently manages :
 - primitive types : int, double, bool, float, Rbyte, ...
 - std::string, const char*
 - STL containers such as std::vector<T> and STL maps such as 
   std::map< std::string, T> provided that the template type T is wrappable 
-  any class that can be implicitely converted to SEXP, through operator SEXP()

Conversion of an R object to a C++ object is managed by the Rcpp::as<T>
template which can handle:
 - primitive types
 - std::string, const char* 
 - STL containers such as std::vector<T>

Rcpp::wrap and Rcpp::as are often used implicitely. For example, when
assigning objects to an environment:

  // grab the global environment
  Rcpp::Environment global = Rcpp::Environment::global_env() ;
  std::deque<bool> z( 3 ); z[0] = false; z[1] = true; z[3] = false ;

  global["x"] = 2 ;                    // implicit call of wrap<int>
  global["y"] = "foo";                 // implicit call of wrap<char*>
  global["z"] = z ;                    // impl. call of wrap<std::deque<bool>>

  int x = global["x"] ;                // implicit call of as<int>
  std::string y = global["y"]          // implicit call of as<std::string>
  std::vector<bool> z1 = global["z"] ; // impl. call of as<std::vector<bool>>

Rcpp contains several examples that illustrate wrap and as. The mechanism was 
designed to be extensible. We have developped separate packages to illustrate
how to extend Rcpp conversion mechanisms to third party types. 
 - RcppArmadillo : conversion of types from the Armadillo C++ library. 
 - RcppGSL       : conversion of types from the GNU Scientific Library. 

Rcpp is also used for data interchange by the RInside package which provides
and easy way of embedding an R instance inside of C++ programs.


===== inline use =====

Rcpp depends on the inline package by Oleg Sklyar et al. Rcpp then uses the
'cfunction' provided by inline (with argument Rcpp=TRUE) to compile, link and
load C++ function from the R session.

As of version 0.8.0 of Rcpp, we also define an R function cppfunction that
acts as a facade function to the inline::cfuntion, with specialization for
C++ use.

This allows quick prototyping of compiled code. All our unit tests are based 
on cppfunction and can serve as examples of how to use the mechanism. For example
this function (from the runit.GenericVector.R unit test file) defines from
R a C++ (simplified) version of lapply: 

  ## create a compiled function cpp_lapply using cppfunction 
  cpp_lapply <- cppfunction(signature(x = "list", g = "function" ), 
  		'Function fun(g) ;
		 List input(x) ;
		 List output( input.size() ) ;
		 std::transform( input.begin(), input.end(), output.begin(), fun ) ;
		 output.names() = input.names() ;
		 return output ;
	    ')
  ## call cpp_lapply on the iris data with the R function summary
  cpp_lapply( iris, summary )	


===== Using Rcpp in other packages =====

Rcpp is designed so that its classes are used from other packages. Using Rcpp
requires : 
 - using the header files provided by Rcpp. This is typically done by adding this
   line in the package DESRIPTION file: 
  
	LinkingTo: Rcpp

  and add the following line in the package code: 
  
	#include <Rcpp.h>

- linking against the Rcpp dynamic or static library, which is achieved by 
  adding this line to the src/Makevars of the package:
  
	PKG_LIBS = $(shell $(R_HOME)/bin/Rscript -e "Rcpp:::LdFlags()" )

  and this line to the src/Makevars.win file: 
  
	PKG_LIBS = $(shell Rscript.exe -e "Rcpp:::LdFlags()")

Rcpp contains a function Rcpp.package.skeleton, modelled after
package.skeleton from the utils package in base r, that creates a skeleton of
a package using Rcpp, including example code.


===== C++ exceptions =====

C++ exceptions are R contexts are both based on non local jumps (at least 
on the implementation of exceptions in gcc), so care must be ensure
that one system does not void assumptions of the other. It is therefore 
very strongly recommended that each function using C++ catches 
C++ exceptions. Rcpp offers the function forward_exception_to_r
to facilitate forwarding the exception to the "R side" as an R condition. 
For example : 

  SEXP foo( ) {
    try {
      // user code here
    } catch( std::exception& __ex__){
      forward_exception_to_r( __ex__ ) ;
    }
    // return something here
  }

Alternatively, functions can enclose the user code with the macros BEGIN_RCPP
and END_RCPP, which provides for a more compact way of programming.  The
function above could be written as follows using the macros:

  SEXP foo( ) {
    BEGIN_RCPP
    // user code here
    END_RCPP
    // return something here
  }

The use of BEGIN_RCPP and END_RCPP is recommended to anticipate future changes
of Rcpp. We might for example decide to install dedicated handlers for specific 
exceptions later.


===== Experimental code generation macros =====

Rcpp contains several macros that can generate repetitive 'boiler plate' code:
  RCPP_FUNCTION_0, ..., RCPP_FUNCTION_65
  RCPP_FUNCTION_VOID_0, ..., RCPP_FUNCTION_VOID_65
  RCPP_XP_METHOD_0, ..., RCPP_XP_METHOD_65
  RCPP_XP_METHOD_CAST_0, ..., RCPP_XP_METHOD_CAST_65
  RCPP_XP_METHOD_VOID_0, ..., RCPP_XP_METHOD_VOID_65

For example: 

  RCPP_FUNCTION_2( int, foobar, int x, int y){
     return x + y ;
  }

This will create a .Call compatible function "foobar" that calls a 
c++ function for which we provide the argument list (int x, int y)
and the return type (int). The macro also encloses the call 
in BEGIN_RCPP/END_RCPP so that exceptions are properly forwarded to R.

Examples of the other macros are given in the NEWS file.

This feature is still experimental, but is being used in packages
highlight and RProtoBuf


===== Quality Assurance =====

Rcpp uses the RUnit package by Matthias Burger et al and the aforementioned
inline package by Oleg Sklyar et al to provide unit testing. Rcpp currently
has over 500 unit tests (called from more than 230 unit test functions) with
very good coverage of the critical parts of the package and library.

Source code for unit test functions are stored in the unitTests directory 
of the installed package and the results are collected in the "Rcpp-unitTests"
vignette. 

The unit tests can be both during the standard R package build and testing
process, and also when the package is installed.  The latter use is helpful
to ensure that no system components have changed in a way that affect the
Rcpp package since it has been installed.  To run the tests, execute

   Rcpp:::test()

where an output directory can be provided as an optional first argument.


===== Backwards Compatibility =====

We believe the new API is now more complete and useful than the previous set
of classes, which we refer to as the "classic Rcpp API". We would therefore
recommend to package authors using 'classic' Rcpp to move to the new API.
However, the classic API is still maintained and will continue to be
maintained to ensure backwards compatibility for code that uses it.

Packages uses the 'Classic API' can use features of the new API selectively
and in incremental steps. This provides for a non-disruptive upgrade path.


===== Documentation =====

The package contains a vignette which provides a short and succinct
introduction to the Rcpp package along with several motivating examples.
Also provided is a vignette containing the regression test summary from
the time the package was built.


===== Links =====

Rcpp main page: http://dirk.eddelbuettel.com/code/rcpp.html
R-forge project page: http://r-forge.r-project.org/projects/rcpp/
Dirk's blog section about Rcpp: http://dirk.eddelbuettel.com/blog/code/rcpp/
Romain's blog section about Rcpp: http://romainfrancois.blog.free.fr/index.php?category/R-package/Rcpp


===== Support =====

Questions about Rcpp should be directed to the Rcpp-devel mailing list
https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel



 -- Dirk Eddelbuettel and Romain Francois
    Chicago, IL, USA, and Montpellier, France
	May 2010


From jayemerson at gmail.com  Mon May 10 18:20:41 2010
From: jayemerson at gmail.com (Jay Emerson)
Date: Mon, 10 May 2010 12:20:41 -0400
Subject: [R-pkgs] Bayesian change point" package bcp 2.2.0 available
Message-ID: <AANLkTikFeZPzjCfgxt-BEEbGauoGlR8CzY9L_prkZJNe@mail.gmail.com>

Version 2.2.0 of package bcp is now available.? It replaces the
suggests of NetWorkSpaces (previously used for optional parallel MCMC)
with the dependency on package foreach, giving greater flexibility and
supporting a wider range of parallel backends (see doSNOW, doMC,
etc...).

For those unfamiliar with foreach (thanks to Steve Weston for this
contribution), it's a beautiful and highly portable looping construct
which can run sequentially or in parallel based on the user's actions
(rather than the programmer's choices).? We think other package
authors might want to consider taking advantage of it for tasks that
might be computationally intensive and could be easily done in
parallel.? Some vignettes are available at
http://cran.r-project.org/web/packages/foreach/index.html.

Jay Emerson & Chandra Erdman

(Apologies, the first version of this announcement was not plain-text.)

--
John W. Emerson (Jay)
Associate Professor of Statistics
Department of Statistics
Yale University
http://www.stat.yale.edu/~jay


From jayemerson at gmail.com  Mon May 10 18:27:24 2010
From: jayemerson at gmail.com (Jay Emerson)
Date: Mon, 10 May 2010 12:27:24 -0400
Subject: [R-pkgs] bigmemory 4.2.3
Message-ID: <AANLkTikV70OIc_-CWa2hz5xV-zqOLNb7AZ0-wJgyh3Ev@mail.gmail.com>

The long-promised revision to bigmemory has arrived, with package
4.2.3 now on CRAN.  The mutexes (locks) have been extracted and will
be available through package synchronicity (on R-Forge, soon to appear
on CRAN).  Initial versions of packages biganalytics and bigtabulate
are on CRAN, and new versions which resolve the warnings and have
streamlined CRAN-friendly configurations will appear shortly.  Package
bigalgebra will remain on R-Forge for the time being as the
user-interface is developed and the configuration possibilities
expand.

For more information, please feel free to email us or visit
http://www.bigmemory.org/.

Jay Emerson & Mike Kane

-- 
John W. Emerson (Jay)
Associate Professor of Statistics
Department of Statistics
Yale University
http://www.stat.yale.edu/~jay


From youngsanger at gmail.com  Wed May 12 17:23:24 2010
From: youngsanger at gmail.com (Matt Young)
Date: Wed, 12 May 2010 08:23:24 -0700
Subject: [R-pkgs] Bidirectional piping in windows
Message-ID: <AANLkTinnKoXGiXkdh-Wu2BXktKidCH3jXsHx71P4b4U_@mail.gmail.com>

Lot of examples for one way pipes, but I need to create some named
pipes from R to another process, especially SQLite.  I am look at the
R/SQLite packages for help.  ANy pointers?


From Max.Kuhn at pfizer.com  Mon May 17 22:17:41 2010
From: Max.Kuhn at pfizer.com (KuhnA03)
Date: Mon, 17 May 2010 16:17:41 -0400
Subject: [R-pkgs] version 4.39 of the caret package
Message-ID: <C8171CA5.9158%Max.Kuhn@pfizer.com>

Version 4.39 of the caret package was sent to CRAN.

caret can be used to tune the parameters of predictive models using
resampling, estimate variable importance and visualize the results.
There are also various modeling and "helper" functions that can be
useful for training models. caret has wrappers to over 75 different
models for classification and regression. See the package vignettes or
the paper at

  http://www.jstatsoft.org/v28/i05

for more details. I'll also be giving a talk at this year's useR!
conference.


Since the last posting to this list:

 - 23 additional models were added to train()

 - weights can be passed in through train()

 - feature selection methods have been added: recursive feature
   elimination (rfe()) and selection by univariate filters (sbf()).
   Both functions can be run in parallel.

 - a set of functions (class "classDist") to computes the class
   centroids and covariance matrix for a training set for
   determining Mahalanobis distances of new samples to each class
   centroid 

 - a faster version of nearZeroVar() due to Allan Engelhardt

 - two new data sets were added

 - several classes for examining the resampling results were added for
   estimating pair-wise differences in models and lattice visualizations

The NEWS file has the blow-by-blow list of changes.


The package homepage is

  https://r-forge.r-project.org/projects/caret/

Send questions, collaborations, comments etc to max.kuhn at pfizer.com.

Max


From racinej at mcmaster.ca  Tue May 18 20:02:07 2010
From: racinej at mcmaster.ca (Jeffrey Racine)
Date: Tue, 18 May 2010 14:02:07 -0400
Subject: [R-pkgs] The npRmpi package (parallel np package for multi-core
	environments)
Message-ID: <7A1DEFE3-D09D-4E48-B095-DF8F307ED5F6@mcmaster.ca>

Dear R users,

A parallel implementation of the np package titled `npRmpi' is now available on CRAN. This package can take advantage of multiple core computing environments to reduce the run time associated with the methods contained in the np package. 

Kindly see the vignette for details and examples on modifying np code and running it in a parallel environment. You are requested to seek local assistance for configuring machines to support MPI aware programs.

Information on the npRmpi package:

This package provides a variety of nonparametric (and semiparametric) kernel methods that seamlessly handle a mix of continuous, unordered, and ordered factor data types. This package incorporates the Rmpi package (Hao Yu <hyu at stats.uwo.ca>) with minor modifications and we are extremely grateful to Hao Yu for his contributions to the R community. We would like to gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada (NSERC:www.nserc.ca), the Social Sciences and Humanities Research Council of Canada (SSHRC:www.sshrc.ca), and the Shared Hierarchical Academic Research Computing Network (SHARCNET:www.sharcnet.ca).

A thorough treatment of the subject matter can be found in Li, Q. and J. S. Racine (2007), Nonparametric Econometrics: Theory and Practice, Princeton University Press, ISBN: 0691121613 (768 Pages) for
those who might be interested (http://press.princeton.edu/titles/8355.html)

-- Jeffrey Racine & Tristen Hayfield.

Professor J. S. Racine         Phone:  (905) 525 9140 x 23825
Department of Economics        FAX:    (905) 521-8232
McMaster University            e-mail: racinej at mcmaster.ca
1280 Main St. W.,Hamilton,     URL: www.economics.mcmaster.ca/racine
Ontario, Canada. L8S 4M4

`The generation of random numbers is too important to be left to chance'


From Yves.Rosseel at UGent.be  Wed May 19 14:26:32 2010
From: Yves.Rosseel at UGent.be (Yves Rosseel)
Date: Wed, 19 May 2010 14:26:32 +0200
Subject: [R-pkgs] New package: `lavaan' for latent variable analysis
 (including structural equation modeling)
Message-ID: <4BF3D8F8.2050802@UGent.be>

Dear R-users,

A new package called `lavaan' (for latent variable analysis) has been 
uploaded to CRAN. The current version of lavaan (0.3-1) can be used for 
path analysis, confirmatory factor analysis, structural equation 
modeling, and growth curve modeling.

More information can be found on the website: http://lavaan.org

Some notable features of lavaan:

- the 'lavaan model syntax' allows users to express their models in a 
compact, elegant and useR-friendly way

- lavaan is robust and reliable: there are no convergence problems and 
numerical results are very close (if not identical) to the commercial 
package Mplus

- many different estimators are available: ML, GLS, WLS, robust ML using 
Satorra-Bentler corrections, and FIML for data with missing values

- full support for meanstructures and multiple groups

- user friendly output including standardized solutions, fit measures, 
modification indices and more

To get a first impression of how the 'lavaan model syntax' looks like, 
below is the full R code for fitting a SEM model:

## begin R Code ##

library(lavaan)

# The industrialization and Political Democracy Example
# Bollen (1989), page 332

model <- '
   # latent variable definitions
      ind60 =~ x1 + x2 + x3
      dem60 =~ y1 + y2 + y3 + y4
      dem65 =~ y5 + y6 + y7 + y8

   # regressions
     dem60 ~ ind60
     dem65 ~ ind60 + dem60

   # residual correlations
     y1 ~~ y5
     y2 ~~ y4 + y6
     y3 ~~ y7
     y4 ~~ y8
     y6 ~~ y8
'

fit <- sem(model, data=PoliticalDemocracy)
summary(fit, fit.measures=TRUE)

## end R code ##


Please feel free to contact me directly with questions and comments.

Best,

Yves Rosseel.



-- 
Yves Rosseel -- http://www.da.ugent.be
Department of Data Analysis, Ghent University
Henri Dunantlaan 1, B-9000 Gent, Belgium
-


From seth at userprimary.net  Sun May 30 22:33:24 2010
From: seth at userprimary.net (Seth Falcon)
Date: Sun, 30 May 2010 13:33:24 -0700
Subject: [R-pkgs] New package RSQLite.extfuns and minor upgrade for RSQLite
Message-ID: <AANLkTinL-VdAf8uJx1ZeeNg7ItIwzOS1Ra0EzHNQTYaC@mail.gmail.com>

RSQLite.extfuns provides SQLite extension functions for use with
RSQLite.  The package is a wrapper of extension functions written by
Liam Healy and made available through the SQLite website
(http://www.sqlite.org/contrib).

You can make the extension functions available on a per db connection
basis like this:

library("RSQLite.extfuns")
db <- dbConnect(SQLite(), dbname = ":memory:")
init_extensions(db)


The extension functions provided by the package include:

Math: acos, asin, atan, atn2, atan2, acosh, asinh, atanh, difference,
degrees, radians, cos, sin, tan, cot, cosh, sinh, tanh, coth, exp,
log, log10, power, sign, sqrt, square, ceil, floor, pi.

String: replicate, charindex, leftstr, rightstr, ltrim, rtrim, trim,
replace, reverse, proper, padl, padr, padc, strfilter.

Aggregate: stdev, variance, mode, median, lower_quartile, upper_quartile.


RSQLite has been modified to provide the SQLite header files in the
installed include directory so that RSQLite.extfuns (and other
packages wishing to provide SQLite extension functions) can use
LinkingTo.  The default value of loadable.extensions is now TRUE.

+ seth

-- 
Seth Falcon | @sfalcon | http://userprimary.net/


From maiagx at gmail.com  Mon May 31 00:58:32 2010
From: maiagx at gmail.com (Charlotte Maia)
Date: Mon, 31 May 2010 10:58:32 +1200
Subject: [R-pkgs] Yet Another Package for Time Data
Message-ID: <AANLkTim6ZdI3c2irLmtGOpUViUSZAqurHLoBe7Vfir9m@mail.gmail.com>

Hi fellow R developers/users,

I've recently revised a package called rtv, and now consider it
reasonably stable.

Description: A package for conveniently representing, manipulating and
visualising time data. Here, time is regarded as a random variable,
and objects are used to represent realisations of that random
variable. This is particularly useful for change points, irregular
timeseries and failure events. There's a strong emphasis on continuous
representations of time, with user-specified origins and units.

http://cran.r-project.org/web/packages/rtv/index.html

The package contains classes notably similar to the POSIXt classes.
However, the classes are based on a somewhat different philosophy.
The major advantage of the package, is that crtv objects (similar to
POSIXct objects) allow user-specified origins and units.
It also allows time events to be represented as fractional months or
fractional years.

More info in the package vignette.

Bug reports and feature requests welcome.


kind regards
-- 
Charlotte Maia
http://sites.google.com/site/maiagx


From wagreen at bricol.net  Fri Jun  4 18:33:58 2010
From: wagreen at bricol.net (W. A. Green)
Date: Fri, 4 Jun 2010 09:33:58 -0700 (PDT)
Subject: [R-pkgs] new package released: stratigraph v. 0.6b
In-Reply-To: <C82C8EC1.E54E%wings@si.edu>
References: <C82C8EC1.E54E%wings@si.edu>
Message-ID: <Pine.LNX.4.64.1006031005470.30296@siegel.dreamhost.com>


Ladies and Gentlemen,

The first public (beta) release of the package stratigraph is now 
available on CRAN:

http://cran.r-project.org/web/packages/stratigraph/index.html

It includes tools for plotting pollen diagrams, an implementation of an 
evolutionary algorithm for drawing stratigraphic lines of correlation, and 
several other functions for the analysis and plotting of geological, 
biological, ecological, and paleontological data distributed through time 
or stratigraphic depth.

There are still some problems with the windows binary, which will 
be resolved shortly, but a source install should work. Older versions, 
which have been privately circulated in the past year are available at 
http://www.bricol.net/stratigraph, where a change log will also be 
maintained. As ever, user patches, comments, bug reports, recommendations, 
etc. are much appreciated.

Walton Green

## .signature
# Walton A. Green
# E-mail: $ echo wagreenXbricol.net | tr 'X' '@'
# URL: <http://www.bricol.net>
# Phone: (203) 640-8122
#################### 60 characters wide ####################


From kogalurshear at gmail.com  Tue Jun 15 17:59:25 2010
From: kogalurshear at gmail.com (Udaya B. Kogalur)
Date: Tue, 15 Jun 2010 11:59:25 -0400
Subject: [R-pkgs] spikeslab 1.1.0 now available on CRAN
Message-ID: <AANLkTilSBwdfEBdqSMkszF39--h5v49pALv9LW-Nun1U@mail.gmail.com>

Please find release 1.1.0 of the CRAN package "spikeslab" now
available for download.

Spike and slab for prediction and variable selection in linear
regression models. Uses a generalized elastic net for variable
selection.

CHANGES TO RELEASE 1.1.0

RELEASE 1.1.0 is a recommended upgrade of the product.

o cv.spikeslab() now takes advantage of the CRAN package "snow".  It
allows users to create a socket cluser on the local machine, enabling
parallel execution of this function.  It scales with the number of CPU
cores on the local machine.

-- 
kogalurshear at gmail.com

Udaya B. Kogalur, Ph.D.
Adjunct Staff, Dept of Quantitative Health Sciences, Cleveland Clinic Foundation
President, Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012


From hadley at rice.edu  Wed Jul  7 19:35:19 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 7 Jul 2010 19:35:19 +0200
Subject: [R-pkgs] ggplot2 version 0.8.8
Message-ID: <AANLkTilW5A4tUckYCFzzrIV9Rs_1I562f_n57hjPKB8P@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

To install or update, run:
install.packages(c("ggplot2", "plyr"))

Find out more at http://had.co.nz/ggplot2, and check out the nearly 500
examples of ggplot in use.  If you're interested, you can also sign up to
the ggplot2 mailing list at http://groups.google.com/group/ggplot2, or track
development at  http://github.com/hadley/ggplot2

ggplot2 0.8.8 (2010-07-02) ----------------------------------------

This version fixes the following 23 bugs:

* coord_equal finally works as expected (thanks to continued prompting
from Jean-Olivier Irisson)
* coord_equal renamed to coord_fixed to better represent capabilities
* coord_polar and coord_polar: new munching system that uses distances
(as defined by the coordinate system) to figure out how many pieces
each segment should be broken in to (thanks to prompting from
Jean-Olivier Irisson)
* fix ordering bug in facet_wrap (thanks to bug report by Frank Davenport)
* geom_errorh correctly responds to height parameter outside of aes
* geom_hline and geom_vline will not impact legend when used for fixed
intercepts
* geom_hline/geom_vline: intercept values not set quite correctly
which caused a problem in conjunction with transformed scales
(reported by Seth Finnegan)
* geom_line: can now stack lines again with position = "stack" (fixes #74)
* geom_segment: arrows now preserved in non-Cartesian coordinate
system (fixes #117)
* geom_smooth now deals with missing values in the same way as
geom_line (thanks to patch from Karsten Loesing)
* guides: check all axis labels for expressions (reported by Benji Oswald)
* guides: extra 0.5 line margin around legend (fixes #71)
* guides: non-left legend positions now work once more (thanks to
patch from Karsten Loesing)
* label_bquote works with more expressions (factors now cast to
characters, thanks to Baptiste Auguie for bug report)
* scale_color: add missing US spellings
* stat: panels with no non-missing values trigged errors with some
statistics. (reported by Giovanni Dall'Olio)
* stat: statistics now also respect layer parameter inherit.aes
(thanks to bug report by Lorenzo Isella and investigation by Brian
Diggs)
* stat_bin no longer drops 0-count bins by default
* stat_bin: fix small bug when dealing with single bin with NA
position (reported by John Rauser)
* stat_binhex: uses range of data from scales when computing binwidth
so hexes are the same size in all facets (thanks to Nicholas Lewin-Koh
for the bug report)
* stat_qq has new dparam parameter for specifying distribution
parameters (thanks to Yunfeng Zhang for the bug report)
* stat_smooth now uses built-in confidence interval (with small sample
correction) for linear models (thanks to suggestion by Ian Fellows)
* stat_spoke: correctly calculate stat_spoke (cos and sin were
flipped, thanks to Jean-Olivier Irisson for bug report and fix)


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From gblair at princeton.edu  Sun Jul 11 18:32:24 2010
From: gblair at princeton.edu (Graeme Blair)
Date: Sun, 11 Jul 2010 17:32:24 +0100
Subject: [R-pkgs] New package "list" for analyzing list survey experiments
Message-ID: <D3885B3B-BDB8-4258-8C33-23E1B8E98F85@princeton.edu>

Dear all,

Kosuke Imai and I announce the new package "list," which is now available on CRAN.

list: Multivariate Statistical Analysis for the Item Count Technique

List allows researchers to conduct multivariate statistical analyses with data from the item count technique for sensitive survey questions. This survey methodology, also known as the list experiment or the unmatched count technique, is an alternative to the commonly used randomized response method. The package implements the methods described in Imai (2010) ``Statistical Inference for the Item Count Technique.''

More information is available at http://imai.princeton.edu/projects/sensitive.html

Best wishes,

Graeme Blair and Kosuke Imai
Department of Politics 
Princeton University

From jfox at mcmaster.ca  Mon Jul 26 23:50:57 2010
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 26 Jul 2010 17:50:57 -0400
Subject: [R-pkgs] version 2.0-0 of the car package
Message-ID: <001801cb2d0c$a119a120$e34ce360$@ca>

Dear all,

Sandy Weisberg and I would like to announce version 2.0-0 of the car
package, now on CRAN. We've released this major revision of the package in
anticipation of the publication of An R Companion to Applied Regression,
Second Edition (Sage, in press), co-authored by us, which should be
available before the end of the year.

The new version of the car package has a number of new functions and data
sets, along with many changes to old functions, including a change in naming
conventions, using "camel-case" rather than period-separated names: for
example, av.plots() is now avPlots(). For the time-being, old function
names, such as av.plots(), are available as deprecated aliases. A few
functions from the alr3 package have also been rewritten, renamed, and are
now part of car. The alr3 package will be updated later in the year.


Regards,
John

--------------------------------
John Fox
Senator William McMaster 
  Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox


From hadley at rice.edu  Tue Jul 27 03:43:59 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 26 Jul 2010 20:43:59 -0500
Subject: [R-pkgs] plyr version 1.1
Message-ID: <AANLkTi=Zh44evGEAHgL+Cu6wFLr8hopMXNbYwVsowFRm@mail.gmail.com>

plyr is a set of tools for a common set of problems: you need to break
down a big data structure into manageable pieces, operate on each
piece and then put all the pieces back together.  For example, you
might want to:

  * fit the same model to subsets of a data frame
  * quickly calculate summary statistics for each group
  * perform group-wise transformations like scaling or standardising

It's already possible to do this with built-in functions (like split
and the apply functions), but plyr just makes it all a bit easier
with:

  * totally consistent names, arguments and outputs
  * input from and output to data.frames, matrices and lists
  * progress bars to keep track of long running operations
  * built-in error recovery, and informative error messages

Some considerable effort has been put into making plyr fast and memory
efficient, and in many cases plyr is as fast, or faster than, the
built-in functions.

You can find out more at http://had.co.nz/plyr/, including a 20 page
introductory guide, http://had.co.nz/plyr/plyr-intro.pdf.  You can ask
questions about plyr (and data-manipulation in general) on the plyr
mailing list.  Sign up at http://groups.google.com/group/manipulatr

plyr 1.1 (2010-07-19) ---------------------------------------------------

* *dply deals more gracefully with the case when all results are NULL
(fixes #10)
* *aply correctly orders output regardless of dimension names (fixes #11)
* join gains type = "full" which preserves all x and y rows



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From gkerns at ysu.edu  Wed Jul 28 14:28:45 2010
From: gkerns at ysu.edu (G. Jay Kerns)
Date: Wed, 28 Jul 2010 08:28:45 -0400
Subject: [R-pkgs] IPSUR-1.0 is on CRAN, plus update to RcmdrPlugin.IPSUR
Message-ID: <AANLkTikp+dVafaDkxrAqrRne4Q=MoA1H+P---R6QVOjt@mail.gmail.com>

IPSUR-1.0 is making its way through CRAN. It is a snapshot of the
development version of the following textbook:

Title: Introduction to Probability and Statistics using R, First Edition
ISBN: 978-0-557-24979-4
Publisher: me

The book is targeted for an undergraduate course in probability and
statistics. The prerequisites are a couple semesters of calculus and a
little bit of linear algebra. I have used various drafts of this
document to supplement my lectures for over four years.

IPSUR is FREE, in the GNU sense of the word. A pdf copy (plus the
LaTeX source) is on the R-Forge Project Page:

http://ipsur.r-forge.r-project.org/

Alternatively, a person can do the following at the command prompt:

install.packages("IPSUR")
library(IPSUR)
read(IPSUR)

There are still many important topics, examples, and (especially)
exercises missing. I will add them as time and two toddlers permit. If
you would like to preview the daily-built, bleeding-edge latest
version you can get it with

install.packages("IPSUR", repos="http://R-Forge.R-project.org")

Please route IPSUR-specific emails to the respective R-Forge mailing lists:

Questions or problems: ipsur-help at lists.r-forge.r-project.org
Mistakes, suggestions: ipsur-devel at lists.r-forge.r-project.org

RcmdrPlugin.IPSUR is a plugin for the R Commander to accompany IPSUR.
The update to version 0.1-7 is an important one, because it squashes a
long-standing incompatibility problem with other plugins. The naming
scheme for menus is also updated to be consistent with the other
plugins in particular, and naming conventions in general.

Cheers,
Jay

P.S. If you are thinking to print parts of IPSUR yourself then I
recommend the publisher-quality PDF linked from the Downloads section
of the R-Forge Project Page.



************************************************
G. Jay Kerns, Ph.D.
Associate Professor
Department of Mathematics & Statistics
Youngstown State University
Youngstown, OH 44555-0002 USA
http://people.ysu.edu/~gkerns/


From chuck at sharpsteen.net  Tue Aug 10 17:51:19 2010
From: chuck at sharpsteen.net (Charlie Sharpsteen)
Date: Tue, 10 Aug 2010 08:51:19 -0700
Subject: [R-pkgs] tikzDevice 0.5.0 released to CRAN
Message-ID: <AANLkTimNzDv9StfVT7BZf2dAFuaQ_XGzzYpgXk_XBRTs@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100810/8bf4de4a/attachment.pl>

From ian.fellows at stat.ucla.edu  Mon Aug 16 19:14:59 2010
From: ian.fellows at stat.ucla.edu (ian fellows)
Date: Mon, 16 Aug 2010 10:14:59 -0700
Subject: [R-pkgs] Major update of Deducer, including GSOC funded work
Message-ID: <3CAA9068-6284-455E-B919-F338E47FE378@stat.ucla.edu>


A new version of Deducer (0.4) has been sent to CRAN, and should be  
propagating to all the mirrors in due course. Also, a new plug-in  
package (DeducerExtras) has also been released to CRAN, containing  
additional dialogs and functionality.

I would like to take this opportunity to thank the R community for  
choosing this project for a Google Summer of Code grant, and for the  
support and encouragement. In particular I would like to thank Hadley  
Wickham for mentoring the Plot Builder GUI, and Dirk Eddelbuettel for  
his organization of students and mentors.

				-------------   Deducer   -------------
Deducer is designed to be a free easy to use alternative to  
proprietary data analysis software such as SPSS, JMP, and Minitab. It  
has a menu system to do common data manipulation and analysis tasks,  
and an excel-like spreadsheet in which to view and edit data frames.  
The goal of the project is two fold.

Provide an intuitive interface so that non-technical users can learn  
and perform analyses without programming getting in their way.
Increase the efficiency of expert R users when performing common  
tasks by replacing hundreds of keystrokes with a few mouse clicks.  
Also, as much as possible the GUI should not get in their way if they  
just want to do some programming.
Deducer is designed to be used with the Java based R console JGR,  
though it supports a number of other R environments (e.g. Windows  
RGUI and RTerm).


For those not familiar with Deducer, an online manual is available  
at: http://www.deducer.org/pmwiki/pmwiki.php?n=Main.DeducerManual .

Introduction to Deducer (8 min): http://www.youtube.com/user/ 
MrIanfellows#p/u/6/iZ857h2j6wA

			    -------------   Plot Builder   -------------

The major change to Deducer is the inclusion of a new plotting GUI  
built on the ggplot2 package. This Google Summer of Code project  
provides an easy to use system to make anything from simple  
histograms, to custom publication ready graphics. Feel free to check  
out the video introduction:

Part 1 (6 min): http://www.youtube.com/user/MrIanfellows#p/u/4/- 
Rym6Ucraes
Part 2 (6 min): http://www.youtube.com/user/MrIanfellows#p/u/3/ 
k6elEgB3OCE

Additional videos:
Templates (5 min): 		http://www.youtube.com/user/MrIanfellows#p/u/2/ 
ktdifzqbLW8
Extending the Builder (4 min):	http://www.youtube.com/user/ 
MrIanfellows#p/u/1/RsxOo0jx0II

			   -------------   Deducer Extras   -------------

The DeducerExtras package is an add-on package containing a variety  
of additional analysis dialogs. These include:
	* Distribution quantiles
	* Single/multiple sample proportion tests
	* Paired t-test, and wilcoxon signed rank test
	* Levene's test and bartlett's test
	* K-means clustering
	* Hierarchical clustering
	* Factor analysis
	* Multi-dimensional scaling

Introduction to Deducer Extras (2 min): http://www.youtube.com/user/ 
MrIanfellows#p/u/0/UCrhxB8tSJY


From hadley at rice.edu  Wed Aug 25 20:08:12 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 25 Aug 2010 13:08:12 -0500
Subject: [R-pkgs] stringr: version 0.4
Message-ID: <AANLkTikeb5uhTFnSVX1cmsiu60CaZOXqh_EiaXsXYGD1@mail.gmail.com>

Strings are not glamorous, high-profile components of R, but they do
play a big role in many data cleaning and preparations tasks. R
provides a solid set of string operations, but because they have grown
organically over time, they can be inconsistent and a little hard to
learn. Additionally, they lag behind the string operations in other
programming languages, so that some things that are easy to do in
languages like Ruby or Python are rather hard to do in R. The
`stringr` package aims to remedy these problems by providing a clean,
modern interface to common string operations.

More concretely, `stringr`:

 * Processes factors and characters in the same way.

 * Gives functions consistent names and arguments.

 * Simplifies string operations by eliminating options that you don't need
   95% of the time.

 * Produces outputs than can easily be used as inputs. This includes ensuring
   that missing inputs result in missing outputs, and zero length inputs
   result in zero length outputs.

 * Completes R's string handling functions with useful functions from other
   programming languages.


New in stringr 0.4:

 * all functions now vectorised with respect to string, pattern (and
   where appropriate) replacement parameters
 * fixed() function now tells stringr functions to use fixed matching, rather
   than escaping the regular expression.  Should improve performance for
   large vectors.
 * new ignore.case() modifier tells stringr functions to ignore case of
   pattern.
 * str_replace renamed to str_replace_all and new str_replace function added.
   This makes str_replace consistent with all functions.
 * new str_sub<- function (analogous to substring<-) for substring replacement
 * str_sub now understands negative positions as a position from the end of
   the string. -1 replaces Inf as indicator for string end.
 * str_pad side argument can be left, right, or both (instead of center)
 * str_trim gains side argument to better match str_pad
 * stringr now has a namespace and imports plyr (rather than requiring it)


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From Alexis.Gabadinho at unige.ch  Thu Aug 26 16:13:44 2010
From: Alexis.Gabadinho at unige.ch (Alexis Gabadinho)
Date: Thu, 26 Aug 2010 16:13:44 +0200
Subject: [R-pkgs] TraMineR version 1.6-1
Message-ID: <4C767698.6030301@unige.ch>

Dear R users,

The TraMineR package for mining, describing and visualizing sequences 
of  states or events, and more generally discrete sequential data has 
been updated to version 1.6-1. Its primary aim is the analysis of 
biographical
longitudinal data in the social sciences, such as data describing 
careers or family trajectories. Most of its features apply however also 
to non temporal data such as text or DNA sequences for instance.

For more information, please visit:

http://mephisto.unige.ch/traminer

It is now possible to submit bug reports and feature requests, as well 
as to join the TraMineR user's list if you have questions. More 
information here:

http://mephisto.unige.ch/traminer/contrib.shtml

Cheers,
The TraMineR team.


From florian.wickelmaier at uni-tuebingen.de  Fri Aug 27 16:30:30 2010
From: florian.wickelmaier at uni-tuebingen.de (florian.wickelmaier at uni-tuebingen.de)
Date: Fri, 27 Aug 2010 16:30:30 +0200 (CEST)
Subject: [R-pkgs] New package: mpt
Message-ID: <alpine.LNX.2.00.1008271628030.31745@linux29.zdv.uni-tuebingen.de>

Dear all,

I have submitted a new package called mpt to CRAN.

It contains functions for fitting and testing multinomial
processing tree (MPT) models, a class of statistical models for
categorical data that involve latent parameters. These parameters
are often interpreted as psychological processing variables.

An introduction to these models is:

Riefer, D.M., & Batchelder, W.H. (1988). Multinomial modeling and
the measurement of cognitive processes. Psychological Review, 95,
318-339.

An overview of applications give:

Batchelder, W.H. & Riefer, D.M. (1999). Theoretical and empirical
review of multinomial process tree modeling. Psychonomic Bulletin
& Review, 6, 57-86.

Erdfelder, E., Auer, T., Hilbig, B.E., Assfalg, A., Moshagen, M.,
& Nadarevic, L. (2009). Multinomial processing tree models: A
review of the literature. Zeitschrift fuer Psychologie, 217,
108-124.

Best regards, Florian

---
Florian Wickelmaier
Department of Psychology
University of Tuebingen
http://homepages.uni-tuebingen.de/florian.wickelmaier


From Mike.Lawrence at dal.ca  Tue Aug 31 14:53:05 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 31 Aug 2010 09:53:05 -0300
Subject: [R-pkgs] ez version 2.0
In-Reply-To: <AANLkTikUGWHc52SdeK8Tr8KZTNgy6dcVm5=mpjZW6af4@mail.gmail.com>
References: <AANLkTikUGWHc52SdeK8Tr8KZTNgy6dcVm5=mpjZW6af4@mail.gmail.com>
Message-ID: <AANLkTi=6PypmTyBDS8R5KsbL=V5kagmsgTS5CejE1eWO@mail.gmail.com>

The ez package was developed to aid those that are new to statistical
programming. Over the course of several years of helping colleagues
and students learn R, I observed that folks are often initially turned
off R because they have difficulty obtaining SPSS-like results quickly
(SPSS is the dominant environment in my field, psychology). ez
attempts to fill this gap, providing quick and easy analysis and
graphics for common experimental designs. By easing the early portions
of the R learning curve, ez hopes to promote the spread of R as a
means of open source and reproducible analysis. ez now also attempts
to pique interest in cutting-edge statistical methods by providing
easy specification and visualization of simple* mixed effects models.

*--> mixed effects models are limited to those with a single random
effect (eg. Participant) and no numeric predictors.


New in version 2.0
- ezDesign(), a function to visualize the balance of data across a
specified experimental design (useful for diagnosing missing data)
- ezPrecis(), a function to summarize a data set (inspired by
summary(), str(), and YaleToolkit:whatis() )
- ezBoot() and ezPlotBoot(), functions to compute and visualize
(respectively) bootstrapped confidence intervals for either cell means
or predictions from a mixed effects model
- ezANOVA() updated with an improved measure of effect size:
generalized eta-square.
- ezPlot() updated to permit simultaneous plotting of multiple DV's,
with each mapped to a row of the plot facets.
- see changelog for further changes


Enjoy!

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~


From grolemund at gmail.com  Tue Aug 31 16:51:49 2010
From: grolemund at gmail.com (Garrett Grolemund)
Date: Tue, 31 Aug 2010 09:51:49 -0500
Subject: [R-pkgs] New package: lubridate 0.1
Message-ID: <AANLkTi=Hs4UU0JQ2=P1_BWyJjm1va-LkKzCgO48LCpBZ@mail.gmail.com>

Please find below the package announcement for the R package lubridate
available from cran.

Thank you,

Garrett Grolemund
Rice University

##lubridate

Date-time data can be frustrating to work with in R. R commands for
date-times are generally unintuitive and change depending on the type
of date-time object being used. Moreover, the methods we use with
date-times must be robust to time zones, leap days, daylight savings
times, and other time related quirks, and R lacks these capabilities
in some situations. Lubridate makes it easier to do the things R does
with date-times and possible to do the things R does not.
Specifically, lubridate provides:

* a set of intuitive date-time related functions that work the same
way for all common date-time classes (including those from?chron,
timeDate,?zoo,?xts,its,?tis,?timeSeries,?fts, and?tseries)

* quick and easy parsing of date-times:?ymd(),?dmy(),?mdy(), ...

* simple functions to extract and modify components of a date-time,
such as years, months, days, hours, minutes, and seconds:?year(),
month(),?day(), ...

* helper functions for handling time zones:?with_tz(),?force_tz()

Lubridate also expands the type of mathematical operations that can be
performed with date-time objects. It introduces three new time span
classes borrowed from http://joda.org.

* durations, which measure the exact amount of time between two points

* periods, which accurately track clock times despite leap years, leap
seconds, and day light savings time

* intervals, a protean summary of the time information between two points


From hadley at rice.edu  Wed Sep  1 14:54:46 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 1 Sep 2010 07:54:46 -0500
Subject: [R-pkgs] testthat: version 0.3
Message-ID: <AANLkTim3G666qV9LucV0gXxU5T4+H3OoiMK+Rzy_OAKs@mail.gmail.com>

# testthat

Testing your code is normally painful and boring. `testthat` tries to
make testing as fun as possible, so that you get a visceral
satisfaction from writing tests. Testing should be fun, not a drag, so
you do it all the time. To make that happen, `testthat`:

* Provides functions that make it easy to describe what you expect a
  function to do, including catching errors, warnings and messages.

* Easily integrates in your existing workflow, whether it's informal testing
  on the command line, building test suites or using R CMD check.

* Can re-run tests automatically as you change your code or tests.

* Displays test progress visually, showing a pass, fail or error for every
  expectation. If you're using the terminal, it'll even colour the output.

`testthat` draws inspiration from the xUnit family of testing
packages, as well from many of the innovative ruby testing libraries,
like [rspec](http://rspec.info/),
[testy](http://github.com/ahoward/testy),
[bacon](http://github.com/chneukirchen/bacon) and
[cucumber](http://wiki.github.com/aslakhellesoy/cucumber/). I have
used what I think works for R, and abandoned what doesn't, creating a
testing environment that is philosophically centred in R.

Changes in version 0.3
-----------------------------------------------------------------

* all expectations now have a shortcut form, so instead of
     expect_that(a, is_identical_to(b))
  you can do
     expect_identical(a, b)

* new shows_message and gives_warning expectations to test warnings and
  messages

* expect_that, equals, is_identical_to and is_equivalent to now have
  additional label argument which allows you to control the appearance of the
  text used for the expected object (for expect_that) and actual object (for
  all other functions) in failure messages. This is useful when you have loops
  that run tests as otherwise all the variable names are identical, and it's
  difficult to tell which iteration caused the failure.

* executing bare tests gives nicer output

* all expectations now give more information on failure to make it easier to
  track down the problem.

* test_file and test_dir now run in code in separate environment to avoid
  pollution of global environment. They also temporary change the working
  directory so tests can use relative paths.

* test_package makes it easier to run all tests in an installed package. Code
  run in this manner has access to non-exported functions and objects. If any
  errors or failures occur, test_package will throw an error, making it
  suitable for use with R CMD check.


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From gchappi at gmail.com  Mon Sep  6 11:41:15 2010
From: gchappi at gmail.com (Hans-Peter Suter)
Date: Mon, 6 Sep 2010 11:41:15 +0200
Subject: [R-pkgs] xlsReadWrite v1.5.2
Message-ID: <AANLkTi=vBGPbU+h3iMoOvjGoJX84pyQv7kA4in9XFyZR@mail.gmail.com>

Natively read and write Excel (.xls) files. Supports Windows 32-bit only (atm).

A new version has been released:

-- changes --

o read.xls
  - new arguments 'checkNames'
  - recognize NA values according to a new 'naStrings' argument
  - recognize NaN values
  - recognize 'true', 'false' (not case-sensitive) as logical when
determing a class for data.frame column;
    when the value in the first cell is an integer, a numeric will be
assumed nevertheless
  - colnames are more consistent with R usage (X, X.1, V1, etc.)
  - matrices always have rownames (as in data.frame). With FALSE
rownames become (integer) 1:length(rows)
  - duplicated rownames no longer accepted
  - allow data with one row which is defined as being the colnames
(i.e. no 'real' data row)
  - colNames/colClasses can optionally contain an entry for the column
used for the rownames
o write.xls
  - error (instead of warning) when length of character colnames
doesn't fit data
  - write NA values according to the 'naStrings' (scalar) argument
  - write NaN values as 'NaN' string (instead of ending as #ZAHL!)
  - colNames can optionally contain an entry for the column used for
the rownames
o template location moved
  - new: R_HOME/library/xlsReadWrite/template/TemplateNew.xls
  - (old/erronous: R_HOME/library/xlsReadWrite/libs/template, reported
by B. Ripley)
o RUnit tests extended, loading simplified
o improve examples and run them on the regular version, polish docu

-- bugfixes --

o file: path may be absolute or relative to the current working directory.
  The 'relative' part was broken (feedback from several people)
o xls.getshlib: sometimes existing dll could not be replaced. Now uses path
  of loaded dll instead of lib.loc and path (reported by G. Grothendieck)
o use .Platform$r_arch for shlib path and R.version$platform in xls.getshlib
  to make pkg compatible with R2.12dev (reported and tips by B. Ripley)
o several fixes related to row/colnames in special cases (without data)

-- 'ecosystem' --

o issue tracking (developer) link change:
  - http://dev.swissr.org (was: https://redmine.swissr.org)
  - allow guest login and directly mention credentials


Cheers,
Hans-Peter


From jon.clayden at gmail.com  Wed Sep  8 18:10:30 2010
From: jon.clayden at gmail.com (Jon Clayden)
Date: Wed, 8 Sep 2010 17:10:30 +0100
Subject: [R-pkgs] New package for medical image registration: RNiftyReg
Message-ID: <AANLkTimH1L35YtT607DDFtQRCWm2BqtEhTnEfuUBMp31@mail.gmail.com>

The first release of "RNiftyReg", an R package for registration
(alignment and resampling) of medical images, is now available on CRAN
[1]. It may also be useful for other 3D array-like data sets.
RNiftyReg is built on top of the NiftyReg library [2], and is written
in a mixture of C, C++ and R. It currently supports 3D rigid-body and
affine registration, and support for 2D and nonlinear registration is
planned for a future release. NIfTI-format files can be read in and
passed to the registration algorithm using the oro.nifti package. In
testing I've found that a standard 12 degree-of-freedom affine
registration typically takes less than a minute, but timings will
depend on the dimensions of the images. Feedback on the package would
be very welcome at this stage.

Over the last few years a number of R packages for medical image
analysis have been produced, and R is gaining momentum as a platform
in this field [3]. I hope that this package will be a useful addition.

All the best,
Jon

--
[1] http://cran.r-project.org/web/packages/RNiftyReg/index.html
[2] http://sourceforge.net/projects/niftyreg/
[3] http://cran.r-project.org/web/views/MedicalImaging.html


From hadley at rice.edu  Fri Sep 10 14:34:54 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 10 Sep 2010 07:34:54 -0500
Subject: [R-pkgs] reshape2: a reboot of the reshape package
Message-ID: <AANLkTimL6yyLMtmVS4oFxUwYphU_50VpzXtNBuF=UF-3@mail.gmail.com>

Reshape2 is a reboot of the reshape package. It's been over five years
since the first release of the package, and in that time I've learned
a tremendous amount about R programming, and how to work with data in
R. Reshape2 uses that knowledge to make a new package for reshaping
data that is much more focussed and much much faster.

This version improves speed at the cost of functionality, so I have
renamed it to `reshape2` to avoid causing problems for existing users.
 Based on user feedback I may reintroduce some of these features.

What's new in `reshape2`:

 * considerably faster and more memory efficient thanks to a much better
   underlying algorithm that uses the power and speed of subsetting to the
   fullest extent, in most cases only making a single copy of the data.

 * cast is replaced by two functions depending on the output type: `dcast`
   produces data frames, and `acast` produces matrices/arrays.

 * multidimensional margins are now possible: `grand_row` and `grand_col` have
   been dropped: now the name of the margin refers to the variable that has
   its value set to (all).

 * some features have been removed such as the `|` cast operator, and the
   ability to return multiple values from an aggregation function. I'm
   reasonably sure both these operations are better performed by plyr.

 * a new cast syntax which allows you to reshape based on functions
   of variables (based on the same underlying syntax as plyr):

 * better development practices like namespaces and tests.

This work has been generously supported by BD (Becton Dickinson).


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From hadley at rice.edu  Fri Sep 10 14:36:20 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 10 Sep 2010 07:36:20 -0500
Subject: [R-pkgs] plyr: version 1.2
Message-ID: <AANLkTimMsCiCataY1FzLH7s5DBm8x2nkzaVN0cum17mn@mail.gmail.com>

plyr is a set of tools for a common set of problems: you need to
__split__ up a big data structure into homogeneous pieces, __apply__ a
function to each piece and then __combine__ all the results back
together. For example, you might want to:

  * fit the same model each patient subsets of a data frame
  * quickly calculate summary statistics for each group
  * perform group-wise transformations like scaling or standardising

It's already possible to do this with base R functions (like split and
the apply family of functions), but plyr makes it all a bit easier
with:

  * totally consistent names, arguments and outputs
  * convenient parallelisation through the foreach package
  * input from and output to data.frames, matrices and lists
  * progress bars to keep track of long running operations
  * built-in error recovery, and informative error messages
  * labels that are maintained across all transformations

Considerable effort has been put into making plyr fast and memory
efficient, and in many cases plyr is as fast as, or faster than, the
built-in functions.

You can find out more at http://had.co.nz/plyr/, including a 20 page
introductory guide, http://had.co.nz/plyr/plyr-intro.pdf.  You can ask
questions about plyr (and data-manipulation in general) on the plyr
mailing list. Sign up at http://groups.google.com/group/manipulatr

Version 1.2 (2010-09-09)
------------------------------------------------------------------------------

NEW FEATURES

* l*ply, d*ply, a*ply and m*ply all gain a .parallel argument that when TRUE,
  applies functions in parallel using a parallel backend registered with the
  foreach package:

  x <- seq_len(20)
  wait <- function(i) Sys.sleep(0.1)
  system.time(llply(x, wait))
  #  user  system elapsed
  # 0.007   0.005   2.005

  library(doMC)
  registerDoMC(2)
  system.time(llply(x, wait, .parallel = TRUE))
  #  user  system elapsed
  # 0.020   0.011   1.038

  This work has been generously supported by BD (Becton Dickinson).

MINOR CHANGES

* a*ply and m*ply gain an .expand argument that controls whether data frames
  produce a single output dimension (one element for each row), or an output
  dimension for each variable.

* new vaggregate (vector aggregate) function, which is equivalent to tapply,
  but much faster (~ 10x), since it avoids copying the data.

* llply: for simple lists and vectors, with no progress bar, no extra info,
  and no parallelisation, llply calls lapply directly to avoid all the
  overhead associated with those unused extra features.

* llply: in serial case, for loop replaced with custom C function that takes
  about 40% less time (or about 20% less time than lapply). Note that as a
  whole, llply still has much more overhead than lapply.

* round_any now lives in plyr instead of reshape

BUG FIXES

* list_to_array works correct even when there are missing values in the array.
  This is particularly important for daply.


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From f.harrell at vanderbilt.edu  Mon Sep 13 20:46:22 2010
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Mon, 13 Sep 2010 13:46:22 -0500 (CDT)
Subject: [R-pkgs] New version of rms package on CRAN
Message-ID: <alpine.DEB.2.00.1009131342390.11575@biostat145>

CRAN has a significant update to rms.  Windows and unix/linux versions 
are available and I expect the Mac version to be available soon. 
The most significant improvement is addition of latex=TRUE 
arguments to model fitting print methods, made especially for use 
with Sweave.

Here is a summary of changes since the previous version.

Changes in version 3.1-0 (2010-09-12)
    * Fixed gIndex to not use scale for labeling unless character
    * Changed default na.action in Gls to na.omit and added a note in 
the help file that na.delete does not work with Gls
    * Added terms component to Gls fit object (latex was not working)
    * Added examples in robcov help file testing sandwich covariance 
estimator
    * Added reference related to the effects package under help file 
for plot.Predict
    * Added more examples and simulations to gIndex
    * Fixed ancient bug in lrm.fit Fortran code to handle case where 
initial estimates are nearly perfect (was trying to step halve); 
thanks: Dan Hogan
    * Changed survdiffplot to use gray(.85) for bands instead of 
gray(.95)
    * Fixed formatting problem in print.psm
    * Added prStats and reVector functions to rmsMisc.s
    * Changed formatting of all print.* functions for model fits to use 
new prStats function
    * Added latex=TRUE option to all model fit print methods; requires 
LaTeX package needspace
    * Re-wrote printing routines to make use of more general model
    * Removed long and scale options from cph printing-related routines
    * Prepare for version 2.36-1 of survival package by adding 
censor=FALSE argument to survfit.coxph
    * Added type="ccterms" to various predict methods
    * Made type="ccterms" the default for partial g-indexes in gIndex, 
i.e., combine all indirectly related (through interactions) terms
    * Added Spiegelhalter calibration test to val.prob
    * Added a check in cph to trigger an error if strata() is used in 
formula
    * Fixed drawing of polygon for shaded confidence bands for 
survplot.survfit (thanks to Patrick Breheny <patrick.breheny at uky.edu>)
    * Changed default adjust.subtitle in bplot to depend on ref.zero, 
thanks to David Winsemius <dwinsemius at comcast.net>
    * Used a namespace and simplified referenced to a few survival 
package functions that survival actually exports


Frank E Harrell Jr   Professor and Chairman        School of Medicine
                      Department of Biostatistics   Vanderbilt University


From marc_schwartz at me.com  Thu Sep 16 21:16:49 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 16 Sep 2010 14:16:49 -0500
Subject: [R-pkgs] WriteXLS - New Version 2.0.1
Message-ID: <F532B28B-6438-428A-BC29-90B91CBBF503@me.com>

The updated package has been submitted to CRAN and will propagate to mirrors over the next day or so.

It is maintained on R-Forge at http://r-forge.r-project.org/projects/writexls, where downloads will eventually be available as well. 

Package: WriteXLS

Version: 2.0.1

Description: Cross-platform Perl based R function to create Excel 2003 (XLS) files from one or more data frames. Each data frame will be written to a separate named worksheet in the Excel spreadsheet. The worksheet name will be the name of the data frame it contains or can be specified by the user.

Author(s): Marc Schwartz <marc_schwartz at me.com>
Maintainer: Marc Schwartz <marc_schwartz at me.com>

License: GPL (>=2)


Changes since version 1.9.0:

1. Major version update to 2.x.y
2. Added the ability to specify the name of a list that contains one or more data frames, in addition to the original vector of one or more data frame names.
3. Updated with newer versions of the included Perl modules.
4. Note that WorkbookBig.pm is no longer required and is therefore removed from the packaged Perl modules.
5. Fixed the underscores "_" in testPerl.Rd
6. Added check of the data frames for rows > 65536 and columns > 256.
7. Temporary CSV file names are now (1:number of data frames).csv
6. SheetNames are now always written to temporary file SheetNames.txt, so the '--SN' argument is deleted from the Perl script


The major user visible functional change is number 2, such that the name of a list can now be specified, where the list contains one or more data frames. An example of this use is:

 iris.split <- split(iris, iris$Species)
 WriteXLS("iris.split", "irissplit.xls")

This will result in 3 worksheets created in an Excel 2003 format XLS file called 'irissplit.xls'. The worksheet names will, by default, be names(iris.split), that is c("setosa", "versicolor", "virginica"). See the function help file for more details.

Regards,

Marc Schwartz


From marc_schwartz at me.com  Sun Sep 19 21:09:20 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Sun, 19 Sep 2010 14:09:20 -0500
Subject: [R-pkgs] WriteXLS - New Version 2.1.0
Message-ID: <1B40A925-F521-4458-8724-88318F4275DD@me.com>

On the heels of the major version update to version 2.0.1 this past week, another incremental update, version 2.1.0, has been submitted to CRAN and will propagate to mirrors over the next day or so.

The package is maintained on R-Forge at http://r-forge.r-project.org/projects/writexls, where downloads will eventually be available as well. 

Package: WriteXLS

Version: 2.1.0

Description: Cross-platform Perl based R function to create Excel 2003 (XLS) files from one or more data frames. Each data frame will be written to a separate named worksheet in the Excel spreadsheet. The worksheet name will be the name of the data frame it contains or can be specified by the user.

Author(s): Marc Schwartz <marc_schwartz at me.com>
Maintainer: Marc Schwartz <marc_schwartz at me.com>

License: GPL (>=2)


Change since version 2.0.1:

New logical argument 'row.names' to enable the ability to export the data frame row names to the Excel file. Defaults to FALSE for compatibility with prior versions.


Regards,

Marc Schwartz


From i.visser at uva.nl  Mon Sep 20 15:45:16 2010
From: i.visser at uva.nl (Ingmar Visser)
Date: Mon, 20 Sep 2010 15:45:16 +0200
Subject: [R-pkgs] depmixS4 1.0-0 on CRAN & vignette/paper on jstatsoft.org
Message-ID: <AANLkTinn-jkEyxWTKmFX6iohJi6d2t5dJq+k5B_VWd=C@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20100920/f274fed3/attachment.pl>

From ian.fellows at stat.ucla.edu  Sat Sep 25 19:01:10 2010
From: ian.fellows at stat.ucla.edu (Ian Fellows)
Date: Sat, 25 Sep 2010 10:01:10 -0700
Subject: [R-pkgs] Deducer 0.4-1 and JGR 1.7-2 released
Message-ID: <52C938A8-5077-406F-BBCC-54F199F07791@stat.ucla.edu>

Hi All,

I would like to announce the release of Deducer 0.4-1 and JGR 1.7-2 to CRAN. The updates should be propagating through the mirrors over the next few days. On the Deducer side we have a number of nice improvements:

1. A new Text Field Widget for plug-ins is included, which is better suited for entering/displaying numeric and short string fields than TextAreaWidget.
2. A new Object Chooser Widget is included, which allows the user to select an object from their workspace, possibly of a specific class.
3. Fixed combobox bug on Mac OS 64-bit.
4. Factor editor and Recode dialog handle empty strings.
5. Created menu items for common plotting templates.

The new JGR includes stability fixes along with a few new features.

Bug fixes:
1. Fixed MacOS JavaGD resize deadlock bug
2. Fixed 100% CPU on start-up bug reported on some UNIX systems.
3. Interrupt R button fixed on unix systems 

New Features:
1. Graphics device save support for png, jpeg, bmp, and tiff
2. User control over the menu system has been improved. Added ability to insert new menus, menu items, separators, and sub-menus. Menus and menu items can also be removed.


Ian Fellows


From daniel.sabanesbove at ifspm.uzh.ch  Mon Sep 27 11:44:50 2010
From: daniel.sabanesbove at ifspm.uzh.ch (=?ISO-8859-1?Q?Daniel_Saban=E9s_Bov=E9?=)
Date: Mon, 27 Sep 2010 11:44:50 +0200
Subject: [R-pkgs] Bayesian Fractional Polynomials package "bfp" on CRAN
Message-ID: <4CA06792.70607@ifspm.uzh.ch>

  Fractional polynomials ("FPs") are an automatic way of fitting 
non-linear, parametric effects. The R-package mfp implements a 
frequentist inference approach for FP models. Recently, we have proposed 
a Bayesian inference approach for normal FP models, which is based on 
the quasi-default hyper-/g/ prior for the regression coefficients [1]. 
This approach is implemented in the new R-package "bfp".

The R-package bfp (current version: 0.0-17) is now available on CRAN [2].
The current development version is (still) available on R-Forge [3].

For a quick start try:

install.packages("bfp")
library(bfp)
example(BmaSamples)

and if you have more time, to reproduce results from the paper [1]:

demo(ozone)

Questions, suggestions or critique are very welcome!

Best regards,
Daniel

[1] Statistics & Computing paper: 
http://dx.doi.org/10.1007/s11222-010-9170-7
[2] CRAN: http://cran.r-project.org/web/packages/bfp/index.html
[3] R-Forge: http://r-forge.r-project.org/projects/bfp/


From Max.Kuhn at pfizer.com  Wed Sep 29 17:01:31 2010
From: Max.Kuhn at pfizer.com (KuhnA03)
Date: Wed, 29 Sep 2010 11:01:31 -0400
Subject: [R-pkgs] caret package version 4.63
Message-ID: <C8C8CD0B.B7B0%Max.Kuhn@pfizer.com>

Version 4.63 of the caret package is now on CRAN.

caret can be used to tune the parameters of predictive models using
resampling, estimate variable importance and visualize the results.
There are also various modeling and "helper" functions that can be
useful for training models.

caret has wrappers to over 99 different models for classification
and regression. See the package vignettes or:

  http://user2010.org/slides/Kuhn.pdf
  http://www.jstatsoft.org/v28/i05

for more details. 


Since the last posting to the list:

 - wrappers for a number of new models were added, notably gam
   models (from both the gam and mgcv packages) and logic trees

 - when resampling with train(), class probabilities can now be
   used to calculate performance (such as the AUC of an ROC curve).
   A basic summary function, twoClassSummary(), can be used to
   calculate sensitivity, specificity and the ROC AUC.

 - repeated k-fold CV and the bootstrap 632 technique are available
   in train()

 - pre-processing can not be used within each resampling iteration
   within train().

 - a function for independent component regression (icr) was added

 - the class for aggregating and visualization resampling results
   (resamples) has been enhanced with more visualization methods.
   The class can also work with caret's feature selection routines
   (rfe() and sbf())

 - the print method for train() has been improved

 - functions can be now be passed to the tuneGrid argument in
   train()

 - an existing function that catalogs the existing models available
   within train(), called modelLookup(), is now available to the
   users

 - when parallel processing, more computations are being executed
   in the worker processes than previously (e.g. performance calcs)

The NEWS file has the blow-by-blow list of changes.


The package homepage is

  https://r-forge.r-project.org/projects/caret/

Send questions, collaborations, comments etc to max.kuhn at pfizer.com.

Max


From jens.oehlschlaegel at truecluster.com  Fri Oct  1 17:36:04 2010
From: jens.oehlschlaegel at truecluster.com (=?UTF-8?Q? Jens_Oehlschl=C3=A4gel ?=)
Date: Fri, 1 Oct 2010 17:36:04 +0200 (CEST)
Subject: [R-pkgs] ff version 2.2.0
Message-ID: <375872627.1570539.1285947364767.JavaMail.fmail@mwmweb018>

Dear R community,

The next release of package ff is available on CRAN. With kind help of Brian Ripley it now supports the Win64 and Sun versions of R. It has three major functional enhancements:

a) new fast in-memory sorting and ordering functions (single-threaded)
b) ff now supports on-disk sorting and ordering of ff vectors and ffdf dataframes
c) ff integer vectors now can be used as subscripts of ff vectors and ffdf dataframes

a) is achieved by careful implementation of NA-handling and exploiting context information
b) although permanently stored, sorting and ordering of ff objects can be faster than the standard routines in R
c) applying an order to ff vectors and ffdf dataframes is substantially slower than in pure R because it involves disk-access AND sorting index positions (to avoid random access). 

There is still room for improvement, however, the current status should already be useful. I run some comparisons with SAS (see end of mail): 
- both could sort German census size (81e6 rows) on a 3GB notebook
- ff sorts and orders faster on single columns
- sorting big multicolumn-tables is faster in SAS

Win64 binaries and version 2.2.1 supporting Sun should appear during the next days on CRAN. For the impatient: checkout from r-forge with revision 67 or higher.
Non-Windows users: please note that you need to set appropriate values for options 'ffbatchbytes' and 'ffmaxbytes' yourself.

Note that  virtual window support is deprecated now because it leads to too complex code. Let us know if you urgently need this and why.

Feedback, ideas and contributions appreciated. To those who offered code during the last months: please forgive us that integrating and documenting was not possible with this release. 


Jens & Daniel



P.S. NEWS


		CHANGES IN ff VERSION 2.2.0


NEW FEATURES

    o	ff now supports the 64 bit Windows and Sun versions of R 
    	(thanks to Brian Ripley)
    o	ff now supports sorting and ordering of ff vectors and dataframes
    	(see ramsort, ffsort, ffdfsort, ramorder, fforder, ffdforder)
    o	ff now supports ff vectors as subscripts of ff objects
    	(currently positive integers only, booleans are planned)
    o	New option 'ffmaxbytes' which allows certain ff procedures like sorting
    	using larger limit of RAM than 'ffbatchbytes' in chunked processing.
    	Such higher limit is useful for (single-R-process) sorting compared to
    	some multi-R-process chunked processing. It is a good idea to reduce 
    	'ffmaxbytes' on slaves or avoid ff sorting there completely.
    o	New generic 'pagesize' with method 'pagesize.ff' which returns the 
    	current pagesize as defined on opening the ff object.


USER VISIBLE CHANGES

    o	[.ff now returns with the same vmode as the ff-object
    o	Certain operations are faster now because we worked around 
    	unnecessary copying triggered by many of R's assignment functions.
    	For example reading a factor from a (well-cached) file is now 20%
    	faster and thus as fast as just creating this factor in-RAM using 
    	levels()<- and class()<- assignments. 
    	(consider this tuning temporary, hoping for a generic fix in base R)
    o	ff() can now open files larger than .Machine$integer.max elements
    	(but gives access only to the first .Machine$integer.max elements)
    o	ff now has default pattern NULL translating to the pattern in 'filename'
        (and only to the previous default 'ff' if no filename is given)
    o	ff now sets the pattern in synch with a requested 'filename'
    o	clone.ff now always creates a file consistent with the previous pattern
    o	clone.ff now always creates a finalizer consistent with the file location
    o	clone.ffdf has a new argument 'nrow' which allows to create an empty copy 
        with a different number of rows (currently requires 'initdata=NULL')
    o	clone.default now deep-copies lists and atomic vectors
    	
    
DEPRECATED

    o	virtual window support is deprecated. Let us know if you urgently need this and why.
   

BUG FIXES

    o	read.table.ffdf now also works if transFUN filters and returns less rows


BUG FIXES at 2.1.4

    o	[<-.ffdf no longer does calculate the number of elements in an ffdf
    	which could led to an integer overflow


BUG FIXES at 2.1.3


    o	ffsafe now always closes ffdf objects - also partially closed ones

    o	ffsafe no longer passes arguments 'add' and 'move' to 'save'

    o	ffsafe and friends now work around the fact that under windows getwd()
    	can report the same path in upper and lower case versions. 



    CHANGES IN bit VERSION 1.1.5


NEW FEATURES

    o new utility functions setattr() and setattributes() allow to set attributes 
      by reference (unlike attr()<- attributes()<- without copying the object)

    o new utility unattr() returns copy of input with attributes removed


USER VISIBLE CHANGES

    o certain operations like creating a bit object are even faster now: need 
      half the time and RAM through the use of setattr() instead of attr()<-

    o [.bit now decorates its logical return vector with attr(,'vmode')='boolean',
      i.e. we retain the information that there are no NAs.


BUG FIXES

    o .onLoad() no longer calls installed.packages() which substantially 
      improves startup time (thanks to Brian Ripley)




P.P.S. Below are some timings in seconds at 3e6, 9e6, 27e6 and 81e6 elements from a Lenovo 410s notebook 
(3GB RAM, i5 m520, 2 real cores, 4 hyperthreaded cores, SSD drive, Windows7 32bit)

Legend for software
  ram:  new in-ram inplace operations receiving enough RAM to optimize for speed, not for memory
   ff:  new on-disk operations limiting RAM for this operation at ~500GB
    R:  timings from standard sort() and order()
  SAS:  timings from SAS 9.2 allowing for multithreaded sorting


Legend for type of random data
  rboolean:  bi-boolean with 50% FALSE and TRUE
  rlogical:  tri-boolean with 33% NA, FALSE and TRUE
    rubyte:  integers from 0..255
     rbyte:  33% NA and 67% -127..127
   rushort:  integers from 0..65535
    rshort:  33% NA and 67% -32767..32767
 ruinteger:  50% NA and 50% integers
  rinteger:  random integers
  rusingle:  50% NA and 50% singles
   rsingle:  random singles
  rudouble:  50% NA and 50% doubles
   rdouble:  doubles
   rfactor:  factor with 64 levels of length 66 (being different at bytes 65 and 66)
     rchar:  64 strings of length 66 (being different at bytes 65 and 66)


Legend for abbreviations
  OOM:  out of memory
  OOD:  out of disk
   NT:  not timed because too slow
   NA:  not available
   


Results for sorting a single column
=====================================

, , 3e6

    rboolean rlogical rubyte rbyte rushort rshort ruinteger rinteger rusingle rsingle rudouble rdouble rfactor rchar
ram     0.02     0.03   0.02  0.04    0.02   0.02      0.17     0.11     0.66    0.36     0.66    0.36    0.03    NA
ff      0.25     0.33   0.22  0.25    0.28   0.26      0.38     0.30     1.02    0.65     0.92    0.67    0.39    NA
R         NA     0.35     NA    NA      NA     NA      0.83     0.54       NA      NA     1.28    0.90   64.83 51.20
SAS       NA       NA     NA    NA      NA     NA      1.61     1.32       NA      NA     1.57    1.29      NA 17.01

, , 9e6

    rboolean rlogical rubyte rbyte rushort rshort ruinteger rinteger rusingle rsingle rudouble rdouble rfactor rchar
ram     0.04     0.07   0.03  0.08    0.03   0.07      0.50     0.31     1.88    0.97     1.87    0.97    0.04    NA
ff      0.72     0.93   0.61  0.73    0.84   0.75      1.08     0.86     2.68    1.62     2.57    1.67    0.78    NA
R         NA     0.90     NA    NA      NA     NA      2.84     1.78       NA      NA     3.51    2.12      NA    NT
SAS       NA       NA     NA    NA      NA     NA      4.99     3.90       NA      NA     4.91    4.48      NA 62.76

, , 27e6

    rboolean rlogical rubyte rbyte rushort rshort ruinteger rinteger rusingle rsingle rudouble rdouble rfactor  rchar
ram     0.10     0.24   0.09  0.23    0.11   0.23      1.58     1.00     6.06    3.15     6.00    3.23    0.16     NA
ff      2.19     2.98   1.92  2.21    2.56   2.31      3.22     2.68     8.49    5.18     8.10    5.35    2.58     NA
R         NA     2.72     NA    NA      NA     NA      9.69     5.80       NA      NA    12.34    6.97      NA     NT
SAS       NA       NA     NA    NA      NA     NA     17.02    12.67       NA      NA    17.05   14.07      NA 176.63

, , 81e6

    rboolean rlogical rubyte rbyte rushort rshort ruinteger rinteger rusingle rsingle rudouble rdouble rfactor rchar
ram     0.27     0.67   0.28  0.67    0.33   0.72      5.58     3.23       NA      NA       NA      NA    0.49    NA
ff      6.56     9.06   5.93  6.88    8.52   7.15     10.70     8.54    51.35   28.98    70.20   44.13    7.91    NA
R        OOM      OOM    OOM   OOM     OOM    OOM       OOM      OOM      OOM     OOM      OOM     OOM     OOM   OOM
SAS       NA       NA     NA    NA      NA     NA     61.45    44.94       NA      NA    63.14   46.56      NA   OOD




Results for calculating the order on a single column
====================================================

, , 3e6

    rboolean rlogical rubyte rbyte rushort rshort ruinteger rinteger rusingle rsingle rudouble rdouble rfactor  rchar
ram     0.05     0.07   0.04  0.07    0.09   0.11      0.92     0.53     1.46    0.81     1.31    0.64    0.06     NA
ff      0.14     0.19   0.77  0.58    0.87   0.67      1.04     0.60     1.66    0.81     1.43    0.85    0.74     NA
R         NA     3.23     NA    NA      NA     NA      4.57     4.07       NA      NA     5.27    4.61    4.59 193.75
SAS       NA       NA     NA    NA      NA     NA      1.86     1.48       NA      NA     1.63    1.39      NA  16.83

, , 9e6

    rboolean rlogical rubyte rbyte rushort rshort ruinteger rinteger rusingle rsingle rudouble rdouble rfactor rchar
ram     0.16     0.21   0.17  0.20    0.30   0.28      3.07     1.61     4.24    2.16     4.22    2.19    0.19    NA
ff      0.48     0.51   2.45  1.84    2.91   2.15      3.38     1.92     4.72    2.48     4.54    2.45    1.91    NA
R         NA    12.31     NA    NA      NA     NA     17.02    15.56       NA      NA    16.96   15.47      NT    NT
SAS       NA       NA     NA    NA      NA     NA      6.71     5.97       NA      NA     6.25    5.41      NA 59.27

, , 27e6

    rboolean rlogical rubyte rbyte rushort rshort ruinteger rinteger rusingle rsingle rudouble rdouble rfactor  rchar
ram     0.51     0.67    0.5  0.69    0.92   0.94      9.89     5.31    15.13    7.69    15.15    7.70    0.58     NA
ff      1.33     1.51    7.6  5.77    9.25   6.79     10.72     6.12    15.98    8.53    15.96    8.92    5.80     NA
R         NA    46.37     NA    NA      NA     NA     65.57    59.17       NA      NA    63.74   58.37      NT     NT
SAS       NA       NA     NA    NA      NA     NA     21.41    18.77       NA      NA    20.22   18.84      NA 182.74

, , 81e6

    rboolean rlogical rubyte rbyte rushort rshort ruinteger rinteger rusingle rsingle rudouble rdouble rfactor rchar
ram     1.49     2.03    1.5  2.06    3.15   2.98     34.33    17.89       NA      NA       NA      NA    1.90    NT
ff      3.98     4.65   22.9 17.42   30.33  21.82     36.68    20.36    77.16   49.55   125.01   59.27   17.39    NT
R        OOM      OOM    OOM   OOM     OOM    OOM       OOM      OOM      OOM     OOM      OOM     OOM     OOM   OOM
SAS       NA       NA     NA    NA      NA     NA     86.24    70.32       NA      NA    84.40   68.66      NA    NA




Results for sorting all columns of a table with m columns of random double data (without NAs)
=============================================================================================


, , 3e6

ncol   1    2    5   10    20
SAS 1.65 1.83 3.71 6.90 14.06
ff  1.97 2.37 3.75 6.21 10.86
R   4.70 5.67 5.65 6.46  8.06

, , 9e6

ncol    1     2     5    10    20
SAS  5.18  6.70 14.02 19.25 41.65
ff   6.38  7.96 12.12 19.58 45.43
R   18.86 19.20 20.58   OOM   OOM

, , 27e6

ncol    1     2     5    10     20
SAS 17.79 19.52 35.03 83.30 142.09
ff  22.68 25.79 46.25 87.55 157.62
R   65.56   OOM   OOM   OOM    OOM

, , 81e6

ncol     1      2      5     10     20
SAS  64.78  83.39 143.59 242.23 408.72
ff  167.52 220.03 324.03 502.42 884.03
R      OOM    OOM    OOM    OOM    OOM


From mfay at niaid.nih.gov  Wed Oct  6 15:13:22 2010
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 6 Oct 2010 09:13:22 -0400
Subject: [R-pkgs] update to exact2x2 package
Message-ID: <E71B6F8FD9DA77498BED796B4E35362C02D7ECDF83@NIHMLBX01.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20101006/91d99fe5/attachment.pl>

From oscar.perpinan at upm.es  Fri Oct  8 10:25:34 2010
From: oscar.perpinan at upm.es (Oscar =?UTF-8?B?UGVycGnDsWFu?= Lamigueiro)
Date: Fri, 8 Oct 2010 10:25:34 +0200
Subject: [R-pkgs] solaR: version 0.20
Message-ID: <20101008102534.79e4da21@OPL-EUITI>

Hello,

I'd like to announce the availability of the version 0.20 of the
"solaR" package. It provides a set of calculation methods of solar
radiation and performance of photovoltaic systems. The package has
been uploaded to CRAN under the GPL-3 license.  

The most important changes included in this version are:  

*The package is now almost entirely designed with S4 classes and
methods. 
*The time series objects are constructed with the 'zoo'
package. 
*Most of the functions and arguments have been renamed in
order to ease the understanding by international users.
*Two new functions have been included for the statistical analysis of
a PV plant composed of several systems.
*The package dependencies have been optimized.
*Several new small functions for date-time calculations are now
available. 
*Several bugs have been corrected.  

An introduction to this package is available as a vignette (both in
English and in Spanish). Moreover, a handbook of photovoltaic systems (in Spanish) is available at
http://procomun.wordpress.com/documentos/libroesf/.  

Best regards.  

Oscar Perpi??n Lamigueiro
Electrical Engineering Department
EUITI-UPM


From dwinsemius at comcast.net  Sat Oct  9 03:08:55 2010
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 8 Oct 2010 21:08:55 -0400
Subject: [R-pkgs]  solaR: version 0.20
References: <mailman.1.1286586175.31653.r-help@r-project.org>
Message-ID: <D833E179-7591-433E-8FDE-DEBCA4DBEB80@comcast.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20101008/e887d65f/attachment.pl>

From source at sharpsteen.net  Sat Oct 16 00:22:26 2010
From: source at sharpsteen.net (Charlie Sharpsteen)
Date: Fri, 15 Oct 2010 15:22:26 -0700
Subject: [R-pkgs] Announcing TikZ Device 0.5.2
Message-ID: <AANLkTikeuv8Adbc9tJ_xCzr5rzUwEQdrGh7+Vs3duj+m@mail.gmail.com>

Version 0.5.2 of the tikzDevice is now available on CRAN in source
form.  Binary builds will become available in the next few days.  This
build supersedes 0.5.1, which was just released a couple of days ago.

Version 0.5.2 is a recommended upgrade for all users as it contains
fixes a major issue:

- Two buffer overflow conditions were found which can cause R to
behave extremely erratically if triggered.

  * The first buffer overflow only affects users of tikzDeivce 0.5.1
who use tikz( ..., sanitize = TRUE ).  The sanitize option to tikz()
was added in 0.5.0, but was non-functional due to a bug.

  * The second buffer overflow affects users of any version of
tikzDevice.  However, it only occurs when bold italic text is used in
plots which is a fairly rare occurrence.

Many thanks to Mikhail Titov for taking the time to file bug reports
that led to the discovery of this issues.

Additionally, the vignette and polypath() functions have been
updated/added to support changes in R 2.12.0 and support for Solaris
was improved.


For more info on the tikzDevice, please visit us on GitHub:

  http://github.com/Sharpie/RTikZDevice


The combined changelog for version 0.5.1 and 0.5.2 is as follows:

---

### Version: 0.5.2

---

#### Contributors
The following people contributed to this release of the tikzDevice:

- mlt for reporting problems with the Sanitize function that led to
the discovery of two situations where buffer overflows were occurring.


#### Bug Fixes

- Fixed buffer overflows and memory leaks related to string pointers
in tikzDevice.c.

- Fixed compilation of the tikzDevice vignette under R 2.12.0.

- Reduced the verbosity of the package startup message.


---

### Version: 0.5.1

---

#### Bug Fixes

- A stub function has been added so that the `polypath()` function
introduced in R 2.12.0 won't crash the device.

- Fixed bug where no string output was shown when the sanitize=TRUE
option was used.

- The path to a LaTeX compiler returned by `Sys.which()` is now
checked by `file.access()` to check that it is actually an executable
and not an error message.  This fixes issues arising from
`Sys.which()` on Solaris.

- On UNIX platforms, `/usr/texbin/pdflatex` is added to the end of the
list of places to search for a LaTeX compiler.  This should help
people using R.app on OS X find a LaTeX compiler without having to
manually specify it.

- `tikz()` produces a better error message when it cannot open a file
for output.

- In the event that LaTeX crashes during a metric calculation, the
LaTeX log output is echoed using `message()` instead of `cat()`.  This
makes it show up during operations that supperss `cat()` output such
as `R CMD build` and `R CMD Sweave`.


From mauricio.zambrano at jrc.ec.europa.eu  Mon Oct 18 12:15:41 2010
From: mauricio.zambrano at jrc.ec.europa.eu (Mauricio Zambrano)
Date: Mon, 18 Oct 2010 12:15:41 +0200
Subject: [R-pkgs] new packages: hydroTSM 0.2-0 and hydroGOF 0.2-0
Message-ID: <1287396941.9923.1.camel@D01RI1002244.h07.jrc.it>

Dear R and hydrological community,

The first public (beta) release of two new R packages are now available
on CRAN:


############
# hydroTSM #
############

1) hydroTSM is a package for management and analysis of hydrological
time series:

http://cran.r-project.org/web/packages/hydroTSM/

hydroTSM includes S3 functions for management, analysis, interpolation
and plot of hydrological time series, mainly oriented to hydrological
modelling tasks. So far, it only works with daily / monthly / seasonal /
annual time series.

The focus of this package has been put in providing a collection of
functions useful for the daily work of hydrologists, and although an
effort was made to optimise each function as much as possible,
functionality has had priority over speed.


############
# hydroGOF #
############

2) hydroGOF is a package for comparison of simulated and observed
hydrological time series:

http://cran.r-project.org/web/packages/hydroGOF/

hydroGOF includes S3 functions implementing both statistical and
graphical goodness-of-fit measures between observed and simulated
values, mainly oriented to be used during the calibration, validation,
and application of hydrological models. 

Missing values in observed and/or simulated values can be removed before
computations. 


################
# Installation #
################

*) From the R console:
> # Required packages:
> install.packages(c("zoo", "gstat", "automap"))

> # Suggested packages:
> install.packages(c("sp", "maptools", "e1071", "rgdal"))

> # hydroTSM
> install.packages("hydroTSM")

> # hydroGOF
> install.packages("hydroGOF")

################
#    Links     #
################

http://meetingorganizer.copernicus.org/EGU2010/EGU2010-13008.pdf
http://www.slideshare.net/posterVienna/egu2010-ra-statisticalenvironmentfordoinghydrologicalanalysis


################
# Beta Notice  #
################

hydroTSM and hydroGOF have been tested for more than a year, but its
development began in early 2008, during the Ph.D programme of the author
at the University of Trento. 
Both packages are reasonably stable, but they are currently flagged as
beta work, in order to get some feedback from a broader audience.


Bugs / comments / questions / collaboration of any kind are very
welcomed, and in particular, datasets that can be included in the
packages for academic purposes.


Kind regards,

Mauricio Zambrano-Bigiarini

=======================================================
FLOODS Action
Land Management and Natural Hazards Unit
Institute for Environment and Sustainability
European Commission, Joint Research Centre
=======================================================
Linux user #454569 -- Ubuntu user #17469
=======================================================
"Learning is not attained by chance, 
it must be sought for with ardor and 
attended to with diligence."
(Abigail Adams, 1744 - 1818)
=======================================================
DISCLAIMER:\ "The views expressed are purely those of th...{{dropped:6}}


From jfox at mcmaster.ca  Mon Oct 18 15:18:22 2010
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 18 Oct 2010 09:18:22 -0400
Subject: [R-pkgs] OpenMX structural equation software
Message-ID: <001401cb6ec6$f04a4410$d0decc30$@ca>

Dear R users,

The OpenMx developer team takes great pride in announcing the availability
of OpenMx 1.0. The team would like to express its gratitude to the large
number of beta-testers who have helped us improve the code. Thank you.

OpenMx is a free suite of R functions and a estimation back-end that
supports fitting a wide variety of structural equation models including
multiple groups, full information ML for missing data, ordinal estimation
with thresholds, multilevel, latent class, and mixture distributions to name
a few.

The most current version of OpenMx (for Mac, Windows and most Linux
variants) may be downloaded by issuing the following R command:

source('http://openmx.psyc.virginia.edu/getOpenMx.R')

OpenMx is not currently hosted on CRAN due to a license restriction on the
one portion of our code, an optimizer, that was not written by the project.
We hope to remedy this situation reasonably soon as we are working on an
open source version of the optimizer.  The remainder of the project is
licensed under Apache 2.0 and the source code may be downloaded from the
OpenMx website and used for any purpose you wish.  We do hope that you wish
to contribute improvements or bug fixes back to the project, but we do not
require it.

The OpenMx website is http://openmx.psyc.virginia.edu, where we host a set
of manuals and tutorials, a wiki, and a set of user forums where issues to
do with OpenMx and SEM in general can be discussed.  We require free
registration in order to post to the forums or wiki so as to slow down the
spambots, but everything else is available without registration.

OpenMx has been in development for 3 years.  The OpenMx beta test program
began in October 2009. Since then, we have improved the interface and sped
up the optimization times considerably. Many new features are in the works
and we encourage you to post to the Wish List forum so that we know what you
would like to see.

>From this point on, we will maintain two binary releases: a stable release
numbered as 1.x.x, and a development binary with the latest and greatest
features and bug-fixes, numbered with the current revision number (e.g.,
1448). The development of OpenMx is on-going and we expect that new
development binaries will be released often. The stable releases are likely
to be updated every few months or so.

For the OpenMx team.

John

--------------------------------
John Fox
Senator William McMaster 
  Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox


From r at nurometic.com  Wed Oct 27 02:48:00 2010
From: r at nurometic.com (Nurometic R Help)
Date: Tue, 26 Oct 2010 20:48:00 -0400
Subject: [R-pkgs] Introducing the futile.paradigm,
	a package for functional	dispatching in R
Message-ID: <1288140480.31580.46.camel@localhost>

Hello useRs,

I'm pleased to announce the general availability of the R package
futile.paradigm, which is a language extension that implements
functional dispatching in R. This is an alternative to the current
object-oriented styles, replacing them with a functional programming
style that provides a clean, fine-grained declarative syntax for
function definitions. The core of the package consists of two operators,
%when% and %must% that implement guard statements that define when a
function variant is executed and post assertions that define the
criteria for success on individual functions. The package also
implements custom type constructors, which are declared using the
'create' function, which is predefined in the futile.paradigm.

Here are some examples to give you an idea of the syntax.

# Factorial function in the 'fac' namespace
fac.0 %when% (x == 0)  # guard statement
fac.0 <- function(x) 1 # function variant

fac.n %when% (x > 0)       # guard statement
fac.n %must% (result >= x) # post-assertion
fac.n <- function(x) x * fac(x-1) # function variant

> fac(4)
[1] 24
> fac(-2)
Error in UseFunction("fac", ...) : No valid function for 'fac/1' : -2

# Numerical optimization with custom type constructors
# Define a function and its derivatives
fx <- function(x) x^2 - 4
f1 <- function(x) 2*x
f2 <- function(x) 2

# Define the numerical optimization harness
converged <- function(x1, x0, tolerance=1e-6) abs(x1 - x0) < tolerance
minimize <- function(x0, algo, max.steps=100)
{
  step <- 0
  old.x <- x0
  while (step < max.steps)
  {
    # Calls abstract function 'iterate' with definitions below
    new.x <- iterate(old.x, algo)
    if (converged(new.x, old.x)) break
    old.x <- new.x
  }
  new.x
}

# Implement Newton-Raphson
iterate.nr %when% (algo %isa% NewtonRaphson)
iterate.nr <- function(x, algo) x - algo$f1(x) / algo$f2(x)

# Implement Gradient Descent
iterate.gd %when% (algo %isa% GradientDescent)
iterate.gd <- function(x, algo) x - algo$step * algo$f1(x)

# Create a custom type constructor
create.GradientDescent <- function(T, f1, step=0.01) list(f1=f1,step=step)

> algo <- create(GradientDescent, f1)
> minimize(3, algo)
[1] 3.677989e-06

# Execute using a dynamic type constructor
> algo <- create(NewtonRaphson, f1=f1,f2=f2)
> minimize(3, algo)
[1] 0

More documentation is available in the package help files and also at
https://nurometic.com/quantitative-finance/futile/paradigm

The current version is version 1.2.0 and is available on CRAN.

Regards,
Brian Lee Yung Rowe


From anup.parikh at gmail.com  Sun Oct 31 01:07:05 2010
From: anup.parikh at gmail.com (Anup Parikh)
Date: Sat, 30 Oct 2010 16:07:05 -0700
Subject: [R-pkgs] Introducing Red-R: visual programming for R
Message-ID: <AANLkTimOH2ehns=payiUSq7eESewn7Dnti-AXpw21YTJ@mail.gmail.com>

Dear R-Packages Mailing List,

The Red-R development team would like to introduce Red-R: a user
friendly visual programming and data analysis framework for R.

Red-R makes the advanced functionality of R available to the
non-computational users by hiding the computational complexity behind
a visual programming interface. In addition, Red-R improves analysis
readability and data sharing to facilitates better communication in
inter-disciplinary teams.

Analyses are performed by visually linking a series of widgets
together that read, manipulate, and interactively display data. These
pipelines, representing both the data and analysis, can be easily
shared with others. Red-R can also generate reports in odt, html and
latex to help better document and share results.

Red-R is an extension of Orange (http://www.ailab.si/orange), a data
mining framework written in Python and Qt. Red-R accesses all the
functionality and data in R, using the Python interface for R provided
by RPy2 (http://rpy.sourceforge.net). This framework is highly
flexible and can be extended to include virtually all the functionally
R packages currently offer.

If you maintain an R package and are interested in created a GUI
interface please don't hesitate to contact us. We would be happy to
provide any help in creating the Red-R packages.

We would like to thank all those that helped test the software over
the last year and a half and welcome any feedback/suggestions from the
R community.

Please visit the Red-R webpage (www.red-r.org) for more information.

Thank you,
Red-R Development Team
Anup Parikh (anup at red-r.org)
Kyle R. Covington (kyle at red-r.org)


From lawrence.michael at gene.com  Fri Nov  5 23:23:38 2010
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 5 Nov 2010 15:23:38 -0700
Subject: [R-pkgs] RGtk2 2.20.x
Message-ID: <AANLkTinqjw_B7TkMJ++bQRKJW+z8ofsFKgPUQHk5fsOY@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20101105/702f38f2/attachment.pl>

From grolemund at gmail.com  Wed Nov 17 16:31:08 2010
From: grolemund at gmail.com (Garrett Grolemund)
Date: Wed, 17 Nov 2010 09:31:08 -0600
Subject: [R-pkgs] lubridate v2.2 available on cran
Message-ID: <AANLkTikPq_jj2MG5y_mhf1F9iN_aqtY_DnA8WDwbZK4_@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20101117/872a2669/attachment.pl>

From maiagx at gmail.com  Wed Nov 17 00:56:26 2010
From: maiagx at gmail.com (Charlotte Maia)
Date: Wed, 17 Nov 2010 12:56:26 +1300
Subject: [R-pkgs] The *makesweave* Package for Using Make with Sweave
	Efficiently
Message-ID: <AANLkTimayH-yB4qD+62yNELeMarZvA+54ULHsi=MF_nX@mail.gmail.com>

Hi R Community,

I've just completed the initial version of (Linux-based) R package,
called *makesweave*, for using Make to build Sweave documents
efficiently.

The idea is that R is started once (per shell) as a background
process, then Make builds each Sweave source file, using the same R
instance.

More information in the package vignette.

Feedback very welcome.


regards
-- 
Charlotte Maia
http://sites.google.com/site/maiagx


From xie at yihui.name  Fri Dec  3 16:11:02 2010
From: xie at yihui.name (Yihui Xie)
Date: Fri, 3 Dec 2010 09:11:02 -0600
Subject: [R-pkgs] formatR update (0.1-5)
Message-ID: <AANLkTikkyBcvx6qdt-9w9y-YFbTiqStqg23=PZASqdz6@mail.gmail.com>

In formatR 0.1-5, the dependency on the gWidgets and animation
packages are removed. The GUI by gWidgets is optional now.

Meanwhile, the function tidy.source() has been moved from the
animation package to this package.

> library(formatR)
> tidy.source(textConnection('
  # rotation of the word "Animation"
  # in a loop; change the angle and color
  # step by step
  for (i in 1:360) {
  # redraw the plot again and again
  plot(1,ann=FALSE,type="n",axes=FALSE)
  # rotate; use rainbow() colors
  text(1,1,"Animation",srt=i,col=rainbow(360)[i],cex=7*i/360)
   # pause for a while
   Sys.sleep(0.01)}
'))

# rotation of the word 'Animation'
# in a loop; change the angle and color
# step by step
for (i in 1:360) {
    # redraw the plot again and again
    plot(1, ann = FALSE, type = "n", axes = FALSE)
    # rotate; use rainbow() colors
    text(1, 1, "Animation", srt = i, col = rainbow(360)[i], cex = 7 * i/360)
    # pause for a while
    Sys.sleep(0.01)
}

For more information, see http://yihui.name/en/2010/12/formatr-update-0-1-5/

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From source at sharpsteen.net  Tue Dec  7 03:51:02 2010
From: source at sharpsteen.net (Charlie Sharpsteen)
Date: Mon, 6 Dec 2010 18:51:02 -0800
Subject: [R-pkgs] tikzDevice 0.5.3 released to CRAN
Message-ID: <AANLkTi=LY4ryXHLmrJ7pu_+t53rL_4E6rH=b6Q2c_-ZE@mail.gmail.com>

A new release of the tikzDevice was posted to CRAN today and will soon
be available from mirrors worldwide.  The tikzDevice package provides
a graphics device that translates R graphics into TeX code suitable
for seamless integration with LaTeX documents.  Version 0.5.3 of the
tikzDevice is a bugfix release that addresses clarity of warning/error
messages and enhances the handling of characters that are special to
LaTeX.  Details are contained in the changelog at the end of this
announcement.

Barring the discovery of significant issues, the next release of the
tikzDevice should be version 0.6.0.  This release is planned to
contain new functionality drawn from one or both of the following
development efforts:

- Support for UTF8 plot text when tikzDevice is used with the XeTeX engine.

- Support for the raster and polypath additions to the R graphics engine.


---

### Version: 0.5.3

---

#### Bug Fixes

- R 2.12.x now throws a warning message when shell commands run via `system()`
  have non-zero exit conditions.  The metric calculation runs LaTeX on a file
  containing an \@@end command.  This causes a non zero exit condition.  The end
  result was that users were getting spammed by warning messages.  These
  messages have been gagged for now and a better way to run LaTeX such that a
  non-zero condition can meaningfully indicate an error is being investigated.

- The range of characters the default sanitizer looks for has been extended.  It
  should now process all characters that are special to TeX with the exception
  of backslashes.  Documentation has been improved.

- Detection of failed string metric calculations has been strengthened and the
  resulting error message has been improved.


Happy TeXing!

-The tikzDevice team


From cameron.bracken at gmail.com  Wed Dec  8 00:26:40 2010
From: cameron.bracken at gmail.com (Cameron Bracken)
Date: Tue, 7 Dec 2010 16:26:40 -0700
Subject: [R-pkgs] pgfSweave 1.1.1 Released
Message-ID: <AANLkTikApA4_FpOi=PGsHZD8GM=UScK0ZRCo92dgEC++@mail.gmail.com>

The next release of?pgfSweave?is now on CRAN! pgfSweave has seen some
significant changes in the past couple of months.

The main new features are:

- Automatic code highlighting via the?highlight?package. This can be
turned off with the new `highlight`?option.
- "Tidying" of source code output via the?tidy?option.
- Access to?tikzDevice?sanitization through a code chunk option?`sanitize`
- Automatic addition of the?\pgfrealjobname?command if it does not
exist similarly to the addition of the?\usepackage{Sweave}?line.
- Setting tex.driver=latex will now (in addition to working) generate
an eps file

And of course bug fixes:

- Fixes for bunches of issues related to the changes in Sweave in R
2.12. I think these issues are now resolved (fingers crossed)
- keep.source?actually works now.

See the?NEWS?file for the complete list of changes and the?vignette
for information on now to use the new options.

Cheers!

-Cameron


From ggrothendieck at gmail.com  Mon Dec 13 16:02:49 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 13 Dec 2010 10:02:49 -0500
Subject: [R-pkgs] batchfiles 0.6-0
Message-ID: <AANLkTinz1NDT9Y=zsnBZx_DqzkAcTCa177hmOz41Fq4r@mail.gmail.com>

batchfiles is a set of batch, javascript and HTML
Application files that are useful for running R and
associated programs on Windows.

Version 0.6-0 updates them for the new architecture
specific directory structure in R 2.12.0 .

A few of the lesser used utilities have been dropped.

Each batchfile is self contained.  To install just
place all or just any that you wish to use anywhere on
your path.  The batch command:

	path

will show you which folders are on your path.


DOWNLOAD

They can be downloaded individually from the svn
repository available via the home page or they can be
downloaded all at one in a zip file from CRAN here:

http://cran.r-project.org/contrib/extra/batchfiles/


MORE INFO

More info is available from the home page:

http://batchfiles.googlecode.com


LIST OF PROGRAMS

Legend:
h = no args gives help
0 = common usage is to enter command name without arguments
d = in development
* = all files marked with one star are the same.  Program checks name
by which its called to determine action.
** = all files marked with two stars are the same.  Program checks
name by which its called to determine action.

#Rscript.bat - put at top of R file to make it a batch file (h) (*)
clip2r.js - pastes clipboard into Rgui.  See comments in file for use
from vim. (0)(d)
copydir.bat - copy a library from one version of R to another (h)
el.js - run elevated - Vista and up, e.g. el Rgui  runs R elevated
find-miktex.hta - GUI to find MiKTeX (0)
kopy.bat - copy Rcmd to other batch files (h)(d)
movedir.bat - move library from one version of R to another (h)
R.bat - like R.exe but finds R from registry (0) (*)
Rcmd.bat - like Rcmd.exe but finds R from registry (h) (*)
Rgui.bat - like Rgui.exe but finds R from registry (0) (*)
RguiStart.bat - like Rgui.bat but arg1 defines folder to start R in (*)
Rscript.bat - run .R script (h) (*)
Rterm.bat - like rterm.exe but finds R from registry (h) (*)
Rtidy.bat - reformat a .R file, e.g. Rtidy myfile.R > outfile.R (d)
Rtools.bat - place Rtools on path for remainder of console session (0) (*)
Rversions.bat - list R and set R version in registry, e.g. on Vista:
el cmd/c Rversions R-2.12.0 (0)
show-svn-info.hta - show svn info if current folder is an svn checkout (0)
Stangle.bat - run arg1 through Stangle (h) (**)
Sweave.bat - run arg1 through Sweave (h) (**)

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From markus.gesmann at googlemail.com  Tue Dec 14 08:49:51 2010
From: markus.gesmann at googlemail.com (Markus Gesmann)
Date: Tue, 14 Dec 2010 07:49:51 +0000
Subject: [R-pkgs] googleVis 0.2.2 - Using the Google Visualisation API with R
Message-ID: <D979C3DE-5D6D-47B4-B301-8141BD54A8D3@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20101214/0b9afe1c/attachment.pl>

From d.rizopoulos at erasmusmc.nl  Wed Dec 15 12:21:06 2010
From: d.rizopoulos at erasmusmc.nl (Dimitris Rizopoulos)
Date: Wed, 15 Dec 2010 12:21:06 +0100
Subject: [R-pkgs] package JM -- version 0.8-0
Message-ID: <4D08A4A2.40908@erasmusmc.nl>

Dear R-users,

I'd like to announce the release of the new version of package JM (soon 
available from CRAN) for the joint modeling of longitudinal and 
time-to-event data using shared parameter models. These models are 
applicable in mainly two settings. First, when focus is in the survival 
outcome and we wish to account for the effect of a time-dependent 
covariate measured with error. Second, when focus is in the longitudinal 
outcome and we wish to correct for nonrandom dropout.

New features include:

* for all joint models fitted by JM there is now the option to use a 
pseudo adaptive Gauss-Hermite rule. This is much faster than the default 
option and produces results of equal or better quality. It can be 
invoked via the 'method' argument of jointModel() by specifying "aGH" 
instead of "GH", e.g., 'method = "piecewise-PH-aGH"' instead of 'method 
= "piecewise-PH-GH"'.

* function rocJM() has been added that estimates time-dependent
sensitivity and specificity (and the corresponding time-dependent
ROCs and AUCs) for longitudinal markers under the joint modeling
framework. The function also allows for several predictions rules.

* the new argument 'interFact' added in jointModel() allows the 
specification of interaction terms between the longitudinal outcome and 
baseline covariates.

* the new arguments 'parameterization' and 'derivForm' added in 
jointModel() allow the specification of more general association 
structures between the longitudinal marker and the risk for an event. 
For instance, if a random intercepts and random slopes mixed model has 
been postulated for the longitudinal outcome, then this argument can be 
used to also associate the risk for an event with the subject-specific 
slopes.

* a predict method has been added. Currently this only calculates fitted 
average longitudinal evolutions based on the information provided in the 
'newdata' argument.

More information can be found in the corresponding help files, and 
examples at http://rwiki.sciviews.org/doku.php?id=packages:cran:jm

As always, any kind of feedback (e.g., questions, suggestions, 
bug-reports, etc.) is more than welcome.

Best,
Dimitris

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web: http://www.erasmusmc.nl/biostatistiek/


From jon.clayden at gmail.com  Thu Dec 16 11:44:31 2010
From: jon.clayden at gmail.com (Jon Clayden)
Date: Thu, 16 Dec 2010 10:44:31 +0000
Subject: [R-pkgs] New package for general-purpose global optimisation: "soma"
Message-ID: <AANLkTikHz5ak60tg5BrQeKZPuTyJ5QGpar=v6NV_xT0h@mail.gmail.com>

Dear all,

I'm pleased to announce the release of an R implementation of the
Self-Organising Migrating Algorithm (SOMA), a general-purpose,
stochastic optimisation algorithm. The approach is similar to that of
genetic algorithms, although it is based on the idea of a series of
"migrations" by a fixed set of individuals, rather than the
development of successive generations. It can be applied to any
cost-minimisation problem with a bounded parameter space, and is
robust to local minima. The algorithm was originally developed by Ivan
Zelinka [1].

I have found the algorithm useful in applications, and I hope others
will too. Testing suggests that for some problems SOMA substantially
outperforms comparable methods available for R, such as Differential
Evolution (the "DEoptim" package [2]).

The "soma" package is now on the main CRAN site [3], and is finding
its way onto the mirrors.

All the best,
Jon

--
[1] http://www.ft.utb.cz/people/zelinka/soma/
[2] http://cran.r-project.org/web/packages/DEoptim/index.html
[3] http://cran.r-project.org/web/packages/soma/index.html


From edd at debian.org  Wed Dec 22 22:27:05 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 22 Dec 2010 15:27:05 -0600
Subject: [R-pkgs] Rcpp 0.9.0 and RcppClassic 0.9.0
Message-ID: <19730.27945.984823.70351@max.nulle.part>



===== Summary =====

Version 0.9.0 of the Rcpp package is now on CRAN and its mirrors.  This
release marks another step in the development of the package, and a few key
points are highlighted below.  More details are in the NEWS and ChangeLog
files included in the package.


===== Overview =====

Rcpp is an R package and associated C++ library that facilitates integration
of C++ code in R packages.

The package features a complete set of C++ classes (Rcpp::IntegerVector,
Rcpp:NumericVector, Rcpp::Function, Rcpp::Environment, ...) that makes it
easier to manipulate R objects of matching types (integer vectors, functions,
environments, etc ...).

Rcpp takes advantage of C++ language features such as the explicit
constructor / destructor lifecycle of objects to manage garbage collection
automatically and transparently.  We believe this is a major improvement over
use of PROTECT/UNPROTECT.  When an Rcpp object is created, it protects the
underlying SEXP so that the garbage collector does not attempt to reclaim the
memory.  This protection is withdrawn when the object goes out of
scope. Moreover, users generally do not need to manage memory directly (via
calls to new / delete or malloc / free) as this is done by the Rcpp classes
or the corresponding STL containers.

A few key points about Rcpp:

 - a rich API covering all core R data types including vectors, matrices,
   functions, environments, ... (with the exeception of factors
   which are less useful in C++)

 - seamless (bi-directional) data interchange between R and C++

 - possibility of inline use permitting definition, compilation, linking and
   loading of C++ functions directly from R

 - extensive documentation now covering eight vignettes

 - exception handling and error propagation back to R

 - extensive test suite using RUnit covering over 700 tests

 - extension packages RcppArmadillo and RcppGSL provide easy-to-use
   integration with the Armadillo (linear algebra) and GNU GSL librasries

 - increasing adoption among R users and package developers with now
   twenty packages from CRAN or BioConductor depending on Rcpp

 - support for the legacy 'classic' Rcpp is now provided by the RcppClassic
   package which is being released concurrently with Rcpp 0.9.0 

Several key features were added during the 0.8.* cycles and are described below.


===== Rcpp sugar =====

Rcpp now provides syntactic sugar: vectorised expressions at the C++ level
which are motivated by the corresponding R expressions.  This covers
operators (binary arithmetic, binary logical, unary), functions (producing
single logical results, mathematical functions and d/p/q/r statistical
functions). Examples comprises anything from ifelse() to pmin()/pmax() or 

A really simply example is a function

    SEXP foo( SEXP xx, SEXP yy){
        NumericVector x(xx), y(yy) ;
        return ifelse( x < y, x*x, -(y*y) ) ;
    }

which deploys the sugar 'ifelse' function modeled after the corresponding R
function. Another simple example is

    double square( double x){
        return x*x ;
    }

    SEXP foo( SEXP xx ){
        NumericVector x(xx) ;
        return sapply( x, square ) ;
    }

where use the sugar function 'sapply' to sweep a simple C++ function which
operates elementwise across the supplied vector.

The Rcpp-sugar vignette describes sugar in more detail.


===== Rcpp modules =====

Rcpp modules are inspired by Boost.Python and make exposing C++ functions or
classes to R even easier.  A first illustration is provided by this simple
C++ code snippet

    const char* hello( const std::string& who ){
        std::string result( "hello " ) ;
        result += who ;
        return result.c_str() ;
    }

    RCPP_MODULE(yada){
        using namespace Rcpp ;
        function( "hello", &hello ) ;
    }

which (after compiling and loading) we can access in R as

    yada <- Module( "yada" )
    yada$hello( "world" )

In a similar way, C++ classes can be exposed very easily.

Rcpp modules are also described in more detail in their own vignette.


===== Reference Classes =====

R release 2.12.0 introduced Reference Classes. These are formal S4 classes
with the corresponding dispatch method, but passed by reference and easy to
use. Reference Classes can also be exposed to R by using Rcpp modules.


===== Extension packackages =====

The RcppArmadillo package permits use of the advanced C++ library 'Armadillo,
a C++ linear algebra library aiming towards a good balance between speed and
ease of use, providing integer, floating point and complex matrices and
vectors with lapack / blas support via R. Armadillo uses templates for a
delayed evaluation approach is employed (during compile time) to combine
several operations into one and reduce (or eliminate) the need for
temporaries.  Armadillo is useful if C++ has been decided as the language of
choice, rather than another language like Matlab ? or Octave, and aims to be
as expressive as the former.  Via Rcpp and RcppArmadillo, R users now have
easy access to this functionality. Examples are provided in the RcppArmadillo
package.

The RcppGSL package permits easy use of the GNU Scientific Library (GSL), a
collection of numerical routines for scientifc computing. It is particularly
useful for C and C++ programs as it provides a standard C interface to a wide
range of mathematical routines such as special functions, permutations,
combinations, fast fourier transforms, eigensystems, random numbers,
quadrature, random distributions, quasi-random sequences, Monte Carlo
integration, N-tuples, differential equations, simulated annealing, numerical
differentiation, interpolation, series acceleration, Chebyshev
approximations, root-finding, discrete Hankel transforms physical constants,
basis splines and wavelets.  There are over 1000 functions in total with an
extensive test suite.  The RcppGSL package provides an easy-to-use interface
between GSL data structures and R using concepts from Rcpp. The RcppGSL
package also contains a vignette with more documentation.


===== Legacy 'classic' API =====

Packages still using code interfacing the initial 'classic' Rcpp API are
encouraged to migrate to the new API.  Should a code transition not be
possible, backwards compatibility is provided by the RcppClassic package
released alongside Rcpp 0.9.0.  By including RcppClassic.h and building
against the RcppClassic package and library, vintage code can remain
operational using the classic API.  The short vignette in the RcppClassic
package has more details.


===== Documentation =====

The package contains a total of eight vignettes the first of which provides a
short and succinct introduction to the Rcpp package along with several
motivating examples.


===== Links =====

Rcpp main page: 
    http://dirk.eddelbuettel.com/code/rcpp.html
R-forge project page: 
    http://r-forge.r-project.org/projects/rcpp/
Dirk's blog section about 
    Rcpp: http://dirk.eddelbuettel.com/blog/code/rcpp/
Romain's blog section about Rcpp: 
    http://romainfrancois.blog.free.fr/index.php?category/R-package/Rcpp


===== Support =====

Questions about Rcpp should be directed to the Rcpp-devel mailing list
    https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel



 -- Dirk Eddelbuettel, Romain Francois, Doug Bates and John Chambers
    December 2010




-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From hadley at rice.edu  Fri Dec 24 17:34:03 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 24 Dec 2010 10:34:03 -0600
Subject: [R-pkgs] ggplot2 0.8.9 - Merry Christmas version
Message-ID: <AANLkTi=s=LNzqrTUEZKQ_Gn1jTk+bHLgavHkdQKcMxXG@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

To install or update, run:
install.packages(c("ggplot2", "plyr"))

Find out more at http://had.co.nz/ggplot2, and check out the nearly 500
examples of ggplot in use.  If you're interested, you can also sign up to
the ggplot2 mailing list at http://groups.google.com/group/ggplot2, or track
development at  http://github.com/hadley/ggplot2

ggplot2 0.8.9 (2010-12-24) ----------------------------------------

A big thanks to Koshke Takahashi, who supplied the majority of
improvements in this release!

GUIDE IMPROVEMENTS

* key size: can specify width and height separately

* axis: can partially handle text rotation (issue #149)

* legend: now can specify the direction of element by opts(legend.direction =
  "vertical") or opts(legend.direction = "horizontal"), and legend box is
  center aligned if horizontal

* legend: now can override the alignment of legend box by
  opts(legend.box = "vertical") or opts(legend.box = "horizontal")

* legend: now can override legend title alignment with opts(legend.title.align
  = 0) or opts(legend.title.align = 1)

* legend: can override legend text alignment with opts(legend.text.align = 0)
  or opts(legend.text.align = 1)

BUG FIXES

* theme_*: can specify font-family for all text elements other than geom_text

* facet_grid: fixed hirozontal spacing when nrow of horizontal strip >= 2

* facet_grid: now can manually specify the relative size of each row and column

* is.zero: now correctly works

* +: adding NULL to a plot returns the plot (idempotent under addition)
  (thanks to suggestion by Matthew O'Meara)

* +: meaningful error message if + doesn't know how to deal with an object
  type

* coord_cartesian and coord_flip: now can wisely zoom when wise = TRUE

* coord_polar: fix point division bugs

* facet_grid: now labels in facet_grid are correctly aligned when the number
  of factors is more then one (fixes #87 and #65)

* geom_hex: now correctly applies alpha to fill colour not outline colour
  (thanks to bug report from Ian Fellows)

* geom_polygon: specifying linetype now works (thanks to fix from Kohske
  Takahashi)

* hcl: can now set c and l, and preserves names (thanks to suggestion by
  Richard Cotton)

* mean_se: a new summary function to work with stat_summary that calculates
  mean and one standard error on either side (thanks to contribution from
  Kohske Takahashi)

* pos_stack: now works with NAs in x

* scale_alpha: setting limits to a range inside the data now works (thanks to
  report by Dr Proteome)

* scale_colour_continuous: works correctly with single continuous value (fixes
  #73)

* scale_identity: now show legends (fix #119)

* stat_function: now works without y values

* stat_smooth: draw line if only 2 unique x values, not three as previously *
  guides: fixed #126

* stat_smooth: once again works if n > 1000 and SE = F (thanks to bug report
  from Theiry Onkelinx and fix from Kohske Takahashi)

* stat_smooth: works with locfit (fix #129)

* theme_text handles alignment better when angle = 90


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From billpikounis at gmail.com  Mon Dec 27 14:32:01 2010
From: billpikounis at gmail.com (Bill Pikounis)
Date: Mon, 27 Dec 2010 08:32:01 -0500
Subject: [R-pkgs] First release of package "cg" for comparison of groups
Message-ID: <AANLkTi=eddvdhsGLbosqA-yzE-kgq3F-R9JWVNR=sEdN@mail.gmail.com>

Version 0.9.0, a first release of cg, is published on CRAN and its
mirrors. The "cg" name stands for "compare groups." Its genesis and
evolution are driven by common "in-practice" needs to compare samples,
treatments, administrations, conditions, etc. in medicine research &
development. The current version provides comparisons of unpaired
samples, i.e. a linear model with one factor of at least two levels.
Good data graphs, modern statistical methods, and useful displays of
results are emphasized.

The cg package is developed with the overall goal of a comprehensive
analysis of data when comparison of groups is a primary interest. A
flow of wrapper functions are contained within it to guide the full
analysis and interpretation of the data. The wrapper functions
encompass functions in base R and other packages. Some features
include:

* Housekeeping of log-scale analysis to express multiplicative effects;

* Use of resistant & robust models to accommodate potential outliers;

* Use of accelerated failure time models to handle limits-of-detection values.

Once the package is loaded, the call

> example(cg)

illustrates the package with two included data sets.

A slide deck presentation of the package can be found at
http://user2010.org/slides/Pikounis+Oleynick.pdf . A manuscript on the
package has just recently been submitted to the Journal of Statistical
Software and is under early review.

Bug reports and questions are welcome and can be directed to at "cg at
billpikounis.net"

Thanks to all of the R Development Core Team for base R and its
packages, all authors and maintainers of the packages Hmisc, grid,
lattice, MASS, survival, multcomp, mvtnorm, nlme and VGAM on which cg
depends, and all of the R community for inspiration.

Bill Pikounis and John Oleynick


From mhsatman at yahoo.com  Fri Dec 24 11:12:37 2010
From: mhsatman at yahoo.com (Mehmet Hakan Satman)
Date: Fri, 24 Dec 2010 02:12:37 -0800 (PST)
Subject: [R-pkgs] mcga 1.1 (machine coded genetic algorithms) package
	released
Message-ID: <668024.5432.qm@web120206.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20101224/4598fb4f/attachment.pl>

