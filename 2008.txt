From brian at braverock.com  Tue Jan  1 01:55:07 2008
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 31 Dec 2007 18:55:07 -0600
Subject: [R-pkgs] PerformanceAnalytics version 0.9.6 released to CRAN
Message-ID: <47798F6B.2080004@braverock.com>

We are pleased to announce the availability on CRAN of
PerformanceAnalytics version 0.9.6.

This is a feature and bugfix release.

http://cran.r-project.org/src/contrib/Descriptions/PerformanceAnalytics.html

PerformanceAnalytics is a library of econometric functions for
performance and risk analysis. This library aims to aid practitioners
and researchers in utilizing the latest research in analysis of
non-normal return streams.

Package: PerformanceAnalytics
Type: Package
Title: Econometric tools for performance and risk analysis.
Version: 0.9.6
Date: 2007-12-29
License: GPL
URL:
http://cran.r-project.org/src/contrib/Descriptions/PerformanceAnalytics.html
URL: http://braverock.com/R/

New Functions:
     chart.ECDF
         Creates an empirical cumulative distribution function (ECDF)
         overlaid with a cumulative distribution function (CDF)
         Inspired by:
         Ruppert, David. 2004.
         Statistics and Finance, an Introduction.
         Ch. 2 Fig. 2.5

     chart.ACF
     chart.ACFplus
         Inspired by (and partially ported from) the website:
         http://www.stat.pitt.edu/stoffer/tsa2/Rcode/acf2.R
         "here's an R function that will plot the ACF and PACF of a time
         series at the same time on the SAME SCALE, and it leaves out
         the zero lag in the ACF [and uses the number of observations
         as the default]"
         That description made a lot of sense, so it's implemented here
         for both the ACF alone and the ACF with the PACF.

     chart.Regression
         Uses a scatterplot to display the relationship of returns
         to a market benchmark.  Fits a linear model and overlays the
         resulting model.  Also overlays a Loess line for comparison.

     Return.read
         Wrapper of 'read.zoo' with some defaults for different
         date formats and frequencies.

     Return.Geltner
         Calculate Geltner liquidity-risk-adjusted return series.
         David Geltner developed a method to remove estimating/liquidity
         bias in real estate index returns.  It has since been applied
         to other return series that show autocorrelation or
         illiquidity effects. The theory is that by correcting for
         autocorrelation, you are uncovering a "true" return from series
         of observed returns that contain illiquidity or manual pricing
         effects.

     SmoothingIndex
         Proposed by Getmansky et al to provide a normalized measure of
         liquidity risk.  The index will produces a number from zero to
         one.  A low number indicates low liquidity risk.  A number
         trending towards one indicates a higher liquidity risk.

     table.Autocorrelation
         Produces data table of autocorrelation coefficients rho and
         corresponding Q(6)-statistic for each column in return series.

     table.CalendarReturns
         Returns a table of returns formatted with years in rows, months
         in columns, and a total column in the last column.
         For additional columns, annual returns will be appended.


Significantly Changed Functions:
     chart.Boxplot
         Added the ability to more completely control the visual display.
         Added the ability to render a Tufte-style compact boxplot.

     chart.Histogram
         Improved visual display for print-quality graphics
         Added fits for extra distributions (stable,cauchy,skew-T)
         Added more control over risk lines
         Added event lines

     chart.QQPlot
         Replaced most internals with port of John Fox's
         qq.plot from 'car'
         Now fits arbitrary distributions
         Allows use of error bands

     We have made changes throughout the package to allow the
     risk-free rate to contain a vector of changing rates corresponding
     with the return series being examined.

     In addition, we have made more extensive use of the features of the
     'zoo' package in this release of PerformanceAnalytics, and removed
     a few external dependencies where those dependencies were minor and
     easily replicated or ported to this package.  We expect both of
     these trends to continue in later releases.  Hopefully, we have
     properly credited the original authors and functions both in our
     code and in the manual pages.

Deprecated Functions:
     rollingCorrelation
     rollingFunction
         These functions have been replaced in our code by the use of
         zoo's 'rollapply' function, and are no longer needed as
         separate custom functions.

New Vignettes:
     We have added as vignettes the presentations we gave on
     PerformanceAnalytics at the R/RMetrics Conference in Mielesalp
     in July 2007 and at UseR! 2007 in Ames, Iowa.

Other:
     This version of PerformanceAnalytics contains many, many minor
     improvements and changes.  We added aver 1500 lines of code
     and comments, and over 1000 lines of documentation.

We have benefited greatly from feedback and comments from the users of
PerformanceAnalytics and from R-SIG-Finance.  Please continue to send
your questions, comments, and complaints.

Full details available in the ChangeLog or in the CVS logs in all .R
files in the source package.

Regards,

     - Brian



From gkerns at ysu.edu  Thu Jan 10 13:40:46 2008
From: gkerns at ysu.edu (G. Jay Kerns)
Date: Thu, 10 Jan 2008 07:40:46 -0500
Subject: [R-pkgs] prob package: elementary probability on finite sample
	spaces
Message-ID: <a695148b0801100440o4b4d8166y8c5a0fb03fa52587@mail.gmail.com>

Dear R Community,

I am pleased to announce the beta-release of the prob package.  The
source code is now on CRAN, and binaries should be generated there
before long. In the meantime, you can get it with

install.packages("prob", repos = "http://r-forge.r-project.org")

The prob package gives a framework for doing elementary probability on
finite sample spaces in R.  The primary notion of "probability space"
has been built around the data frame structure, both for simplicity
and to maximize compatibility with the R Commander by John Fox.

The package addresses an ample proportion of material in a typical
undergraduate course in elementary probability, or the probability
material in an introductory statistics course. For details, see
vignette("prob").

Since the focus is on sample/probability spaces, the prob package
could be used as a precursor to the more sophisticated distrxxx-family
of packages.

Topics:

* construction of sample spaces (in the sense of 'prob' ) of various
kinds.  Some standard sample spaces are included (toss a coin, roll a
die, sample from an urn, draw cards, roulette, etc.)
* counting and the Multiplication Principle,
* subsets and events including methods for intersect, union, and
setdiff extending those in the base package,
* the prob function for finding probability and conditional
probability of events,
* simulation and relative frequencies,
* random variables, marginal distributions,
* extensions for more general sample spaces,
* discrete multivariate distributions with finite support,
* more...

Some discussion and examples can be found at the R-Forge prob project web page:

http://prob.r-forge.r-project.org/

There are many avenues for future development/improvement;  all
suggestions and comments are welcomed.  I would appreciate hearing
about your experiences with it in the classroom and elsewhere.

The audience for this package would include teachers and students of
elementary probability, or simply anyone wanting to dabble with
probability on a finite sample space.

Regards,
Jay




***************************************************
G. Jay Kerns, Ph.D.
Assistant Professor / Statistics Coordinator
Department of Mathematics & Statistics
Youngstown State University
Youngstown, OH 44555-0002 USA
Office: 1035 Cushwa Hall
Phone: (330) 941-3310 Office (voice mail)
-3302 Department
-3170 FAX
E-mail: gkerns at ysu.edu
http://www.cc.ysu.edu/~gjkerns/



From izmirlian at nih.gov  Tue Jan  8 20:33:13 2008
From: izmirlian at nih.gov (Grant Izmirlian)
Date: Tue, 8 Jan 2008 14:33:13 -0500
Subject: [R-pkgs] PwrGSD
Message-ID: <200801081433.13738.izmirlian@nih.gov>

Hello List:

Please find uploaded to CRAN a new package, PwrGSD

The package is intended for the design and analysis of group sequential trials
There are two main functions, 
(1) GrpSeqBnds: computes group sequential stopping boundaries for interim
      analysis of a sequential trial based upon a normally distributed test 
      statistic. This can be done via the Lan-Demets procedure with 
      Obrien-Fleming, Pocock or Wang-Tsiatis spending. This can also be
      done via boundaries created to correspond with the stochastic 
      curtailment procedure.  

(2) PwrGSD (same as the package name) which computes operating 
      characteristics such as power, expected duration, weighted avergage 
      relative risks at the boundaries among other things, that correspond to 
      a user supplied hypothetical two arm trial under a user supplied choice
      of monitoring scheme and choice of test statistic within the weighted 
      log-rank class of test statistics. Computations are done either via 
      aysmptotic methods or via simulation.  Note:  another feature is the 
      flexible provision for time dependent non-compliance.  

      The function has a nice calling interface based upon the specification
      of boundary methods via functional forms.  There are alot of nice
      summarization methods which allow the user to explore the space of
      hypothetical trial scenarios and boundary construction methods, such as 
      a compound object class for linking individuals calls to PwrGSD to 
      components of a list that are linked to an indexing dataframe for 
      reference purpose.

      I appologize for a lengthy note, but attach a quite informative example 
      below.  

      Best Regards,

      Grant Izmirlian
      Mathematical Statistician
      Division of Cancer Prevention
      US National Cancer Institute
      1-(301)496-7519
      izmirlig at mail.nih.gov
     ????? ?????????
---------------------------------------------------------------------------------
       tlook <- c(7.14, 8.14, 9.14, 10.14, 10.64, 11.15, 12.14, 13.14,
                      14.14, 15.14, 16.14, 17.14, 18.14, 19.14, 20.14)
       t0 <- 0:19      
       h0 <- c(rep(3.73e-04, 2), rep(7.45e-04, 3), rep(1.49e-03, 15))
       rhaz <-c(1, 0.9125, 0.8688, 0.7814, 0.6941, 0.6943, 0.6072, 0.5202,  
                      0.4332, 0.652, 0.6524, 0.6527, 0.653, 0.6534, 0.6537, 
                      0.6541, 0.6544, 0.6547, 0.6551, 0.6554)
	hc <- c(rep(1.05e-02, 2), rep(2.09e-02, 3), rep(4.19e-02, 15))
        hd1B <- c(0.1109, 0.1381, 0.1485, 0.1637, 0.2446, 0.2497, 0)


      test.example <- PwrGSD(
         EfficacyBoundary=LanDemets(alpha=0.05, spending= ObrienFleming),
         FutilityBoundary=LanDemets(alpha=0.1,spending=ObrienFleming),
         RR.Futility = 0.82, sided="<",method="A",accru =7.73, accrat=9818.65,
         tlook =tlook, tcut0 =t0, h0=h0, tcut1=t0, rhaz=rhaz, 
         tcutc0=t0, hc0=hc, tcutc1=t0, hc1=hc, 
         tcutd0B =c(0, 13), hd0B =c(0.04777, 0),
         tcutd1B =0:6, hd1B =hd1B,
         noncompliance =crossover, gradual =TRUE,
         WtFun =c("FH", "SFH", "Ramp"),
         ppar =c(0, 1, 0, 1, 10, 10))

     ## we will construct a variety of alternate hypotheses relative to the
     ## base case specified above

       max.effect <- 0.80 + 0.05*(0:8)
       n.me <- length(max.effect)

     ## we will also vary extent of censoring relative to the base case
     ## specified above

       cens.amt <- 0.75 + 0.25*(0:2)
       n.ca <- length(cens.amt)

     ## we may also wish to compare the Lan-Demets/O'Brien-Fleming efficacy
     ## boundary with a Pocock efficacy boundary

       Eff.bound.choice <- 1:2
       ebc.nms <- c("LanDemets(alpha=0.05, spending=ObrienFleming)",
                    "SC(alpha=0.05, crit=0.90)")
       n.ec <- length(Eff.bound.choice)

     ## The following line creates the indexing dataframe, `descr', with one
     ## line for each possible combination of the selection variables we've
     ## created.

       descr <- 
          as.data.frame(
             cbind(Eff.bound.choice=rep(Eff.bound.choice, each=n.ca*n.me),
                      cens.amt=rep(rep(cens.amt, each=n.me), n.ec),
                      max.effect=rep(max.effect, n.ec*n.ca)))

       descr$Eff.bound.choice <- ebc.nms[descr$Eff.bound.choice]

     ## Now descr contains one row for each combination of the levels of
     ## the user defined selection variables, `Eff.bound.choice',
     ## `max.effect' and `cens.amt'. Keep in mind that the names and number
     ## of these variables is arbitrary. Next we create a skeleton
     ## `cpd.PwrGSD' object with a call to the function `cpd.PwrGSD' with
     ## argument `descr'

       test.example.set <- cpd.PwrGSD(descr)

     ## Now, the newly created object, of class `cpd.PwrGSD', contains
     ## an element `descr', a component `date', the date created
     ## and a component `Elements', an empty list of length equal
     ## to the number of rows in `descr'.  Next we do the computation in
     ## a loop over the rows of `descr'.

       n.descr <- nrow(descr)
       for(k in 1:n.descr){

         ## First, we copy the original call to the current call,
         ## `Elements[[k]]$call'

         test.example.set$Elements[[k]]$call <- test.example$call

         ## Use the efficacy boundary choice in the kth row of `descr'
         ## to set the efficacy boundary choice in the current call

         test.example.set$Elements[[k]]$call$EfficacyBoundary <-
         parse(text=as.character(descr[k,"Eff.bound.choice"]))[[1]]

         ## Derive the `rhaz' defined by the selection variable "max.effect"
         ## in the kth row of `descr' and use this to set the `rhaz'
         ## components of the current call

         test.example.set$Elements[[k]]$call$rhaz <-
                                 exp(descr[k,"max.effect"] * log(rhaz))

         ## Derive the censoring components from the selection variable
         ## "cens.amt" in the kth row of `descr' and place that result
         ## into the current call

         test.example.set$Elements[[k]]$call$hc0 <-
         test.example.set$Elements[[k]]$call$hc1 <-
                                    exp(descr[k, "cens.amt"] * log(hc))

         ## Now the current call corresponds exactly to the selection
         ## variable values in row `k' of `descr'. The computation is
         ## done by calling `update'

         test.example.set$Elements[[k]] <-
                               update(test.example.set$Elements[[k]])
         cat(k/n.descr, "\r")
       }


       ## We can plot the results -- see the help under `plot.cpd.PwrGSD'

       plot(test.example.set, formula = ~ max.effect | stat * cens.amt,
            subset=(substring(Eff.bound.choice, 1,9)=="LanDemets"))

       plot(test.example.set, formula = ~ max.effect | stat * cens.amt,
            subset=(substring(Eff.bound.choice, 1,2)=="SC"))

       ## Notice the appearance of the selection variable `stat' which was
       ## not defined in the dataset `descr'.



From h.wickham at gmail.com  Fri Jan 11 23:16:36 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 11 Jan 2008 16:16:36 -0600
Subject: [R-pkgs] New version of ggplot2: 0.5.7
Message-ID: <f8e6ff050801111416s4707ffeao92483948815e2fe3@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the over 500
examples of ggplot in use.

ggplot 0.5.7
----------------------------------------

New geoms, scales and aesthetics

  * stat_step and geom_step to draw staircase plots (like plot(type="s"))
  * order aesthetic (currently only for lines/paths) allows you to
control the drawing order within a group
  * scale_manual makes it easier to let ggplot uses the exact
colours/sizes/linetypes that you want
  * scale_reverse allows you to reverse the scale of x and y axes
  * scale_grey is a new black and white scale for categorical data
(colour and fill)


Improved options handling

  * new function opts() to allow modification of plot options by addition
  * update(p, theme_bw) and p + theme_bw now work

These changes mean that you can modify plot options in the same way
that you modify all other aspects of the plot, e.g.  qplot(mpg, wt,
data=mptcars) + opts(title = "Fuel economy vs weight")

Improved documentation

  * many tweaks to the online documentation, particular including the
actual code you need to run for each object!
  * every page now has a link to a form where you can submit feedback
on exactly you do or don't like about a page
  * required aesthetics now listed in documentation
  * geom_polygon now has a decent example
  * numerous minor corrections suggested by J?rg Beyer
  * separated plotting advice from details of plot construction (what
vs how), thanks to Bert Gunter for this suggestion


Improved map projections (with coord_map)

  * coord_map defaults to orientation = c(90, 0, mean(range(y))) -
this ensures that multiple layers line up correctly, but means you
will have to specify the orientation yourself for many projections
  * coord_map now respects limits set by scales
  * removed useless ticks from coord_map

If you're using ggplot to draw maps and have thought of other features
that would make your life easier, please let me know.


Bug fixes

  * adding data and aesthetics in separate steps should now work
  * layers with set parameters will not use mapped aesthetics
  * use LazyLoad: false instead of SaveData: true for better future
compatability

  * coord_cartesian: fixed bug that prevented you from overriding the
default axis expansion
  * coord_equal: now scales correctly if ratio < 1
  * geom_abline: fix bug where slope was ignored
  * geom_jitter now works correctly with groups and categorical values
(was actually a bug in how scale_discrete deals with continuous
values)
  * geom_path: automatically switch between polylineGrob and
segmentsGrob when drawing paths so that setting line type now works
properly
  * geom_segment now uses both ends of segments to calculate axis limits
  * plotmatrix: fix bug in scatterplot matrix where all scatterplots
were transposed!
  * qplot: should now work better within functions
  * quickplot added as an alias of qplot, to avoid confusion with qunif, etc
  * scale_*: better error message if you add a scale without a
matching aesthetic mapping in the plot
  * scale_identity no longer converts everything to character
  * scale_identity: grob argument renamed to guide
  * stat_*: made all statistics more robust to errors
  * stat_quantile: fixed bug when only drawing a single quantile
  * stat_smooth: returns silently if <2 non-missing data points


Minor aesthetic improvements

  * coord_polar now specifies aspect.ratio by default, and I've made a
few other tweaks to make polar coordinates plot look nicer
  * geom_bar no longer draws gray borders by default, but instead uses
the same colour as fill (this eliminates a tiny gap between
neighbouring bars)
  * plotmatrix: tweaks to improve display of scatterplot matrix
  * scale_brewer: added option to reverse palette
  * scale_colour: colour and fill legends now look exactly the same
(previously colour was missing a grey border)
  * scale_discrete has slightly larger expansion (0.75 vs 0.5)
  * stat_bar: only output bars with > 0 count


See CHANGELOG for changes in previous versions


-- 
http://had.co.nz/



From bxc at steno.dk  Thu Jan 17 17:09:40 2008
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Thu, 17 Jan 2008 17:09:40 +0100
Subject: [R-pkgs] New version of Epi package out (1.0.7)
Message-ID: <40D3930AC1C8EA469E39536E5BC8083505452383@EXDKBA021.corp.novocorp.net>

A new major upgrade of the Epi package for Epidemiological data analysis
has been put on CRAN, it is now at version 1.0.7.

It contains an entirely new way of representing follow-up data on
multiple timescales and multiple states. See the function Lexis().

Plus a lot of other useful stuff for epidemiological analysis.
See more on the package homepage, www.biostat.ku.dk/~bxc/Epi

Note also that there will be a course 28 May - 2 June in Estonia, see
www.biostat.ku.dk/~bxc/SPE.

Bendix Carstensen
Epi package maintainer	
______________________________________________

Bendix Carstensen
Senior Statistician
Steno Diabetes Center
Niels Steensens Vej 2-4
DK-2820 Gentofte
Denmark
+45 44 43 87 38 (direct)
+45 30 75 87 38 (mobile)
bxc at steno.dk   http://www.biostat.ku.dk/~bxc



From ggrothendieck at gmail.com  Sat Jan 19 18:41:11 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 19 Jan 2008 12:41:11 -0500
Subject: [R-pkgs] batchfiles 0.4-0
Message-ID: <971536df0801190941q672c4fcbx4e4f8701fec75831@mail.gmail.com>

batchfiles 0.4-0 consists of a set of Windows Vista
.bat, .hta and .pl files.

More information is available on the home page:
http://batchfiles.googlecode.com

CHANGES

- now tested with Vista exclusively (use 0.3-2 instead on XP)

- sweave.bat now has no dependencies on the other batch
  files.  With this change all .bat and .hta files now
  have no dependencies except possibly for R.

- RguiStart.bat is like Rgui.bat but takes a single argument
  which may be an .Rdata file or a folder.  It can be
  placed in your SendTo folder in which case you can
  right click in Windows Explorer choosing
   SendTo | RguiStart.bat

- Rversions.hta now elevates RSetReg automatically (but
  you will still be prompted for confirmation)

- new toggleDoc.pl perl program from Dieter Menne which
  unclutters 00Index.html Help files in packages.  See
  sample output at:
  http://www.menne-biomed.de/download/toggleDoc/00Index.html
  and try toggling the Show All checkbox to see what it does.

- Rversions.bat, Rfind.bat, makepkg.bat and withgs.bat
  are no longer part of the package but are still available
  in version 0.3-2.

PACKAGE DESCRIPTION

(Note that this is a collection of Windows batch and other
files available in the CRAN Other area for R as opposed to
a package written in R.)

batchfiles is a collection of .bat, .hta and .pl scripts
that are useful when using R or developing R software.

The .bat and .hta files are easy to install as they have no
dependencies other than R and they automatically look up R
in the registry so no paths have to be set.  Just place them
all or just those you want anywhere in your path.  There are
utilities for running R, creating packages, switching the
current R version, R scripting and runing sweave as well as
others.

- Rcmd.bat, R.bat and Rgui.bat are all the same file which
query what name it was called by and acts in a similar way
to the R .exe files of the same name except that they first
attempt to find R by checking the registry and common
locations so to use them all you do is put them anywhere in
your path.

- RguiStart.bat is the same as Rgui.bat except it accepts
a single argument that is an R directory or .Rdata file
so if you place it in your SendTo folder and right click
any folder in Windows Explorer choosing SendTo | RguiStart.bat
it will start up R in that folder.  If an .Rdata file is
right clicked then R starts up loading that file.

- sweave.bat will run sweave and the pdflatex and then display
the pdf file (or some subset of those depending on switches).
It has builtin makefile functionality so it will not proceed
to the next step if the prior step has failed.  It also
creates and displays a backup copy of the pdf with a unique
name so two versions of the same pdf file can be simultaneously
displayed.

- #Rscript.bat can be used as the first line of an R script to
make it callable as a batch file.  Rscript.bat is a variation
of it used differently.

- Rtidy.bat reformats R programs.  Its primarily included as
a simple example of #Rscript.bat .

- Rversions.hta - if there are multiple versions of R installed
this program locates all versions in the registry and
provides a GUI interface with a drop down menu to choose
which one you wish to make current.

- copydir.bat/movedir.bat copy or move packages from one library
to another such as would be done when upgrading R.  They will
create new copies but will never overwrite any files that are
already there so they should be safe to use.

- toggleDoc.pl is a perl program which unclutters HTML help
files contributed by Dieter Menne.  For an example see:
http://www.menne-biomed.de/download/toggleDoc/00Index.html



From cgenolin at u-paris10.fr  Mon Jan 21 10:27:59 2008
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Mon, 21 Jan 2008 10:27:59 +0100
Subject: [R-pkgs] New package: R to LaTeX Univariate Analyses
Message-ID: <4794659F.3060000@u-paris10.fr>

Hi the list

*** New package ***
R to LaTeX : Univariate analyses
r2lUniv
*URL:*http://www.r-project.org, http://christophe.genolini.free.fr/r2lUniv

*** Description ***
r2lUniv performs some basic analyses, then generates a code to be 
included in a LaTeX document
to print the analyses in a (so nice!) LaTeX way.
r2lUniv performs the analyses automatically according to the classical 
statistics
type definition that are nominal, ordinal, discrete and continuous. The 
analysis performed are:
- Nominal : modality, size, barplot
- Ordinal: modality, size, quartile, barplot
- Discrete: modality, size, mean, var, quartile, boxplot, barplot
- Continuous: mean, var, quartile, boxplot, barplot

*** I am a Rookie... ***
Well, I know that. This is my first package and I am almost a beginner in R.
So any comment on any subject (programming style, way of writing the 
man, use of S3) are welcome
("You did a nice job, but classical usage is to..." or "Hmmm, that would 
be more practical if...").

*** Other project ***
Well, Univariate Analysis is the first step, the second is Bivariate 
analysis.
Also, before posting here, I submit this package on a French forum.
The first suggestion is to extend this package to HTML. I will not have 
time to do it alone.
So if some people are interested, two other project are almost open :
- R to LaTeX Bivaraite Analysis
- R to HTML Univariate Analysis

Thanks

Christophe Genolini

Junior statistician
"PSIGIAM: Paris Sud Innovation Group in Adolescent Mental Health"
INSERM U669 / Maison de Solenn / Paris



From Michael.Hoehle at stat.uni-muenchen.de  Mon Jan 21 10:13:23 2008
From: Michael.Hoehle at stat.uni-muenchen.de (=?ISO-8859-1?Q?Michael_H=F6hle?=)
Date: Mon, 21 Jan 2008 10:13:23 +0100
Subject: [R-pkgs] Package surveillance (v0.9-8) on CRAN
Message-ID: <47946233.2000709@stat.uni-muenchen.de>

Dear R Community,

I would like to announce the package "surveillance", which provides
methods for the surveillance of count data time series originating
from the routine collection of public health data.

The package addresses epidemiologists and statisticians working with
routine surveillance, but it also offers an infrastructure for
developers of new detection algorithms.

Implemented outbreak detection algorithms are:
* Stroup et al. (1989)
* Farrington et al. (1996)
* A Bayesian predictive posterior approach
* Time varying Poisson means as documented in Rogerson and Yamada (2004)
* Approximate CUSUM method for time varying Poisson means by
   Rossi et al. (1999)
* A generalized likelihood ratio detector for time varying Poisson
   and and negative binomial means

Modelling routines:
* A Poisson and negative binomial model for the analysis of
multivariate infectious disease surveillance data described in Held
et al. (2005)

The paper available from http://dx.doi.org/10.1007/s00180-007-0074-8
provides a good overview of the package. Source code and binaries
(currently version 0.9-8) are available from CRAN. Visit the R-Forge
project web page for more information, development versions and forums
to discuss ideas and report bugs:

       	    http://surveillance.r-forge.r-project.org/

I would appreciate hearing about your experiences with the package.

Best regards,

Michael
-on behalf of the surveillance development team

--

Michael H?hle, Ph.D.
Department of Statistics
University of Munich
Ludwigstr. 33
80539 Munich
Germany

Homepage: http://www.stat.uni-muenchen.de/~hoehle



From HDoran at air.org  Wed Jan 23 17:42:48 2008
From: HDoran at air.org (Doran, Harold)
Date: Wed, 23 Jan 2008 11:42:48 -0500
Subject: [R-pkgs] MiscPsycho 1.1 uploaded to CRAN
Message-ID: <2323A6D37908A847A7C32F1E3662C80E0153615F@dc1ex01.air.org>

Version 1.1 of the MiscPsycho package had been uploaded to CRAN. The
package has been updated to include the following:

1) The irt.ability() function that estimates examinee ability given a
set of item parameters. The function is very general and can be used to
estimate ability when there are only dichotomous items (1-, 2-, or 3PL),
only polytomous items (generalized partial credit model), or a mixture
of dichotomous and polytomous items. The function can be used to
estimate maximum likelihood estimates or two bayesian estimates: the
maximum a posteriori (MAP) and the expected a posteriori (EAP).

2) The plaus.val() function that uses rejection sampling to draw random
samples from any IRT posterior distribution. 

3) The posterior() function that computes the density of any IRT
posterior distribution.

4) The class.acc() function that can be used to perform integration from
[-Inf,b] or [a,Inf] of any IRT posterior distribution.

5) Complete technical documentation describing all of the mathematical
methods underlying the functions as well as complete examples
demonstrating the use of all functions. This documentation lives in the
"doc" subdirectory of the MiscPsycho library.

Any bug reports, issues, and comments on the package are welcome.

Harold Doran



From seth at userprimary.net  Sat Jan 26 19:47:57 2008
From: seth at userprimary.net (Seth Falcon)
Date: Sat, 26 Jan 2008 10:47:57 -0800
Subject: [R-pkgs] RSQLite 0.6-7 -- changes to dbGetQuery semantics
Message-ID: <m2ve5gtode.fsf@userprimary.net>

RSQLite 0.6-7 has been uploaded to CRAN and should hit a mirror near
you in the next few days.

This version changes the behavior of the dbGetQuery method to make it
more consistent with dbSendQuery.  Specifically:

1. dbGetQuery now closes a complete result set as dbSendQuery does.

2. If there is an incomplete result set open, dbGetQuery still opens a
   new temporary connection, but now issues a warning.  It is best
   practice to explicitly close open result sets before issuing
   further queries.

These changes are in response to the following discussion on the
r-sig-db list:

    https://stat.ethz.ch/pipermail/r-sig-db/2008q1/000399.html

+ seth

-- 
Seth Falcon | seth at userprimary.net | blog: http://userprimary.net/user/



From Achim.Zeileis at R-project.org  Mon Jan 28 11:46:26 2008
From: Achim.Zeileis at R-project.org (Achim Zeileis)
Date: Mon, 28 Jan 2008 11:46:26 +0100 (CET)
Subject: [R-pkgs] dynlm: new version 0.2-0
Message-ID: <Pine.LNX.4.44.0801281053320.29044-100000@disco.wu-wien.ac.at>

Dear useRs,

I've release a new version of the "dynlm" package to CRAN which adds two
new features:

  o instrumental variables regression (two-stage least squares) via
    formulas like
      dynlm(y ~ x1 + x2 | z1 + z2 + z3, data = mydata)
    where z1, z2, z3 are the instruments which can again contain
    lags/differences/season via the d()/L()/season() operators.

  o specification of multiple lags via formulas like
      dynlm(y ~ L(x, 0:4), data = mydata)
    where y is regressed on x and lags 1 through 4 of x.

Furthermore, I've enhanced some convenience funcitonality such as printing
and fixed a bug in the time alignment when there were leading NAs in the
underlying data.
Z



From Soren.Hojsgaard at agrsci.dk  Mon Jan 28 12:46:20 2008
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Mon, 28 Jan 2008 12:46:20 +0100
Subject: [R-pkgs] New package: gRain - gRAphical Independence Networks
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0562FAF0@DJFPOST01.djf.agrsci.dk>

Dear useRs
 
I have uploaded a new package, gRain, for propability propagation in graphical independence networks; sometimes also called probabilistic expertsystems and Bayesian networks.
 
Regards
S?ren H?jsgaard



From patrick.mair at wu-wien.ac.at  Tue Jan 29 00:32:02 2008
From: patrick.mair at wu-wien.ac.at (Patrick Mair)
Date: Mon, 28 Jan 2008 15:32:02 -0800
Subject: [R-pkgs] eRm: new version 0.9-6
Message-ID: <479E65F2.7050907@wu-wien.ac.at>

Dear useRs,

new and updated features in eRm 0.9-6 for extended Rasch modeling:

- infit and outfit mean-square statistics added to functions personfit() 
and itemfit().

- new method: plotPImap() plots a person-item map (cf. Bond & Fox, 
2007), i.e., a map
of locations of item (and threshold) parameters, and the distribution of 
person parameters.

- new options in plotGOF():
'conf': draws confidence ellipses for item parameters, optionally single 
items can be chosen interactively.
'ctrline': draws confidence bands along the diagonal line based on the 
se's of the item parameters (cf. Wright &
Stone, 1999) .
plotGOF() now displays difficulty parameters (see below).

- unification of output for item parameter estimates: all plotting 
functions and the function thresholds() display
item difficulty parameters. all numeric output (i.e. from model objects) 
gives item easiness parameters.

- new and enhanced options in plotICC():
'empirical': empirical ICCs can now be smoothed using various smoothers 
(such as Tukey, loess, or kernel).
'ask': interactive turning over of plots can be switched off (only 
useful if automated figure export is in effect,
e.g., when using Sweave).

- simulation module for 0-1 response matrices: sim.rasch() for Rasch 
homogeneous data,
sim.2pl() for 2-PL data, sim.xdim() for unidimensionality violation, and
sim.locdep() for locally dependent item responses.

- package vignette "eRmvig" added.

Best,
Patrick



From toni.giorgino at gmail.com  Tue Jan 29 12:32:26 2008
From: toni.giorgino at gmail.com (Toni Giorgino)
Date: Tue, 29 Jan 2008 12:32:26 +0100
Subject: [R-pkgs] New package: dtw - Dynamic Time Warping
Message-ID: <9b2eed510801290332ga0381e6ua278e6b446261e72@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20080129/5962cfe0/attachment.pl>

From Mike.Prager at noaa.gov  Thu Jan 31 19:36:18 2008
From: Mike.Prager at noaa.gov (Michael H. Prager)
Date: Thu, 31 Jan 2008 13:36:18 -0500
Subject: [R-pkgs] Update of X2R (with FishGraph) sent to CRAN, 30 Jan 2008
Message-ID: <47A21522.4060201@noaa.gov>

X2R is a bundle of three software libraries allowing the user to pass
structured data easily from Fortran, C/C++, or AD Model Builder to R.

An update to X2R has been sent to CRAN and should be available at 
mirrors shortly. We also have uploaded FishGraph, a set of R functions
to generate graphics from fish population models. From the menu at the 
left of the CRAN home page, look under Software / Other.

Changes in this Update

- Minor bug fixes and improvements have been made throughout, both in
the software and users' guides.
- ADMB2R is compatible with gcc as well as with the Borland compiler.
- FishGraph is available from CRAN.
- ADMB2R includes a detailed example compatible with FishGraph. This
should minimize the learning curve for those getting started with ADMB2R
and FishGraph.

X2R is supplied as files X2R.zip and X2R.tar.gz, which are equivalent.
The version and release date can be identified from the contents of file
"VersionInfo.txt" in the root of each archive. The new version bears
date January 19, 2008.

FishGraph is supplied separately as a Windows installer in the same
directory. If we hear from anyone interested in using it under other 
operating system(s), we can collaborate on making it work.

                                * * *

More detail for the interested:

X2R is composed of three independent but related software libraries:
C2R, ADMB2R, and For2R (together, X2R). Each contains output routines to
simplify transfer of complicated data structures from models written in
a compiled language to R (note 1). Through calls to X2R routines, the
user's data is written as a structured ASCII file. That file can be read
by R with a single dget() function call to create an R data object of
type list. The list may contain components such as vectors, data frames,
matrices, and other lists.

These are NOT R packages; rather they are subroutine libraries to be
used with programmers' own modeling codes. Limited testing indicates
compatibility with S-PLUS, as well (note 2).

Languages supported are Fortran 95 (with For2R), C and C++ (with C2R)
and AD Model Builder (with ADMB2R) (note 3). Source code and detailed 
users' manuals are supplied.

ADMB2R has been tested with ADMB versions 6.03 and 7.71 and recent
versions of the gcc and Borland C++ compilers.

FishGraph is a set of R functions providing exploratory and presentation 
graphics of fishery catch-at-age or catch-at-length models. By taking 
its data from an R list assumed to have a certain structure (diagram 
provided), FishGraph determines which graphs should be generated and for 
how many data series, years, etc. The data structure may be generated 
with X2R or within R itself and may contain any amount of additional 
data. Most FishGraph routines have options to control titles, colors, 
and reference lines. The combination of X2R and FishGraph allows 
automating graphics production from routine fish stock assessments. The 
FishGraph functions can be modified or supplemented to reflect the needs 
of the analysis at hand.

This work has been tested and is regularly used by the authors. However,
any software may contain bugs, and these works are classified by NOAA as
"Experimental Products."  THIS SOFTWARE IS SUPPLIED WITH NO WARRANTY OF
ANY KIND. Nonetheless, the authors will endeavor to fix bugs promptly 
and to add requested features.  Send bug reports, suggestions, and 
extensions to either author.

Michael H. Prager - mike.prager at noaa.gov
Southeast Fisheries Science Center
National Marine Fisheries Service, NOAA
101 Pivers Island Road
Beaufort, North Carolina 28516 USA

Jennifer L. Martin - jennifer.martin at noaa.gov
Northeast Fisheries Science Center
National Marine Fisheries Service, NOAA
166 Water Street
Woods Hole, Massachusetts 02543 USA


* Note 1. Use of product names (commercial or otherwise) does not imply
endorsement or recommendation by any U.S. government agency, nor by the
authors in their government capacities.
* Note 2. S-PLUS is a commercial product, released by Insightful 
Corporation.
* Note 3. AD Model Builder is a commercial product, released by Otter
Research.



From Greg.Snow at imail.org  Mon Feb  4 18:32:59 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Mon, 4 Feb 2008 10:32:59 -0700
Subject: [R-pkgs] Package blockrand version 1.1 on CRAN
Message-ID: <07E228A5BE53C24CAD490193A7381BBBE99432@LP-EXCHVS07.CO.IHC.COM>

This is to announce an updated version of the blockrand package has been
uploaded to CRAN.

The blockrand package is used for creating randomizations for clinical
trials or other studies where random assignments are made one at a time.
It implements the ideas of randomizing within blocks so that the numbers
of subjects in each group remain fairly balanced (but allows for
unbalanced blocks to make anticipation of future allocations more
difficult). 

It also includes a function to print randomization cards (creates a pdf
file) that can be put into envelopes for a study coordinator to use to
assign subjects to treatments.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
(801) 408-8111
 



From ubk2101 at columbia.edu  Mon Feb 11 22:23:40 2008
From: ubk2101 at columbia.edu (Udaya B. Kogalur)
Date: Mon, 11 Feb 2008 16:23:40 -0500
Subject: [R-pkgs] Release 3.2.0 of randomSurvivalForest is now availablle
Message-ID: <38c08c270802111323t753c5804j99381a7daa28ddcd@mail.gmail.com>

Dear useRs:

Release 3.2.0 of the CRAN package randomSurvivalForest is now available.

----------------------------------------------------------------------------------------------

Release 3.2.0 represents a significant upgrade in the functionality of
the product.  Key changes are as follows:

o A second method of perturbing the data set in order to calculate
variable importance (VIMP) has been implemented.  In addition to
permuting the values for a single variable, a random split approach
has been taken in which a data point is randomly assigned to the left
or right daughter node when a split occurs on the specified variable.

o The joint VIMP among multiple variables of a (potentially proper)
subset of the GROW data can now be calculated using the new function
interaction.rsf().  This represents a third mode of operation for the
application, and follows rsf.default (GROW) and predict.rsf (PREDICT).
See the documentation for details.

o An additional option in GROW mode can now be specified.  The option
'varUsed' allows users to quantify which variables have been split
upon within a single tree or over the entire forest.  See the
documentation for more details.

o The ability to multiply impute data has been implemented.  This
involves imputing data while growing a forest and using the results to
grow a new forest in order to better impute the data.

o In GROW mode, the application now outputs both the in-bag and OOB
summary imputed values.

o An additional split rule 'randomsplit' has been implemented.
See the documentation for more details.

o The split rule 'logrankscore' is now calculated correctly.

o The split rule 'logrankapprox' has been removed and replaced by
the new split rule 'logrankrandom'.  See the documentation for more details.


ubk2101 at columbia.edu

Udaya B. Kogalur, Ph.D.
Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012



From spencer.graves at pdf.com  Wed Feb 13 09:27:40 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 13 Feb 2008 00:27:40 -0800
Subject: [R-pkgs] FinTS_0.2-7
Message-ID: <47B2A9FC.90905@pdf.com>

Hi, All:

	  FinTS version 0.2-7 is now available on CRAN.  This version adds two 
new functions:

	  * ArchTest to compute the Engle (1982) Lagrange multiplier test for 
conditional heteroscedasticity, discussed on pp. 101-102 of Tsay, with 
examples on those pages worked in the R script in 
"~R\library\FinTS\scripts\ch03.R", where "~R" is your local R 
installation directory.  The code for this was kindly provided by 
Bernhard Pfaff.

	  * Acf and plot.Acf to plot the autocorrelation function without the 
noninformative unit spike at lag 0, facilitating the production of many 
ACF plots in Tsay (2005) Analysis of Financial
Time Series, 2nd ed. (Wiley) that follow this secondary standard.

	 Spencer Graves



From dimitris.rizopoulos at med.kuleuven.be  Wed Feb 20 09:39:47 2008
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 20 Feb 2008 09:39:47 +0100
Subject: [R-pkgs] New Package 'JM' for the Joint Modelling of Longitudinal
	and Survival Data
Message-ID: <00c801c8739c$26581ba0$0e40210a@www.domain>

Dear R-users,

I'd like to announce the release of the new package JM (JM_0.1-0 
available from CRAN) for the joint modelling of longitudinal and 
time-to-event data.

The package has a single model-fitting function called jointModel(), 
which accepts as main arguments a linear mixed effects object fit 
returned by function lme() of package nlme, and a survival object fit 
returned by either function coxph() or function survreg() of package 
survival. In addition, the method argument of jointModel() specifies 
the type of the survival submodel to be fitted and the type of the 
numerical integration technique; available options are:

    * "ph-GH": the time-dependent version of a proportional hazards 
model with unspecified baseline hazard function. This option 
corresponds to the joint model proposed by Wulfsohn and Tsiatis, 
Biometrics, 1997.

    * "weibull-GH": the Weibull model under the accelerated failure 
time formulation.

    * "ch-GH" and "ch-Laplace": an additive log cumulative hazard 
model, in which the log cumulative baseline hazard is approximated 
using B-splines.

For "ph-GH", "weibull-GH" and "ch-GH" the Gauss-Hermite integration 
rule is used to approximate the required integrals, whereas for 
"ch-Laplace" a fully exponential Laplace approximation method is 
applied. The last option is more suitable for high-dimensional random 
effects vectors, when e.g., modelling nonlinear subject-specific 
trajectories with splines or high-order polynomials.

Sample analyses can be found at:
http://student.kuleuven.be/~m0390867/R%20packages%20&%20Computing/R%20Packages/pbc.R, 
and
http://student.kuleuven.be/~m0390867/R%20packages%20&%20Computing/R%20Packages/aids.R

Any kind of feedback (questions, suggestions, bug-reports, etc.) is 
more than welcome.

Best,
Dimitris

----
Dimitris Rizopoulos
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From csardi at rmki.kfki.hu  Wed Feb 20 21:11:10 2008
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Wed, 20 Feb 2008 21:11:10 +0100
Subject: [R-pkgs] igraph package, version 0.5
Message-ID: <20080220201110.GC8077@localdomain>

igraph is a package for graphs and networks. It has a C core and 
uses a simple and fast graph representation allowing millions 
of vertices and edges.

NEW FEATURES:

- We use the ARPACK library for graph related eigenvalue problems, 
  like Page Rank calculation, Kleinberg's hub and authority scores,
  eigenvector centrality, etc. There is also a generic interface 
  if someone wants to use ARPACK for a different (not necessarily 
  graph-related) problem.

- We support the BLISS graph isomorphism algorithm, and the 
  implementation of the VF2 algorithm can calculate subgraph isomorphisms
  now.

- We include a collection of "famous" graphs, these can be created 
  by referring to their name.

- We have a new 'graph.formula' function, for creating small graphs
  using symbolic names, by giving simple R formulae.

- Many functions support weighted graphs now: Page Rank, modularity
  calculation, the fast greedy community finding algorithm, etc.

- We have a new graph layout algorithm called 'graphopt'.

- A bunch of new functions are added: biconnected components and 
  articulation points, dyad and triad census, functions for vertex 
  similarity, functions for estimating closeness, betweenness and 
  edge betweenness, etc.

- igraph can write files in the DOT format now.

- Some graphics improvements, e.g. it is possible to draw 
  graphs on top of each other, etc.

- Many bugs were fixed, the most important one is probably that 
  now memory is always properly deallocated when CTRL+C (ESC) is 
  used to interrupt a computation.

PACKAGE DESCRIPTION:

igraph is originally a C library for graphs, but has interfaces
to high level languages like R, Python and Ruby. The R package 
contains BOTH the C library and its R interface. 

igraph supports:

- graph generators, creating both regular structures like trees,
  lattices, etc. and various random graphs.

- a rich set of functions calculating structural properties of 
  graphs, like vertex centrality (degree, betweenness, closeness,
  page rank, eigenvector centrality, Burt's constraints, etc.),
  shortest paths, dyad and triad census, network motifs, girth, 
  K-core decomposition, etc.

- attributes can be associated with the vertices/edges of the graph,
  or the graph itself. The attributes can be arbitrary R objects.

- graph visualization using regular R devices, interactive visualization
  using Tcl/Tk, 3D visualization using RGL.

- graph layout generators, the standard Kamada-Kawai and 
  Fruchterman-Reingold algorithms are included, plus many more.

- Functions for graph and subgraph isomorphism, the BLISS and the VF2
  algorithms are included.

- Functions for maximal network flows, minimal cuts, vertex and 
  edge connectivity.

- igraph can read and write many popular file formats used for 
  storing graph data: GraphML, Pajek, GML and others.

- igraph contains implementations of many community structure 
  detection algorithms proposed recently.

See more at the igraph homepage:
http://cneurocvs.rmki.kfki.hu/igraph/index.html

-- 
Csardi Gabor <csardi at rmki.kfki.hu>



From Greg.Snow at imail.org  Sat Feb 23 19:00:08 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Sat, 23 Feb 2008 11:00:08 -0700
Subject: [R-pkgs] Announcement: obsSens Package
Message-ID: <07E228A5BE53C24CAD490193A7381BBBE2F513@LP-EXCHVS07.CO.IHC.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20080223/19d0ca1a/attachment.pl>

From longhai.li at gmail.com  Sun Feb 24 16:58:32 2008
From: longhai.li at gmail.com (Longhai Li)
Date: Sun, 24 Feb 2008 09:58:32 -0600
Subject: [R-pkgs] Bayesian Prediction with High-order Interactions
Message-ID: <90c54480802240758y22967accpa75be28a2cfd070b@mail.gmail.com>

Hi Everybody,

A new package called ``Bayesian Prediction with High-order
Interactions'' is available from CRAN. The description of this package
is as follows"

"This R package is used in two situations. The first is to predict the
next outcome based on the previous states of a discrete sequence. The
second is to classify a discrete response based on a number of
discreate covariates. In both situations, we use Bayesian logistic
regression models that consider the high-order interactions. The time
arising from using high-order interactions is reduced greatly by our
compression technique that represents a group of original parameters
as a single one in MCMC step. In this version, we use log-normal prior
for the hyperparameters. When it is used for the second situation ---
classification, we consider the full set of interaction patterns up to
a specified order."

The website of this package is

http://fisher.utstat.toronto.edu/~longhai/software/BPHO/release.html

-- 

Longhai Li, PhD

Assistant Professor
Department of Mathematics and  Statistics
University of Saskatchewan

Homepage: http://math.usask.ca/~longhai



From adrian at maths.uwa.edu.au  Tue Feb 26 08:10:19 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Tue, 26 Feb 2008 16:10:19 +0900 (WST)
Subject: [R-pkgs] Course on analysing spatial point patterns
In-Reply-To: <mailman.11.1203937203.11666.r-sig-geo@stat.math.ethz.ch>
References: <mailman.11.1203937203.11666.r-sig-geo@stat.math.ethz.ch>
Message-ID: <50266.130.95.98.17.1204009819.squirrel@130.95.98.17>


A full set of course notes on
          'Analysing spatial point patterns in R'
is now available at
     <http://www.csiro.au/resources/pf16h.html>

The course is based on the package 'spatstat'. It includes a brief
introduction to R, a detailed introduction to the 'spatstat' package, and
a discussion of statistical methodology.

Adrian Baddeley



From bigbear at iastate.edu  Thu Feb 28 18:49:06 2008
From: bigbear at iastate.edu (Barret Schloerke)
Date: Thu, 28 Feb 2008 11:49:06 -0600
Subject: [R-pkgs] New Package: geozoo. High-Dimensional Geometric Objects
Message-ID: <4e2dfc530802280949j7f575aadr714a3e72464339ca@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20080228/77e7aba5/attachment.pl>

From david.kraus at matfyz.cz  Thu Feb 28 19:02:16 2008
From: david.kraus at matfyz.cz (David Kraus)
Date: Thu, 28 Feb 2008 19:02:16 +0100
Subject: [R-pkgs] surv2sample 0.1-2
Message-ID: <op.t68xp212d6fnbv@dk.kolej.mff.cuni.cz>

Dear useRs,

There is a new version 0.1-2 of the package surv2sample available on CRAN.  
Users of the previous versions should update because a bug in the function  
cif2.ks has been fixed.

General information about the package:

surv2sample provides various two-sample tests for right-censored survival  
data. Three main areas and corresponding methods are:

* comparison of two survival distributions
   - surv2.logrank: weighted logrank tests and their combinations (max, sum)
   - surv2.neyman: Neyman's smooth test and its data-driven version
   - surv2.ks: Kolmogorov?Smirnov, Cram?r?von Mises and Anderson?Darling  
test

* comparison of two cumulative incidence functions for competing risks data
   - cif: estimation and plotting of cumulative incidence functions
   - cif2.logrank: logrank-type test for subdistribution hazards
   - cif2.neyman: Neyman's smooth test and its data-driven version
   - cif2.ks: Kolmogorov?Smirnov test
   - cif2.int: integrated-difference test

* goodness of fit tests of the proportional rate assumption (proportional  
hazards or proportional odds functions in two samples)
   - proprate2: estimation based on the simplified partial likelihood
   - proprate2.ks: Kolmogorov?Smirnov test
   - proprate2.neyman: Neyman's smooth test and its data-driven version
   - proprate2.gs: Gill?Schumacher type test

See http://www.davidkraus.net/surv2sample/ for details and references.

Best regards,

-- 
David Kraus

Institute of Information Theory and Automation
Pod Vodarenskou vezi 4
CZ-18208 Prague 8
Czechia

david.kraus at matfyz.cz
http://www.davidkraus.net/



From HDoran at air.org  Fri Feb 29 15:24:42 2008
From: HDoran at air.org (Doran, Harold)
Date: Fri, 29 Feb 2008 09:24:42 -0500
Subject: [R-pkgs] MiscPsycho 1.1 revised posted
Message-ID: <2323A6D37908A847A7C32F1E3662C80E015368B4@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20080229/23c44c44/attachment.pl>

From arne.henningsen at googlemail.com  Fri Mar  7 11:45:55 2008
From: arne.henningsen at googlemail.com (Arne Henningsen)
Date: Fri, 7 Mar 2008 11:45:55 +0100
Subject: [R-pkgs] Packages micEcon, sampleSelection, and maxLik
Message-ID: <200803071145.55715.arne.henningsen@googlemail.com>

Dear R Users:

We have splitted up the micEcon package into three packages:

a) Package "maxLik" provides tools for maximum likelihood estimations 
(see http://www.maxLik.org).

b) Package "sampleSelection" provides tools for estimating Heckman-type sample 
selection/generalized tobit models (see http://www.sampleSelection.org).

c) Package "micEcon" contains the remainder, i.e. mainly tools for 
microeconomic demand and firm models, e.g. estimating the "Almost Ideal 
Demand System" or the "Symmetric Normalized Quadratic" / "Symmetric 
Generalized McFadden" profit function (see http://www.micEcon.org).

All these packages are available for download from CRAN and from their 
websites (see above).

Any comments and suggestions on these packages are welcome!
Ott & Arne

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From Peter.Rossi at chicagogsb.edu  Fri Mar  7 20:41:51 2008
From: Peter.Rossi at chicagogsb.edu (Rossi, Peter E.)
Date: Fri, 07 Mar 2008 13:41:51 -0600
Subject: [R-pkgs] bayesm version 2.2-0
Message-ID: <FC7768358736E54AB330E0B99FFB5E1F566F04@GSBHEX2V.gsb.uchicago.edu>

bayesm version 2.2-0 is now available on CRAN.

Major changes include:

1. general density estimation using a Dirichlet Process Prior and a
normal base
2. linear instrumental variable models with unknown error distributions
   (the Bayesian analogue of IV methods).  Achieved via DP priors.

peter r

................................
 Peter E. Rossi
 Joseph T. and Bernice S. Lewis Professor of Marketing and Statistics
 Director, Kilts Center for Marketing
 Editor, Quantitative Marketing and Economics
 Rm 353, Graduate School of Business, U of Chicago
 5807 S. Woodlawn Ave, Chicago IL 60637
 Tel: (773) 702-7513   |   Fax: (773) 834-2081 
 WWW: http://ChicagoGsb.edu/fac/peter.rossi
 SSRN: http://ssrn.com/author=22862



From adinno at post.harvard.edu  Sat Mar  8 00:27:29 2008
From: adinno at post.harvard.edu (adinno at post.harvard.edu)
Date: Fri, 7 Mar 2008 15:27:29 -0800 (PST)
Subject: [R-pkgs] A new version of paran is available
In-Reply-To: <Pine.LNX.4.64.0803071224170.12743@pathos.globalovermind.com>
References: <Pine.LNX.4.64.0803071224170.12743@pathos.globalovermind.com>
Message-ID: <Pine.LNX.4.64.0803071525480.18037@pathos.globalovermind.com>



Horn's parallel analysis method of deciding how many factors to retain has 
been implemented in R in the paran package. This update to paran adds an 
option to produce a graph of the analysis along the lines of what Horn 
presented in his seminal 1965 paper. It also makes a few minor improvements 
to the formatting of the program's output.

Alexis Dinno



From kate at few.vu.nl  Thu Mar 13 16:23:45 2008
From: kate at few.vu.nl (Katharine Mullen)
Date: Thu, 13 Mar 2008 16:23:45 +0100 (CET)
Subject: [R-pkgs] new version of minpack.lm
Message-ID: <Pine.GSO.4.56.0803131616540.29333@laurel.few.vu.nl>

The package minpack.lm allows nonlinear regression problems to be
addressed with a modification of the Levenberg-Marquardt algorithm based
on the implementation of 'lmder' and 'lmdif' in MINPACK. Version 1.0-8 of
the package is now available on CRAN.

Changes in version 1.0-8 include:

    o possibility to obtain standard error estimates on the parameters
      via new methods for the generic functions 'summary' and 'vcov'

    o possibility to extract other information via new methods for the
      generic functions 'coef', 'deviance', 'df.residual', 'print',
      and 'residuals'

    o the argument 'control' of 'nls.lm' now defaults to
      'nls.lm.control()'; 'nls.control.lm' allows a maximum number of
      iterations to be specified; when the element 'nprint' of the
      'control' argument of a call to 'nls.lm' is an integer greater
      than 0, the residual sum of squares is now included in the
      information printed every 'nprint' iterations

`   o the list returned by 'nls.lm' includes elements 'niter' and
      'deviance' that represent the number of iterations performed and
      the residual sum of squares, respectively

side-note on Levenberg-Marquardt (LM) versus Gauss-Newton (GN):
There was some discussion
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/108758.html) on Rhelp
regarding whether one comes across real-world problems in which LM
performs better than GN.  I have been seeing such problems recently in
some applications where GN as implemented in 'nls' reduces the step to a
very small value, resulting in little change in the residual sum of
squares from the starting values, whereas both NL2SOL applied via 'nls'
called with 'algorithm="port"' or LM as implemented in
'minpack.lm::nls.lm' significantly reduce the RSS.  The implementation of
NL2SOL is slower by a significant factor on these problems as compared to
either the GN or LM implementations, making use of 'minpack.lm::nls.lm'
attractive.  Note that these problems may be considered pathological;
there are issues with near collinearity of columns of the Jacobian and
with the assumption that the residuals are Gaussian.

Kate Mullen
Timur Elzhov



From jeremy.stephens at Vanderbilt.Edu  Tue Mar 25 16:33:19 2008
From: jeremy.stephens at Vanderbilt.Edu (Jeremy Stephens)
Date: Tue, 25 Mar 2008 10:33:19 -0500
Subject: [R-pkgs] New package: yaml 1.0 released to CRAN
Message-ID: <200803251033.19872.jeremy.stephens@vanderbilt.edu>

Hi all,

I've released a new package to CRAN called 'yaml'.  It allows R to 
parse YAML documents (http://yaml.org) into R objects, and there are 
a few methods to convert R objects into YAML.  The package uses the 
Syck YAML parser (http://whytheluckystiff.net/syck/), the same parser 
that Ruby and other languages use to parse YAML.

For more information, please visit:
http://biostat.mc.vanderbilt.edu/YamlR

Thanks!
Jeremy
-- 
Jeremy Stephens
Computer Systems Analyst I
Department of Biostatistics
Vanderbilt University



From kjbeath at kagi.com  Tue Mar 25 05:09:30 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Tue, 25 Mar 2008 15:09:30 +1100
Subject: [R-pkgs] new package 'randomLCA'
Message-ID: <640EC882-0095-4A7E-94F6-67DE7333E639@kagi.com>

A new package 'randomLCA' is available on CRAN.

Its main purpose is to fit latent class models with random effects,  
such as those used in diagnostic testing.  This methodology can also  
be applied in other areas. It also fits standard latent class and will  
plot.

Ken



From longhai at math.usask.ca  Wed Mar 26 16:41:14 2008
From: longhai at math.usask.ca (Longhai Li)
Date: Wed, 26 Mar 2008 09:41:14 -0600
Subject: [R-pkgs] Naive Gibbs Sampling with Metropolis Steps (pkg: gibbs.met)
Message-ID: <90c54480803260841h2c70b846he588805b60d034cd@mail.gmail.com>

Hi R Users:

This package provides two generic functions for performing Markov
chain sampling in a naive way for a user-defined target distribution,
which involves only continuous variables. The function "gibbs_met"
performs Gibbs sampling with each 1-dimensional distribution sampled
with Metropolis update using Gaussian proposal distribution centered
at the previous state. The function "met_gaussian" updates the whole
state with Metropolis method using independent Gaussian proposal
distribution centered at the previous state. The sampling is carried
out without considering any special tricks for improving efficiency.
This package is aimed at only routine applications in
moderate-dimensional problems.

The website for this software is

        http://math.usask.ca/~longhai/software/gibbs.met/release.html

-- 

Longhai Li, PhD

Assistant Professor
Department of Mathematics and Statistics
University of Saskatchewan

Homepage: http://math.usask.ca/~longhai



From M.Stevenson at massey.ac.nz  Wed Mar 26 00:34:00 2008
From: M.Stevenson at massey.ac.nz (Mark Stevenson)
Date: Wed, 26 Mar 2008 12:34:00 +1300
Subject: [R-pkgs] New package: epiR
Message-ID: <000001c88ed0$b41dc210$b5ac7b82@massey.ac.nz>

A new package 'epiR' is available on CRAN. Package description as follows:

Package: epiR
Version: 0.9-3
Date: 2008-03-24
Title: Functions for analysing epidemiological data
Author: Mark Stevenson <M.Stevenson at massey.ac.nz> with contributions 
	from Telmo Nunes, Javier Sanchez, and Ron Thornton.
Maintainer: Mark Stevenson <M.Stevenson at massey.ac.nz>
Description: A package for analysing epidemiological data. Contains
functions
	for directly and indirectly adjusting measures of disease frequency,
	quantifying measures of association on the basis of single or
multiple
	strata of count data presented in a contingency table, and computing

	confidence intervals around incidence risk and incidence rate
estimates.
	Miscellaneous functions for use in meta-analysis, diagnostic test 
	interpretation, and sample size calculations.
Depends: R (>= 2.0.0)
License: GPL (>= 2)
URL: http://epicentre.massey.ac.nz

Regards,

Mark S

************************************************* 
Mark Stevenson 
Associate Professor, Veterinary Epidemiology 
IVABS, Massey University 
Private Bag 11-222 
Palmerston North New Zealand 
Ph: + 64 (06) 350 5915 
Fx: + 64 (06) 350 5716 
M.Stevenson at massey.ac.nz



From Greg.Snow at imail.org  Wed Mar 26 17:55:00 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Wed, 26 Mar 2008 10:55:00 -0600
Subject: [R-pkgs] Update of TeachingDemos package
Message-ID: <07E228A5BE53C24CAD490193A7381BBBFC3AFF@LP-EXCHVS07.CO.IHC.COM>

This is to announce that versio 2.0 of the TeachingDemos package is now
on CRAN (and hopefully soon to a mirror near you).

This is a major upgrade of the package, some of the improvements
include:

The package now uses an NAMESPACE so it is easier to load just the parts
that you need.

Some of the GUI demonstrations now use tkrplot so that the graph is in
the same window as the controls (there are still 'old' versions of these
functions available if you want the old functionality).  The rest of the
GUI demos will be updated to use tkrplot as well, and after R2.7 comes
out they all will be upgraded to use the themed widgets to give a more
uniform look with your OS.

Many of the examples sections of the help pages have replaced
"\dontrun{" with "if(interactive()){" so that they will be run by the
"example" function, but still not block in the automatic checking.  I
recommend running "example" with the argument "ask=FALSE", otherwise you
will need to hit enter 2-4 times each time a diolog pops up and every
time you update something in the dialog.

There are several new functions including:

tkexamp, a tool for creating interactive Tk based examples of what
options to functions do (mainly for plots, but one example shows a
non-plotting function).

dynIdentify and TkIdentify, tools that create a scatterplot with labels,
then allow you to drag the labels with the mouse to better locations.

col2grey, a tool to convert your colors to greyscale so you can get a
general feel of how they would look when printed non-color, or copied,
etc.

SensSpec.demo, a demonstration of how to compute positive and negative
predictive value from sensitivity, specificity, and prevelance using a
virtual population rather than Bayes Theorem and algebra.

TkApprox and TkSpline, GUI wrappers to the approxfun and splinfun
functions that graph your data, the predictions, and allow you to drag
reference lines on the plot to show the predicted values, differences,
and derivatives.

tkprogress, a utility to create and update a progress bar to show how
far through a loop or other iterative process you are.

A set of functions (see txtStart and etxtStart) that will create a plain
text transcript of your R session including both commands and output
(think glorified sink + history).  The 'etxt' versions add markup so
that the text file can be processed by the enscript program to create a
postscript file with some syntax coloring and inclusion of graphs.  The
postscript file can then be converted to pdf or other formats.


Hope others find this helpful,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
(801) 408-8111
 



From maechler at stat.math.ethz.ch  Fri Mar 28 15:18:37 2008
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 28 Mar 2008 15:18:37 +0100
Subject: [R-pkgs] "The Matrix" is approaching version 1.0-0
Message-ID: <18412.65085.549853.54741@stat.math.ethz.ch>


A new version of "the Matrix" 
(well, actually the R package named "Matrix") has become
available on the CRAN mirrors.  

As some of you have noticed, the version numbers (current is version
0.999375-8) are converging to one, and we feel that we have solved
enough of the many (mostly small) problems to announce that release
1.0-0 is imminent.

In the DESCRIPTION of the package we say
--------------------------------------------------------------
Title: A Matrix package for R
Author: Douglas Bates <....> and Martin Maechler <....>
Maintainer: Doug and Martin <Matrix-authors at R-project.org>
Description: Classes and methods for dense and sparse matrices and
   operations on them using Lapack, CSparse and CHOLMOD
--------------------------------------------------------------

The Matrix package provides efficient methods for several formal
(i.e. S4) classes of matrices where each of the actual classes are
some combination of the following three categories

1) dense or sparse
2) symmmetric, triangular, diagonal or "general" (or "permutation")
3) numeric ("d"ouble), logical (TRUE/FALSE/NA) or "patter[n]" (0/1) matrices

Interfaces to many efficient algorithms from Lapack (for "dense") and from
CHOLMOD / Csparse (for "sparse") are all implemented via method definitions
for the customary linear algebra functions
  %*%, t(), crossprod(), tcrossprod(), chol(), qr(), solve(),
  colSums(), rowSums(), kronecker(), determinant(), ...
and for various formal groups of generics, such as
  "Math" (sin,exp,gamma,..)  "Arith" (+,-,*,...),
  "Logic" (>, <=, ..),  "Summary" (sum, max, ...)  etc;
  is.na()

Furthermore, 'indexing' : "A[...]" and "A[..] <- value" of
all(!) kinds of S/R indexing and some new generic functions such as

 lu()     {LU decomposition}
 Schur(), BunchKaufman(),
 norm(), rcond()        {Matrix norms and condition numbers}
 expm()   {Matrix exponential},
 band(), triu(), tril()  {extract band-diagonal or triangular sub-matrices}
 symmpart(), skewpart()   { (x + t(x))/2  and  (x - t(x)) / 2 }

are provided. Further, an extension to the xtabs function
  xtabs(*, sparse=TRUE)
for large sparse, two-way contingency tables
and coercion of one *factor* (possibly crossed with one <numeric>)
to the corresponding (potentially huge) sparse model matrix for sparse
least squares and related computations.

Further to the above, "Matrix" objects are also constructed by
Matrix(), spMatrix(), bdiag() {block-diagonal}, Diagonal() and many
as(., "....Matrix") possibilities.

The Matrix package also provides a C level API (header files of
exported C functions providing low-level functionality) to many of its
internal algorithms that other packages can link to.  Currently, the
'lme4' package makes heavy use of these exported C functions.

---------------------------------------------------------------------------

One of the things we plan to improve considerably is the documentation
for the package.  Currently there are four vignettes but all but the

   Comparisons: Comparisons of Least Squares calculation speeds

are really not complete in one way or another.

---------------------------------------------------------------------------

We would appreciate current users of the Matrix package (and also
generally interested useRs) exploring the package's capabilities and
giving us feedback about problems that they might encounter or missing
features, inefficiencies and maybe even "infelicities" (a.k.a. bugs).
Fixing problems before the release of the 1.0-0 version of "The Matrix",
rather than after its release, is our preferred approach.

Douglas Bates and Martin Maechler
Matrix-authors <at> r-project <.> org



From spencer.graves at pdf.com  Sun Mar 30 00:50:16 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 29 Mar 2008 16:50:16 -0700
Subject: [R-pkgs] FinTS_0.3-1
Message-ID: <47EED5B8.9040004@pdf.com>

Hi, All:

	  FinTS version 0.3-1 is now available on CRAN.  This version
adds a function 'apca' for "Asymptotic Principal Components Analysis", 
as discussed in Tsay (2005) Analysis of Financial Time Series, 2nd ed. 
(Wiley, sec. 9.6), in addition to minor improvements in the partially 
complete scripts for chapters 3 and 9.

	 Spencer Graves



From h.wickham at gmail.com  Fri Apr  4 02:45:48 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 3 Apr 2008 19:45:48 -0500
Subject: [R-pkgs] ggplot2 - version 0.6
Message-ID: <f8e6ff050804031745l3b97910dm2e02bd942cd8134c@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the over 400
examples of ggplot in use.

ggplot 0.6
----------------------------------------

The two big changes in this release are improved documentation and legends:

 * all major ggplot2 components now have their own built in
documentation, so that (e.g.) ?stat_smooth or ?geom_point now give you
useful information

 * the legend code is now considerably more sophisticated and will
attempt to merge together legends for the same variable

 * also, legends are drawn based on the geoms used (instead of the
scales used, as previously) so should match the plot much better (e.g.
for geom_smooth, geom_boxplot, geom_vline, geom_abline,
geom_pointrange).

These features are new, so there are likely to be a few bugs that I
haven't discovered.  Please me know if you do find any.

Other additions and corrections

  * coord_equal: should now work correctly in all situations
  * coord_polar: add start and direction parameters, giving more
control over the layout of the polar coords
  * coord_polar: added my favourite pie chart example
  * coord_trans now deals with groups appropriately, at the cost of
decreased speed
  * geom_abline, geom_vline, geom_hline: should now behave better in a
wider variety of settings
  * geom_boxplot: deals with continuous x-axis and grouping much better
  * geom_boxplot: now has it's own legend which actually looks like a boxplot
  * geom_boxplot: reports if missing values removed
  * geom_crossbar: the middle line is now display thicker than the
other lines, controlled by the parameter fatten (thanks to Heike
Hofmann for the suggestion)
  * geom_density: fix scale adjustment bug in geom_density
  * geom_line, geom_text: all size measurements (now lines and text as
well) are measured in mm, lines/paths default to paths 0.5mm wide
  * geom_rug: new to add marginal rug plots
  * geom_smooth: added example showing how to use geom_smooth with
your own models
  * geom_smooth: fixed bug where if se=FALSE x axis always includes 0
  * geom_vline, geom_hline: yet another rewrite which should make them
more powerful and less error prone.
  * ggsave reports width and height of saved image
  * position_stack: fixed bug when data was empty
  * qplot: allow qplot to use computed aesthetics too
  * scale_continuous: tweaks to minor breaks to make appearance better
on wider range of coordinate systems
  * scale_discrete: all discrete scales now have labels argument which
you can use to override the factor levels
  * scale_discrete: now works correctly with character vectors
  * scale_size: changed default range to [0.5, 3] to better reflect
new sizing decisions
  * scale_size: legends resize to avoid overlaps
  * scale_x_continuous, scale_y_continuous: new convenience functions
xlim and ylim (and zlim) that make it even easier to adjust the limits
of the x, y, and z axes
  * stat_bin, geom_area: fixed bug in combination of stat_bin and
geom_area that made it difficult to draw frequency polygons
  * stat_bin: fixed bug which resulted in increased counts when the x
axis was a categorical variable with a single level (thanks to Bob
Muenchen for pointing this out!)
  * stat_bin: no longer incorrectly warns that binwidth is unspecified
when breaks are set
  * stat_bin: now takes origin argument to manually specify origin of
first bin (default is round_any(min(range), bin_width, floor))
  * stat_boxplot, stat_contour, stat_density2d, stat_qq, stat_density:
na.rm parameter added to the following statistics (thanks to Leena
Choi for suggesting this)
  * stat_function: new, makes it easy to superimpose a function on the plot
  * stat_qq: axes flipped to agree with base R
  * stat_qq: now uses sample aesthetic to select variable for summary
  * stat_quantile: updated to work with latest version of quantreg
  * stat_spoke: new, to make it possible to use geom_segment
parameterised by angle and radius (thanks to Jiho for the suggestion)
  * stat_summary: better documentation
  * stat_summary: convenient auto wrapping of simple summary functions

Miscellaneous changes:

  * it's now easy to change the default scales (and their arguments)
with the set_default_scale function, see ?set_default_scale for more
details (thanks to Bob Muenchen for the suggestion)
  * new order aesthetic which controls the order in which elements are plotted
  * min and max are now scaled the same way as y
  * functions are silently dropped (e.g. aes(colour=col))
  * scales do not try and map variables that don't exist (fixes some
rather obscure bugs)
  * aes(mpg, wt) is now equivalent to aes(x = mpg, y = wt)


See CHANGELOG for changes in previous versions

Regards,

Hadley

-- 
http://had.co.nz/



From rpeng at jhsph.edu  Fri Apr  4 21:47:52 2008
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 04 Apr 2008 15:47:52 -0400
Subject: [R-pkgs] cacher v0.1-2
Message-ID: <47F685E8.9070209@jhsph.edu>

The 'cacher' package contains a set of routines for caching statistical 
analyses.  The idea is that an analysis stored in a file (say, 'foo.R') is run 
and the results of the evaluated expressions are cached in a database.  These 
cached results can subsequently be packaged up and distributed over the interweb.

I've just uploaded to CRAN version 0.1-2 of the 'cacher' package.

There is a brief document describing the package available at

http://www.biostat.jhsph.edu/~rpeng/papers/archive/cacher.pdf

Some sample cached analyses can be found at

http://penguin.biostat.jhsph.edu/cpkg.html

For example, if you wanted to download the analysis associated with the 
'sample.R' file, you could run

library(cacher)
clonecache(id = "44bf", all.files = TRUE)

Using the tools in the 'cacher' package you could then explore the data and code 
that make up this analysis.

This package is by no means 'complete' and is still evolving.  I would greatly 
appreciate any feedback or suggestions on the design if you end up using the 
package for any reason.

-roger
-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/



From mrizzo at bgnet.bgsu.edu  Wed Apr  9 03:04:01 2008
From: mrizzo at bgnet.bgsu.edu (Maria Rizzo)
Date: Tue, 08 Apr 2008 21:04:01 -0400
Subject: [R-pkgs] energy 1.1-0 with dcov
Message-ID: <6.2.0.14.2.20080407182457.020a5180@mail.bex.net>

Dear R-users,

An updated version of the energy package, energy 1.1-0, is now available on 
CRAN.

This version has merged the dcov package (previously available from my 
personal web page) into energy.

New functions include:

dcov (distance covariance)
dcor (distance correlation)
DCOR (four statistics)
dcov.test (distance covariance test of multivariate independence)
indep.test (choice of nonparametric energy tests of multivariate independence)

These functions implement the new methods introduced in our recent article:

G. J. Szekely, M. L. Rizzo and N. K. Bakirov (2007) Measuring and Testing 
Independence by Correlation of Distances, Annals of Statistics, Vol. 35 No. 
6, pp. 2769-2794.

Distance correlation R is a scalar statistic for measuring and testing 
independence of random vectors. It satisfies 0<=R<=1 and R=0 only if 
independence holds. Distance covariance V determines a statistically 
consistent test of independence.

The distance covariance test is theoretically related to, but different 
from the original test based on coefficient I_n implemented in indep.etest. 
The new dcov.test is faster by a factor O(n) than indep.etest.

With the introduction of a second and faster test, we provide a new 
function indep.test with a choice of methods to obtain either test. The 
original indep.etest is now deprecated.

Reprints of the article are available upon request.

Comments and suggestions are always welcome.

   Maria Rizzo and Gabor Szekely



From landronimirc at gmail.com  Wed Apr  9 15:27:36 2008
From: landronimirc at gmail.com (Liviu Andronic)
Date: Wed, 9 Apr 2008 15:27:36 +0200
Subject: [R-pkgs] RcmdrPlugin.Export_0.2-0 released
In-Reply-To: <68b1e2610804090034k6841c182u44ce39ee1dbc9f62@mail.gmail.com>
References: <68b1e2610804090034k6841c182u44ce39ee1dbc9f62@mail.gmail.com>
Message-ID: <68b1e2610804090627j24f3436i3e2d232898f4bcb2@mail.gmail.com>

Dear R users,

I am pleased to announce the release of the Export plug-in for Rcmdr.
At the moment, it is simply a graphical user interface to xtable().
Several developments are, however, planned. It is worth to note that
the Manual offers several pointers on using Sweave together with LyX,
and from this perspective the plugin is an attempt to simplify
creating (LaTeX) reports by using graphical interfaces only.

In the near future, only exporting to LaTeX and HTML will be
supported. Exporting to other formats (say, RTF or ODF) could be
integrated provided that someone is willing to contribute the code
(say, personal scripts that were never published), or point to a
sensible way of automating the process. Any such contributions are
heartily welcome.

Comments and suggestions are, of course, always welcome.
Liviu



From erich.neuwirth at univie.ac.at  Thu Apr 17 14:25:52 2008
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 17 Apr 2008 14:25:52 +0200
Subject: [R-pkgs] RExcelInstaller
Message-ID: <480741D0.2040504@univie.ac.at>

RExcelInstaller_2.0-15

installs RExcel, an add-in for Excel, which connects R and Excel.

RExcel allows to transfer data between R and Excel,
writing VBA macros using R as a library for Excel,
and calling R functions as worksheet function in Excel.
RExcel integrates nicely with R Commander (Rcmdr),
turning R Commander's menus into Excel menus.
It comes with a comprehensive set of example worksheet
illustrating different usage scenarios.

This R package installs the Excel add-in for Excel versions
from 2000 to 2007. It only works on MS Windows (XP and Vista)

-- 
Erich Neuwirth, University of Vienna
Faculty of Computer Science
Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-39464 Fax: +43-1-4277-39459



From friendly at yorku.ca  Fri Apr 18 15:43:56 2008
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 18 Apr 2008 09:43:56 -0400
Subject: [R-pkgs] new candisc package on CRAN
Message-ID: <4808A59C.8030406@yorku.ca>

I'm happy to announce the candisc package, v 0.5-9, now on CRAN.

Generalized Canonical Discriminant Analysis

Description
This package includes functions for computing and visualizing 
generalized canonical discriminant analyses for a multivariate linear 
model. They are designed to provide low-rank visualizations of terms in 
a mlm via the plot method and the heplots package.

The methods are described in

Friendly, M. (2007). HE plots for Multivariate General Linear Models. 
Journal of Computational and Graphical Statistics, 16 (2), 421-444. 
http://www.math.yorku.ca/SCS/Papers/heplots.pdf

Friendly, M. (2006). Data Ellipses, HE Plots and Reduced-Rank Displays 
for Multivariate Linear Models: SAS Software and Examples. Journal of 
Statistical Software, 17(6), 1-42. http://www.jstatsoft.org/v17/i06/


-Michael


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From jan.graffelman at upc.edu  Mon Apr 21 12:00:30 2008
From: jan.graffelman at upc.edu (Jan Graffelman)
Date: Mon, 21 Apr 2008 12:00:30 +0200
Subject: [R-pkgs] Upload HardyWeinberg package (1.1)
Message-ID: <480C65BE.6000103@upc.edu>

Hi all,

I've uploaded to CRAN a new version of the HardyWeinberg package. This
package has routines for performing graphical significance tests (based 
on the ternary plot) for Hardy-Weinberg equilibrium of bi-allelic marker 
  data.

Jan.

-- 
------------------------------------------------------------------------
|Jan Graffelman                          |tel:   +34-93-4011739        |
|Dpt. of Statistics & Operations Research|fax:   +34-93-4016575        |
|Universitat Politecnica de Catalunya    |email: jan.graffelman at upc.edu|
|Av. Diagonal 647, 6th floor             |www:                         |
|08028 Barcelona, Spain                  |  http://www-eio.upc.es/~jan/|



From r.hankin at noc.soton.ac.uk  Wed Apr 23 12:11:09 2008
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Wed, 23 Apr 2008 11:11:09 +0100
Subject: [R-pkgs] new package multipol
Message-ID: <C02F20DD-A630-4E81-9FF8-F49EEEDF0B55@noc.soton.ac.uk>

Hello List

please find a new package, multipol, recently uploaded to CRAN.

This package generalizes the polynom package (which handles univariate
polynomials) to the multivariate case.   A  short article discussing the
package will appear in the next issue of Rnews,  Insha'Allah


enjoy



--
Robin Hankin
Uncertainty Analyst and Neutral Theorist,
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From h.wickham at gmail.com  Fri May  2 20:57:33 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 2 May 2008 13:57:33 -0500
Subject: [R-pkgs] New package: profr 0.1 - an alternative display for
	profiling information
Message-ID: <f8e6ff050805021157h7aaa3281q66b950000599e612@mail.gmail.com>

profr 0.1 ----------------------------

profr provides an alternative data structure and display for profiling
data.  It still uses Rprof() to collect the data, but outputs a
data.frame which should be easier to manipulate.  It also implements a
novel visualisation which allows you to see the length of each call,
as well as the context in which it was called.

To get started, try:

install.packages("profr")
library(profr)
p <- profr(my.slow.function())
plot(p)

Two built in examples are:

plot(nesting_prof)
plot(reshape_prof)

(and the second has helped me to considerably speed up (5-20x) the
development version of reshape)

Regards,

Hadley

PS.  If you'd like to contribute to the development of profr, the
source code is available from http://github.com/hadley/profr.

-- 
http://had.co.nz/



From ggrothendieck at gmail.com  Mon May  5 13:14:10 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 5 May 2008 07:14:10 -0400
Subject: [R-pkgs] batchfiles 0-4.1
Message-ID: <971536df0805050414v4b59aafdqd7342a4e13e47593@mail.gmail.com>

batchfiles 0.4-1 consists of a set of Windows Vista .bat and
other scripts used as front ends to R CMD ... and for other
purposes.

Whereas Version 0.4-0 of batchfiles eliminated the need to
set any paths when running R, version 0.4-1 now eliminates
the need to set any paths when building and installing R
packages.  It does this by using the registry to find R and
rtools and uses a heuristic to find MiKTeX (since MiKTeX
does not have a reliable registry key) and temporarily sets
the path to include rtools and MiKTeX.

Version 0.4-1 also includes an rtools.bat utility which will
set the paths for that session that would have otherwise had
to be set in case you want to use rtools and MiKTeX with
other programs -- this is not needed if you only want to use
R or if you only want to build and install R packages.

Also there is a new el utility (el.js) which runs the
command given as its argument in elevated mode.  e.g.
    el cmd
spawns a cmd session which is elevated.

The scripts Rcmd.bat, R.bat, Rterm.bat, Rscript.bat,
#Rscript.bat, Rgui.bat, RguiStart.bat, Rjgr.bat are actually
all the same script which query the name by which it was
called to determine the appropriate action.  These scripts
are each self containd single file scripts which do not
depend on each other or on other software.  To install any
of them just copy it to any place on your PATH and it can be
immediately used.  Uninstall by deleting it.  Atlhough they
query the registry they do not set the registry (except for
Rversions.hta which calls RSetReg.exe, a program that comes
bundled with R, that in turn sets the registry.)

Version 0.4-0 of these utilities and later have only been
tested on Vista.  Version 0.3-2 and earlier have only been
tested on XP.

More information is available on the home page:
http://batchfiles.googlecode.com



From berthier at supagro.inra.fr  Fri May  9 09:03:01 2008
From: berthier at supagro.inra.fr (Karine Berthier)
Date: Fri, 9 May 2008 07:03:01 +0000
Subject: [R-pkgs] ncf package version 1.0-4
Message-ID: <BAY103-W15C63339C51BF9DCA71A149DD30@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20080509/8a51d676/attachment.pl>

From Achim.Zeileis at R-project.org  Sat May 10 09:58:37 2008
From: Achim.Zeileis at R-project.org (Achim Zeileis)
Date: Sat, 10 May 2008 09:58:37 +0200 (CEST)
Subject: [R-pkgs] AER: Applied Econometrics with R
Message-ID: <Pine.LNX.4.64.0805100957400.6755@paninaro.stat-math.wu-wien.ac.at>

The package AER accompanying the forthcoming book "Applied
Econometrics with R" by Christian Kleiber and me in the
Springer useR! series has (finally!) been released to CRAN:
   http://CRAN.R-project.org/package=AER

It contains some new R functionality
   o tobit regression convenience interface (to "survival")
   o instrumental variables regression (two-stage least squares)
   o (over-) dispersion test (via auxiliary regression)
but the main feature are ~100 data sets taken from popular
econometrics text books and the data archives of JAE (Journal
of Applied Econometrics) and JBES (Journal of Business and
Economic Statistics). Extensive examples are provided with
the data sets, reproducing many of the analyses in the
books/papers they were taken from. In particular, all data
sets from the following books with many of the associated
examples are provided:
   o "Econometrics" (Baltagi, 2002)
   o "Econometric Analysis" (Greene, 2003)
   o "Introduction to Econometrics" (Stock & Watson, 2007)

Until the book becomes available in autumn 2008, we will add
vignettes to the package reproducing the examples from our
book.

Best wishes,
Z



From tabelow at wias-berlin.de  Mon May 19 15:25:51 2008
From: tabelow at wias-berlin.de (Karsten Tabelow)
Date: Mon, 19 May 2008 15:25:51 +0200
Subject: [R-pkgs] Updated package adimpro
Message-ID: <48317FDF.8020809@wias-berlin.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

This package implements tools for manipulationg digital images and the
Propagation Separation approach for smoothing digital images.

Version 0.6.1 is a major update with many new features:

Input/Output:

- - we now keep exif information as comment of an image
~  this information is evaluated to recover the original adimpro-object
~  used to produce the image file, see demo(io).
~  This may be changed to using rpm-profiles.
- - new function write.raw provides a possibility to store
~  RAW sensor data as a greyscale png-image
~  these images are recognized by read.raw, see demo(raw).
- - write.image now keeps color space by default
- - read.image/write.image now also handles xyz, yuv, yiq and
~  hsi color spaces correctly
- - the location of ImageMagick is now automatically determined
~  using function Sys.which and set as an environment variable
~  ImageMagick when the package is loaded (This requires R >=2.6.0).
~  The argument convert.path in read.image and write.image is no
~  longer needed and has been removed.
- - make.image no longer has an argument gamma

Adaptive smoothing:

- - functions awsimage, awspimage:

- - value of ladjust      1.0 -- 1.25, different lseq
- - new arguments plateau=NULL, homogen=TRUE, earlystop=TRUE
- - new varmodel "Quadratic"
- - location kernel with choice "Plateau"
- - statistical kernel changed to Plateau with spmin=0.25
- - FORTRAN subroutine awsimg has fewer parameters
- - lseq extended (if it is to short) by last element rather than by 1
- - FORTRAN subroutine awsvimage has differing parameters
- - FORTRAN subroutine mawsimg has fewer parameters
- - FORTRAN subroutine awspimg has fewer parameters
- - handles lower/uppercase for some arguments

- - new function awsprop for testing propagation condition

- - new function awsaniso for anisotropic structural adaptive smoothing

Color space conversions:

- - increased and changed functionality of adjust.image
- - rgb2xxx  also accepts colorspaces xyz , yuv and yiq
- - xxx2rgb - functions now allow to specify RGB-color space (default
~  "Adobe")
- - new function cam2rgb for conversion of camera color spaces to RGB
- - new funcions rgb2xyzmat and xyz2rgbmat
- - function gamma.correction  now uses gammatype instead of arguments ga
~  and bp
- - new function for inverse gamma correction
- - new function whitepoint, wpofT, changewhitepoint  for white point
~  definitions and manipulation
- - whitebalance no uses whitepoint and color temperature
- - adjust.image  now allows to set gammatype, cspace, whitep, color
~  temperature blackpoint and exposure
- - new function demosaic.raw to convert RAW sensor data to RGB


Image manipulations and diagnostics:

- - function edges has a new argument abs
- - functions shrink.image, rotate.image, clip.image also accept "RAW"
- - rotate.image has new argument compress
- - new function extract.info for extracting EXIF-Information

Bug fixes: e.g. in make.image, invgamma.correction (internal),
~           read.ppm(internal), read.pgm(internal),

Demos:

We added an extensive set of demos.
demo(adimpro) just runs all demos sequentially. Especially
demo(awspimage) (local polynomial smoothing) is time consuming.




- --
Karsten Tabelow, Dr.
WIAS Berlin
Mohrenstrasse 39, 10117 Berlin, Germany

email: tabelow at wias-berlin.de
phone: +49-30-20372 564
fax  : +49-30-2044975
url  : http://www.wias-berlin.de/people/tabelow/
url  : http://www.wias-berlin.de/project-areas/stat/a3
Member of Matheon (www.matheon.de)

D08D1822
8EC1 479A ECD6 18C1 5DD7 E63E 32F1 50A9 D08D 1822

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (GNU/Linux)
Comment: Using GnuPG with SUSE - http://enigmail.mozdev.org

iD8DBQFIMX/fMvFQqdCNGCIRAjQ1AJ9BkbKNO6hQnDj2p466KxWRGOQ9EgCZAUfX
djO1KxHt9uogG9fNDSLtKUI=
=pbts
-----END PGP SIGNATURE-----



From tabelow at wias-berlin.de  Mon May 19 15:25:49 2008
From: tabelow at wias-berlin.de (Karsten Tabelow)
Date: Mon, 19 May 2008 15:25:49 +0200
Subject: [R-pkgs] Updated package fmri
Message-ID: <48317FDD.7030604@wias-berlin.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

fmri is a contributed package for R, that implements functions for
analyzing single-subject fmri data with structural adaptive smoothing
methods.

New in version 1.2-6
- --------------------

~  - new function cutroi()
~  - plot.fmridata() is now able to produce anatomical overlay for pvalue
~    data for AFNI, and NIFTI data
~  - read.AFNI() should be able to interpret filenames more flexible:
~    with, without extensions, with dots in name.





- --
Karsten Tabelow, Dr.
WIAS Berlin
Mohrenstrasse 39, 10117 Berlin, Germany

email: tabelow at wias-berlin.de
phone: +49-30-20372 564
fax  : +49-30-2044975
url  : http://www.wias-berlin.de/people/tabelow/
url  : http://www.wias-berlin.de/project-areas/stat/a3
Member of Matheon (www.matheon.de)

D08D1822
8EC1 479A ECD6 18C1 5DD7 E63E 32F1 50A9 D08D 1822

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (GNU/Linux)
Comment: Using GnuPG with SUSE - http://enigmail.mozdev.org

iD8DBQFIMX/cMvFQqdCNGCIRAgfoAJ4hxwFLSTup4Zf8NYriVvzKiKbErwCfSIXI
Vt0ggjbb7GEfCMJVhzkWeRQ=
=IHty
-----END PGP SIGNATURE-----



From tabelow at wias-berlin.de  Mon May 19 15:25:46 2008
From: tabelow at wias-berlin.de (Karsten Tabelow)
Date: Mon, 19 May 2008 15:25:46 +0200
Subject: [R-pkgs] New package dti
Message-ID: <48317FDA.2080506@wias-berlin.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

dti is a new contributed package for R, that implements functions for
smoothing Diffusion-weighted MR data with structural adaptive smoothing
methods.

Version 0.5-2 contains functions for smoothing DW data in the context of
the Diffusion Tensor Model and for visualization of Diffusion Tensor
Data and anisotropy maps derived thereof. The tensor estimation can be
done using a linearized model, or using a non-linear model. A correction
for Rician bias can be included.



- --
Karsten Tabelow, Dr.
WIAS Berlin
Mohrenstrasse 39, 10117 Berlin, Germany

email: tabelow at wias-berlin.de
phone: +49-30-20372 564
fax  : +49-30-2044975
url  : http://www.wias-berlin.de/people/tabelow/
url  : http://www.wias-berlin.de/project-areas/stat/a3
Member of Matheon (www.matheon.de)

D08D1822
8EC1 479A ECD6 18C1 5DD7 E63E 32F1 50A9 D08D 1822

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (GNU/Linux)
Comment: Using GnuPG with SUSE - http://enigmail.mozdev.org

iD8DBQFIMX/aMvFQqdCNGCIRAt3gAKCCdv9f8h030EAFpzIWL8npiJCq/wCfXWYK
IufrFV0vmO7Dcz/Rr2QzFGs=
=HWa8
-----END PGP SIGNATURE-----



From hastie at stanford.edu  Mon Jun  2 20:08:16 2008
From: hastie at stanford.edu (Trevor Hastie)
Date: Mon, 02 Jun 2008 11:08:16 -0700
Subject: [R-pkgs] New glmnet package on CRAN
Message-ID: <48443710.8090209@stanford.edu>

glmnet is a package that fits the regularization path for linear, two- 
and multi-class logistic regression
models with "elastic net" regularization (tunable mixture of L1 and L2 
penalties).
glmnet uses pathwise coordinate descent, and is very fast.

Some of the features of glmnet:

* by default it computes the path at 100 uniformly spaced (on the log 
scale) values of the regularization parameter
* glmnet appears to be faster than any of the packages that are freely 
available, in some cases by two orders of magnitude.
* recognizes and exploits sparse input matrices (ala Matrix package). 
Coefficient matrices are output in sparse matrix representation.
* penalty is (1-a)*||\beta||_2^2 +a*||beta||_1  where a is between 0 and 
1;  a=0 is the Lasso penalty, a=1 is the ridge penalty.
   For many correlated predictors, a=.95 or thereabouts improves the 
performance of the lasso.
* convenient predict, plot, print, and coef methods
* variable-wise penalty modulation allows each variable to be penalized 
by a scalable amount; if zero that variable always enters
* glmnet uses a symmetric parametrization for multinomial, with 
constraints enforced by the penalization.

Other families such as poisson might appear in later versions of glmnet.

Examples of glmnet speed trials:
 
Newsgroup data: N=11,000, p=4 Million, two class logistic. 100 values 
along lasso path.   Time = 2mins
14 Class cancer data: N=144, p=16K, 14 class multinomial, 100 values 
along lasso path. Time = 30secs

Authors: Jerome Friedman, Trevor Hastie, Rob Tibshirani.

See our paper http://www-stat.stanford.edu/~hastie/Papers/glmnet.pdf for 
implementation details,
and comparisons with other related software.

-- 
--------------------------------------------------------------------
  Trevor Hastie                                  hastie at stanford.edu
  Professor & Chair, Department of Statistics, Stanford University
  Phone: (650) 725-2231 (Statistics)	         Fax: (650) 725-8977
	 (650) 498-5233 (Biostatistics)		 Fax: (650) 725-6951
  URL: http://www-stat.stanford.edu/~hastie
  address: room 104, Department of Statistics, Sequoia Hall
	          390 Serra Mall, Stanford University, CA 94305-4065



From patrick.mair at wu-wien.ac.at  Thu Jun  5 19:04:40 2008
From: patrick.mair at wu-wien.ac.at (Patrick Mair)
Date: Thu, 05 Jun 2008 10:04:40 -0700
Subject: [R-pkgs] smacof package for multidimensional scaling
Message-ID: <48481CA8.4050704@wu-wien.ac.at>

Dear UserR's,

The smacof package (see also our PsychoR repository on 
http://r-forge.r-project.org/projects/psychor/) is uploaded on CRAN.

This package provides the following approaches of multidimensional 
scaling (MDS) based on stress minimization by means of majorization 
(smacof): - Simple smacof on symmetric dissimilarity matrices
- smacof for rectangular matrices (unfolding models)
- smacof with constraints on the configuration (linear, unique, 
diagonal, or user-specified constraints; fitting simplex or circumplex)
- 3-way smacof for individual differences (including constraints for 
idioscal, indscal, and identity)
- Sphere projections (spherical smacof, primal and dual algorithm).

Each of these approaches is implemented in a metric and nonmetric manner 
including primary, secondary, and tertiary approaches for tie handling. 
Various 2- and 3D-plots are provided and a package vignette is included.

Patrick



From s.wood at bath.ac.uk  Mon Jun  9 15:34:33 2008
From: s.wood at bath.ac.uk (Simon Wood)
Date: Mon, 9 Jun 2008 14:34:33 +0100
Subject: [R-pkgs] Fwd: mgcv 1.4 on CRAN
Message-ID: <200806091434.33328.s.wood@bath.ac.uk>

mgcv 1.4 is now on CRAN. It includes new features to allow mgcv::gam to fit
almost any (quadratically) penalized GLM, plus some extra smoother classes.

New gam features
-------------------------

*  Linear functionals of smooths can be included in the gam linear predictor,
allowing, e.g., functional generalized linear models/signal regression,
smooths of interval data, etc.

* The parametric component of a model can be quadratically penalized, giving
easy access to gam's fitting and smoothing parameter selection methods, for
any model with a penalized glm structure.

* Smooths can be linked to have the same estimated smoothing parameter.

* `by' variables (used for varying coefficient models) can now be factor
variables, to enable easy conditioning of smooths on factors.

* The default p-values for smooth terms have been substantially improved.

* see ?gam.models and ?summary.gam for further details.

New smoothers
----------------------

* Eilers and Marx style P-splines are now built in, along with a cyclic
version. See ?p.spline.

* An adaptive smoother class has been added. See ?adaptive.smooth.

* The interface for adding user defined smooths has been modified and
simplified. See ?smooth.construct.

A fuller list of changes is at
http://cran.r-project.org/web/packages/mgcv/ChangeLog

--

> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283

-------------------------------------------------------

-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283



From felix at nfrac.org  Thu Jun 19 13:15:17 2008
From: felix at nfrac.org (Felix Andrews)
Date: Thu, 19 Jun 2008 21:15:17 +1000
Subject: [R-pkgs] playwith 0.8-55
Message-ID: <94730b8a0806190415g74a5496ev58890553cb11342f@mail.gmail.com>

playwith package version 0.8-55 is now on CRAN.
It provides a GTK+ interface for interacting with R plots.

Screenshots of some examples are online at:
http://code.google.com/p/playwith/wiki/Screenshots

Changes in Version 0.8-55

  o argument `parameters`: automatically constructs
    widgets to control parameter values appearing in the call.

  o default action when dragging on the plot is zoom.
    default action on right-click is zoomout.

  o whether to start in time.mode is determined by looking at
    the data: TRUE if the x data has a 'ts' or 'zoo' class.

  o restrict zooming to x axis in time.mode
    only if a time.vector was not specified.

  o concept of the "main function" which accepts typical plot
    arguments (xlim, ylim, main, etc) -- not necessarily the
    top-level call. By default, a depth-first search is used
    to find a function that accepts `xlim` or `...`.

  o callArg() now uses standard evaluation by default, rather than
    quoting its argument. Old code will need to be changed!

  o use RGtk2 rather than gWidgets for edit.call and edit.annotations
    because gWidgets is very slow.

  o reasonable guess for data points and labels with ggplot::qplot()

  o enabled pretty ggplot2 plots (print.ggplot with pretty=TRUE)
    if using grid package version >= 2.7
    (older versions had a problem with viewports being popped).

  o code reorganisation: split tools into separate files; ESS style.


The predecessor to this package, plotAndPlayGTK, has been moved to the
CRAN archive.

-- 
Felix Andrews / ???
PhD candidate
Integrated Catchment Assessment and Management Centre
The Fenner School of Environment and Society
The Australian National University (Building 48A), ACT 0200
Beijing Bag, Locked Bag 40, Kingston ACT 2604
http://www.neurofractal.org/felix/
3358 543D AAC6 22C2 D336 80D9 360B 72DD 3E4C F5D8



From adrian at maths.uwa.edu.au  Mon Jun 23 10:13:08 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Mon, 23 Jun 2008 16:13:08 +0800 (WST)
Subject: [R-pkgs] scuba 1.2-1
Message-ID: <60291.121.221.140.172.1214208788.squirrel@121.221.140.172>


	scuba 1.2-1

	** now with added Helium **

'scuba' is a contributed R package that performs theoretical calculations
about scuba diving --- dive profiles, decompression models,
gas toxicity and so on.

New features in version 1.2-1:

	. Breathing gases may now contain Helium
          as well as Oxygen and Nitrogen.

	. Decompression models now handle breathing gases
          containing Helium.

	. Haldane (diffusion compartment) models are now
		represented by objects of a special class "hm".

	. Dive profiles (objects of class "dive") can be
		modified more easily. You can change the breathing gas,
                modify the depth and duration of a dive,
                or cut-and-paste several dive profiles.

	. Bug fix in showstates().

New functions:

	ndl	Calculates No-Decompression Limits

	trimix	Creates a gas object representing trimix
		(oxygen/nitrogen/helium mixture)

	hm	Creates a new Haldane model (diffusion compartment model
		for decompression theory).

	pickmodel
		Selects one of the standard Haldane models.

	tanklist
	tanklist<-
		Extracts or modifies the breathing gases used in a dive.

	chop.dive
		Extracts part of a dive profile.

	depths.dive<-
	times.dive<-
	durations.dive<-
		Operators for modifying a dive profile.


Adrian Baddeley, 22 june 2008



From david.ardia at unifr.ch  Mon Jun 23 10:56:55 2008
From: david.ardia at unifr.ch (Ardia David)
Date: Mon, 23 Jun 2008 10:56:55 +0200
Subject: [R-pkgs] AdMit 1.00-02
Message-ID: <485F6557.8030709@unifr.ch>

'AdMit' 1.00-02 is a contributed R package which provides functions to 
perform the fitting of an
adaptive mixture of Student-t distributions to a target density through 
its kernel function.
The mixture approximation can then be used as the importance density
in importance sampling or as the candidate density in the 
Metropolis-Hastings algorithm to
obtain quantities of interest for the target density itself.

http://cran.at.r-project.org/web/packages/AdMit/index.html

-- 
David Ardia
H-building, room 11-26
Econometric Institute
Erasmus University
PO Box 1738
NL 3000 DR Rotterdam
The Netherlands
Phone: +31 (0)10 408 2269



From jayemerson at gmail.com  Wed Jun 25 15:09:14 2008
From: jayemerson at gmail.com (Jay Emerson)
Date: Wed, 25 Jun 2008 09:09:14 -0400
Subject: [R-pkgs] Package bigmemory now available on CRAN
Message-ID: <d4588dec0806250609h4530d0c9v2a666aa7708792ae@mail.gmail.com>

Package "bigmemory" is now available on CRAN.  A brief abstract follows:

Multi-gigabyte data sets challenge and frustrate R users even on
well-equipped hardware.
C/C++ and Fortran programming can be helpful, but is cumbersome for interactive
data analysis and lacks the flexibility and power of R's rich
statistical programming environment.
The new package bigmemory bridges this gap, implementing massive matrices
in memory (managed in R but implemented in C++) and supporting their
basic manipulation
and exploration. It is ideal for problems involving the analysis in R
of manageable
subsets of the data, or when an analysis is conducted mostly in C++.
In a Unix environment,
the data structure may be allocated to shared memory with transparent read
and write locking, allowing separate processes on the same computer to
share access to a
single copy of the data set. This opens the door for more powerful
parallel analyses and
data mining of massive data sets.

-- 
John W. Emerson (Jay)
Assistant Professor of Statistics
Department of Statistics
Yale University
http://www.stat.yale.edu/~jay



From spencer.graves at pdf.com  Mon Jul  7 04:48:49 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 06 Jul 2008 19:48:49 -0700
Subject: [R-pkgs] Functional Data Analysis, fda_1.2.4
Message-ID: <48718411.4050909@pdf.com>

Hi, All:

	  Version 1.2.4 of the Functional Data Analysis (fda) package is now 
available on CRAN.  In this version, both 'smooth.basis' and 
'smooth.basisPar' have been modified to make them easier to use.  They 
have more useful defaults and they return an object of class
'fdSmooth', with methods for 'plot', 'lines', and 'plotfit'.  In 
addition, there have also been improvements to the 'plotfit' function 
and the 'CanadianWeather' data.  Also, a function 'norder' has been
added, which returns the order of a B-spline.

	 Spencer Graves



From nkraemer at cs.tu-berlin.de  Thu Jul 10 17:28:19 2008
From: nkraemer at cs.tu-berlin.de (Nicole Kraemer)
Date: Thu, 10 Jul 2008 17:28:19 +0200
Subject: [R-pkgs] ppls: version 1.02 including a new data set
Message-ID: <48762A93.8080907@cs.tu-berlin.de>

Dear R users,

an update of the package ppls - Penalized Partial Least Squares - is now 
available on CRAN.

It implements the methods described in

N. Kr?mer, A.-L. Boulesteix, G. Tutz
"Penalized Partial Least Squares with Applications to B-Spline 
Transformations and Functional Data"
Chem. Intell. Lab. Sys. 2008
http://dx.doi.org/10.1016/j.chemolab.2008.06.009


Features of the package include

* the estimation of functional data with penalized PLS,
* the estimation of generalized additive models with penalized PLS based 
on spline transformations,
* model selection for both methods based on cross validation.

The most important changes since 1.01 are

(1) a more efficient implementation of the penalized PLS algorithm that 
decreases the run-time substantially,
(2) the inclusion of the data set "cookie" that contains measurements 
from quantitative near-infrared spectroscopy.

Best regards,

Nicole & Anne-Laure


-- 
Dr. Nicole Kr?mer
TU Berlin
Machine Learning/Intelligent Data Analysis	fon: (+49) 30 314 78627
Franklinstr. 28/29, 10587 Berlin, Germany	fax: (+49) 30 314 78622

web: http://ml.cs.tu-berlin.de/~nkraemer



From racinej at mcmaster.ca  Fri Jul 25 16:41:03 2008
From: racinej at mcmaster.ca (Jeffrey S. Racine)
Date: Fri, 25 Jul 2008 10:41:03 -0400
Subject: [R-pkgs] Package np version 0.20-0 released to CRAN
Message-ID: <1216996863.46684.28.camel@pc-racine1.economics.mcmaster.ca>

Dear R users,

An updated version of the np package has recently been uploaded to CRAN
(version 0.20-0). Version 0.20-0 is documented in

Tristen Hayfield and Jeffrey S. Racine (2008). Nonparametric
Econometrics: The np Package. Journal of Statistical Software 27(5). URL
http://www.jstatsoft.org/v27/i05/

and also in a vignette (vignette("np",package="np")). There is also a
FAQ located in the package browse directory (np_faq.pdf, also available
at http://socserv.mcmaster.ca/racine/np_faq.pdf).

A much more thorough treatment of the subject matter can be found in Li,
Q. and J. S. Racine (2007), Nonparametric Econometrics: Theory and
Practice, Princeton University Press, ISBN: 0691121613 (768 Pages) for
those who might be interested
(http://press.princeton.edu/titles/8355.html)

Information on the np package:

This package provides a variety of nonparametric (and semiparametric)
kernel methods that seamlessly handle a mix of continuous, unordered,
and ordered factor datatypes. We would like to gratefully acknowledge
support from  the Natural Sciences and Engineering Research Council of
Canada (NSERC:www.nserc.ca), the Social Sciences and Humanities Research
Council of Canada (SSHRC:www.sshrc.ca), and the Shared Hierarchical
Academic Research Computing Network (SHARCNET:www.sharcnet.ca).

Changes from 0.14-3 to 0.20-0

* npksum now supports an expanded set of kernels (including 
  convolution, derivative and integral), which can be selected
  via the 'operator' argument.
* automatic bandwidth searches are now performed when attempting to 
  evaluate on data without bandwidths.
* npsigtest interface brought in line with other functions.
* significance tests can now be performed on npreg outputs.
* added a vignette and faq.
* summary on npconmode now properly retrieves names from bandwidth 
  objects.
* fixed the 6th and 8th order epanechnikov kernels.
* fixed some quietness issues.
* npplot now returns data upon request for conditional densities.
* npreg and npcdens now take the appropriate limits in some 
  pathological cases.

We are grateful to John Fox, Achim Zeilies, Roger Koenker, and numerous
users for their valuable feedback which resulted in an improved version
of the package.

-- Jeffrey Racine & Tristen Hayfield.
-- 
Professor J. S. Racine         Phone:  (905) 525 9140 x 23825
Department of Economics        FAX:    (905) 521-8232
McMaster University            e-mail: racinej at mcmaster.ca
1280 Main St. W.,Hamilton,     URL:
http://www.economics.mcmaster.ca/racine/
Ontario, Canada. L8S 4M4

`The generation of random numbers is too important to be left to chance'



From ubk2101 at columbia.edu  Mon Jul 28 14:28:08 2008
From: ubk2101 at columbia.edu (Udaya B. Kogalur)
Date: Mon, 28 Jul 2008 08:28:08 -0400
Subject: [R-pkgs] randomSurvivalForest 3.5.0 now available
Message-ID: <38c08c270807280528t38900327w80eae921228f9284@mail.gmail.com>

Please find release 3.5.0 of the CRAN package "randomSurvivalForest"
now posted on CRAN.  Thank you.


ubk2101 at columbia.edu

Udaya B. Kogalur, Ph.D.
Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012

---------------------------------------------------------------------------------
CHANGES TO RELEASE 3.5.0

RELEASE 3.5.0 represents a significant upgrade in the functionality of
the product.  Key changes are as follows:

o A random version of all computed split rules is now available.  See
the documentation for more details.

o The ability to handle factors has been implemented.  If the factor
is ordered, then splits are similar to real valued variables.  If the
factor is unordered, a split will move a subset of the levels in the
parent node to the left daughter, and the complementary subset to the
right daughter.  All possible complementary pairs are considered and
apply to factors with an unlimited number of levels.  However, for
deterministic splitting there is an optimization check to ensure that
the number of splits is not greater than the number of complementary
pairs in a node (this internal check will be overridden in random
splitting mode if nsplit is set high enough).  Note that when
predicting on test data involving factors, the factor labels in the
test data must be the same as in the grow (training) data.  Consider
setting labels that are unique in the test data to missing.



From bertrand.iooss at cea.fr  Fri Aug  1 16:39:19 2008
From: bertrand.iooss at cea.fr (IOOSS Bertrand 165542)
Date: Fri, 1 Aug 2008 16:39:19 +0200
Subject: [R-pkgs]  sensitivity
Message-ID: <6AF7979EE40736408C94E7D414EBD62804B0CD59@THEZE.intra.cea.fr>

Hi All,

the new release v1.4-0 of the "sensitivity" package is now available on CRAN
The "sensitivity" package is devoted to factor screening and global sensitivity analysis
of numerical model output. 

Here are the new features list:

New functionalities:
	 * sequential bifurcation method (sb function) [VERSION ALPHA] 
       * 3D plot 3D for the Morris method (function plot3d.morris, needs the rgl package) 
       * simplex designs for Morris method (function morris) 
       * multidimensional Sobol indices (function sobol) 
       * argument return.var in sobol methods in order to have local variables
         which are not saved in the output object, for example the bootstrap replicates
	   (functions sobol and sobol2002) 
       * template files writing (function template.replace) 
       * new argument ylim to control the ordinate axis for graphics (src, pcc, sobol, sobol2002, fast)
 
Small changes in the functions:
       * several names of parameters and variables in the objects have changed 
       * function "srcpcc" has been divided in two functions: "src" and "pcc" 
       * function "sobol" has been divided in two functions: "sobol" (original 1993 method) and "sobol2002"
       * function "fast" has been renamed "fast99"
       * the space filling design optimization for the Morris design has been rearranged in order
	   to gain computing memory. Some C code additions will be done later. 
 

------------------------------------------------------------------
Bertrand Iooss
CEA Cadarache
DEN/CAD/DER/SESI/LCFR
13108 Saint Paul lez Durance
France

Laboratoire de Conduite et de Fiabilit? des R?acteurs
bertrand.iooss at cea.fr
Tel : (33/0) 4 42 25 72 73
Fax : (33/0) 4 42 25 24 08



From a.p.s.l.rouzic at bio.uio.no  Fri Aug  1 17:55:03 2008
From: a.p.s.l.rouzic at bio.uio.no (Arnaud Le Rouzic)
Date: Fri, 01 Aug 2008 17:55:03 +0200
Subject: [R-pkgs] New package: noia
Message-ID: <489331D7.8070607@bio.uio.no>

Hi the list,

A new version (0.92) of my package 'noia' will be available soon on CRAN 
mirrors, and I think it might be a good opportunity to introduce it 
shortly to the R community.

In summary: 'noia' will be of absolutely no interest for 99.99% of you. 
The 0.01% remaining are quantitative geneticists who are interested in 
measuring the effect of genes in a proper way.

Since some of you may want to know why it is worth to let this 'noia' 
package take a few bytes on the CRAN server, I will try to introduce 
very shortly the scientific problem. The rules that explain the 
transmission of genes between generations are well known since the end 
of the 19th century. One important consequence of these rules is that in 
all diploid organisms (having two copies of the genomes, i.e. most of 
them, including us), it is virtually impossible to produce an equal 
number of offspring of each "type" from non-inbred parents: you end up, 
most of the time, with frequencies such as 1/4 vs 3/4, or 7/16 vs 9/16, 
or many other combinations. For quantitative traits, the link between 
the genes and the characters is complex, and the effect of genes has to 
be measured through models that look like cross-factor ANOVA designs. 
Because of the unequal segregating ratios, these ANOVAs are highly 
unbalanced, with all well-known annoying consequences: correlations 
between effect estimates, non-orthogonal variance decomposition, etc.

For a long time, comparing estimates measured in differently designed 
populations was not considered as a big issue. However, the recent need 
of effective model selection procedures lead to the proposition of new 
models aiming to a (more or less) orthogonal decomposition of genetic 
effects. This package provides tools to perform linear regressions using 
various models, to manipulate the genetic effects, and to compute 
genotype to phenotype maps, i.e. the function explaining how the genes 
expresses a given character. In addition, the 'noia' package provides a 
tool to perform 'multilinear' regression, an attempt of non-linear 
genotype-phenotype mapping.

In summary, 'noia' is a wrapper for lm() and nls() functions in a very 
specific context: estimating the effects of genes on a given trait.

NB: 'noia' is useless if the location of the genes is not known. 
Locating the genes requires a QTL detection procedure, for which 
packages already exist (see Rqtl for instance).

Much more information can be found in scientific publications. Two are 
particularly relevant:

* This package and its functions are described in a recent paper:
Arnaud Le Rouzic and Jos? M. ?lvarez-Castro, Estimation of Genetic 
Effects and Genotype-Phenotype Maps, /Evolutionary Bioinformatics 
/2008:4 225-235.  http://la-press.com/article.php?article_id=887

* The corresponding statistical framework is extensively described in:
Jos? M. ?lvarez-Castro and ?rjan Carlborg, A unified model for 
functional and statistical epistasis and its application in QTL 
analysis, Genetics, Vol. 176, 1151-1167 2007. 
http://www.genetics.org/cgi/content/abstract/176/2/1151

Given the probable low impact of the package, I am not planning to 
follow the R help mailing list. However, my email address is everywhere 
in the manual, and I would be very happy to answer questions related to 
this package; so don't hesitate to forward potential questions or to 
encourage users to contact me directly.

Arnaud Le Rouzic.



From gregoire.pau at ebi.ac.uk  Thu Jul 31 19:11:30 2008
From: gregoire.pau at ebi.ac.uk (Gregoire Pau)
Date: Thu, 31 Jul 2008 18:11:30 +0100
Subject: [R-pkgs] hwriter - Writing R objects in HTML format
Message-ID: <4891F242.4090602@ebi.ac.uk>

Dear R community,

I'm pleased to announce the availability of hwriter v0.92 on CRAN.

hwriter is an easy-to-use package able to format and output R objects in 
HTML format. It supports advanced formatting, tables, CSS styling, 
images and provides a convenient mapping between R tables and HTML tables.

hwriter combines the simple syntax of the xtable package and the 
strength of HTML/CSS styling. Making a complex HTML template with 
images, nested tables and nested HTML components is particularly easy.

hwriter web page is written by itself, using 'example(hwriter)':
http://www.ebi.ac.uk/~gpau/hwriter/

Its CRAN page is http://cran.r-project.org/web/packages/hwriter/

Hoping this package will be useful to the R community,
Best regards,

Greg
-- 
Gregoire Pau
EMBL/EBI Cambridge, UK
http://www.ebi.ac.uk/~gpau



From jens.oehlschlaegel at truecluster.com  Mon Aug  4 10:12:56 2008
From: jens.oehlschlaegel at truecluster.com (=?iso-8859-15?Q?Jens_Oehlschl=E4gel?=)
Date: Mon, 04 Aug 2008 10:12:56 +0200
Subject: [R-pkgs] major release ff 2.0 (large atomic objects)
Message-ID: <1060702519@web.de>

Dear R community,

ff Version 2.0 is available on CRAN. Based on paging concepts from version 1.0, 
2.0 is a major redesign of this package for handling large datasets. 
We have implemented numerous enhancements and performance improvements to make 
this package suitable as a 'base' package for large data processing. 

The ff package provides atomic data structures that are stored on disk but 
behave (almost) as if they were in RAM by transparently mapping only a section 
(pagesize) in main memory - the effective virtual memory consumption per ff 
object.

In addition to the 'double' data type, ff objects now have support for
'logical', 'raw' and 'integer' atomic datatypes, plus close-to-atomic types 
like 'factor', 'POSIXct' or custom close-to-atomic types. In addition to fast 
vector access, ff now has native support for matrices and arrays with flexible 
dimorder (major column-order, major row-order and generalizations for arrays). 

While the raw data still gets stored on binary flat files in native encoding,
'ff' objects have been extended to carry their meta information as physical
and virtual attributes. ff objects have well-defined hybrid copying semantics, 
which gives rise to certain performance improvements through virtualization. 

The new ff objects can be stored and reopened across R sessions. Flat files can 
be shared by multiple 'ff' R objects (using different data en/de-coding 
schemes) in the same process or from multiple R processes to exploit 
parallelism. A wide choice of finalizer options allows to work with 'permanent'
files as well as creating/removing 'temporary' ff files completely transparent 
to the user. On certain OS/Filesystem combinations, the creation process of 
large atomic data sets has been speed-up dramatically using sparse file 
allocation.

Several access optimization techniques such as Hybrid Index Preprocessing and 
Virtualization are implemented to achieve good performance even with large 
datasets, for example virtual matrix transpose without touching a single byte 
on disk.

Further, to reduce disk I/O, the atomic data gets stored native and compact on
binary flat files i.e. logicals take up exactly 2 bits to represent TRUE, FALSE
and NA.

Beyond basic access functions, the ff package also provides compatibility 
functions that facilitate writing code for ff and ram objects and support for 
batch processing on ff objects (e.g. as.ram, as.ff, ffapply).

A package that supports convenient processing of large ff objects is in the 
making. R.ff will make the bigger part of R's basic functions available for ff 
objects through method dispatch and/or an evaluator that handles expressions 
which contain ff objects. 

NOTE: A professional extension is available from the authors, which integrates
      additional high-performance features neatly into the ff package. 
      The extension allows  efficient handling of symmetric matrices 
      and supports more packed data types: 
      boolean (1 bit), quad (2 bit unsigned), nibble (4 bit unsigned)
      , byte (1 byte signed with NAs), ubyte (1 byte unsigned)
      , short (2 byte signed with NAs), ushort (2 byte unsigned)
      , single (4 byte float with NAs). 
      For example 'quad' allows efficient storage of genomic data as an 
      'A','T','G','C' factor. The unsigned types support 'circular' arithmetic. 
 
P.S. If you are interested in ff 2.0 you might want to visit our presentation 
August 5th at JSM "High-Performance Processing of Large Data Sets via Memory 
Mapping: A Case Study in R And C++" or the official package presentation at 
UseR!2008 in Dortmund scheduled for August 13th. 

The ff authors
Daniel Adler <dadler at uni-goettingen.de>
Christian Gl?ser <christian_glaeser at gmx.de>
Oleg Nenadic <onenadi at uni-goettingen.de>
Jens Oehlschl?gel <Jens.Oehlschlaegel at truecluster.com>
Walter Zucchini <wzucchi at uni-goettingen.de>



From jfox at mcmaster.ca  Fri Aug  8 16:19:46 2008
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 8 Aug 2008 10:19:46 -0400
Subject: [R-pkgs] New version of Rcmdr package
Message-ID: <000801c8f961$cf529960$6df7cc20$@ca>

Dear R users,

A new version (1.4-0) of the Rcmdr package (providing a basic-statistics
graphical user interface to R) is now on CRAN. This is the annual update of
the package (apart from bug-fixes and minor changes). Updated Italian and
Russian translations are included with the package (courtesy, respectively,
of Stefano Calza and Alexey Shipunov); I'll submit minor updates as other
translations arrive.

The new version of the Rcmdr package has a number of new facilities (see the
CHANGES file installed with the package), the most important of which is
probably the ability of plug-in packages to remove (as well as add to) the
Rcmdr menus. This should permit individuals to use the Rcmdr infrastructure
to create GUIs for specialized applications.

As usual, comments, suggestions, and bug-reports are welcome.

John

------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox



From alexis at ci.tuwien.ac.at  Fri Aug  8 14:51:53 2008
From: alexis at ci.tuwien.ac.at (Alexandros Karatzoglou)
Date: Fri, 8 Aug 2008 14:51:53 +0200 (CEST)
Subject: [R-pkgs] kernlab version 0.9-7
Message-ID: <Pine.LNX.4.64.0808081432590.21158@elendil.ci.tuwien.ac.at>


kernlab version 0.9-7 is now online and incorporates :

  + a much improved fast implementation of string kernels "stringdot"
    based on suffix arrays.

  + a new kernel method kmmd() which implements a non-parametric kernel
    based two sample test.

The new kernlab version also includes many minor improvements and fixes.


Alexandros



From amlg at sun.ac.za  Wed Aug 13 12:04:20 2008
From: amlg at sun.ac.za (La Grange, AM)
Date: Wed, 13 Aug 2008 12:04:20 +0200
Subject: [R-pkgs] New package: BiplotGUI
Message-ID: <1218621860.6744.68.camel@anthony-laptop>

Dear R users,

I am pleased to announce the release of the new BiplotGUI package on
CRAN.

Biplots are graphs in which the samples and all the variables of a data
matrix are represented simultaneously. They can be very useful for
exploring multivariate data.

The BiplotGUI package allows users to construct and interact with
biplots as they are described in "Biplots" (Gower and Hand, 1996). In
such biplots, the samples are represented as points, while the variables
are represented as calibrated biplot axes. The representations are
similar to ordinary scatter plots, but with all the variables
represented at one time. 

Version 0.0-2 of the package has the following features:

* A graphical user interface (GUI), making it easy to use
* Support for different types of biplots (PCA, covariance/correlation,
CVA, regression, Procrustes, circular non-linear), both interpolative
and predictive
* Support for different scaling techniques (PCO, metric MDS, non-metric
MDS, semi-metric MDS)
* Various data transformations and distance metrics
* Additional descriptors (convex hulls, alpha-bags, point densities,
classification regions)
* Intermediate quantities for export back to R
* Diagnostics (graphs of convergence; point, group and axis
predictivities; Shepard diagrams)
* Interactivity (variable value prediction, zooming, point and axis
drag-and-drop, 3D biplots)
* Highly customisable graphics
* Import of data directly from Excel 1997-2003 files

The package can be downloaded from CRAN:
<http://cran.r-project.org/web/packages/BiplotGUI/index.html> or a
favourite mirror.

The project homepage is at <http://biplotgui.r-forge.r-project.org>. It
includes screenshots and example biplots. A manual is included within
the package itself, but is also available from the website.

At present, the package runs under Windows only. 


I would appreciate any feedback so that the package can be further
improved.


Thanks,

Anthony la Grange
Department of Statistics and Actuarial Science
Stellenbosch University
South Africa



From joseclaudio.faria at gmail.com  Mon Aug 18 17:44:28 2008
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Mon, 18 Aug 2008 12:44:28 -0300
Subject: [R-pkgs] New packages bpca: biplot (2d and 3d) and diagnostic tools
Message-ID: <c86bda880808180844s4e2d489dpe227423326529a1a@mail.gmail.com>

Dear R Community,

We am pleased to announce the release of the 'bcpa' package.  The
source code and binaries is now on CRAN
(http://cran.r-project.org/web/packages/bpca/index.html).

The bpca package implements biplot (2d and 3d) and diagnostic tools of
the quality of the reduction.
It depends R (>= 2.6.0), scatterplot3d, rgl and MASS packages.

Regards,
-- 
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica - prof. Titular
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
joseclaudio.faria at terra.com.br
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\



From rpeng at jhsph.edu  Thu Aug 28 04:35:24 2008
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 27 Aug 2008 22:35:24 -0400
Subject: [R-pkgs] filehash 2.0
Message-ID: <66f3bd910808271935ved14acdmcb5de37e8d83baee@mail.gmail.com>

I have just uploaded to CRAN version 2.0 of the 'filehash' package.
This version contains a major rewriting of many of the internals (much
rewritten in C) for the DB1 format, which is the default.  This
development has lead to better file locking for concurrent access and
faster reading and writing of data in general.

In addition to rewriting the internals, I have added two modules for a
stack and queue data structure, implemented using 'filehash'
databases.  These are mostly for my own amusement, but perhaps you
will find them useful also.

For users of the 'filehash' package I would appreciate any general
comments as well as any bug reports, particularly considering the
number of changes that were made to the internals this time around.

-roger

-- 
Roger D. Peng | http://www.biostat.jhsph.edu/~rpeng/



From chris.jackson at mrc-bsu.cam.ac.uk  Wed Aug 27 15:38:57 2008
From: chris.jackson at mrc-bsu.cam.ac.uk (Chris Jackson)
Date: Wed, 27 Aug 2008 14:38:57 +0100
Subject: [R-pkgs] New package: ``denstrip'' for compactly illustrating
	distributions
Message-ID: <48B558F1.4000806@mrc-bsu.cam.ac.uk>

Dear R users,

I'd like to announce a new package on CRAN called ``denstrip''.  It
implements ``density strips'' and other graphical methods for
illustrating and comparing distributions in a compact fashion.

Posterior distributions of parameters are often summarised using point
and line drawings of means and credible intervals.  This is common,
for example, in multiple regression or meta-analysis.  Density
strips generalise these to illustrate whole distributions.  Instead of a
point and line, a shaded strip indicates the density as proportional to
the darkness of the shading.  They taper to white at the end of the
strip, instead of terminating at a clear limit - this may discourage
casually categorising effects as ``significant'' if the line excludes
the null.

The shading idea generalises to ``density regions'' to show
uncertainty about continuously-varying quantities, such as predictions
from time series.  The package includes other functions for
illustrating distributions in ``one dimension'', such as varying-width
strips (similar to violin plots) and sectioned density plots.

If you're interested in reading more about these methods, I discuss
them in a forthcoming article in The American Statistician, ``Displaying
uncertainty with shading'', also available from

http://www.mrc-bsu.cam.ac.uk/personal/chris/papers/denstrip.pdf

Comments and suggestions for improvement of the package are welcome.

-- 
Christopher Jackson <chris.jackson at mrc-bsu.cam.ac.uk>
Research Statistician, MRC Biostatistics Unit, Institute of Public
Health, Robinson Way, Cambridge, UK, CB2 0SR. +44 (1223) 330381



From max.kuhn at pfizer.com  Sat Sep  6 03:10:39 2008
From: max.kuhn at pfizer.com (Max)
Date: Fri, 05 Sep 2008 21:10:39 -0400
Subject: [R-pkgs] New caret packages
Message-ID: <C4E750CF.254E%max.kuhn@pfizer.com>

New major versions of the caret packages (caret 3.37, caretLSF 1.23 and
caretNWS 0.23) have been uploaded to CRAN.

caret is a package for building and evaluating a wide variety of predictive
models. There are functions for pre-processing, tuning models using
resampling, visualizing the results, calculating performance and estimating
variable importance.  caretNWS and caretLSF are two parallel processing
versions that can reduce the training time when multiple compute nodes are
available.

The project is now hosted on R-Forge. The homepage is

   http://caret.r-forge.r-project.org/

The package currently includes model tuning/resampling for the following
models: lm, single trees (C4.5, rpart, ctree, logistic model trees), mars
(via earth), boosted models (ada, gbm, blackboost, glmboost, gamboost,
logitboost), bagged models (trees, earth, fda), randomforests (randomforest
and cforest), rule-based models (Ripper and M5 prime), discriminant models
(lda, fda, rda, ssda, slda), kernel methods (lssvm, ksvm, rvm, gausspr),
nnet, nnet with initial pca step, multinom, pls, plsda, gpls, nearest
shrunken centroids, the lasso, the elastic net, supervised pca, knn, lvq and
NaiveBayes.

Recent changes include:
 - Estimation of class probabilities from PLS discriminant analysis using
Bayes rule (in addition to softmax)
- Added predict.train and predit.list
- More lattice plots to visualize resampling results (xyplot, stripplot,
densitplot, histogram)
- User-specified performance metrics for resampling
- User-specified algorithms for determining the optimal tuning parameters
(instead of highest/lowest)
- A CHANGES files now exists to track the specifics of the version changes
 
Max



From tlumley at u.washington.edu  Tue Sep  9 23:17:03 2008
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 9 Sep 2008 14:17:03 -0700 (PDT)
Subject: [R-pkgs] survey package
Message-ID: <Pine.LNX.4.64.0809091409590.5729@homer23.u.washington.edu>


Version 3.9 of the survey package is now on CRAN.  Since the last 
announcement (version 3.6-11, about a year ago) the main changes are
  - Database-backed survey objects: the data can live in a SQLite (or other 
DBI-compatible) database and be loaded as needed.
  - Ordinal logistic regression
  - Support for the 'mitools' package and multiply-imputed data
  - Conditioning plots, transparent scatterplots, survival and CDF plots.

There is more information on the package web page at
http://faculty.washington.edu/tlumley/survey/

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From christophe.pouzat at gmail.com  Wed Sep 10 10:56:06 2008
From: christophe.pouzat at gmail.com (Christophe Pouzat)
Date: Wed, 10 Sep 2008 10:56:06 +0200
Subject: [R-pkgs] STAR (Spike Train Analysis with R) uploaded on CRAN
Message-ID: <79ff51fb0809100156o3498531y5ef28da153a23cd6@mail.gmail.com>

Hi all,

I've uploaded STAR (Spike Train Analysis with R) on CRAN two days ago.

The package is designed to analyze neuronal spike (action potential)
trains. It uses S3 classes and methods and makes heavy use of other
CRAN packages like gss, R2HTML, mgcv, survival.

* Analysis of both spontaneous and stimulus evoked activity is
implemented for single neuron spike trains as well as for many neurons
recorded simultaneously.
* Several bi variate duration distribution can be automatically fitted
to "spontaneous" spike trains. Tests for renewal processes are
implemented.
* A non-parametric, smoothing spline based, approach to the estimation
of the conditional intensity of the trains is also available (this
feature is under development).
* The full collection of Ogata's tests (1988, JASA, 83:9) for
point-process models is implemented and the data set used by him
(table 1 of the paper) is made available.
* A new goodness of fit test for point-process is also proposed based
on the fact that the martingale of the process plotted as a function
of the integrated conditional intensity starts behaving very quickly
as a standard Wiener process (if the model is correct). By the way I
have no clean and formal proof of the latter statement so anyone able
(and wiling) to give me some help on that is invited to send me an
email.
* Many data sets are included as well as vignette (covering only part
of the present functionalities) and several demos.

Any feed-back, comment, critic, is welcome.

Christophe

--
A Master Carpenter has many tools and is expert with most of them. If you
only know how to use a hammer, every problem starts to look like a nail.
Stay away from that trap.
Richard B Johnson.
--

Betweeen May and October I'll be mainly staying
in the Peter Kloppenburg's lab in Cologne, You can
call me there at: +49 (0)221 470 5207

Christophe Pouzat
Laboratoire de Physiologie Cerebrale
CNRS UMR 8118
UFR biomedicale de l'Universite Paris-Descartes
45, rue des Saints Peres
75006 PARIS
France

tel: +33 (0)1 42 86 38 28
fax: +33 (0)1 42 86 38 30
mobile: +33 (0)6 62 94 10 34
web: http://www.biomedicale.univ-paris5.fr/physcerv/C_Pouzat.html
sip:christophe.pouzat at ekiga.net



From daj025 at gmail.com  Thu Sep 11 18:46:21 2008
From: daj025 at gmail.com (David James)
Date: Thu, 11 Sep 2008 12:46:21 -0400
Subject: [R-pkgs] new RMySQL and new maintainer
Message-ID: <74c69e370809110946q3274adco196a99b5c34fe91a@mail.gmail.com>

Hello,

[This is a re-posting of a previous announcement; I believe the
original posting of a couple of days ago didn't go through.]

The latest version of RMySQL 0.6-1 is now in CRAN. Please see the NEWS
file for more details.

Also, I'm happy to announce that Jeff Horner
<jeff.horner at vanderbilt.edu> has kindly agreed to maintain RMySQL from
now on.   Please continue sending your comments, suggestions, bug
reports , patches, etc., to the R-sig-DB mailing list.

Regards,
--
David



From Matthias.Kohl at stamats.de  Mon Sep 15 12:14:50 2008
From: Matthias.Kohl at stamats.de (Matthias Kohl)
Date: Mon, 15 Sep 2008 12:14:50 +0200
Subject: [R-pkgs] RobASt-Packages
Message-ID: <48CE359A.4070505@stamats.de>

-----------------------------------------------------------------------------------------
Packages for the computation of optimally robust estimators
-----------------------------------------------------------------------------------------

We would like to announce the availability on CRAN (with possibly a
minor delay until on every mirror) of new versions of our packages for
the computation of optimally robust estimators; i.e., "RandVar",
"ROptEst", "RobLox" as well as a new package "RobAStBase" (not yet:
ROptRegTS and RobRex).

-----------------------------------------------------------------------------------------
Devel versions on R-forge
-----------------------------------------------------------------------------------------
The development of these packages is under r-forge project RobASt
(Robust Asymptotic Statistics):

http://r-forge.r-project.org/projects/robast/
http://robast.r-forge.r-project.org/

If you find this project interesting and would like to collaborate, you
are warmly welcome.

We look forward to receiving questions, comments and suggestions.

Matthias Kohl
Peter Ruckdeschel

-----------------------------------------------------------------------------------------
RandVar - Implementation of random variables (version 0.6.3)
-----------------------------------------------------------------------------------------
The package RandVar which includes an S4 implementation of random
variables together with the packages distr, distrEx and distrMod form
the basis of our packages on robust statistics.

-----------------------------------------------------------------------------------------
RobAStBase - Robust Asymptotic Statistics (version 0.1.0)
-----------------------------------------------------------------------------------------
This is a new package including some necessary S4 class infrastructure
like neighborhoods, influence curves and robust models.

-----------------------------------------------------------------------------------------
ROptEst - Optimally robust estimation (version 0.6.0)
-----------------------------------------------------------------------------------------
This is the main package for the optimally robust estimation in smoothly
(L2-differentiable) parametric models [optimal in the sense of the
shrinking neighborhood setup]. By using S4 classes and methods
the implementation so far covers the optimally robust estimation for
all(!) smoothly (L2-differentiable/differentiable in quadratic mean)
parametric models which are based on a univariate distribution. Many
well-known parametric (in particular, exponential) families (Binomial,
Poission, Normal, Gamma, Gumbel, ...) are L2-differentiable.
We include several
   +neighborhood types (convex contamination, total variation)
   +risks (MSE, Hampel, overshoot/undershoot),
   +bias-types (symmetric, one-sided, asymmetric)
   +norms (unstandardized, self-standardized, information-standardized)
for all these models.
After installation you find a folder "scripts" in the package directory
which includes many example scripts.
As the computation of optimally robust estimators involves several
steps, we -- in this new version -- added an interface function
"roptest" which can be used to perform all steps via one function.

-----------------------------------------------------------------------------------------
RobLox - Optimally robust influence curves for location and scale
(version 0.6.0)
-----------------------------------------------------------------------------------------
This package includes functions for the computation of many well known
influence curves (e.g., Huber-, Hampel-, Tukey-, Andrews-type) for
normal location and scale in the framework of our asymptotic setup.
Moreover, (and for us, more importantly) it includes the functions
"roblox", "rowRoblox" and "colRoblox" which can be used to compute
optimally robust estimators in case of normal location and scale. These
functions are optimized for speed and can be applied to large scale
problems like for instance gene expression data. Using rowRobLox the
computation for a 50000 x 20 matrix takes about 2 sec. on a Centrino Duo
with 1.66 GHz. As a comparison (all on the same system): using apply and
huberM (robustbase), resp. huber (MASS) takes about 168 sec. resp 197
sec., using apply and roblox takes about 16 minutes and using apply and
roptest (ROptEst) takes about 1 month.

-----------------------------------------------------------------------------------------
ROptRegTS - Optimally robust estimation for regression-type models
RobRex - Optimally robust influence curves for regression and scale
-----------------------------------------------------------------------------------------
These two packages which provide S4 classes and methods for the
computation of optimally robust estimators in regression-type models are
not yet adapted to the new implementation. If you are interested in
working with these packages you have to use the old versions of the
above packages which we are pleased to provide on request (the sources
can also be found in the CRAN archives). But, of course, we will try to
update these packages as soon as possible.

-- 
Dr. Matthias Kohl
www.stamats.de



From Achim.Zeileis at R-project.org  Tue Sep 16 18:52:39 2008
From: Achim.Zeileis at R-project.org (Achim Zeileis)
Date: Tue, 16 Sep 2008 18:52:39 +0200 (CEST)
Subject: [R-pkgs] AER 1.0-0: Applied Econometrics with R
Message-ID: <Pine.LNX.4.64.0809161847440.3883@paninaro.stat-math.wu-wien.ac.at>

Version 1.0-0 of the package "AER" for "Applied Econometrics with R" has been 
released to CRAN (http://CRAN.R-project.org/package=AER) a few weeks ago. 
It accompanies

   Applied Econometrics with R
   Christian Kleiber, Achim Zeileis
   http://www.springer.com/978-0-387-77316-2
   http://www.amazon.com/Applied-Econometrics-R-Use/dp/0387773169/

from Springer's useR! series.

This version contains a new package vignette
   vignette("AER", package = "AER")
providing an overview of the package. An extensive list of worked examples 
is available in a new set of demos
   demo(package = "AER")
which reproduce all the examples from the above book.

Many of the examples and demos in the AER package use other CRAN packages for 
econometric analyses of various data sets. A collection of some of these CRAN 
packages is presented in a recently published special volume of JSS:

   Econometrics in R
   Journal of Statistical Software
   Special Volume edited by Achim Zeileis and Roger Koenker
   http://www.jstatsoft.org/v27/

We hope that all these provide useful information for econometric analyses 
using R.



From vincent.goulet at act.ulaval.ca  Mon Sep 15 22:02:06 2008
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Mon, 15 Sep 2008 16:02:06 -0400
Subject: [R-pkgs] New version of actuar
Message-ID: <710886E8-95E7-46B0-B1F9-3FE42F218D9D@act.ulaval.ca>

=== actuar: An R Package for Actuarial Science ===

We are pleased to announce the immediate availability of version 1.0-0  
of actuar. This release follows publication of our papers in JSS (*)  
and R News (**). From the NEWS file:

Version 1.0-0
=============

NEW FEATURES

   o Improved support for regression credibility models. There is now
     an option to make the computations with the intercept at the
     barycenter of time. This assures that the credibility adjusted
     regression line (or plane, or ...) lies between the individual and
     collective ones. In addition, contracts without data are now
     supported like in other credibility models.

   o Argument 'right' for grouped.data() to allow intervals closed on
     the right (default) or on the left.

   o Method of quantile() for grouped data objects to compute the
     inverse of the ogive.

USER-VISIBLE CHANGES

   o cm() no longer returns the values of the unbiased estimators when
     method = "iterative".

   o Specification of regression models in cm() has changed: one should
     now provide the regression model as a formula and the regressors
     in a separate matrix or data frame.

   o Due to above change, predict.cm() now expects 'newdata' to be a
     data frame as for stats:::predict.lm().

   o Function bstraub() is no longer exported. Users are expected to
     use cm() as interface instead.

BUG FIXES

   o Functions r<foo>() are now more consistent in warning when NA's
     (specifically NaN's) are generated (as per the change in R 2.7.0).

   o frequency.portfolio was wrongly counting NAs.

   o Domain of pdfs returned by aggregateDist() now restricted to
     [0, 1].

   o Quantiles are now computed correctly (and more efficiently) in 0
     and 1 by quantile.aggregateDist().

   o coverage() no longer requires a cdf when it is not needed, namely
     when there is no deductible and no limit.


The CRAN page for the package is

	http://cran.r-project.org/package=actuar

The project's web site is

	http://www.actuar-project.org

Comments and contributions to the project are more than welcome.

(*) http://www.jstatsoft.org/v25/i07
(**) http://cran.r-project.org/doc/Rnews/Rnews_2008-1.pdf

---
   Vincent Goulet, Associate Professor
   ?cole d'actuariat
   Universit? Laval, Qu?bec
   Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From h.wickham at gmail.com  Tue Sep 30 16:55:31 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 30 Sep 2008 09:55:31 -0500
Subject: [R-pkgs] New package: plyr
Message-ID: <f8e6ff050809300755j4f516a98n9d4ed69f103be19d@mail.gmail.com>

plyr is a set of tools that solves a common set of problems: you need
to break a big problem down into manageable pieces, operate on each
pieces and then put all the pieces back together.  It's already
possible to do this with split and the apply functions, but plyr just
makes it all a bit easier with:

  * consistent names, arguments and outputs
  * input from and output to data.frames, matrices and lists
  * progress bars to keep track of long running operations
  * built-in error recovery
  * the choice of passing chunks as rows or as variables

plyr functions are named according to the type of object they input
(first letter) and output (second letter):

  * llply = from a list to a list
  * alply = from an array (or vector, or matrix) to a list
  * ldply = from a list to a data.frame
  * d_ply = from a data.frame, ignore output
  * and so on for llply, laply, ldply, l_ply, alply, aaply, adply,
a_ply, dlply, daply, dply, d_ply

plyr also provides:

  * m*ply which works in a similar way to mapply
  * r*ply which works in a similar way to replicate

You can find out more at http://had.co.nz/plyr/, including a 20 page
introductory guide, http://had.co.nz/plyr/plyr-intro.pdf.

Regards,

Hadley


-- 
http://had.co.nz/



From h.wickham at gmail.com  Sun Oct  5 17:41:35 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 5 Oct 2008 10:41:35 -0500
Subject: [R-pkgs] ggplot2 - version 0.7
Message-ID: <f8e6ff050810050841q4d7cf8cav777e9b096e4492c9@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the nearly 500
examples of ggplot in use.

ggplot2 0.7 introduces a new theming system which allows you to
control (almost) every aspect of the appearance of the plot.  This
system is documented in the book chapter "Polishing your plots for
publication", available from
http://had.co.nz/ggplot2/book/polishing.pdf.

Bugs fixed

* geom_boxplot: now displays outliers even if only one present
* geom_jitter: setting one jitter direction to 0 now works
* geom_segment: should now work correctly in all coordinate systems
(note that arrows only work in Cartesian coordinates)
* ggsave: correctly uses dpi for raster devices and default dpi
changed to 72 (thanks to Brian Ripley for pointing this out)
* ggsave: current device no longer closes if error occurs
* position_jitter: now works correctly with 0 jitter
* remove_missing: some statistics were calculated incorrectly when
missing values were present
* scales: extra scales ignored (again)
* scales: legends respect fixed parameters of the layer
* scales: legends won't appear when aesthetics are mapped to NULL, or
set to fixed value
* scales: xend and yend now transformed correctly
* scale_date: breaks are now rounded to correct position

New functionality

* geom_point: can now control colour and fill separately for point
glyphs with borders
* geom_step: now has parameter direction which can take values vh
(vertical then horizontal) or hv (horizontal then vertical) describing
the shape of the stairs
* qplot: new asp argument to set aspect ratio
* qplot: now captures the environment in which it was run, which
should make it much more robust at finding the variables you expect it
to find
* qplot: now treats any arguments wrapped in I() as parameters, not
aesthetics, e.g. qplot(mpg, wt, data=mtcars, colour = I("red")) or
qplot(mpg, wt, data=mtcars, size = I(5))
* scale_continuous: new minor_breaks argument to controls position of
minor breaks
* scale_discrete: new discrete position scales which make it possible
to manually position elements
* scale_gradientn: new colour scale which creates gradient between any
list of colours

More consistent interfaces

* can use color instead of colour, and old R names throughout ggplot2
* geom_jitter: Arguments changed to height and width to match other
position adjustments
* scales: any point outside of limits is dropped (this was previously
the behaviour for discrete scales, but not continuous scales)
* scales: limits are consistent across discrete and continuous scales
(limits c(1, NA) form no longer works for continuous scales)
* scales: order of legends reversed to match order of x axis (and to
be consistent with previous versions)
* scale_date: new limits argument to set axis limits
* scale_discrete: all discrete scales accept breaks argument
* scale_discrete: all discrete scales have limits and labels argument
to better control legends
* scale_discrete: character and logical vectors now reliably treated
as discrete scales
* stat_density2d, geom_density2d: density2d used consistently (instead
of density_2d in some places)

Improved aesthetics

* coord_polar: more tweaks to grid lines to enhance appearance
* coord_polar: new expand argument to control whether axes should be
expanded outside the range of the data
* geom_contour, geom_smooth, geom_quantile: now use blue lines
* position_stack, position_dodge: should be more informative if
conditions for stacking/dodging not met
* position_jitter: default amount of jittering tweaked to align with
boxplots etc.
* scales: background colour of legends key matches plot
* themes: Complete rewrite of theming system, see new book chapter for details
* themes: direct access to plot options via $ is now disabled

Improved documentation and error messages

* facet_grid: documentation improved
* qplot: Better error messages when needed variables are missing
* scale_discrete: improved error message for too many values in domain
* scale_size: improved documentation for discrete variables
* online documentation generally tweaked and primped to work a little
better and look a little nicer
* website now includes a search box
* links from rdoc now point to correct pages


-- 
http://had.co.nz/



From HDoran at air.org  Wed Oct  1 19:39:09 2008
From: HDoran at air.org (Doran, Harold)
Date: Wed, 1 Oct 2008 13:39:09 -0400
Subject: [R-pkgs] MiscPsycho 1.3 posted to CRAN
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE016E2328@DC1EXCL01.air.org>

An updated version of the Miscellaneous Psychometrics package has been
updated to CRAN. The following updates are included in the package:

1) An implementation of the Stocking-Lord procedure for linking test
scales.
2) An implementation of the Levenshtein algorithm for comparing
character strings
3) stringProbs, a function for computing the probability of a given
Levenshtein Distance
4) Three sources of documentation on all functions. There is complete
technical documentation on the functions used in MiscPsycho in the file
MP.pdf, the stocking-lord implementation is documented in
stock_lord.pdf, and a paper describing the Levenshtein algorithm and its
application in educational measurement is provided in levenshtein.pdf.
All of these are in the docs folder in the package distribution.

Any comments, reactions, critiques, are welcome.

Harold



From mathieu.pigeon at uclouvain.be  Fri Oct  3 11:24:14 2008
From: mathieu.pigeon at uclouvain.be (Mathieu Pigeon)
Date: Fri, 03 Oct 2008 11:24:14 +0200
Subject: [R-pkgs] New package: expert 1.0-0
Message-ID: <7.0.1.0.2.20081003111605.02113920@uclouvain.be>

expert: Modeling Without Data Using Expert Opinion

Expert opinion is a technique to do statistical modeling when data is
scarse (e.g. accidents in nuclear plants) or even absent, at least for
the analyst (e.g. confidential settlements in liability insurance).
Opinions on the distribution of the decision random variable is sought
from experts in the field. The experts give their opinion in the form
of a few quantiles for the decision variable and for a set of "seed
variables" for which the analyst knows the true quantiles. Results for
seed variables are compared to the true values and used to determine
the influence of each expert on the aggregated distribution. The
package supports three different ways to aggregate the information
provided by the experts in one final distribution:

1. the classical model of Cooke (1991);
2. the Bayesian model of Mendel and Sheridan (1989);
3. an ad-hoc procedure where the weight of each expert is pre-
determined by the analyst.

The main function of the package is expert(), a unified interface to
all three methods above. The package also provides a few utility
functions to display, plot or compute probabilities and quantiles from
the aggregated distribution returned by expert().


Best regards,

Mathieu Pigeon
Institut de Statistique
Universite Catholique de Louvain
Voie du Roman Pays, 20
1348 Louvain-la-Neuve
BELGIUM

E-mail address : mathieu.pigeon at uclouvain.be



From elff at uni-mannheim.de  Mon Oct  6 10:23:52 2008
From: elff at uni-mannheim.de (Martin Elff)
Date: Mon, 6 Oct 2008 10:23:52 +0200
Subject: [R-pkgs] New verision 0.95 of package 'memisc' released to CRAN
Message-ID: <200810061023.52293.POLMETH@artsci.wustl.edu>

Dear useRs,

I am pleased to announce the availability of version 0.95 of package 'memisc' 
on CRAN (http://cran.r-project.org/web/packages/memisc/).

'memisc' does not implement any new estimators, but focuses on providing an 
infrastructure for data analysis especially of survey data. It may be of 
interest to all those who have had to use a commercial package like SPSS or 
Stata in order to prepare data for analysis in R. I wrote this package to 
become independent from commercial software and to do everything in R, from 
data management to data analysis and presentation of analysis results. I hope 
that the package will be as useful for others as it has become for me. UseRs 
may want to check out the vignette "Analysing the American National Election 
Study of 1948" to see the package in action.

Feedback is more than welcome. Please to do not hesitate to inform me if you 
find any bugs in this package.


All the best,

Martin 

Package description:
=============================================================================================

Package: memisc
Type: Package
Title: Tools for Management of Survey Data, Graphics, Programming, Statistics, 
and Simulation
Version: 0.95-1
Date: 2008-10-1
Author: Martin Elff
Maintainer: Martin Elff <elff at uni-mannheim.de>
Description: One of the aims of this package is to make life easier for useRs
  who deal with survey data sets. It provides an infrastructure for the 
  management of survey data including value labels, definable missing values,
  recoding of variables, production of code books, and import of (subsets of)
  SPSS and Stata files. Further, it provides functionality to produce tables
  and data frames of arbitrary descriptive statistics and (almost)  
  publication-ready tables of regression model estimates. Also some 
  convenience tools for graphics, programming, and simulation are provided.
License: GPL-2
LazyLoad: Yes
Depends: lattice, grid, stats, methods, utils, MASS
URL: 
http://webrum.uni-mannheim.de/sowi/elff/content.php/EnglishVersion/MartinsRPackages

=============================================================================================

-- 
-------------------------------------------------
Dr. Martin Elff
Department of Social Sciences
University of Mannheim
A5, Room 328
68131 Mannheim
Germany

Phone: ++49-621-181-2093
Fax: ++49-621-181-2099
E-Mail: elff at sowi.uni-mannheim.de
Homepage: 
http://webrum.uni-mannheim.de/sowi/elff
http://www.sowi.uni-mannheim.de/lspwivs/
-------------------------------------------------

**********************************************************
             Political Methodology E-Mail List
   Editors: Melanie Goodrich, <melaniegoodrich at nyu.edu>
            Delia Bailey, <dbailey at wustl.edu>
**********************************************************
        Send messages to polmeth at artsci.wustl.edu
  To join the list, cancel your subscription, or modify
           your subscription settings visit:

          http://polmeth.wustl.edu/polmeth.php



From landronimirc at gmail.com  Thu Oct  9 19:59:17 2008
From: landronimirc at gmail.com (Liviu Andronic)
Date: Thu, 9 Oct 2008 19:59:17 +0200
Subject: [R-pkgs] release of RcmdrPlugin.Export 0.2-1
Message-ID: <68b1e2610810091059kd5f932ei3cecea503d3c9c91@mail.gmail.com>

Dear R users,

A new version of RcmdrPlugin.Export is currently available on CRAN.
The release introduces support for the "file" and "append" options of
print.xtable(). The new features make easier to include exported HTML
code into documents created with regular word-processing programmes,
such as .odt (OpenOffice.org) and .doc (Microsoft Word). The exported
LaTeX code can also be `Imported as File' into LyX documents.

As always, suggestions and bug reports are most welcome.

Regards,
Liviu



From jens.oehlschlaegel at truecluster.com  Fri Oct 10 18:08:51 2008
From: jens.oehlschlaegel at truecluster.com (=?iso-8859-15?Q?Jens_Oehlschl=E4gel?=)
Date: Fri, 10 Oct 2008 18:08:51 +0200
Subject: [R-pkgs] New package: bit 1.0
Message-ID: <1096847731@web.de>

Dear R community,

Package 'bit' Version 1.0 is available on CRAN. 
It provides bitmapped vectors of booleans (no NAs), 
coercion from and to logicals, integers and integer subscripts; 
fast boolean operators and fast summary statistics. 

With bit vectors you can store true binary booleans {FALSE,TRUE} at the expense 
of 1 bit only, on a 32 bit architecture this means factor 32 less RAM and 
factor 32 more speed on boolean operations. With this speed gain it even 
pays-off to convert to bit in order to avoid a single boolean operation on 
logicals or a single set operation on (longer) integer subscripts, the pay-off 
is dramatic when such components are used more than once. 

Reading from and writing to bit is approximately as fast as accessing standard 
logicals - mostly due to R's time for memory allocation. The package allows to 
work with pre-allocated memory for return values by calling .Call() directly: 
when evaluating the speed of C-access with pre-allocated vector memory, coping 
from bit to logical requires only 70% of the time for copying from logical to 
logical; and copying from logical to bit comes at a performance penalty of 150%.

Functions 'which' and 'xor' are made S3 generic, 'xor.default' is implemented 
much faster than in base R (this should go into base R).

The package has automated regression-tests and is hopefully useful for better
handling large datasets, together with packages 'rindex' and 'ff'.

Best regards


Jens Oehlschl?gel
Munich, 10.10.2008



From gregoire.pau at ebi.ac.uk  Tue Oct  7 21:13:27 2008
From: gregoire.pau at ebi.ac.uk (Gregoire Pau)
Date: Tue, 07 Oct 2008 20:13:27 +0100
Subject: [R-pkgs] hwriter - Writing R objects in HTML format
Message-ID: <48EBB4D7.4060607@ebi.ac.uk>

Dear R community,

I'm pleased to announce the availability of hwriter v0.93 on CRAN.

hwriter is an easy-to-use package able to format and output R objects in
HTML format. It supports advanced formatting, tables, CSS styling,
images and provides a convenient mapping between R tables and HTML tables.

hwriter combines the simple syntax of the xtable package and the
strength of HTML/CSS styling. Making a complex HTML template with
images, nested tables and nested HTML components is particularly easy.

hwriter project page (written by itself, using 'example(hwriter)'):
http://www.ebi.ac.uk/~gpau/hwriter/

Its CRAN page is http://cran.r-project.org/web/packages/hwriter/

Hoping this package will be useful to the R community,
Best regards,

Greg
-- 
Gregoire Pau
EMBL/EBI Cambridge, UK
http://www.ebi.ac.uk/~gpau



From madorazi at istat.it  Mon Oct 13 10:39:58 2008
From: madorazi at istat.it (Marcello D'Orazio)
Date: Mon, 13 Oct 2008 10:39:58 +0200
Subject: [R-pkgs] New package: StatMatch 0.4
Message-ID: <48F3095E.6050809@istat.it>

Dear useRs,

I am pleased to announce the availability of the new package 'StatMatch'
(version 0.4)
http://cran.at.r-project.org/web/packages/StatMatch/index.html


'StatMatch' contains some functions to perform Statistical Matching.
Statistical Matching methods aim at integrate two samples, referred to
the same target population, sharing a certain number of common variables
but without overlapping of the units.
Note that some functions in 'StatMatch' can also be used to impute
missing values in a data set.

Best Regards,
Marcello D'Orazio

-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 Marcello D'Orazio

 ISTAT       (Italian National Statistical Institute)		
 Via Cesare Balbo, 16 (1? piano, stanza 153)
 00184 ROMA  ITALY
 Tel.: +39 06 4673 2772
 Fax:  +39 06 4673 2955
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
________________________________________________________________________

 Legal Disclaimer:
 Any views expressed by the sender of this message are not necessarily
 those of the Italian National Statistical Institute.



From edd at debian.org  Wed Oct 15 04:41:37 2008
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 14 Oct 2008 21:41:37 -0500
Subject: [R-pkgs] New package RPostgreSQL 0.1.0
Message-ID: <18677.22625.526067.785258@ron.nulle.part>


       RPostgreSQL version 0.1.0

We are pround to announce the availability of the RPostgreSQL package on CRAN
and its mirrors.  This package provides an a DBI-compliant interface between
PostgreSQL and R.

RPostgreSQL was developed as part of the Google Summer of Code 2008 program
by Sameer Kumar Prayaga.

Some highlights:

  o  Implemented all the DBI features 

  o  Added support for transaction management 

  o  Added type mapping for dates & timestamps

Known bugs/deficiencies:

  o  Building on Windows unknown/untested. Feedback welcome

RPostgreSQL is hosted on Google Code, for more information see

   http://rpostgresql.googlecode.com/

For any suggestions and queries, please contact:

   Sameer Kumar Prayaga <sameer.bits at gmail.com>
   Dirk Eddelbuettel <edd at debian.org>

-- 
Three out of two people have difficulties with fractions.



From rmpruzek at yahoo.com  Tue Oct 14 20:02:24 2008
From: rmpruzek at yahoo.com (bob pruzek)
Date: Tue, 14 Oct 2008 11:02:24 -0700 (PDT)
Subject: [R-pkgs] New versions of two packages: granova and PSAgraphics
Message-ID: <895632.31528.qm@web63406.mail.re1.yahoo.com>

Dear R users,

This is to announce new versions of our packages granova and PSAgraphics, both now v.1.2.

granova derives from ?graphical analysis of variance.? The package consists of four functions that facilitate seeing basic data as well as standard summary statistics for various ANOVA applications. The functions are especially flexible, so they are able to handle widely different data specifications. Focus is directed to basic questions that drive methods, so that the graphics can help to learn how data play out in answer to question(s) posed by methods. Experience suggests these functions can be particularly helpful for students and non-statistician analysts, since they help understand the methods themselves, as well as the data. Dynamic graphics are used to depict two-way data. In all cases numerical results accompany the graphical displays. 

PSAgraphics aims chiefly to facilitate visualization of various results in the context of propensity score analysis. One set of functions concerns assessment of covariate balance, with respect to defined propensity scores; both numerical and graphical functions are provided. Two other functions help to understand PSA effects after adjustment for propensity scores. The functions have been designed to be flexible, and in all cases numerical results complement the graphic displays. 

Various documents and displays that illustrate graphic results for these methods are available; write rmp at  rmpruzek at yahoo.com . 

All comments, suggestions for improvement and bug-reports are solicited.

Bob Pruzek & James Helmreich








From ggrothendieck at gmail.com  Mon Oct 20 15:45:36 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 20 Oct 2008 09:45:36 -0400
Subject: [R-pkgs] New verion 0.3-7 of gsubfn package
Message-ID: <971536df0810200645m1c5e1f77ga408fc02e67f3f07@mail.gmail.com>

Version 0.3-7 of the gsubfn package is available on CRAN.
Changes to the package are:

- all known bugs have been fixed.

- in gsubfn and strapply the replacement object can be a
  list (or a function, formula, character string or proto
  object, as before).  In the case of a list, regexp matches
  are looked up in the list names and the corresponding list
  component used.

  # Example 1 - at string end replace M with e6 & G with e9
  gsubfn(".$", list(M = "e6", G = "e9"), c("19G", "32.5M"))

- the backref= argument in gsubfn now defaults to the
  negative of its prior default.  Thus by default if there
  are back references only they and not the entire match is
  passed to the user function.  (Although the changed
  default introduces an incompatibility with prior versions
  this incompatability is small because it only affects
  situations where back references are present in the
  regular expression _and_ backref= was not used. Since the
  previous default for backref= was not useful in that case
  there would be very few, if any, such instances.)  On the
  other hand, it does mean that the backref= argument can be
  omitted most cases now.

For more info, see home page and brief description below.
	http://gsubfn.googlecode.com

The gsubfn package - summary
============================

A seemingly small enhancement to R's gsub function, allowing
the replacement string to be a function, formula, list or
proto object gives surprising additional power allowing
parsing of strings by content rather than delimiters.  e.g.
extract numbers:

	# Example 2. Replace each number with its increment
	gsubfn("[0-9]+", ~ as.numeric(x) + 1, "90 and 17")

	# Example 3. extract numbers
	strapply("Over 90 stones in 17 places", "[0-9]+")

The optional function passed to gsubfn and strapply may be
specified using usual R function notation or by a formula
whose left hand side represents the arguments (defaulting to
variables appearing in right hand side) and whose right hand
side represents the body.  In order to extend this
functionality beyond gsubfn and strapply to the rest of R
any R function may be prefaced with fn$ like this:

	# Example 4. Integrate x^2
	fn$integrate(~ x^2, 0, 1)

It also supports quasi-perl style string interpolation:

	# Example 5. Quasi-perl style string interpolation
	fn$cat("pi = $pi and e = `exp(1)`\n")

match.funfn is an alternative to match.fun which allows
developers to add this functionality to their own functions
by simply replacing match.fun with match.funfn -- a one line
change.  In that case even the fn$ prefix is not needed.



From clement.calenge at oncfs.gouv.fr  Mon Oct 27 20:24:13 2008
From: clement.calenge at oncfs.gouv.fr (=?UTF-8?B?Q2zDqW1lbnQgQ2FsZW5nZQ==?=)
Date: Mon, 27 Oct 2008 20:24:13 +0100
Subject: [R-pkgs] adehabitat version 1.8
Message-ID: <4906155D.8020508@oncfs.gouv.fr>

Dear all,

I have uploaded to CRAN the version 1.8 of the package 'adehabitat'.
Significant changes are listed below:

* getverticeshr now relies on the function contourLines(), and returns
   smoother estimates of the kernel home range (see the help page).

* the new function kernelkc (and related functions) now allows the
   estimation of the utilization distribution in space and time of
   animals using the product kernel algorithm advocated by Keating and
   Cherry (Ecology, in press).

* the new function findmaxasc allows to find the local maxima on a map
   of class 'asc'. It can be potentially useful to identify the points
   of attraction in the home range of an animal (modes of the
   utilization distribution).

* the new functions engen2008I and engen2008II implements the method of
   Engen et al. (2008, Journal of Animal Ecology) for the study of
   habitat selection using multivariate data.

* The function dunnfa performs a factorial decomposition of the
   Mahalanobis distances in habitat selection studies. This method has
   been suggested by Prof. James Dunn as an alternative

* A new bug tracking system has been set up for adehabitat thanks to
   the great work of Paolo Cavallini (Faunalia). It is available at:
   https://www.faunalia.it/animove/trac/
   Any other project intended to manage, store, analyze animals
   movements can be added there, provided it is free and open source.

* Note that my e-mail adress has changed. It is now:
clement.calenge at oncfs.gouv.fr

Happy testing,


Cl?ment Calenge

-- 
Cl?ment CALENGE
Office national de la chasse et de la faune sauvage
Saint Benoist - 78610 Auffargis
tel. (33) 01.30.46.54.14



From Adrian.Baddeley at csiro.au  Mon Nov  3 09:08:17 2008
From: Adrian.Baddeley at csiro.au (Adrian Baddeley)
Date: Mon, 3 Nov 2008 17:08:17 +0900
Subject: [R-pkgs] scuba 1.2-2 posted
Message-ID: <490EB171.6070402@csiro.au>


        scuba 1.2-2

'scuba' is a contributed package that performs theoretical calculations
about scuba diving --- dive profiles, decompression models, gas toxicity
and so on.

New features in version 1.2-2:

        . Package vignette provides detailed explanations.

        . Improved handling of data from dive computers.

        . Gas switches (switching from one tank of breathing gas
          to another during the dive) are now easy to specify.

        . Relative tissue saturations can be computed easily

        . Eleven new datasets: real dive profiles

        . Dives with multiple tanks of breathing gas are now plotted
           using a different colour for each gas.

New functions:

        whichtank
        whichtank<-
                        Choice of breathing gas tank
                        at each waypoint during the dive

Improvements:

        dive
                For easier handling of data uploaded from dive computers,
                dive() now accepts elapsed time values in the formats
                "hh:mm:ss", and "mm:ss" where mm can exceed 60.

        plot.dive
                Dives with multiple tanks of breathing gas are now plotted
                using a different colour for each gas.

                The choice of colours is controlled by the
                argument 'col.gases'.

        haldane
                This function has a new argument 'relative'.
                If relative=TRUE, tissue saturations are computed
                as fractions of the surfacing M-value.

        ndl
                Improved numerical stability, in mixed-gas case.

                The return value of ndl now has an attribute
                which identifies the controlling tissue.

        showstates
                Improved plot labels.

Adrian Baddeley, 30 october 2008



From arne.henningsen at googlemail.com  Sat Nov  8 22:53:20 2008
From: arne.henningsen at googlemail.com (Arne Henningsen)
Date: Sat, 8 Nov 2008 22:53:20 +0100
Subject: [R-pkgs] New package "frontier" for Stochastic Frontier Analysis
	(SFA)
Message-ID: <200811082253.20567.arne.henningsen@googlemail.com>

Hi!

A few weeks ago, I have uploaded a new R package "frontier" for Stochastic 
Frontier Analysis (SFA) [1] to CRAN [2]. It includes the FORTRAN code of Tim 
Coelli's [3] software "Frontier 4.1" [4]. Hence, the R package "frontier" 
should have the same capabilities as "Frontier 4.1", i.e. Maximum Likelihood 
Estimation of Stochastic Frontier Production and Cost Functions. Two 
specifications are available: the error components specification with 
time-varying efficiencies (Battese and Coelli, 1992) [5] and a model 
specification in which the firm effects are directly influenced by a number 
of variables (Battese and Coelli, 1995) [6].
     The functions "front41WriteInput" and "front41ReadOutput" for creating 
input files for and reading output files of "Frontier 4.1" will be moved from 
the "micEcon" package [7] to the "frontier" package within a short time.
     The "frontier" package is developed on R-Forge [8]. All useRs and 
developeRs are invited to contribute to this package.

[1] http://en.wikipedia.org/wiki/Stochastic_Frontier_Analysis
[2] http://cran.r-project.org/web/packages/frontier/index.html
[3] http://www.uq.edu.au/economics/cepa/coelli.htm
[4] http://www.uq.edu.au/economics/cepa/frontier.htm
[5] Battese, G. E. & Coelli, T. J. (1992): Frontier Production Functions, 
Technical Efficiency and Panel Data: With Application to Paddy Farmers in 
India. Journal of Productivity Analysis, 3, p. 153-169.
[6] Battese, G. E. & Coelli, T. J. (1992) A Model for Technical Inefficiency 
Effects in a Stochastic Frontier Production Function for Panel Data. 
Empirical Economics, 20, p. 325-332.
[7] http://cran.r-project.org/web/packages/micEcon/index.html
[8] http://r-forge.r-project.org/projects/frontier/

Any hints, suggestions, and bug reports are welcome,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name



From mdsumner at utas.edu.au  Mon Nov 10 13:09:08 2008
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Mon, 10 Nov 2008 23:09:08 +1100
Subject: [R-pkgs] trip package: version 1.1-2
Message-ID: <49182464.8050005@utas.edu.au>

Hello,

A long overdue update to the 'trip' package is now on CRAN.

o New function forceConstraints() to impose the common problems found in 
track data of duplicated records, and duplicated time stamps.
o Bug fix to speedfilter() which would never finish for trips of 3 
locations.
o Clean up of trip methods to fix a bug that caused R CMD check to fail 
in 2.8.0.

Thanks to all who provide feedback for problems and ideas for improvements.

Regards,
Mike.



From cepardot at unal.edu.co  Sat Nov 15 23:19:58 2008
From: cepardot at unal.edu.co (Campo Elias Pardo Turriago)
Date: Sat, 15 Nov 2008 17:19:58 -0500
Subject: [R-pkgs] New Package FactoClass
Message-ID: <f6df8039264f.491f04be@unal.edu.co>

  new R package FactoClass to combine factorial methods and cluster
analysis is uploaded to CRAN. This package is implemented in order to perform a
multivariate exploration of a data table according to Lebart et al. (1995). We
use some ade4 functions (Chessel et al. 2004) to perform the factorial analysis
of the data and some stats functions in R to perform cluster methods.
Some new functions are programmed to make specific tasks and another old
ones are modified.


Campo-El?as PARDO
Departamento de Estad?stica
Universidad Nacional de Colombia - Bogot?



From felix at nfrac.org  Tue Nov 18 05:15:14 2008
From: felix at nfrac.org (Felix Andrews)
Date: Tue, 18 Nov 2008 15:15:14 +1100
Subject: [R-pkgs] latticist and playwith
Message-ID: <94730b8a0811172015l6c8dbd25l19388100b3540f53@mail.gmail.com>

A new package, *latticist*, is available now from CRAN.

Latticist is a graphical user interface for exploratory visualisation.
It is primarily an interface to the Lattice graphics system, but also
produces displays from the vcd package for categorical data.

Given a multivariate dataset (either a data frame or a table),
Latticist attempts to produce useful displays based on the properties
of the data. The user chooses variables for the plot axes, for
grouping, conditioning and subsetting. Some hypervariate displays are
also available. The plots can be customised by editing the calls used
to generate them.

A simple graphical user interface is available, built on the gWidgets
package. This requires one of the "toolkit implementations" to be
installed: currently gWidgetstcltk or gWidgetsRGtk2 (note, the
gWidgetsrJava toolkit is still in testing). Alternatively, Latticist
can be run as a toolbar extension to playwith. This brings many extra
features, such as dynamic zooming, identifying data points, etc.

A major new version of *playwith* is also available.

The playwith package provides a GTK+ graphical user interface for
editing and interacting with R plots. It has been redesigned, and the
GUI has been overhauled completely. The most prominent new features
are linked brushing, identifying co-variates of data points, dialogs
boxes for various settings, and a better API.

The websites for playwith and latticist include screenshots and demos.

http://latticist.googlecode.com/
http://playwith.googlecode.com/

Feedback welcome...

(and job offers? :-)
-- 
Felix Andrews / ???
http://www.neurofractal.org/felix/
3358 543D AAC6 22C2 D336  80D9 360B 72DD 3E4C F5D8



From pgilbert at bank-banque-canada.ca  Tue Nov 18 19:37:53 2008
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue, 18 Nov 2008 13:37:53 -0500
Subject: [R-pkgs] Packages for time series databases
Message-ID: <49230B81.2060604@bank-banque-canada.ca>

I recently put several packages for time series databases on CRAN. The 
main package, TSdbi, provides a common interface to time series 
databases. The objective is to define a standard interface so users can 
retrieve time series data from various sources with a simple, common, 
set of commands, and so programs can be written to be portable with 
respect to the data source. The SQL implementations also provide a 
database table design, so users needing to set up a time series database 
have a reasonably complete way to do this easily. The interface provides 
for a variety of options with respect to the representation of time 
series in R. There is also a (not yet well tested) mechanism to handle 
multilingual data documentation.

-TSdbi  is the main package.

-TSMySQL,  TSPostgreSQL, and  TSSQLite provide interfaces for these 
three SQL databases  (using RMySQL, RSQLite, and RPostgreSQL).

-TSodbc  provides an interface using RODBC (tested only with a 
PostgreSQL server).

-TSfame  provides an interface to Fame using the fame package.

-TSpadi  provides an interface to Fame using a (somewhat dated) padi server.

-TShistQuote  provides an interface to get.hist.quote.

Many thanks to the authors and maintainers of the underlying packages, 
and several people who have commented on early versions of the TS* packages.

Paul Gilbert
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

------------------------------------------------------------------------------------

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

From h.wickham at gmail.com  Fri Nov 21 13:53:31 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 21 Nov 2008 06:53:31 -0600
Subject: [R-pkgs] ggplot2 - version 0.8
Message-ID: <f8e6ff050811210453u2a5edd8dkcc0b8553872a1b81@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the nearly 500
examples of ggplot in use.  If you're interested, you can also sign up to
the ggplot2 mailing list at http://groups.google.com/group/ggplot2, or track
development at  http://github.com/hadley/ggplot2

ggplot2 0.8  (2008-11-18)
----------------------------------------

The two biggest new features in this release are the (long awaited)
ability to have scales that vary between facets, and a faceting system
that works like lattice (facet_wrap). From qplot, you can use
facet_wrap by specifying one sided formula (~ colour, as opposed to .
~ color). To see some potential uses for these new features, see the
"Positioning" chapter of the book or the documentation for facet_wrap
and facet_grid.  Implementing these changes has required a rewrite of
large parts of the coordinate systems code, so if anything seems
strange with non-Cartesian coordinate systems, please get in touch.

I've also made another round of tweaks to make the plots more
aesthetically pleasing.  This includes using a bright blue colour for
geoms used to add statistical summaries to plots (contour, smooth, and
quantiles), and tweaking the default colour scheme for the continuous
colour scale.  Please let me know what you think.  Remember that most
of these options are controllable with the theming system - see the
book chapter "Polishing your plots for publication".

Accompanying this new release of the package is an updated and
expanded version of the book.  The content of the book is now largely
complete (~170 pages), and over the coming months I will be working on
make it polished and easy to understand.  See
http://had.co.nz/ggplot2/book.  I love to hear your feedback about the
book, but at this point please don't bother reporting minor typos, I
would much rather hear about what you want to do, but can't figure out
from the book.

Other new features:

* geom_bin2d/stat_bin2d & geom_hex/stat_binhex: for 2d square and
hexagon binning, particularly useful for alleviating overplotting in
scatterplots
* geom_freqpoly: draws frequency polygons (= stat_bin + geom_line)
* scale_position: both discrete and continuous gain a new formatter
argument to control the default formatting of the axis labels.  See
also the handy numeric formatters: dollar, comma and percent
* the xlim and ylim functions now produce discrete scales when
appropriate, and generate a reverse scale if the minimum is greater
than the maximum

Improvements

* coord_map gains experimental axis labels
* facet_grid: new support for varying scales in rows and columns
* facet_wrap: new faceter which wraps a 1d ribbon of panels into 2d,
in a similar way to lattice
* geom_bin: gains a drop argument to control whether or not 0 count
bins should be removed
* geom_path and geom_line gain arrows argument to match geom_segment
* ggsave now checks that you are using it with a ggplot plot
* ggsave now produces postscript files that are suitable for embedding
in another document
* ggsave now recognises the .svg extension and will produce svg files,
if possible
* ggsave: default dpi changed to 300, on the assumption that you are
saving the plot for printing
* qplot: uses facet_wrap if formula looks like ~ a + b (as opposed to a ~ b)

Aesthetic tweaks

* geom_bar, geom_polygon, geom_rect, ...: default fill colour is now
much closer to black to match the defaults in other geoms (point,
line, etc)
* geom_line, geom_path, geom_segment: lines have squared ends
* geom_point, geom_pointrange and geom_boxplot: now use shape = 16
instead of 19.  This shape does not have a border from R 2.8 on, and
so will look better when displayed transparently.
* geom_contour, geom_density2d, geom_quantile and geom_smooth use a
bright blue colour for lines, to make them stand out when used with
black points
* scale_gradient: tweaked default colours to make more aesthetically pleasing
* theme: new theme setting panel.margin (a unit) controls gap between
panels in facetted plots (for both grid and wrap)
* theme_gray: removed black border around strips
* theme_bw: tweaks to make black and white theme look a little nicer

Bug fixes

* coord_cartesian now correctly clips instead of dropping points
outside of its limits
* facet_grid: margins now grouped correctly in default case
(non-aesthetic variables ignored when generating default group value)
* facet_grid: fix long standing bug when combining datasets with
different levels of facetting variable
* geom_smooth calls stat::predict explicitly to avoid conflicts with
packages that override predict for S4 model classes
* grid: correctly expose subcomponents of strips and axes
* mapping aesthetics to functions of stat output now works in a much
wider variety of cases
* order aesthetic should now work with bars (and in general more geoms)
* position_dodge now works with points and other geoms that lack xmin and xmax
* scale_area works once more
* scale_discrete_position: empty levels are no longer displayed by
default, if you want them, use breaks = levels(myfactor)
* scale_discrete_position: fixed bug when limits were set
* scale_discrete_position: more aesthetically pleasing expansion for a
wider ranges of plots (picks expansion based on whether or not geom
with width used, e.g. bars)
* scale_gradient*: axes are correctly labelled when a transformation is used
* scale_x_log10, scale_y_sqrt etc now correctly transform output from
statistics as well as raw data
* scale_z_* now removed because no longer used by anything
* stat_bin: correctly returns 0 when no observations in a bin (was
previously returning NA)
* stat_quantreg: deal with yet another new output format from quantreg
* stat_contour now has arguments to control the position of the
contours, rather than relying on the z scale
* theme: panel.empty setting removed as it is no longer used
* theme_grey now aliased to theme_gray
* theme_line: setting size works correctly
* theme_rect, theme_segment: size now measured in mm, to be consistent
with the rest of ggplot

Regards,

Hadley

-- 
http://had.co.nz/



From Mike.Prager at noaa.gov  Thu Nov 20 14:13:52 2008
From: Mike.Prager at noaa.gov (Michael H. Prager)
Date: Thu, 20 Nov 2008 08:13:52 -0500
Subject: [R-pkgs] Update of X2R (with FishGraph) at CRAN, 20 Nov 2008
Message-ID: <49256290.1070309@noaa.gov>

X2R is a bundle of three software libraries for passing complicated data 
structures from Fortran, C/C++, or AD Model Builder to R.  An update has 
been sent to CRAN and should be available from mirrors shortly. From the 
menu at the left of the CRAN home page, look under Software / Other. 

We also have updated FishGraph, a compatible set of R functions for 
examining output from fish population models.  

* * *

Changes in this Update

The update adds minor bug fixes only.  In For2R, nested lists are now 
handled correctly.  In FishGraph, correct axis units are now used in the 
CLD.plots (catch, landings, discards) routine.

* * *

More detail, for those interested:

X2R is three independent but related software libraries:  C2R, ADMB2R, 
and For2R (together, X2R). Each contains output routines to  simplify 
transfer of complicated data structures from models written in a 
compiled language to R (note 1). Through calls to X2R routines, the 
user's data is written as a structured ASCII file. That file can be read 
by R with a single dget() function call to create an R data object of 
type list. The list may contain components such as vectors, data frames, 
matrices, and other lists.

These are NOT R packages; rather they are subroutine libraries to be 
used with programmers' own modeling codes. Limited testing indicates 
compatibility with S-PLUS, as well (note 2).

Languages supported are Fortran 95 (with For2R), C and C++ (with C2R) 
and AD Model Builder (with ADMB2R) (note 3).  Source code and detailed 
users' manuals are supplied.

ADMB2R has been tested with ADMB versions 6.03 and 7.71 and recent 
versions of the gcc and Borland C++ compilers.

The compatible software FishGraph is a set of R functions providing 
exploratory and presentation graphics of fishery catch-at-age or 
catch-at-length models. By taking its data from an R list assumed to 
have a certain structure (diagram provided), FishGraph determines which 
graphs should be generated. The required data structure may be generated 
with X2R or within R itself and may contain any amount of additional 
data. Most FishGraph routines have options to control titles, colors, 
and reference lines. The combination of X2R and FishGraph allows 
automating graphics from routine fish stock assessments. The FishGraph 
functions can be modified or supplemented to reflect the needs of the 
analysis at hand.

X2R is supplied as files X2R.zip and X2R.tar.gz, which are equivalent.  
Version and release date are found in file  "VersionInfo.txt" in the 
root of each archive. The new version is dated November 19, 2008.

FishGraph (same CRAN directory) is supplied as a Windows installer.  We 
will gladly collaborate with anyone interested in adapting FishGraph to 
other operating systems.

This work has been tested and is regularly used by the authors. However, 
any software may contain bugs, and these works are classified by NOAA as 
"Experimental Products."  THIS SOFTWARE IS SUPPLIED WITH NO WARRANTY OF 
ANY KIND. The authors will endeavor to fix bugs promptly and to add 
requested features.  Send bug reports, suggestions, and extensions to

Michael H. Prager - mike.prager at noaa.gov
Southeast Fisheries Science Center
National Marine Fisheries Service, NOAA
101 Pivers Island Road
Beaufort, North Carolina 28516 USA


* Note 1. Use of product names (commercial or otherwise) does not imply 
endorsement or recommendation by any U.S. government agency, nor by the 
authors in their government capacities.
* Note 2. S-PLUS is a commercial product that requires licensing by the 
user.
* Note 3. AD Model Builder, formerly a commercial product, is now an 
open-source free-software project. See http://admb-project.org/.



From ronggui.huang at gmail.com  Mon Nov 24 07:39:11 2008
From: ronggui.huang at gmail.com (ronggui)
Date: Mon, 24 Nov 2008 14:39:11 +0800
Subject: [R-pkgs] RQDA-0.1.5 is released
Message-ID: <38b9f0350811232239p3e19a0feh112e53eee9376e84@mail.gmail.com>

RDQA is a package for Qualitative Data Analysis built upon R. It works
both on the Windows and Linux/FreeBSD platforms. RQDA is an
easy-to-use tool to assist in the analysis of textual data. At the
present, it supports only plain text format data. All the information
is stored in SQLite database via the R package of RSQLite. The GUI is
based on RGtk2, via the aid of gWidgetsRGtk2. It includes a number of
standard Computer-Aided Qualitative Data Analysis features. Besides,
it seamlessly integrated with R, which means that a) statistical
analysis on the coding is possible, and b) functions about data
manipulation and analysis can be easily extended by writing R
functions. To some extent, RQDA and R makes an integrated platform for
both quantitative and qualitative data analysis.

The current version should be regarded as Release Candidate Version, I
will test it preliminary under Chinese Windows  OS, but it should work
under Linux and FreeBSD.

By the GUI, it can:
# Import documents from plain text
# Support non-English documents, Simplified Chinese Character is
well-tested under Windows
# Character-level coding using codes
# Memos of documents, codes, coding, project, files and more
# Retrieval of coding
# Single-file (*.rqda) format, which is basically SQLite database.
Data are stored in UTF-8, so it should be portable
# Facilitator helps to categorize codes,which is key to theory
building. I deliberately avoid using tree-like categorization
# There is a case category, which is crucial feature to bridge
qualitative and quantative research
# Search information about selected case from the Internet vis popup menu
# Temporary delete files and codes
# Rename the files,code, code category, case and others

More information can be found in http://rqda.r-forge.r-project.org/

Comments and suggestions are welcome:)

-- 
HUANG Ronggui, Wincent
Tel: (00852) 3442 3832
Ph.D. Candidate, CityU of HK
Master of sociology, Fudan University, China
Bachelor of Social Work, Fudan University, China
Personal homepage: http://ronggui.huang.googlepages.com/



From dusa.adrian at gmail.com  Tue Nov 25 20:01:01 2008
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Tue, 25 Nov 2008 21:01:01 +0200
Subject: [R-pkgs] RQDA-0.1.5 is released
In-Reply-To: <38b9f0350811232239p3e19a0feh112e53eee9376e84@mail.gmail.com>
References: <38b9f0350811232239p3e19a0feh112e53eee9376e84@mail.gmail.com>
Message-ID: <200811252101.02073.dusa.adrian@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20081125/afd230d3/attachment.pl>

From jfox at mcmaster.ca  Fri Nov 28 16:22:34 2008
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 28 Nov 2008 10:22:34 -0500
Subject: [R-pkgs] version 2.0-0 of the effects package
Message-ID: <001101c9516d$237253b0$6a56fb10$@ca>

Dear R users,

I'd like to announce version 2.0-0 of the effects package, which is now on
CRAN. The package constructs graphical and tabular "effect displays," e.g.,
of interactions, for several kinds of models. These displays are
generalizations of "adjusted" means in linear models. 

The major addition to the package is the ability to display terms in
multinomial and proportional-odds logit models (using results described in
Fox, J. and R. Andersen (2006), "Effect displays for multinomial and
proportional-odds logit models," Sociological Methodology 36, 225-255; the
original package was described in Fox, J. (2003), "Effect displays in R for
generalised linear models," Journal of Statistical Software 8:15, 1-27.)

The new version of the package is co-authored with Jangman Hong.

Regards,
 John

------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox



From edd at debian.org  Wed Dec  3 03:46:11 2008
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 2 Dec 2008 20:46:11 -0600
Subject: [R-pkgs] Rcpp package relaunched
Message-ID: <18741.62195.684768.963812@ron.nulle.part>


New Rcpp versions 0.6.0 and 0.6.1
---------------------------------
		
The Rcpp package provides C++ classes that greatly facilitate interfacing C
or C++ code in R packages using the .Call() interface provided by R.

Rcpp provides matching C++ classes for a large number of basic R data
types. Hence, a package author can keep his data in normal R data structure
without having to worry about translation or transfer to C++. At the same
time, the data structures can be accessed as easily at the C++ level, and
used in the normal manner.

The mapping of data types works in both directions. It is as straightforward
to pass data from R to C++, as it is it return data from C++ to R.  The
following two sections list supported data types.

Transfer from R to C++:
Standard R datatypes that are understood in C++ are
 o named lists containing numeric (i.e. floating point), integer,
   character, logical (i.e. boolean) or Date and Datetime (i.e. POSIXct at
   the microsecond granularity) arguments;
 o data frames containing numeric, integer, logical, character,
   Date, Datetime or Factor columns;
 o named vectors containing numeric or integer values,
 o vectors and matrices of different values
 o character strings

Transfer from C++ to R:
Standard C++ datatypes can be returned to R in a named list, the most
general data type in R.  Permissible components of the returns list
are the following C++ types:
 o double (scalar as well as vectors and vectors of vectors),
 o int (scalar as well as vectors and vectors of vectors), string,
 o STL vector types and vector<vector> types of int and double
 o STL vector of strings
 o internal Rcpp types RcppDate, RcppDateVector, RcppDatetime,
   RcppDatetimeVector, RcppStringVector, RcppVector of int or double,
   RcppMatrix of int or double, RcppFrame

Rcpp was initially written by Dominick Samperi as part of his contributions
to RQuantLib, and later released as a standalone package (under both the Rcpp
and RcppTemplate names).   Its development had ceased in late 2006.

As of November 2008, I have made new release with substantially expanded
documentation, simpler yet more comprehensive build structure leading to
easier use of Rcpp from other packages, and support for Windows, Linux and
Mac OS X (with special thanks to Simon for some extended cluebat waving).

More information for Rcpp can be found at
 o the package homepage at http://dirk.eddelbuettel.com/code/rcpp.html
 o the R-forge repository at https://r-forge.r-project.org/projects/rcpp/
 o the CRAN page at http://cran.r-project.org/web/packages/Rcpp/index.html

Regards,  Dirk
 
-- 
Three out of two people have difficulties with fractions.



From jeff.horner at vanderbilt.edu  Fri Dec  5 17:03:30 2008
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Fri, 05 Dec 2008 10:03:30 -0600
Subject: [R-pkgs] RMySQL 0.7-2 now available on CRAN
Message-ID: <493950D2.1090806@vanderbilt.edu>

Dear R users,

RMySQL 0.7-2 is now available on CRAN:

http://cran.r-project.org/web/packages/RMySQL/index.html

 From the NEWS file:

* New maintainer is Jeffrey Horner <jeff.horner at vanderbilt.edu>.

* We no longer distribute libmysql.dll. This library is now found
  either by reading the MYSQL_HOME environment variable or by reading
  the windows registry entries.

* Removed dependence on MySQL C function load_defaults() as it was
  meant for command-line tools, not for (re)connecting to a database.

* Fixed \r issue with dbWriteTable().

* Tests have been added and depend on proper values set in the
  environment variables MYSQL_DATABASE, MYSQL_USER, and
  MYSQL_PASSWD.

Best,

Jeff



From arne.henningsen at googlemail.com  Tue Dec  9 17:33:21 2008
From: arne.henningsen at googlemail.com (Arne Henningsen)
Date: Tue, 9 Dec 2008 11:33:21 -0500
Subject: [R-pkgs] SFA tools moved from micEcon to frontier
Message-ID: <200812091133.21668.arne.henningsen@googlemail.com>

Dear R users,

I would like to inform you that everything of the "micEcon" package that is 
related to Stochastic Frontier Analysis (SFA) has been moved to the "frontier" 
package, because this is a more appropriate place for the functions 
"front41WriteInput", "front41ReadOutput", and "front41Est", and the 
corresponding (S3) methods. The data sets "riceProdPhil" and "Coelli" have 
been removed from the "micEcon" package, because they were already included in 
the "frontier" package (the latter is named "front41Data" in the "frontier" 
package). The new "frontier" package (with the "front41..." functions) is 
available on CRAN now and the new "micEcon" package (without the "front41..." 
functions) will be available on CRAN in some time. Please use the meantime to 
update your code. 

Please don't hesitate to contact me if you have any questions 
or comments,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name/



From h.wickham at gmail.com  Sun Dec 14 21:38:36 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 14 Dec 2008 14:38:36 -0600
Subject: [R-pkgs] New version of ggplot2, 0.8.1
Message-ID: <f8e6ff050812141238y4dbf8079w37890ded03e5e060@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the nearly 500
examples of ggplot in use.  If you're interested, you can also sign up to
the ggplot2 mailing list at http://groups.google.com/group/ggplot2, or track
development at  http://github.com/hadley/ggplot2

ggplot2 0.8.1  (2008-12-12)
----------------------------------------

New features

* new labs, xlab & ylab functions for easily modifying axis labels and
legend titles
* qplot now guesses what geom you want based on the position
aesthetics that you provide:
  * both x & y: scatterplot
  * only x: histogram
  * only y: scatterplot of seq_along(y) vs y
* scale_datetime: a first attempt at a scale for date time objects of
class POSIXt

Aesthetic improvements

* legends should now work in cases where you have multiple layers the
use the same geom and have different aesthetic mappings
* theme: new theme setting legend.key.size determines size of keys in legend
* theme: new theme setting plot.margins to control the plot margins
* tweaks to plot and legend layout

Other minor improvements

* geom_point warns if missing values present in data and not displayed on plot
* geom_smooth gives a more accurate warning when you have incorrectly
specified the grouping
* geom_smooth will switch to an alternative smoothing method
(mgcv::gam(y ~ s(x, bs = "cr"))), when there are more than 1000
observations
* layers gain a legend argument, which allow you to force the layer
either into (TRUE) or out of (FALSE) the legend

Bug fixes

* coord_equal now calculates scales correctly again
* coord_flip: flips axes labels again too
* coord_trans fix bug where transformation incorrect
* facet_grid: fix bug where tick labels where being produced outside
the range of the axes
* facet_wrap: fixed bug with ncol = 1 or nrow = 1
* facet_wrap: labels correctly clipped to axis ranges
* facet_wrap: labels will match panels even when factor levels are not
in alphabetical order
* facet_wrap: now works when a layer doesn't contain every level of
the faceting variables
* geom_abline should now work in a wider variety of situations
* geom_smooth now gives correct asymmetric standard errors with
generalised linear models (thanks to Thierry Onkelinx)
* geom_vline and geom_hline now correctly transform their intercepts
if the scale is transformed
* geom_vline and geom_hline: now use xintercept and yintercept instead
of intercept
* legend.position and legend.justification work again
* position_dodge now works for any number of elements with smaller
widths, not just 2!
* scale_discrete_position: does a better job of calculating axis
limits when plotting a mixture of continuous and discrete values (e.g.
with geom_jitter)
* summary: tweaks to improve output


-- 
http://had.co.nz/



From chenshu at med.umich.edu  Mon Dec 15 20:14:21 2008
From: chenshu at med.umich.edu (Shu Chen)
Date: Mon, 15 Dec 2008 14:14:21 -0500
Subject: [R-pkgs] R CMD check on window XP
Message-ID: <4946663D.43DF.0027.0@med.umich.edu>

Hi, there,

I used R CMD check  to build my "ATGGS" package under window XP system. My R version is 2.7.2. But I encounter some problems. The log file is like:
**********************************************************************************
installing R.css in C:/ATGGS.Rcheck


---------- Making package ATGGS ------------
  adding build stamp to DESCRIPTION
  installing R files
  installing inst files
find: `C:/ATGGS.Rcheck/ATGGS/csvscripts': Permission denied
make[2]: *** [C:/ATGGS.Rcheck/ATGGS/inst] Error 1
make[1]: *** [all] Error 2
make: *** [pkg-ATGGS] Error 2
Can't read C:/ATGGS.Rcheck/ATGGS/auxData: Invalid argument at c:\R\R-27~1.2/bin/INSTALL line 434
Can't remove directory C:/ATGGS.Rcheck/ATGGS/auxData: Directory not empty at c:\R\R-27~1.2/bin/INSTALL line 434
Can't read C:/ATGGS.Rcheck/ATGGS/csvData: Invalid argument at c:\R\R-27~1.2/bin/INSTALL line 434
Can't remove directory C:/ATGGS.Rcheck/ATGGS/csvData: Directory not empty at c:\R\R-27~1.2/bin/INSTALL line 434
Can't read C:/ATGGS.Rcheck/ATGGS/csvscripts: Invalid argument at c:\R\R-27~1.2/bin/INSTALL line 434
Can't remove directory C:/ATGGS.Rcheck/ATGGS/csvscripts: Directory not empty at c:\R\R-27~1.2/bin/INSTALL line 434
Can't read C:/ATGGS.Rcheck/ATGGS/doc: Invalid argument at c:\R\R-27~1.2/bin/INSTALL line 434
Can't remove directory C:/ATGGS.Rcheck/ATGGS: Directory not empty at c:\R\R-27~1.2/bin/INSTALL line 434
*** Installation of ATGGS failed ***

Removing 'C:/ATGGS.Rcheck/ATGGS'

****************************************************************************************

I am not able to delete c:/ATGGS.Rcheck until I change the permission of the folder. I'm the admin of C driver. I have full control of all other folders under  C driver.


Thanks for help.

Sue



**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues



From brian at braverock.com  Tue Jan  1 01:55:07 2008
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 31 Dec 2007 18:55:07 -0600
Subject: [R-pkgs] PerformanceAnalytics version 0.9.6 released to CRAN
Message-ID: <47798F6B.2080004@braverock.com>

We are pleased to announce the availability on CRAN of
PerformanceAnalytics version 0.9.6.

This is a feature and bugfix release.

http://cran.r-project.org/src/contrib/Descriptions/PerformanceAnalytics.html

PerformanceAnalytics is a library of econometric functions for
performance and risk analysis. This library aims to aid practitioners
and researchers in utilizing the latest research in analysis of
non-normal return streams.

Package: PerformanceAnalytics
Type: Package
Title: Econometric tools for performance and risk analysis.
Version: 0.9.6
Date: 2007-12-29
License: GPL
URL:
http://cran.r-project.org/src/contrib/Descriptions/PerformanceAnalytics.html
URL: http://braverock.com/R/

New Functions:
     chart.ECDF
         Creates an empirical cumulative distribution function (ECDF)
         overlaid with a cumulative distribution function (CDF)
         Inspired by:
         Ruppert, David. 2004.
         Statistics and Finance, an Introduction.
         Ch. 2 Fig. 2.5

     chart.ACF
     chart.ACFplus
         Inspired by (and partially ported from) the website:
         http://www.stat.pitt.edu/stoffer/tsa2/Rcode/acf2.R
         "here's an R function that will plot the ACF and PACF of a time
         series at the same time on the SAME SCALE, and it leaves out
         the zero lag in the ACF [and uses the number of observations
         as the default]"
         That description made a lot of sense, so it's implemented here
         for both the ACF alone and the ACF with the PACF.

     chart.Regression
         Uses a scatterplot to display the relationship of returns
         to a market benchmark.  Fits a linear model and overlays the
         resulting model.  Also overlays a Loess line for comparison.

     Return.read
         Wrapper of 'read.zoo' with some defaults for different
         date formats and frequencies.

     Return.Geltner
         Calculate Geltner liquidity-risk-adjusted return series.
         David Geltner developed a method to remove estimating/liquidity
         bias in real estate index returns.  It has since been applied
         to other return series that show autocorrelation or
         illiquidity effects. The theory is that by correcting for
         autocorrelation, you are uncovering a "true" return from series
         of observed returns that contain illiquidity or manual pricing
         effects.

     SmoothingIndex
         Proposed by Getmansky et al to provide a normalized measure of
         liquidity risk.  The index will produces a number from zero to
         one.  A low number indicates low liquidity risk.  A number
         trending towards one indicates a higher liquidity risk.

     table.Autocorrelation
         Produces data table of autocorrelation coefficients rho and
         corresponding Q(6)-statistic for each column in return series.

     table.CalendarReturns
         Returns a table of returns formatted with years in rows, months
         in columns, and a total column in the last column.
         For additional columns, annual returns will be appended.


Significantly Changed Functions:
     chart.Boxplot
         Added the ability to more completely control the visual display.
         Added the ability to render a Tufte-style compact boxplot.

     chart.Histogram
         Improved visual display for print-quality graphics
         Added fits for extra distributions (stable,cauchy,skew-T)
         Added more control over risk lines
         Added event lines

     chart.QQPlot
         Replaced most internals with port of John Fox's
         qq.plot from 'car'
         Now fits arbitrary distributions
         Allows use of error bands

     We have made changes throughout the package to allow the
     risk-free rate to contain a vector of changing rates corresponding
     with the return series being examined.

     In addition, we have made more extensive use of the features of the
     'zoo' package in this release of PerformanceAnalytics, and removed
     a few external dependencies where those dependencies were minor and
     easily replicated or ported to this package.  We expect both of
     these trends to continue in later releases.  Hopefully, we have
     properly credited the original authors and functions both in our
     code and in the manual pages.

Deprecated Functions:
     rollingCorrelation
     rollingFunction
         These functions have been replaced in our code by the use of
         zoo's 'rollapply' function, and are no longer needed as
         separate custom functions.

New Vignettes:
     We have added as vignettes the presentations we gave on
     PerformanceAnalytics at the R/RMetrics Conference in Mielesalp
     in July 2007 and at UseR! 2007 in Ames, Iowa.

Other:
     This version of PerformanceAnalytics contains many, many minor
     improvements and changes.  We added aver 1500 lines of code
     and comments, and over 1000 lines of documentation.

We have benefited greatly from feedback and comments from the users of
PerformanceAnalytics and from R-SIG-Finance.  Please continue to send
your questions, comments, and complaints.

Full details available in the ChangeLog or in the CVS logs in all .R
files in the source package.

Regards,

     - Brian



From gkerns at ysu.edu  Thu Jan 10 13:40:46 2008
From: gkerns at ysu.edu (G. Jay Kerns)
Date: Thu, 10 Jan 2008 07:40:46 -0500
Subject: [R-pkgs] prob package: elementary probability on finite sample
	spaces
Message-ID: <a695148b0801100440o4b4d8166y8c5a0fb03fa52587@mail.gmail.com>

Dear R Community,

I am pleased to announce the beta-release of the prob package.  The
source code is now on CRAN, and binaries should be generated there
before long. In the meantime, you can get it with

install.packages("prob", repos = "http://r-forge.r-project.org")

The prob package gives a framework for doing elementary probability on
finite sample spaces in R.  The primary notion of "probability space"
has been built around the data frame structure, both for simplicity
and to maximize compatibility with the R Commander by John Fox.

The package addresses an ample proportion of material in a typical
undergraduate course in elementary probability, or the probability
material in an introductory statistics course. For details, see
vignette("prob").

Since the focus is on sample/probability spaces, the prob package
could be used as a precursor to the more sophisticated distrxxx-family
of packages.

Topics:

* construction of sample spaces (in the sense of 'prob' ) of various
kinds.  Some standard sample spaces are included (toss a coin, roll a
die, sample from an urn, draw cards, roulette, etc.)
* counting and the Multiplication Principle,
* subsets and events including methods for intersect, union, and
setdiff extending those in the base package,
* the prob function for finding probability and conditional
probability of events,
* simulation and relative frequencies,
* random variables, marginal distributions,
* extensions for more general sample spaces,
* discrete multivariate distributions with finite support,
* more...

Some discussion and examples can be found at the R-Forge prob project web page:

http://prob.r-forge.r-project.org/

There are many avenues for future development/improvement;  all
suggestions and comments are welcomed.  I would appreciate hearing
about your experiences with it in the classroom and elsewhere.

The audience for this package would include teachers and students of
elementary probability, or simply anyone wanting to dabble with
probability on a finite sample space.

Regards,
Jay




***************************************************
G. Jay Kerns, Ph.D.
Assistant Professor / Statistics Coordinator
Department of Mathematics & Statistics
Youngstown State University
Youngstown, OH 44555-0002 USA
Office: 1035 Cushwa Hall
Phone: (330) 941-3310 Office (voice mail)
-3302 Department
-3170 FAX
E-mail: gkerns at ysu.edu
http://www.cc.ysu.edu/~gjkerns/



From izmirlian at nih.gov  Tue Jan  8 20:33:13 2008
From: izmirlian at nih.gov (Grant Izmirlian)
Date: Tue, 8 Jan 2008 14:33:13 -0500
Subject: [R-pkgs] PwrGSD
Message-ID: <200801081433.13738.izmirlian@nih.gov>

Hello List:

Please find uploaded to CRAN a new package, PwrGSD

The package is intended for the design and analysis of group sequential trials
There are two main functions, 
(1) GrpSeqBnds: computes group sequential stopping boundaries for interim
      analysis of a sequential trial based upon a normally distributed test 
      statistic. This can be done via the Lan-Demets procedure with 
      Obrien-Fleming, Pocock or Wang-Tsiatis spending. This can also be
      done via boundaries created to correspond with the stochastic 
      curtailment procedure.  

(2) PwrGSD (same as the package name) which computes operating 
      characteristics such as power, expected duration, weighted avergage 
      relative risks at the boundaries among other things, that correspond to 
      a user supplied hypothetical two arm trial under a user supplied choice
      of monitoring scheme and choice of test statistic within the weighted 
      log-rank class of test statistics. Computations are done either via 
      aysmptotic methods or via simulation.  Note:  another feature is the 
      flexible provision for time dependent non-compliance.  

      The function has a nice calling interface based upon the specification
      of boundary methods via functional forms.  There are alot of nice
      summarization methods which allow the user to explore the space of
      hypothetical trial scenarios and boundary construction methods, such as 
      a compound object class for linking individuals calls to PwrGSD to 
      components of a list that are linked to an indexing dataframe for 
      reference purpose.

      I appologize for a lengthy note, but attach a quite informative example 
      below.  

      Best Regards,

      Grant Izmirlian
      Mathematical Statistician
      Division of Cancer Prevention
      US National Cancer Institute
      1-(301)496-7519
      izmirlig at mail.nih.gov
     ????? ?????????
---------------------------------------------------------------------------------
       tlook <- c(7.14, 8.14, 9.14, 10.14, 10.64, 11.15, 12.14, 13.14,
                      14.14, 15.14, 16.14, 17.14, 18.14, 19.14, 20.14)
       t0 <- 0:19      
       h0 <- c(rep(3.73e-04, 2), rep(7.45e-04, 3), rep(1.49e-03, 15))
       rhaz <-c(1, 0.9125, 0.8688, 0.7814, 0.6941, 0.6943, 0.6072, 0.5202,  
                      0.4332, 0.652, 0.6524, 0.6527, 0.653, 0.6534, 0.6537, 
                      0.6541, 0.6544, 0.6547, 0.6551, 0.6554)
	hc <- c(rep(1.05e-02, 2), rep(2.09e-02, 3), rep(4.19e-02, 15))
        hd1B <- c(0.1109, 0.1381, 0.1485, 0.1637, 0.2446, 0.2497, 0)


      test.example <- PwrGSD(
         EfficacyBoundary=LanDemets(alpha=0.05, spending= ObrienFleming),
         FutilityBoundary=LanDemets(alpha=0.1,spending=ObrienFleming),
         RR.Futility = 0.82, sided="<",method="A",accru =7.73, accrat=9818.65,
         tlook =tlook, tcut0 =t0, h0=h0, tcut1=t0, rhaz=rhaz, 
         tcutc0=t0, hc0=hc, tcutc1=t0, hc1=hc, 
         tcutd0B =c(0, 13), hd0B =c(0.04777, 0),
         tcutd1B =0:6, hd1B =hd1B,
         noncompliance =crossover, gradual =TRUE,
         WtFun =c("FH", "SFH", "Ramp"),
         ppar =c(0, 1, 0, 1, 10, 10))

     ## we will construct a variety of alternate hypotheses relative to the
     ## base case specified above

       max.effect <- 0.80 + 0.05*(0:8)
       n.me <- length(max.effect)

     ## we will also vary extent of censoring relative to the base case
     ## specified above

       cens.amt <- 0.75 + 0.25*(0:2)
       n.ca <- length(cens.amt)

     ## we may also wish to compare the Lan-Demets/O'Brien-Fleming efficacy
     ## boundary with a Pocock efficacy boundary

       Eff.bound.choice <- 1:2
       ebc.nms <- c("LanDemets(alpha=0.05, spending=ObrienFleming)",
                    "SC(alpha=0.05, crit=0.90)")
       n.ec <- length(Eff.bound.choice)

     ## The following line creates the indexing dataframe, `descr', with one
     ## line for each possible combination of the selection variables we've
     ## created.

       descr <- 
          as.data.frame(
             cbind(Eff.bound.choice=rep(Eff.bound.choice, each=n.ca*n.me),
                      cens.amt=rep(rep(cens.amt, each=n.me), n.ec),
                      max.effect=rep(max.effect, n.ec*n.ca)))

       descr$Eff.bound.choice <- ebc.nms[descr$Eff.bound.choice]

     ## Now descr contains one row for each combination of the levels of
     ## the user defined selection variables, `Eff.bound.choice',
     ## `max.effect' and `cens.amt'. Keep in mind that the names and number
     ## of these variables is arbitrary. Next we create a skeleton
     ## `cpd.PwrGSD' object with a call to the function `cpd.PwrGSD' with
     ## argument `descr'

       test.example.set <- cpd.PwrGSD(descr)

     ## Now, the newly created object, of class `cpd.PwrGSD', contains
     ## an element `descr', a component `date', the date created
     ## and a component `Elements', an empty list of length equal
     ## to the number of rows in `descr'.  Next we do the computation in
     ## a loop over the rows of `descr'.

       n.descr <- nrow(descr)
       for(k in 1:n.descr){

         ## First, we copy the original call to the current call,
         ## `Elements[[k]]$call'

         test.example.set$Elements[[k]]$call <- test.example$call

         ## Use the efficacy boundary choice in the kth row of `descr'
         ## to set the efficacy boundary choice in the current call

         test.example.set$Elements[[k]]$call$EfficacyBoundary <-
         parse(text=as.character(descr[k,"Eff.bound.choice"]))[[1]]

         ## Derive the `rhaz' defined by the selection variable "max.effect"
         ## in the kth row of `descr' and use this to set the `rhaz'
         ## components of the current call

         test.example.set$Elements[[k]]$call$rhaz <-
                                 exp(descr[k,"max.effect"] * log(rhaz))

         ## Derive the censoring components from the selection variable
         ## "cens.amt" in the kth row of `descr' and place that result
         ## into the current call

         test.example.set$Elements[[k]]$call$hc0 <-
         test.example.set$Elements[[k]]$call$hc1 <-
                                    exp(descr[k, "cens.amt"] * log(hc))

         ## Now the current call corresponds exactly to the selection
         ## variable values in row `k' of `descr'. The computation is
         ## done by calling `update'

         test.example.set$Elements[[k]] <-
                               update(test.example.set$Elements[[k]])
         cat(k/n.descr, "\r")
       }


       ## We can plot the results -- see the help under `plot.cpd.PwrGSD'

       plot(test.example.set, formula = ~ max.effect | stat * cens.amt,
            subset=(substring(Eff.bound.choice, 1,9)=="LanDemets"))

       plot(test.example.set, formula = ~ max.effect | stat * cens.amt,
            subset=(substring(Eff.bound.choice, 1,2)=="SC"))

       ## Notice the appearance of the selection variable `stat' which was
       ## not defined in the dataset `descr'.



From h.wickham at gmail.com  Fri Jan 11 23:16:36 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 11 Jan 2008 16:16:36 -0600
Subject: [R-pkgs] New version of ggplot2: 0.5.7
Message-ID: <f8e6ff050801111416s4707ffeao92483948815e2fe3@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the over 500
examples of ggplot in use.

ggplot 0.5.7
----------------------------------------

New geoms, scales and aesthetics

  * stat_step and geom_step to draw staircase plots (like plot(type="s"))
  * order aesthetic (currently only for lines/paths) allows you to
control the drawing order within a group
  * scale_manual makes it easier to let ggplot uses the exact
colours/sizes/linetypes that you want
  * scale_reverse allows you to reverse the scale of x and y axes
  * scale_grey is a new black and white scale for categorical data
(colour and fill)


Improved options handling

  * new function opts() to allow modification of plot options by addition
  * update(p, theme_bw) and p + theme_bw now work

These changes mean that you can modify plot options in the same way
that you modify all other aspects of the plot, e.g.  qplot(mpg, wt,
data=mptcars) + opts(title = "Fuel economy vs weight")

Improved documentation

  * many tweaks to the online documentation, particular including the
actual code you need to run for each object!
  * every page now has a link to a form where you can submit feedback
on exactly you do or don't like about a page
  * required aesthetics now listed in documentation
  * geom_polygon now has a decent example
  * numerous minor corrections suggested by J?rg Beyer
  * separated plotting advice from details of plot construction (what
vs how), thanks to Bert Gunter for this suggestion


Improved map projections (with coord_map)

  * coord_map defaults to orientation = c(90, 0, mean(range(y))) -
this ensures that multiple layers line up correctly, but means you
will have to specify the orientation yourself for many projections
  * coord_map now respects limits set by scales
  * removed useless ticks from coord_map

If you're using ggplot to draw maps and have thought of other features
that would make your life easier, please let me know.


Bug fixes

  * adding data and aesthetics in separate steps should now work
  * layers with set parameters will not use mapped aesthetics
  * use LazyLoad: false instead of SaveData: true for better future
compatability

  * coord_cartesian: fixed bug that prevented you from overriding the
default axis expansion
  * coord_equal: now scales correctly if ratio < 1
  * geom_abline: fix bug where slope was ignored
  * geom_jitter now works correctly with groups and categorical values
(was actually a bug in how scale_discrete deals with continuous
values)
  * geom_path: automatically switch between polylineGrob and
segmentsGrob when drawing paths so that setting line type now works
properly
  * geom_segment now uses both ends of segments to calculate axis limits
  * plotmatrix: fix bug in scatterplot matrix where all scatterplots
were transposed!
  * qplot: should now work better within functions
  * quickplot added as an alias of qplot, to avoid confusion with qunif, etc
  * scale_*: better error message if you add a scale without a
matching aesthetic mapping in the plot
  * scale_identity no longer converts everything to character
  * scale_identity: grob argument renamed to guide
  * stat_*: made all statistics more robust to errors
  * stat_quantile: fixed bug when only drawing a single quantile
  * stat_smooth: returns silently if <2 non-missing data points


Minor aesthetic improvements

  * coord_polar now specifies aspect.ratio by default, and I've made a
few other tweaks to make polar coordinates plot look nicer
  * geom_bar no longer draws gray borders by default, but instead uses
the same colour as fill (this eliminates a tiny gap between
neighbouring bars)
  * plotmatrix: tweaks to improve display of scatterplot matrix
  * scale_brewer: added option to reverse palette
  * scale_colour: colour and fill legends now look exactly the same
(previously colour was missing a grey border)
  * scale_discrete has slightly larger expansion (0.75 vs 0.5)
  * stat_bar: only output bars with > 0 count


See CHANGELOG for changes in previous versions


-- 
http://had.co.nz/



From bxc at steno.dk  Thu Jan 17 17:09:40 2008
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Thu, 17 Jan 2008 17:09:40 +0100
Subject: [R-pkgs] New version of Epi package out (1.0.7)
Message-ID: <40D3930AC1C8EA469E39536E5BC8083505452383@EXDKBA021.corp.novocorp.net>

A new major upgrade of the Epi package for Epidemiological data analysis
has been put on CRAN, it is now at version 1.0.7.

It contains an entirely new way of representing follow-up data on
multiple timescales and multiple states. See the function Lexis().

Plus a lot of other useful stuff for epidemiological analysis.
See more on the package homepage, www.biostat.ku.dk/~bxc/Epi

Note also that there will be a course 28 May - 2 June in Estonia, see
www.biostat.ku.dk/~bxc/SPE.

Bendix Carstensen
Epi package maintainer	
______________________________________________

Bendix Carstensen
Senior Statistician
Steno Diabetes Center
Niels Steensens Vej 2-4
DK-2820 Gentofte
Denmark
+45 44 43 87 38 (direct)
+45 30 75 87 38 (mobile)
bxc at steno.dk   http://www.biostat.ku.dk/~bxc



From ggrothendieck at gmail.com  Sat Jan 19 18:41:11 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 19 Jan 2008 12:41:11 -0500
Subject: [R-pkgs] batchfiles 0.4-0
Message-ID: <971536df0801190941q672c4fcbx4e4f8701fec75831@mail.gmail.com>

batchfiles 0.4-0 consists of a set of Windows Vista
.bat, .hta and .pl files.

More information is available on the home page:
http://batchfiles.googlecode.com

CHANGES

- now tested with Vista exclusively (use 0.3-2 instead on XP)

- sweave.bat now has no dependencies on the other batch
  files.  With this change all .bat and .hta files now
  have no dependencies except possibly for R.

- RguiStart.bat is like Rgui.bat but takes a single argument
  which may be an .Rdata file or a folder.  It can be
  placed in your SendTo folder in which case you can
  right click in Windows Explorer choosing
   SendTo | RguiStart.bat

- Rversions.hta now elevates RSetReg automatically (but
  you will still be prompted for confirmation)

- new toggleDoc.pl perl program from Dieter Menne which
  unclutters 00Index.html Help files in packages.  See
  sample output at:
  http://www.menne-biomed.de/download/toggleDoc/00Index.html
  and try toggling the Show All checkbox to see what it does.

- Rversions.bat, Rfind.bat, makepkg.bat and withgs.bat
  are no longer part of the package but are still available
  in version 0.3-2.

PACKAGE DESCRIPTION

(Note that this is a collection of Windows batch and other
files available in the CRAN Other area for R as opposed to
a package written in R.)

batchfiles is a collection of .bat, .hta and .pl scripts
that are useful when using R or developing R software.

The .bat and .hta files are easy to install as they have no
dependencies other than R and they automatically look up R
in the registry so no paths have to be set.  Just place them
all or just those you want anywhere in your path.  There are
utilities for running R, creating packages, switching the
current R version, R scripting and runing sweave as well as
others.

- Rcmd.bat, R.bat and Rgui.bat are all the same file which
query what name it was called by and acts in a similar way
to the R .exe files of the same name except that they first
attempt to find R by checking the registry and common
locations so to use them all you do is put them anywhere in
your path.

- RguiStart.bat is the same as Rgui.bat except it accepts
a single argument that is an R directory or .Rdata file
so if you place it in your SendTo folder and right click
any folder in Windows Explorer choosing SendTo | RguiStart.bat
it will start up R in that folder.  If an .Rdata file is
right clicked then R starts up loading that file.

- sweave.bat will run sweave and the pdflatex and then display
the pdf file (or some subset of those depending on switches).
It has builtin makefile functionality so it will not proceed
to the next step if the prior step has failed.  It also
creates and displays a backup copy of the pdf with a unique
name so two versions of the same pdf file can be simultaneously
displayed.

- #Rscript.bat can be used as the first line of an R script to
make it callable as a batch file.  Rscript.bat is a variation
of it used differently.

- Rtidy.bat reformats R programs.  Its primarily included as
a simple example of #Rscript.bat .

- Rversions.hta - if there are multiple versions of R installed
this program locates all versions in the registry and
provides a GUI interface with a drop down menu to choose
which one you wish to make current.

- copydir.bat/movedir.bat copy or move packages from one library
to another such as would be done when upgrading R.  They will
create new copies but will never overwrite any files that are
already there so they should be safe to use.

- toggleDoc.pl is a perl program which unclutters HTML help
files contributed by Dieter Menne.  For an example see:
http://www.menne-biomed.de/download/toggleDoc/00Index.html



From cgenolin at u-paris10.fr  Mon Jan 21 10:27:59 2008
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Mon, 21 Jan 2008 10:27:59 +0100
Subject: [R-pkgs] New package: R to LaTeX Univariate Analyses
Message-ID: <4794659F.3060000@u-paris10.fr>

Hi the list

*** New package ***
R to LaTeX : Univariate analyses
r2lUniv
*URL:*http://www.r-project.org, http://christophe.genolini.free.fr/r2lUniv

*** Description ***
r2lUniv performs some basic analyses, then generates a code to be 
included in a LaTeX document
to print the analyses in a (so nice!) LaTeX way.
r2lUniv performs the analyses automatically according to the classical 
statistics
type definition that are nominal, ordinal, discrete and continuous. The 
analysis performed are:
- Nominal : modality, size, barplot
- Ordinal: modality, size, quartile, barplot
- Discrete: modality, size, mean, var, quartile, boxplot, barplot
- Continuous: mean, var, quartile, boxplot, barplot

*** I am a Rookie... ***
Well, I know that. This is my first package and I am almost a beginner in R.
So any comment on any subject (programming style, way of writing the 
man, use of S3) are welcome
("You did a nice job, but classical usage is to..." or "Hmmm, that would 
be more practical if...").

*** Other project ***
Well, Univariate Analysis is the first step, the second is Bivariate 
analysis.
Also, before posting here, I submit this package on a French forum.
The first suggestion is to extend this package to HTML. I will not have 
time to do it alone.
So if some people are interested, two other project are almost open :
- R to LaTeX Bivaraite Analysis
- R to HTML Univariate Analysis

Thanks

Christophe Genolini

Junior statistician
"PSIGIAM: Paris Sud Innovation Group in Adolescent Mental Health"
INSERM U669 / Maison de Solenn / Paris



From Michael.Hoehle at stat.uni-muenchen.de  Mon Jan 21 10:13:23 2008
From: Michael.Hoehle at stat.uni-muenchen.de (=?ISO-8859-1?Q?Michael_H=F6hle?=)
Date: Mon, 21 Jan 2008 10:13:23 +0100
Subject: [R-pkgs] Package surveillance (v0.9-8) on CRAN
Message-ID: <47946233.2000709@stat.uni-muenchen.de>

Dear R Community,

I would like to announce the package "surveillance", which provides
methods for the surveillance of count data time series originating
from the routine collection of public health data.

The package addresses epidemiologists and statisticians working with
routine surveillance, but it also offers an infrastructure for
developers of new detection algorithms.

Implemented outbreak detection algorithms are:
* Stroup et al. (1989)
* Farrington et al. (1996)
* A Bayesian predictive posterior approach
* Time varying Poisson means as documented in Rogerson and Yamada (2004)
* Approximate CUSUM method for time varying Poisson means by
   Rossi et al. (1999)
* A generalized likelihood ratio detector for time varying Poisson
   and and negative binomial means

Modelling routines:
* A Poisson and negative binomial model for the analysis of
multivariate infectious disease surveillance data described in Held
et al. (2005)

The paper available from http://dx.doi.org/10.1007/s00180-007-0074-8
provides a good overview of the package. Source code and binaries
(currently version 0.9-8) are available from CRAN. Visit the R-Forge
project web page for more information, development versions and forums
to discuss ideas and report bugs:

       	    http://surveillance.r-forge.r-project.org/

I would appreciate hearing about your experiences with the package.

Best regards,

Michael
-on behalf of the surveillance development team

--

Michael H?hle, Ph.D.
Department of Statistics
University of Munich
Ludwigstr. 33
80539 Munich
Germany

Homepage: http://www.stat.uni-muenchen.de/~hoehle



From HDoran at air.org  Wed Jan 23 17:42:48 2008
From: HDoran at air.org (Doran, Harold)
Date: Wed, 23 Jan 2008 11:42:48 -0500
Subject: [R-pkgs] MiscPsycho 1.1 uploaded to CRAN
Message-ID: <2323A6D37908A847A7C32F1E3662C80E0153615F@dc1ex01.air.org>

Version 1.1 of the MiscPsycho package had been uploaded to CRAN. The
package has been updated to include the following:

1) The irt.ability() function that estimates examinee ability given a
set of item parameters. The function is very general and can be used to
estimate ability when there are only dichotomous items (1-, 2-, or 3PL),
only polytomous items (generalized partial credit model), or a mixture
of dichotomous and polytomous items. The function can be used to
estimate maximum likelihood estimates or two bayesian estimates: the
maximum a posteriori (MAP) and the expected a posteriori (EAP).

2) The plaus.val() function that uses rejection sampling to draw random
samples from any IRT posterior distribution. 

3) The posterior() function that computes the density of any IRT
posterior distribution.

4) The class.acc() function that can be used to perform integration from
[-Inf,b] or [a,Inf] of any IRT posterior distribution.

5) Complete technical documentation describing all of the mathematical
methods underlying the functions as well as complete examples
demonstrating the use of all functions. This documentation lives in the
"doc" subdirectory of the MiscPsycho library.

Any bug reports, issues, and comments on the package are welcome.

Harold Doran



From seth at userprimary.net  Sat Jan 26 19:47:57 2008
From: seth at userprimary.net (Seth Falcon)
Date: Sat, 26 Jan 2008 10:47:57 -0800
Subject: [R-pkgs] RSQLite 0.6-7 -- changes to dbGetQuery semantics
Message-ID: <m2ve5gtode.fsf@userprimary.net>

RSQLite 0.6-7 has been uploaded to CRAN and should hit a mirror near
you in the next few days.

This version changes the behavior of the dbGetQuery method to make it
more consistent with dbSendQuery.  Specifically:

1. dbGetQuery now closes a complete result set as dbSendQuery does.

2. If there is an incomplete result set open, dbGetQuery still opens a
   new temporary connection, but now issues a warning.  It is best
   practice to explicitly close open result sets before issuing
   further queries.

These changes are in response to the following discussion on the
r-sig-db list:

    https://stat.ethz.ch/pipermail/r-sig-db/2008q1/000399.html

+ seth

-- 
Seth Falcon | seth at userprimary.net | blog: http://userprimary.net/user/



From Achim.Zeileis at R-project.org  Mon Jan 28 11:46:26 2008
From: Achim.Zeileis at R-project.org (Achim Zeileis)
Date: Mon, 28 Jan 2008 11:46:26 +0100 (CET)
Subject: [R-pkgs] dynlm: new version 0.2-0
Message-ID: <Pine.LNX.4.44.0801281053320.29044-100000@disco.wu-wien.ac.at>

Dear useRs,

I've release a new version of the "dynlm" package to CRAN which adds two
new features:

  o instrumental variables regression (two-stage least squares) via
    formulas like
      dynlm(y ~ x1 + x2 | z1 + z2 + z3, data = mydata)
    where z1, z2, z3 are the instruments which can again contain
    lags/differences/season via the d()/L()/season() operators.

  o specification of multiple lags via formulas like
      dynlm(y ~ L(x, 0:4), data = mydata)
    where y is regressed on x and lags 1 through 4 of x.

Furthermore, I've enhanced some convenience funcitonality such as printing
and fixed a bug in the time alignment when there were leading NAs in the
underlying data.
Z



From Soren.Hojsgaard at agrsci.dk  Mon Jan 28 12:46:20 2008
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Mon, 28 Jan 2008 12:46:20 +0100
Subject: [R-pkgs] New package: gRain - gRAphical Independence Networks
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0562FAF0@DJFPOST01.djf.agrsci.dk>

Dear useRs
 
I have uploaded a new package, gRain, for propability propagation in graphical independence networks; sometimes also called probabilistic expertsystems and Bayesian networks.
 
Regards
S?ren H?jsgaard



From patrick.mair at wu-wien.ac.at  Tue Jan 29 00:32:02 2008
From: patrick.mair at wu-wien.ac.at (Patrick Mair)
Date: Mon, 28 Jan 2008 15:32:02 -0800
Subject: [R-pkgs] eRm: new version 0.9-6
Message-ID: <479E65F2.7050907@wu-wien.ac.at>

Dear useRs,

new and updated features in eRm 0.9-6 for extended Rasch modeling:

- infit and outfit mean-square statistics added to functions personfit() 
and itemfit().

- new method: plotPImap() plots a person-item map (cf. Bond & Fox, 
2007), i.e., a map
of locations of item (and threshold) parameters, and the distribution of 
person parameters.

- new options in plotGOF():
'conf': draws confidence ellipses for item parameters, optionally single 
items can be chosen interactively.
'ctrline': draws confidence bands along the diagonal line based on the 
se's of the item parameters (cf. Wright &
Stone, 1999) .
plotGOF() now displays difficulty parameters (see below).

- unification of output for item parameter estimates: all plotting 
functions and the function thresholds() display
item difficulty parameters. all numeric output (i.e. from model objects) 
gives item easiness parameters.

- new and enhanced options in plotICC():
'empirical': empirical ICCs can now be smoothed using various smoothers 
(such as Tukey, loess, or kernel).
'ask': interactive turning over of plots can be switched off (only 
useful if automated figure export is in effect,
e.g., when using Sweave).

- simulation module for 0-1 response matrices: sim.rasch() for Rasch 
homogeneous data,
sim.2pl() for 2-PL data, sim.xdim() for unidimensionality violation, and
sim.locdep() for locally dependent item responses.

- package vignette "eRmvig" added.

Best,
Patrick



From toni.giorgino at gmail.com  Tue Jan 29 12:32:26 2008
From: toni.giorgino at gmail.com (Toni Giorgino)
Date: Tue, 29 Jan 2008 12:32:26 +0100
Subject: [R-pkgs] New package: dtw - Dynamic Time Warping
Message-ID: <9b2eed510801290332ga0381e6ua278e6b446261e72@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20080129/5962cfe0/attachment-0001.pl>

From Mike.Prager at noaa.gov  Thu Jan 31 19:36:18 2008
From: Mike.Prager at noaa.gov (Michael H. Prager)
Date: Thu, 31 Jan 2008 13:36:18 -0500
Subject: [R-pkgs] Update of X2R (with FishGraph) sent to CRAN, 30 Jan 2008
Message-ID: <47A21522.4060201@noaa.gov>

X2R is a bundle of three software libraries allowing the user to pass
structured data easily from Fortran, C/C++, or AD Model Builder to R.

An update to X2R has been sent to CRAN and should be available at 
mirrors shortly. We also have uploaded FishGraph, a set of R functions
to generate graphics from fish population models. From the menu at the 
left of the CRAN home page, look under Software / Other.

Changes in this Update

- Minor bug fixes and improvements have been made throughout, both in
the software and users' guides.
- ADMB2R is compatible with gcc as well as with the Borland compiler.
- FishGraph is available from CRAN.
- ADMB2R includes a detailed example compatible with FishGraph. This
should minimize the learning curve for those getting started with ADMB2R
and FishGraph.

X2R is supplied as files X2R.zip and X2R.tar.gz, which are equivalent.
The version and release date can be identified from the contents of file
"VersionInfo.txt" in the root of each archive. The new version bears
date January 19, 2008.

FishGraph is supplied separately as a Windows installer in the same
directory. If we hear from anyone interested in using it under other 
operating system(s), we can collaborate on making it work.

                                * * *

More detail for the interested:

X2R is composed of three independent but related software libraries:
C2R, ADMB2R, and For2R (together, X2R). Each contains output routines to
simplify transfer of complicated data structures from models written in
a compiled language to R (note 1). Through calls to X2R routines, the
user's data is written as a structured ASCII file. That file can be read
by R with a single dget() function call to create an R data object of
type list. The list may contain components such as vectors, data frames,
matrices, and other lists.

These are NOT R packages; rather they are subroutine libraries to be
used with programmers' own modeling codes. Limited testing indicates
compatibility with S-PLUS, as well (note 2).

Languages supported are Fortran 95 (with For2R), C and C++ (with C2R)
and AD Model Builder (with ADMB2R) (note 3). Source code and detailed 
users' manuals are supplied.

ADMB2R has been tested with ADMB versions 6.03 and 7.71 and recent
versions of the gcc and Borland C++ compilers.

FishGraph is a set of R functions providing exploratory and presentation 
graphics of fishery catch-at-age or catch-at-length models. By taking 
its data from an R list assumed to have a certain structure (diagram 
provided), FishGraph determines which graphs should be generated and for 
how many data series, years, etc. The data structure may be generated 
with X2R or within R itself and may contain any amount of additional 
data. Most FishGraph routines have options to control titles, colors, 
and reference lines. The combination of X2R and FishGraph allows 
automating graphics production from routine fish stock assessments. The 
FishGraph functions can be modified or supplemented to reflect the needs 
of the analysis at hand.

This work has been tested and is regularly used by the authors. However,
any software may contain bugs, and these works are classified by NOAA as
"Experimental Products."  THIS SOFTWARE IS SUPPLIED WITH NO WARRANTY OF
ANY KIND. Nonetheless, the authors will endeavor to fix bugs promptly 
and to add requested features.  Send bug reports, suggestions, and 
extensions to either author.

Michael H. Prager - mike.prager at noaa.gov
Southeast Fisheries Science Center
National Marine Fisheries Service, NOAA
101 Pivers Island Road
Beaufort, North Carolina 28516 USA

Jennifer L. Martin - jennifer.martin at noaa.gov
Northeast Fisheries Science Center
National Marine Fisheries Service, NOAA
166 Water Street
Woods Hole, Massachusetts 02543 USA


* Note 1. Use of product names (commercial or otherwise) does not imply
endorsement or recommendation by any U.S. government agency, nor by the
authors in their government capacities.
* Note 2. S-PLUS is a commercial product, released by Insightful 
Corporation.
* Note 3. AD Model Builder is a commercial product, released by Otter
Research.



From Greg.Snow at imail.org  Mon Feb  4 18:32:59 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Mon, 4 Feb 2008 10:32:59 -0700
Subject: [R-pkgs] Package blockrand version 1.1 on CRAN
Message-ID: <07E228A5BE53C24CAD490193A7381BBBE99432@LP-EXCHVS07.CO.IHC.COM>

This is to announce an updated version of the blockrand package has been
uploaded to CRAN.

The blockrand package is used for creating randomizations for clinical
trials or other studies where random assignments are made one at a time.
It implements the ideas of randomizing within blocks so that the numbers
of subjects in each group remain fairly balanced (but allows for
unbalanced blocks to make anticipation of future allocations more
difficult). 

It also includes a function to print randomization cards (creates a pdf
file) that can be put into envelopes for a study coordinator to use to
assign subjects to treatments.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
(801) 408-8111
 



From ubk2101 at columbia.edu  Mon Feb 11 22:23:40 2008
From: ubk2101 at columbia.edu (Udaya B. Kogalur)
Date: Mon, 11 Feb 2008 16:23:40 -0500
Subject: [R-pkgs] Release 3.2.0 of randomSurvivalForest is now availablle
Message-ID: <38c08c270802111323t753c5804j99381a7daa28ddcd@mail.gmail.com>

Dear useRs:

Release 3.2.0 of the CRAN package randomSurvivalForest is now available.

----------------------------------------------------------------------------------------------

Release 3.2.0 represents a significant upgrade in the functionality of
the product.  Key changes are as follows:

o A second method of perturbing the data set in order to calculate
variable importance (VIMP) has been implemented.  In addition to
permuting the values for a single variable, a random split approach
has been taken in which a data point is randomly assigned to the left
or right daughter node when a split occurs on the specified variable.

o The joint VIMP among multiple variables of a (potentially proper)
subset of the GROW data can now be calculated using the new function
interaction.rsf().  This represents a third mode of operation for the
application, and follows rsf.default (GROW) and predict.rsf (PREDICT).
See the documentation for details.

o An additional option in GROW mode can now be specified.  The option
'varUsed' allows users to quantify which variables have been split
upon within a single tree or over the entire forest.  See the
documentation for more details.

o The ability to multiply impute data has been implemented.  This
involves imputing data while growing a forest and using the results to
grow a new forest in order to better impute the data.

o In GROW mode, the application now outputs both the in-bag and OOB
summary imputed values.

o An additional split rule 'randomsplit' has been implemented.
See the documentation for more details.

o The split rule 'logrankscore' is now calculated correctly.

o The split rule 'logrankapprox' has been removed and replaced by
the new split rule 'logrankrandom'.  See the documentation for more details.


ubk2101 at columbia.edu

Udaya B. Kogalur, Ph.D.
Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012



From spencer.graves at pdf.com  Wed Feb 13 09:27:40 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 13 Feb 2008 00:27:40 -0800
Subject: [R-pkgs] FinTS_0.2-7
Message-ID: <47B2A9FC.90905@pdf.com>

Hi, All:

	  FinTS version 0.2-7 is now available on CRAN.  This version adds two 
new functions:

	  * ArchTest to compute the Engle (1982) Lagrange multiplier test for 
conditional heteroscedasticity, discussed on pp. 101-102 of Tsay, with 
examples on those pages worked in the R script in 
"~R\library\FinTS\scripts\ch03.R", where "~R" is your local R 
installation directory.  The code for this was kindly provided by 
Bernhard Pfaff.

	  * Acf and plot.Acf to plot the autocorrelation function without the 
noninformative unit spike at lag 0, facilitating the production of many 
ACF plots in Tsay (2005) Analysis of Financial
Time Series, 2nd ed. (Wiley) that follow this secondary standard.

	 Spencer Graves



From dimitris.rizopoulos at med.kuleuven.be  Wed Feb 20 09:39:47 2008
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 20 Feb 2008 09:39:47 +0100
Subject: [R-pkgs] New Package 'JM' for the Joint Modelling of Longitudinal
	and Survival Data
Message-ID: <00c801c8739c$26581ba0$0e40210a@www.domain>

Dear R-users,

I'd like to announce the release of the new package JM (JM_0.1-0 
available from CRAN) for the joint modelling of longitudinal and 
time-to-event data.

The package has a single model-fitting function called jointModel(), 
which accepts as main arguments a linear mixed effects object fit 
returned by function lme() of package nlme, and a survival object fit 
returned by either function coxph() or function survreg() of package 
survival. In addition, the method argument of jointModel() specifies 
the type of the survival submodel to be fitted and the type of the 
numerical integration technique; available options are:

    * "ph-GH": the time-dependent version of a proportional hazards 
model with unspecified baseline hazard function. This option 
corresponds to the joint model proposed by Wulfsohn and Tsiatis, 
Biometrics, 1997.

    * "weibull-GH": the Weibull model under the accelerated failure 
time formulation.

    * "ch-GH" and "ch-Laplace": an additive log cumulative hazard 
model, in which the log cumulative baseline hazard is approximated 
using B-splines.

For "ph-GH", "weibull-GH" and "ch-GH" the Gauss-Hermite integration 
rule is used to approximate the required integrals, whereas for 
"ch-Laplace" a fully exponential Laplace approximation method is 
applied. The last option is more suitable for high-dimensional random 
effects vectors, when e.g., modelling nonlinear subject-specific 
trajectories with splines or high-order polynomials.

Sample analyses can be found at:
http://student.kuleuven.be/~m0390867/R%20packages%20&%20Computing/R%20Packages/pbc.R, 
and
http://student.kuleuven.be/~m0390867/R%20packages%20&%20Computing/R%20Packages/aids.R

Any kind of feedback (questions, suggestions, bug-reports, etc.) is 
more than welcome.

Best,
Dimitris

----
Dimitris Rizopoulos
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From csardi at rmki.kfki.hu  Wed Feb 20 21:11:10 2008
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Wed, 20 Feb 2008 21:11:10 +0100
Subject: [R-pkgs] igraph package, version 0.5
Message-ID: <20080220201110.GC8077@localdomain>

igraph is a package for graphs and networks. It has a C core and 
uses a simple and fast graph representation allowing millions 
of vertices and edges.

NEW FEATURES:

- We use the ARPACK library for graph related eigenvalue problems, 
  like Page Rank calculation, Kleinberg's hub and authority scores,
  eigenvector centrality, etc. There is also a generic interface 
  if someone wants to use ARPACK for a different (not necessarily 
  graph-related) problem.

- We support the BLISS graph isomorphism algorithm, and the 
  implementation of the VF2 algorithm can calculate subgraph isomorphisms
  now.

- We include a collection of "famous" graphs, these can be created 
  by referring to their name.

- We have a new 'graph.formula' function, for creating small graphs
  using symbolic names, by giving simple R formulae.

- Many functions support weighted graphs now: Page Rank, modularity
  calculation, the fast greedy community finding algorithm, etc.

- We have a new graph layout algorithm called 'graphopt'.

- A bunch of new functions are added: biconnected components and 
  articulation points, dyad and triad census, functions for vertex 
  similarity, functions for estimating closeness, betweenness and 
  edge betweenness, etc.

- igraph can write files in the DOT format now.

- Some graphics improvements, e.g. it is possible to draw 
  graphs on top of each other, etc.

- Many bugs were fixed, the most important one is probably that 
  now memory is always properly deallocated when CTRL+C (ESC) is 
  used to interrupt a computation.

PACKAGE DESCRIPTION:

igraph is originally a C library for graphs, but has interfaces
to high level languages like R, Python and Ruby. The R package 
contains BOTH the C library and its R interface. 

igraph supports:

- graph generators, creating both regular structures like trees,
  lattices, etc. and various random graphs.

- a rich set of functions calculating structural properties of 
  graphs, like vertex centrality (degree, betweenness, closeness,
  page rank, eigenvector centrality, Burt's constraints, etc.),
  shortest paths, dyad and triad census, network motifs, girth, 
  K-core decomposition, etc.

- attributes can be associated with the vertices/edges of the graph,
  or the graph itself. The attributes can be arbitrary R objects.

- graph visualization using regular R devices, interactive visualization
  using Tcl/Tk, 3D visualization using RGL.

- graph layout generators, the standard Kamada-Kawai and 
  Fruchterman-Reingold algorithms are included, plus many more.

- Functions for graph and subgraph isomorphism, the BLISS and the VF2
  algorithms are included.

- Functions for maximal network flows, minimal cuts, vertex and 
  edge connectivity.

- igraph can read and write many popular file formats used for 
  storing graph data: GraphML, Pajek, GML and others.

- igraph contains implementations of many community structure 
  detection algorithms proposed recently.

See more at the igraph homepage:
http://cneurocvs.rmki.kfki.hu/igraph/index.html

-- 
Csardi Gabor <csardi at rmki.kfki.hu>



From Greg.Snow at imail.org  Sat Feb 23 19:00:08 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Sat, 23 Feb 2008 11:00:08 -0700
Subject: [R-pkgs] Announcement: obsSens Package
Message-ID: <07E228A5BE53C24CAD490193A7381BBBE2F513@LP-EXCHVS07.CO.IHC.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20080223/19d0ca1a/attachment-0001.pl>

From longhai.li at gmail.com  Sun Feb 24 16:58:32 2008
From: longhai.li at gmail.com (Longhai Li)
Date: Sun, 24 Feb 2008 09:58:32 -0600
Subject: [R-pkgs] Bayesian Prediction with High-order Interactions
Message-ID: <90c54480802240758y22967accpa75be28a2cfd070b@mail.gmail.com>

Hi Everybody,

A new package called ``Bayesian Prediction with High-order
Interactions'' is available from CRAN. The description of this package
is as follows"

"This R package is used in two situations. The first is to predict the
next outcome based on the previous states of a discrete sequence. The
second is to classify a discrete response based on a number of
discreate covariates. In both situations, we use Bayesian logistic
regression models that consider the high-order interactions. The time
arising from using high-order interactions is reduced greatly by our
compression technique that represents a group of original parameters
as a single one in MCMC step. In this version, we use log-normal prior
for the hyperparameters. When it is used for the second situation ---
classification, we consider the full set of interaction patterns up to
a specified order."

The website of this package is

http://fisher.utstat.toronto.edu/~longhai/software/BPHO/release.html

-- 

Longhai Li, PhD

Assistant Professor
Department of Mathematics and  Statistics
University of Saskatchewan

Homepage: http://math.usask.ca/~longhai



From adrian at maths.uwa.edu.au  Tue Feb 26 08:10:19 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Tue, 26 Feb 2008 16:10:19 +0900 (WST)
Subject: [R-pkgs] Course on analysing spatial point patterns
In-Reply-To: <mailman.11.1203937203.11666.r-sig-geo@stat.math.ethz.ch>
References: <mailman.11.1203937203.11666.r-sig-geo@stat.math.ethz.ch>
Message-ID: <50266.130.95.98.17.1204009819.squirrel@130.95.98.17>


A full set of course notes on
          'Analysing spatial point patterns in R'
is now available at
     <http://www.csiro.au/resources/pf16h.html>

The course is based on the package 'spatstat'. It includes a brief
introduction to R, a detailed introduction to the 'spatstat' package, and
a discussion of statistical methodology.

Adrian Baddeley



From bigbear at iastate.edu  Thu Feb 28 18:49:06 2008
From: bigbear at iastate.edu (Barret Schloerke)
Date: Thu, 28 Feb 2008 11:49:06 -0600
Subject: [R-pkgs] New Package: geozoo. High-Dimensional Geometric Objects
Message-ID: <4e2dfc530802280949j7f575aadr714a3e72464339ca@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20080228/77e7aba5/attachment-0001.pl>

From david.kraus at matfyz.cz  Thu Feb 28 19:02:16 2008
From: david.kraus at matfyz.cz (David Kraus)
Date: Thu, 28 Feb 2008 19:02:16 +0100
Subject: [R-pkgs] surv2sample 0.1-2
Message-ID: <op.t68xp212d6fnbv@dk.kolej.mff.cuni.cz>

Dear useRs,

There is a new version 0.1-2 of the package surv2sample available on CRAN.  
Users of the previous versions should update because a bug in the function  
cif2.ks has been fixed.

General information about the package:

surv2sample provides various two-sample tests for right-censored survival  
data. Three main areas and corresponding methods are:

* comparison of two survival distributions
   - surv2.logrank: weighted logrank tests and their combinations (max, sum)
   - surv2.neyman: Neyman's smooth test and its data-driven version
   - surv2.ks: Kolmogorov?Smirnov, Cram?r?von Mises and Anderson?Darling  
test

* comparison of two cumulative incidence functions for competing risks data
   - cif: estimation and plotting of cumulative incidence functions
   - cif2.logrank: logrank-type test for subdistribution hazards
   - cif2.neyman: Neyman's smooth test and its data-driven version
   - cif2.ks: Kolmogorov?Smirnov test
   - cif2.int: integrated-difference test

* goodness of fit tests of the proportional rate assumption (proportional  
hazards or proportional odds functions in two samples)
   - proprate2: estimation based on the simplified partial likelihood
   - proprate2.ks: Kolmogorov?Smirnov test
   - proprate2.neyman: Neyman's smooth test and its data-driven version
   - proprate2.gs: Gill?Schumacher type test

See http://www.davidkraus.net/surv2sample/ for details and references.

Best regards,

-- 
David Kraus

Institute of Information Theory and Automation
Pod Vodarenskou vezi 4
CZ-18208 Prague 8
Czechia

david.kraus at matfyz.cz
http://www.davidkraus.net/



From HDoran at air.org  Fri Feb 29 15:24:42 2008
From: HDoran at air.org (Doran, Harold)
Date: Fri, 29 Feb 2008 09:24:42 -0500
Subject: [R-pkgs] MiscPsycho 1.1 revised posted
Message-ID: <2323A6D37908A847A7C32F1E3662C80E015368B4@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20080229/23c44c44/attachment-0001.pl>

From arne.henningsen at googlemail.com  Fri Mar  7 11:45:55 2008
From: arne.henningsen at googlemail.com (Arne Henningsen)
Date: Fri, 7 Mar 2008 11:45:55 +0100
Subject: [R-pkgs] Packages micEcon, sampleSelection, and maxLik
Message-ID: <200803071145.55715.arne.henningsen@googlemail.com>

Dear R Users:

We have splitted up the micEcon package into three packages:

a) Package "maxLik" provides tools for maximum likelihood estimations 
(see http://www.maxLik.org).

b) Package "sampleSelection" provides tools for estimating Heckman-type sample 
selection/generalized tobit models (see http://www.sampleSelection.org).

c) Package "micEcon" contains the remainder, i.e. mainly tools for 
microeconomic demand and firm models, e.g. estimating the "Almost Ideal 
Demand System" or the "Symmetric Normalized Quadratic" / "Symmetric 
Generalized McFadden" profit function (see http://www.micEcon.org).

All these packages are available for download from CRAN and from their 
websites (see above).

Any comments and suggestions on these packages are welcome!
Ott & Arne

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From Peter.Rossi at chicagogsb.edu  Fri Mar  7 20:41:51 2008
From: Peter.Rossi at chicagogsb.edu (Rossi, Peter E.)
Date: Fri, 07 Mar 2008 13:41:51 -0600
Subject: [R-pkgs] bayesm version 2.2-0
Message-ID: <FC7768358736E54AB330E0B99FFB5E1F566F04@GSBHEX2V.gsb.uchicago.edu>

bayesm version 2.2-0 is now available on CRAN.

Major changes include:

1. general density estimation using a Dirichlet Process Prior and a
normal base
2. linear instrumental variable models with unknown error distributions
   (the Bayesian analogue of IV methods).  Achieved via DP priors.

peter r

................................
 Peter E. Rossi
 Joseph T. and Bernice S. Lewis Professor of Marketing and Statistics
 Director, Kilts Center for Marketing
 Editor, Quantitative Marketing and Economics
 Rm 353, Graduate School of Business, U of Chicago
 5807 S. Woodlawn Ave, Chicago IL 60637
 Tel: (773) 702-7513   |   Fax: (773) 834-2081 
 WWW: http://ChicagoGsb.edu/fac/peter.rossi
 SSRN: http://ssrn.com/author=22862



From adinno at post.harvard.edu  Sat Mar  8 00:27:29 2008
From: adinno at post.harvard.edu (adinno at post.harvard.edu)
Date: Fri, 7 Mar 2008 15:27:29 -0800 (PST)
Subject: [R-pkgs] A new version of paran is available
In-Reply-To: <Pine.LNX.4.64.0803071224170.12743@pathos.globalovermind.com>
References: <Pine.LNX.4.64.0803071224170.12743@pathos.globalovermind.com>
Message-ID: <Pine.LNX.4.64.0803071525480.18037@pathos.globalovermind.com>



Horn's parallel analysis method of deciding how many factors to retain has 
been implemented in R in the paran package. This update to paran adds an 
option to produce a graph of the analysis along the lines of what Horn 
presented in his seminal 1965 paper. It also makes a few minor improvements 
to the formatting of the program's output.

Alexis Dinno



From kate at few.vu.nl  Thu Mar 13 16:23:45 2008
From: kate at few.vu.nl (Katharine Mullen)
Date: Thu, 13 Mar 2008 16:23:45 +0100 (CET)
Subject: [R-pkgs] new version of minpack.lm
Message-ID: <Pine.GSO.4.56.0803131616540.29333@laurel.few.vu.nl>

The package minpack.lm allows nonlinear regression problems to be
addressed with a modification of the Levenberg-Marquardt algorithm based
on the implementation of 'lmder' and 'lmdif' in MINPACK. Version 1.0-8 of
the package is now available on CRAN.

Changes in version 1.0-8 include:

    o possibility to obtain standard error estimates on the parameters
      via new methods for the generic functions 'summary' and 'vcov'

    o possibility to extract other information via new methods for the
      generic functions 'coef', 'deviance', 'df.residual', 'print',
      and 'residuals'

    o the argument 'control' of 'nls.lm' now defaults to
      'nls.lm.control()'; 'nls.control.lm' allows a maximum number of
      iterations to be specified; when the element 'nprint' of the
      'control' argument of a call to 'nls.lm' is an integer greater
      than 0, the residual sum of squares is now included in the
      information printed every 'nprint' iterations

`   o the list returned by 'nls.lm' includes elements 'niter' and
      'deviance' that represent the number of iterations performed and
      the residual sum of squares, respectively

side-note on Levenberg-Marquardt (LM) versus Gauss-Newton (GN):
There was some discussion
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/108758.html) on Rhelp
regarding whether one comes across real-world problems in which LM
performs better than GN.  I have been seeing such problems recently in
some applications where GN as implemented in 'nls' reduces the step to a
very small value, resulting in little change in the residual sum of
squares from the starting values, whereas both NL2SOL applied via 'nls'
called with 'algorithm="port"' or LM as implemented in
'minpack.lm::nls.lm' significantly reduce the RSS.  The implementation of
NL2SOL is slower by a significant factor on these problems as compared to
either the GN or LM implementations, making use of 'minpack.lm::nls.lm'
attractive.  Note that these problems may be considered pathological;
there are issues with near collinearity of columns of the Jacobian and
with the assumption that the residuals are Gaussian.

Kate Mullen
Timur Elzhov



From jeremy.stephens at Vanderbilt.Edu  Tue Mar 25 16:33:19 2008
From: jeremy.stephens at Vanderbilt.Edu (Jeremy Stephens)
Date: Tue, 25 Mar 2008 10:33:19 -0500
Subject: [R-pkgs] New package: yaml 1.0 released to CRAN
Message-ID: <200803251033.19872.jeremy.stephens@vanderbilt.edu>

Hi all,

I've released a new package to CRAN called 'yaml'.  It allows R to 
parse YAML documents (http://yaml.org) into R objects, and there are 
a few methods to convert R objects into YAML.  The package uses the 
Syck YAML parser (http://whytheluckystiff.net/syck/), the same parser 
that Ruby and other languages use to parse YAML.

For more information, please visit:
http://biostat.mc.vanderbilt.edu/YamlR

Thanks!
Jeremy
-- 
Jeremy Stephens
Computer Systems Analyst I
Department of Biostatistics
Vanderbilt University



From kjbeath at kagi.com  Tue Mar 25 05:09:30 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Tue, 25 Mar 2008 15:09:30 +1100
Subject: [R-pkgs] new package 'randomLCA'
Message-ID: <640EC882-0095-4A7E-94F6-67DE7333E639@kagi.com>

A new package 'randomLCA' is available on CRAN.

Its main purpose is to fit latent class models with random effects,  
such as those used in diagnostic testing.  This methodology can also  
be applied in other areas. It also fits standard latent class and will  
plot.

Ken



From longhai at math.usask.ca  Wed Mar 26 16:41:14 2008
From: longhai at math.usask.ca (Longhai Li)
Date: Wed, 26 Mar 2008 09:41:14 -0600
Subject: [R-pkgs] Naive Gibbs Sampling with Metropolis Steps (pkg: gibbs.met)
Message-ID: <90c54480803260841h2c70b846he588805b60d034cd@mail.gmail.com>

Hi R Users:

This package provides two generic functions for performing Markov
chain sampling in a naive way for a user-defined target distribution,
which involves only continuous variables. The function "gibbs_met"
performs Gibbs sampling with each 1-dimensional distribution sampled
with Metropolis update using Gaussian proposal distribution centered
at the previous state. The function "met_gaussian" updates the whole
state with Metropolis method using independent Gaussian proposal
distribution centered at the previous state. The sampling is carried
out without considering any special tricks for improving efficiency.
This package is aimed at only routine applications in
moderate-dimensional problems.

The website for this software is

        http://math.usask.ca/~longhai/software/gibbs.met/release.html

-- 

Longhai Li, PhD

Assistant Professor
Department of Mathematics and Statistics
University of Saskatchewan

Homepage: http://math.usask.ca/~longhai



From M.Stevenson at massey.ac.nz  Wed Mar 26 00:34:00 2008
From: M.Stevenson at massey.ac.nz (Mark Stevenson)
Date: Wed, 26 Mar 2008 12:34:00 +1300
Subject: [R-pkgs] New package: epiR
Message-ID: <000001c88ed0$b41dc210$b5ac7b82@massey.ac.nz>

A new package 'epiR' is available on CRAN. Package description as follows:

Package: epiR
Version: 0.9-3
Date: 2008-03-24
Title: Functions for analysing epidemiological data
Author: Mark Stevenson <M.Stevenson at massey.ac.nz> with contributions 
	from Telmo Nunes, Javier Sanchez, and Ron Thornton.
Maintainer: Mark Stevenson <M.Stevenson at massey.ac.nz>
Description: A package for analysing epidemiological data. Contains
functions
	for directly and indirectly adjusting measures of disease frequency,
	quantifying measures of association on the basis of single or
multiple
	strata of count data presented in a contingency table, and computing

	confidence intervals around incidence risk and incidence rate
estimates.
	Miscellaneous functions for use in meta-analysis, diagnostic test 
	interpretation, and sample size calculations.
Depends: R (>= 2.0.0)
License: GPL (>= 2)
URL: http://epicentre.massey.ac.nz

Regards,

Mark S

************************************************* 
Mark Stevenson 
Associate Professor, Veterinary Epidemiology 
IVABS, Massey University 
Private Bag 11-222 
Palmerston North New Zealand 
Ph: + 64 (06) 350 5915 
Fx: + 64 (06) 350 5716 
M.Stevenson at massey.ac.nz



From Greg.Snow at imail.org  Wed Mar 26 17:55:00 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Wed, 26 Mar 2008 10:55:00 -0600
Subject: [R-pkgs] Update of TeachingDemos package
Message-ID: <07E228A5BE53C24CAD490193A7381BBBFC3AFF@LP-EXCHVS07.CO.IHC.COM>

This is to announce that versio 2.0 of the TeachingDemos package is now
on CRAN (and hopefully soon to a mirror near you).

This is a major upgrade of the package, some of the improvements
include:

The package now uses an NAMESPACE so it is easier to load just the parts
that you need.

Some of the GUI demonstrations now use tkrplot so that the graph is in
the same window as the controls (there are still 'old' versions of these
functions available if you want the old functionality).  The rest of the
GUI demos will be updated to use tkrplot as well, and after R2.7 comes
out they all will be upgraded to use the themed widgets to give a more
uniform look with your OS.

Many of the examples sections of the help pages have replaced
"\dontrun{" with "if(interactive()){" so that they will be run by the
"example" function, but still not block in the automatic checking.  I
recommend running "example" with the argument "ask=FALSE", otherwise you
will need to hit enter 2-4 times each time a diolog pops up and every
time you update something in the dialog.

There are several new functions including:

tkexamp, a tool for creating interactive Tk based examples of what
options to functions do (mainly for plots, but one example shows a
non-plotting function).

dynIdentify and TkIdentify, tools that create a scatterplot with labels,
then allow you to drag the labels with the mouse to better locations.

col2grey, a tool to convert your colors to greyscale so you can get a
general feel of how they would look when printed non-color, or copied,
etc.

SensSpec.demo, a demonstration of how to compute positive and negative
predictive value from sensitivity, specificity, and prevelance using a
virtual population rather than Bayes Theorem and algebra.

TkApprox and TkSpline, GUI wrappers to the approxfun and splinfun
functions that graph your data, the predictions, and allow you to drag
reference lines on the plot to show the predicted values, differences,
and derivatives.

tkprogress, a utility to create and update a progress bar to show how
far through a loop or other iterative process you are.

A set of functions (see txtStart and etxtStart) that will create a plain
text transcript of your R session including both commands and output
(think glorified sink + history).  The 'etxt' versions add markup so
that the text file can be processed by the enscript program to create a
postscript file with some syntax coloring and inclusion of graphs.  The
postscript file can then be converted to pdf or other formats.


Hope others find this helpful,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
(801) 408-8111
 



From maechler at stat.math.ethz.ch  Fri Mar 28 15:18:37 2008
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 28 Mar 2008 15:18:37 +0100
Subject: [R-pkgs] "The Matrix" is approaching version 1.0-0
Message-ID: <18412.65085.549853.54741@stat.math.ethz.ch>


A new version of "the Matrix" 
(well, actually the R package named "Matrix") has become
available on the CRAN mirrors.  

As some of you have noticed, the version numbers (current is version
0.999375-8) are converging to one, and we feel that we have solved
enough of the many (mostly small) problems to announce that release
1.0-0 is imminent.

In the DESCRIPTION of the package we say
--------------------------------------------------------------
Title: A Matrix package for R
Author: Douglas Bates <....> and Martin Maechler <....>
Maintainer: Doug and Martin <Matrix-authors at R-project.org>
Description: Classes and methods for dense and sparse matrices and
   operations on them using Lapack, CSparse and CHOLMOD
--------------------------------------------------------------

The Matrix package provides efficient methods for several formal
(i.e. S4) classes of matrices where each of the actual classes are
some combination of the following three categories

1) dense or sparse
2) symmmetric, triangular, diagonal or "general" (or "permutation")
3) numeric ("d"ouble), logical (TRUE/FALSE/NA) or "patter[n]" (0/1) matrices

Interfaces to many efficient algorithms from Lapack (for "dense") and from
CHOLMOD / Csparse (for "sparse") are all implemented via method definitions
for the customary linear algebra functions
  %*%, t(), crossprod(), tcrossprod(), chol(), qr(), solve(),
  colSums(), rowSums(), kronecker(), determinant(), ...
and for various formal groups of generics, such as
  "Math" (sin,exp,gamma,..)  "Arith" (+,-,*,...),
  "Logic" (>, <=, ..),  "Summary" (sum, max, ...)  etc;
  is.na()

Furthermore, 'indexing' : "A[...]" and "A[..] <- value" of
all(!) kinds of S/R indexing and some new generic functions such as

 lu()     {LU decomposition}
 Schur(), BunchKaufman(),
 norm(), rcond()        {Matrix norms and condition numbers}
 expm()   {Matrix exponential},
 band(), triu(), tril()  {extract band-diagonal or triangular sub-matrices}
 symmpart(), skewpart()   { (x + t(x))/2  and  (x - t(x)) / 2 }

are provided. Further, an extension to the xtabs function
  xtabs(*, sparse=TRUE)
for large sparse, two-way contingency tables
and coercion of one *factor* (possibly crossed with one <numeric>)
to the corresponding (potentially huge) sparse model matrix for sparse
least squares and related computations.

Further to the above, "Matrix" objects are also constructed by
Matrix(), spMatrix(), bdiag() {block-diagonal}, Diagonal() and many
as(., "....Matrix") possibilities.

The Matrix package also provides a C level API (header files of
exported C functions providing low-level functionality) to many of its
internal algorithms that other packages can link to.  Currently, the
'lme4' package makes heavy use of these exported C functions.

---------------------------------------------------------------------------

One of the things we plan to improve considerably is the documentation
for the package.  Currently there are four vignettes but all but the

   Comparisons: Comparisons of Least Squares calculation speeds

are really not complete in one way or another.

---------------------------------------------------------------------------

We would appreciate current users of the Matrix package (and also
generally interested useRs) exploring the package's capabilities and
giving us feedback about problems that they might encounter or missing
features, inefficiencies and maybe even "infelicities" (a.k.a. bugs).
Fixing problems before the release of the 1.0-0 version of "The Matrix",
rather than after its release, is our preferred approach.

Douglas Bates and Martin Maechler
Matrix-authors <at> r-project <.> org



From spencer.graves at pdf.com  Sun Mar 30 00:50:16 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 29 Mar 2008 16:50:16 -0700
Subject: [R-pkgs] FinTS_0.3-1
Message-ID: <47EED5B8.9040004@pdf.com>

Hi, All:

	  FinTS version 0.3-1 is now available on CRAN.  This version
adds a function 'apca' for "Asymptotic Principal Components Analysis", 
as discussed in Tsay (2005) Analysis of Financial Time Series, 2nd ed. 
(Wiley, sec. 9.6), in addition to minor improvements in the partially 
complete scripts for chapters 3 and 9.

	 Spencer Graves



From h.wickham at gmail.com  Fri Apr  4 02:45:48 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 3 Apr 2008 19:45:48 -0500
Subject: [R-pkgs] ggplot2 - version 0.6
Message-ID: <f8e6ff050804031745l3b97910dm2e02bd942cd8134c@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the over 400
examples of ggplot in use.

ggplot 0.6
----------------------------------------

The two big changes in this release are improved documentation and legends:

 * all major ggplot2 components now have their own built in
documentation, so that (e.g.) ?stat_smooth or ?geom_point now give you
useful information

 * the legend code is now considerably more sophisticated and will
attempt to merge together legends for the same variable

 * also, legends are drawn based on the geoms used (instead of the
scales used, as previously) so should match the plot much better (e.g.
for geom_smooth, geom_boxplot, geom_vline, geom_abline,
geom_pointrange).

These features are new, so there are likely to be a few bugs that I
haven't discovered.  Please me know if you do find any.

Other additions and corrections

  * coord_equal: should now work correctly in all situations
  * coord_polar: add start and direction parameters, giving more
control over the layout of the polar coords
  * coord_polar: added my favourite pie chart example
  * coord_trans now deals with groups appropriately, at the cost of
decreased speed
  * geom_abline, geom_vline, geom_hline: should now behave better in a
wider variety of settings
  * geom_boxplot: deals with continuous x-axis and grouping much better
  * geom_boxplot: now has it's own legend which actually looks like a boxplot
  * geom_boxplot: reports if missing values removed
  * geom_crossbar: the middle line is now display thicker than the
other lines, controlled by the parameter fatten (thanks to Heike
Hofmann for the suggestion)
  * geom_density: fix scale adjustment bug in geom_density
  * geom_line, geom_text: all size measurements (now lines and text as
well) are measured in mm, lines/paths default to paths 0.5mm wide
  * geom_rug: new to add marginal rug plots
  * geom_smooth: added example showing how to use geom_smooth with
your own models
  * geom_smooth: fixed bug where if se=FALSE x axis always includes 0
  * geom_vline, geom_hline: yet another rewrite which should make them
more powerful and less error prone.
  * ggsave reports width and height of saved image
  * position_stack: fixed bug when data was empty
  * qplot: allow qplot to use computed aesthetics too
  * scale_continuous: tweaks to minor breaks to make appearance better
on wider range of coordinate systems
  * scale_discrete: all discrete scales now have labels argument which
you can use to override the factor levels
  * scale_discrete: now works correctly with character vectors
  * scale_size: changed default range to [0.5, 3] to better reflect
new sizing decisions
  * scale_size: legends resize to avoid overlaps
  * scale_x_continuous, scale_y_continuous: new convenience functions
xlim and ylim (and zlim) that make it even easier to adjust the limits
of the x, y, and z axes
  * stat_bin, geom_area: fixed bug in combination of stat_bin and
geom_area that made it difficult to draw frequency polygons
  * stat_bin: fixed bug which resulted in increased counts when the x
axis was a categorical variable with a single level (thanks to Bob
Muenchen for pointing this out!)
  * stat_bin: no longer incorrectly warns that binwidth is unspecified
when breaks are set
  * stat_bin: now takes origin argument to manually specify origin of
first bin (default is round_any(min(range), bin_width, floor))
  * stat_boxplot, stat_contour, stat_density2d, stat_qq, stat_density:
na.rm parameter added to the following statistics (thanks to Leena
Choi for suggesting this)
  * stat_function: new, makes it easy to superimpose a function on the plot
  * stat_qq: axes flipped to agree with base R
  * stat_qq: now uses sample aesthetic to select variable for summary
  * stat_quantile: updated to work with latest version of quantreg
  * stat_spoke: new, to make it possible to use geom_segment
parameterised by angle and radius (thanks to Jiho for the suggestion)
  * stat_summary: better documentation
  * stat_summary: convenient auto wrapping of simple summary functions

Miscellaneous changes:

  * it's now easy to change the default scales (and their arguments)
with the set_default_scale function, see ?set_default_scale for more
details (thanks to Bob Muenchen for the suggestion)
  * new order aesthetic which controls the order in which elements are plotted
  * min and max are now scaled the same way as y
  * functions are silently dropped (e.g. aes(colour=col))
  * scales do not try and map variables that don't exist (fixes some
rather obscure bugs)
  * aes(mpg, wt) is now equivalent to aes(x = mpg, y = wt)


See CHANGELOG for changes in previous versions

Regards,

Hadley

-- 
http://had.co.nz/



From rpeng at jhsph.edu  Fri Apr  4 21:47:52 2008
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 04 Apr 2008 15:47:52 -0400
Subject: [R-pkgs] cacher v0.1-2
Message-ID: <47F685E8.9070209@jhsph.edu>

The 'cacher' package contains a set of routines for caching statistical 
analyses.  The idea is that an analysis stored in a file (say, 'foo.R') is run 
and the results of the evaluated expressions are cached in a database.  These 
cached results can subsequently be packaged up and distributed over the interweb.

I've just uploaded to CRAN version 0.1-2 of the 'cacher' package.

There is a brief document describing the package available at

http://www.biostat.jhsph.edu/~rpeng/papers/archive/cacher.pdf

Some sample cached analyses can be found at

http://penguin.biostat.jhsph.edu/cpkg.html

For example, if you wanted to download the analysis associated with the 
'sample.R' file, you could run

library(cacher)
clonecache(id = "44bf", all.files = TRUE)

Using the tools in the 'cacher' package you could then explore the data and code 
that make up this analysis.

This package is by no means 'complete' and is still evolving.  I would greatly 
appreciate any feedback or suggestions on the design if you end up using the 
package for any reason.

-roger
-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/



From mrizzo at bgnet.bgsu.edu  Wed Apr  9 03:04:01 2008
From: mrizzo at bgnet.bgsu.edu (Maria Rizzo)
Date: Tue, 08 Apr 2008 21:04:01 -0400
Subject: [R-pkgs] energy 1.1-0 with dcov
Message-ID: <6.2.0.14.2.20080407182457.020a5180@mail.bex.net>

Dear R-users,

An updated version of the energy package, energy 1.1-0, is now available on 
CRAN.

This version has merged the dcov package (previously available from my 
personal web page) into energy.

New functions include:

dcov (distance covariance)
dcor (distance correlation)
DCOR (four statistics)
dcov.test (distance covariance test of multivariate independence)
indep.test (choice of nonparametric energy tests of multivariate independence)

These functions implement the new methods introduced in our recent article:

G. J. Szekely, M. L. Rizzo and N. K. Bakirov (2007) Measuring and Testing 
Independence by Correlation of Distances, Annals of Statistics, Vol. 35 No. 
6, pp. 2769-2794.

Distance correlation R is a scalar statistic for measuring and testing 
independence of random vectors. It satisfies 0<=R<=1 and R=0 only if 
independence holds. Distance covariance V determines a statistically 
consistent test of independence.

The distance covariance test is theoretically related to, but different 
from the original test based on coefficient I_n implemented in indep.etest. 
The new dcov.test is faster by a factor O(n) than indep.etest.

With the introduction of a second and faster test, we provide a new 
function indep.test with a choice of methods to obtain either test. The 
original indep.etest is now deprecated.

Reprints of the article are available upon request.

Comments and suggestions are always welcome.

   Maria Rizzo and Gabor Szekely



From landronimirc at gmail.com  Wed Apr  9 15:27:36 2008
From: landronimirc at gmail.com (Liviu Andronic)
Date: Wed, 9 Apr 2008 15:27:36 +0200
Subject: [R-pkgs] RcmdrPlugin.Export_0.2-0 released
In-Reply-To: <68b1e2610804090034k6841c182u44ce39ee1dbc9f62@mail.gmail.com>
References: <68b1e2610804090034k6841c182u44ce39ee1dbc9f62@mail.gmail.com>
Message-ID: <68b1e2610804090627j24f3436i3e2d232898f4bcb2@mail.gmail.com>

Dear R users,

I am pleased to announce the release of the Export plug-in for Rcmdr.
At the moment, it is simply a graphical user interface to xtable().
Several developments are, however, planned. It is worth to note that
the Manual offers several pointers on using Sweave together with LyX,
and from this perspective the plugin is an attempt to simplify
creating (LaTeX) reports by using graphical interfaces only.

In the near future, only exporting to LaTeX and HTML will be
supported. Exporting to other formats (say, RTF or ODF) could be
integrated provided that someone is willing to contribute the code
(say, personal scripts that were never published), or point to a
sensible way of automating the process. Any such contributions are
heartily welcome.

Comments and suggestions are, of course, always welcome.
Liviu



From erich.neuwirth at univie.ac.at  Thu Apr 17 14:25:52 2008
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 17 Apr 2008 14:25:52 +0200
Subject: [R-pkgs] RExcelInstaller
Message-ID: <480741D0.2040504@univie.ac.at>

RExcelInstaller_2.0-15

installs RExcel, an add-in for Excel, which connects R and Excel.

RExcel allows to transfer data between R and Excel,
writing VBA macros using R as a library for Excel,
and calling R functions as worksheet function in Excel.
RExcel integrates nicely with R Commander (Rcmdr),
turning R Commander's menus into Excel menus.
It comes with a comprehensive set of example worksheet
illustrating different usage scenarios.

This R package installs the Excel add-in for Excel versions
from 2000 to 2007. It only works on MS Windows (XP and Vista)

-- 
Erich Neuwirth, University of Vienna
Faculty of Computer Science
Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-39464 Fax: +43-1-4277-39459



From friendly at yorku.ca  Fri Apr 18 15:43:56 2008
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 18 Apr 2008 09:43:56 -0400
Subject: [R-pkgs] new candisc package on CRAN
Message-ID: <4808A59C.8030406@yorku.ca>

I'm happy to announce the candisc package, v 0.5-9, now on CRAN.

Generalized Canonical Discriminant Analysis

Description
This package includes functions for computing and visualizing 
generalized canonical discriminant analyses for a multivariate linear 
model. They are designed to provide low-rank visualizations of terms in 
a mlm via the plot method and the heplots package.

The methods are described in

Friendly, M. (2007). HE plots for Multivariate General Linear Models. 
Journal of Computational and Graphical Statistics, 16 (2), 421-444. 
http://www.math.yorku.ca/SCS/Papers/heplots.pdf

Friendly, M. (2006). Data Ellipses, HE Plots and Reduced-Rank Displays 
for Multivariate Linear Models: SAS Software and Examples. Journal of 
Statistical Software, 17(6), 1-42. http://www.jstatsoft.org/v17/i06/


-Michael


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From jan.graffelman at upc.edu  Mon Apr 21 12:00:30 2008
From: jan.graffelman at upc.edu (Jan Graffelman)
Date: Mon, 21 Apr 2008 12:00:30 +0200
Subject: [R-pkgs] Upload HardyWeinberg package (1.1)
Message-ID: <480C65BE.6000103@upc.edu>

Hi all,

I've uploaded to CRAN a new version of the HardyWeinberg package. This
package has routines for performing graphical significance tests (based 
on the ternary plot) for Hardy-Weinberg equilibrium of bi-allelic marker 
  data.

Jan.

-- 
------------------------------------------------------------------------
|Jan Graffelman                          |tel:   +34-93-4011739        |
|Dpt. of Statistics & Operations Research|fax:   +34-93-4016575        |
|Universitat Politecnica de Catalunya    |email: jan.graffelman at upc.edu|
|Av. Diagonal 647, 6th floor             |www:                         |
|08028 Barcelona, Spain                  |  http://www-eio.upc.es/~jan/|



From r.hankin at noc.soton.ac.uk  Wed Apr 23 12:11:09 2008
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Wed, 23 Apr 2008 11:11:09 +0100
Subject: [R-pkgs] new package multipol
Message-ID: <C02F20DD-A630-4E81-9FF8-F49EEEDF0B55@noc.soton.ac.uk>

Hello List

please find a new package, multipol, recently uploaded to CRAN.

This package generalizes the polynom package (which handles univariate
polynomials) to the multivariate case.   A  short article discussing the
package will appear in the next issue of Rnews,  Insha'Allah


enjoy



--
Robin Hankin
Uncertainty Analyst and Neutral Theorist,
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From h.wickham at gmail.com  Fri May  2 20:57:33 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 2 May 2008 13:57:33 -0500
Subject: [R-pkgs] New package: profr 0.1 - an alternative display for
	profiling information
Message-ID: <f8e6ff050805021157h7aaa3281q66b950000599e612@mail.gmail.com>

profr 0.1 ----------------------------

profr provides an alternative data structure and display for profiling
data.  It still uses Rprof() to collect the data, but outputs a
data.frame which should be easier to manipulate.  It also implements a
novel visualisation which allows you to see the length of each call,
as well as the context in which it was called.

To get started, try:

install.packages("profr")
library(profr)
p <- profr(my.slow.function())
plot(p)

Two built in examples are:

plot(nesting_prof)
plot(reshape_prof)

(and the second has helped me to considerably speed up (5-20x) the
development version of reshape)

Regards,

Hadley

PS.  If you'd like to contribute to the development of profr, the
source code is available from http://github.com/hadley/profr.

-- 
http://had.co.nz/



From ggrothendieck at gmail.com  Mon May  5 13:14:10 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 5 May 2008 07:14:10 -0400
Subject: [R-pkgs] batchfiles 0-4.1
Message-ID: <971536df0805050414v4b59aafdqd7342a4e13e47593@mail.gmail.com>

batchfiles 0.4-1 consists of a set of Windows Vista .bat and
other scripts used as front ends to R CMD ... and for other
purposes.

Whereas Version 0.4-0 of batchfiles eliminated the need to
set any paths when running R, version 0.4-1 now eliminates
the need to set any paths when building and installing R
packages.  It does this by using the registry to find R and
rtools and uses a heuristic to find MiKTeX (since MiKTeX
does not have a reliable registry key) and temporarily sets
the path to include rtools and MiKTeX.

Version 0.4-1 also includes an rtools.bat utility which will
set the paths for that session that would have otherwise had
to be set in case you want to use rtools and MiKTeX with
other programs -- this is not needed if you only want to use
R or if you only want to build and install R packages.

Also there is a new el utility (el.js) which runs the
command given as its argument in elevated mode.  e.g.
    el cmd
spawns a cmd session which is elevated.

The scripts Rcmd.bat, R.bat, Rterm.bat, Rscript.bat,
#Rscript.bat, Rgui.bat, RguiStart.bat, Rjgr.bat are actually
all the same script which query the name by which it was
called to determine the appropriate action.  These scripts
are each self containd single file scripts which do not
depend on each other or on other software.  To install any
of them just copy it to any place on your PATH and it can be
immediately used.  Uninstall by deleting it.  Atlhough they
query the registry they do not set the registry (except for
Rversions.hta which calls RSetReg.exe, a program that comes
bundled with R, that in turn sets the registry.)

Version 0.4-0 of these utilities and later have only been
tested on Vista.  Version 0.3-2 and earlier have only been
tested on XP.

More information is available on the home page:
http://batchfiles.googlecode.com



From berthier at supagro.inra.fr  Fri May  9 09:03:01 2008
From: berthier at supagro.inra.fr (Karine Berthier)
Date: Fri, 9 May 2008 07:03:01 +0000
Subject: [R-pkgs] ncf package version 1.0-4
Message-ID: <BAY103-W15C63339C51BF9DCA71A149DD30@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20080509/8a51d676/attachment-0001.pl>

From Achim.Zeileis at R-project.org  Sat May 10 09:58:37 2008
From: Achim.Zeileis at R-project.org (Achim Zeileis)
Date: Sat, 10 May 2008 09:58:37 +0200 (CEST)
Subject: [R-pkgs] AER: Applied Econometrics with R
Message-ID: <Pine.LNX.4.64.0805100957400.6755@paninaro.stat-math.wu-wien.ac.at>

The package AER accompanying the forthcoming book "Applied
Econometrics with R" by Christian Kleiber and me in the
Springer useR! series has (finally!) been released to CRAN:
   http://CRAN.R-project.org/package=AER

It contains some new R functionality
   o tobit regression convenience interface (to "survival")
   o instrumental variables regression (two-stage least squares)
   o (over-) dispersion test (via auxiliary regression)
but the main feature are ~100 data sets taken from popular
econometrics text books and the data archives of JAE (Journal
of Applied Econometrics) and JBES (Journal of Business and
Economic Statistics). Extensive examples are provided with
the data sets, reproducing many of the analyses in the
books/papers they were taken from. In particular, all data
sets from the following books with many of the associated
examples are provided:
   o "Econometrics" (Baltagi, 2002)
   o "Econometric Analysis" (Greene, 2003)
   o "Introduction to Econometrics" (Stock & Watson, 2007)

Until the book becomes available in autumn 2008, we will add
vignettes to the package reproducing the examples from our
book.

Best wishes,
Z



From tabelow at wias-berlin.de  Mon May 19 15:25:51 2008
From: tabelow at wias-berlin.de (Karsten Tabelow)
Date: Mon, 19 May 2008 15:25:51 +0200
Subject: [R-pkgs] Updated package adimpro
Message-ID: <48317FDF.8020809@wias-berlin.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

This package implements tools for manipulationg digital images and the
Propagation Separation approach for smoothing digital images.

Version 0.6.1 is a major update with many new features:

Input/Output:

- - we now keep exif information as comment of an image
~  this information is evaluated to recover the original adimpro-object
~  used to produce the image file, see demo(io).
~  This may be changed to using rpm-profiles.
- - new function write.raw provides a possibility to store
~  RAW sensor data as a greyscale png-image
~  these images are recognized by read.raw, see demo(raw).
- - write.image now keeps color space by default
- - read.image/write.image now also handles xyz, yuv, yiq and
~  hsi color spaces correctly
- - the location of ImageMagick is now automatically determined
~  using function Sys.which and set as an environment variable
~  ImageMagick when the package is loaded (This requires R >=2.6.0).
~  The argument convert.path in read.image and write.image is no
~  longer needed and has been removed.
- - make.image no longer has an argument gamma

Adaptive smoothing:

- - functions awsimage, awspimage:

- - value of ladjust      1.0 -- 1.25, different lseq
- - new arguments plateau=NULL, homogen=TRUE, earlystop=TRUE
- - new varmodel "Quadratic"
- - location kernel with choice "Plateau"
- - statistical kernel changed to Plateau with spmin=0.25
- - FORTRAN subroutine awsimg has fewer parameters
- - lseq extended (if it is to short) by last element rather than by 1
- - FORTRAN subroutine awsvimage has differing parameters
- - FORTRAN subroutine mawsimg has fewer parameters
- - FORTRAN subroutine awspimg has fewer parameters
- - handles lower/uppercase for some arguments

- - new function awsprop for testing propagation condition

- - new function awsaniso for anisotropic structural adaptive smoothing

Color space conversions:

- - increased and changed functionality of adjust.image
- - rgb2xxx  also accepts colorspaces xyz , yuv and yiq
- - xxx2rgb - functions now allow to specify RGB-color space (default
~  "Adobe")
- - new function cam2rgb for conversion of camera color spaces to RGB
- - new funcions rgb2xyzmat and xyz2rgbmat
- - function gamma.correction  now uses gammatype instead of arguments ga
~  and bp
- - new function for inverse gamma correction
- - new function whitepoint, wpofT, changewhitepoint  for white point
~  definitions and manipulation
- - whitebalance no uses whitepoint and color temperature
- - adjust.image  now allows to set gammatype, cspace, whitep, color
~  temperature blackpoint and exposure
- - new function demosaic.raw to convert RAW sensor data to RGB


Image manipulations and diagnostics:

- - function edges has a new argument abs
- - functions shrink.image, rotate.image, clip.image also accept "RAW"
- - rotate.image has new argument compress
- - new function extract.info for extracting EXIF-Information

Bug fixes: e.g. in make.image, invgamma.correction (internal),
~           read.ppm(internal), read.pgm(internal),

Demos:

We added an extensive set of demos.
demo(adimpro) just runs all demos sequentially. Especially
demo(awspimage) (local polynomial smoothing) is time consuming.




- --
Karsten Tabelow, Dr.
WIAS Berlin
Mohrenstrasse 39, 10117 Berlin, Germany

email: tabelow at wias-berlin.de
phone: +49-30-20372 564
fax  : +49-30-2044975
url  : http://www.wias-berlin.de/people/tabelow/
url  : http://www.wias-berlin.de/project-areas/stat/a3
Member of Matheon (www.matheon.de)

D08D1822
8EC1 479A ECD6 18C1 5DD7 E63E 32F1 50A9 D08D 1822

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (GNU/Linux)
Comment: Using GnuPG with SUSE - http://enigmail.mozdev.org

iD8DBQFIMX/fMvFQqdCNGCIRAjQ1AJ9BkbKNO6hQnDj2p466KxWRGOQ9EgCZAUfX
djO1KxHt9uogG9fNDSLtKUI=
=pbts
-----END PGP SIGNATURE-----



From tabelow at wias-berlin.de  Mon May 19 15:25:49 2008
From: tabelow at wias-berlin.de (Karsten Tabelow)
Date: Mon, 19 May 2008 15:25:49 +0200
Subject: [R-pkgs] Updated package fmri
Message-ID: <48317FDD.7030604@wias-berlin.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

fmri is a contributed package for R, that implements functions for
analyzing single-subject fmri data with structural adaptive smoothing
methods.

New in version 1.2-6
- --------------------

~  - new function cutroi()
~  - plot.fmridata() is now able to produce anatomical overlay for pvalue
~    data for AFNI, and NIFTI data
~  - read.AFNI() should be able to interpret filenames more flexible:
~    with, without extensions, with dots in name.





- --
Karsten Tabelow, Dr.
WIAS Berlin
Mohrenstrasse 39, 10117 Berlin, Germany

email: tabelow at wias-berlin.de
phone: +49-30-20372 564
fax  : +49-30-2044975
url  : http://www.wias-berlin.de/people/tabelow/
url  : http://www.wias-berlin.de/project-areas/stat/a3
Member of Matheon (www.matheon.de)

D08D1822
8EC1 479A ECD6 18C1 5DD7 E63E 32F1 50A9 D08D 1822

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (GNU/Linux)
Comment: Using GnuPG with SUSE - http://enigmail.mozdev.org

iD8DBQFIMX/cMvFQqdCNGCIRAgfoAJ4hxwFLSTup4Zf8NYriVvzKiKbErwCfSIXI
Vt0ggjbb7GEfCMJVhzkWeRQ=
=IHty
-----END PGP SIGNATURE-----



From tabelow at wias-berlin.de  Mon May 19 15:25:46 2008
From: tabelow at wias-berlin.de (Karsten Tabelow)
Date: Mon, 19 May 2008 15:25:46 +0200
Subject: [R-pkgs] New package dti
Message-ID: <48317FDA.2080506@wias-berlin.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

dti is a new contributed package for R, that implements functions for
smoothing Diffusion-weighted MR data with structural adaptive smoothing
methods.

Version 0.5-2 contains functions for smoothing DW data in the context of
the Diffusion Tensor Model and for visualization of Diffusion Tensor
Data and anisotropy maps derived thereof. The tensor estimation can be
done using a linearized model, or using a non-linear model. A correction
for Rician bias can be included.



- --
Karsten Tabelow, Dr.
WIAS Berlin
Mohrenstrasse 39, 10117 Berlin, Germany

email: tabelow at wias-berlin.de
phone: +49-30-20372 564
fax  : +49-30-2044975
url  : http://www.wias-berlin.de/people/tabelow/
url  : http://www.wias-berlin.de/project-areas/stat/a3
Member of Matheon (www.matheon.de)

D08D1822
8EC1 479A ECD6 18C1 5DD7 E63E 32F1 50A9 D08D 1822

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (GNU/Linux)
Comment: Using GnuPG with SUSE - http://enigmail.mozdev.org

iD8DBQFIMX/aMvFQqdCNGCIRAt3gAKCCdv9f8h030EAFpzIWL8npiJCq/wCfXWYK
IufrFV0vmO7Dcz/Rr2QzFGs=
=HWa8
-----END PGP SIGNATURE-----



From hastie at stanford.edu  Mon Jun  2 20:08:16 2008
From: hastie at stanford.edu (Trevor Hastie)
Date: Mon, 02 Jun 2008 11:08:16 -0700
Subject: [R-pkgs] New glmnet package on CRAN
Message-ID: <48443710.8090209@stanford.edu>

glmnet is a package that fits the regularization path for linear, two- 
and multi-class logistic regression
models with "elastic net" regularization (tunable mixture of L1 and L2 
penalties).
glmnet uses pathwise coordinate descent, and is very fast.

Some of the features of glmnet:

* by default it computes the path at 100 uniformly spaced (on the log 
scale) values of the regularization parameter
* glmnet appears to be faster than any of the packages that are freely 
available, in some cases by two orders of magnitude.
* recognizes and exploits sparse input matrices (ala Matrix package). 
Coefficient matrices are output in sparse matrix representation.
* penalty is (1-a)*||\beta||_2^2 +a*||beta||_1  where a is between 0 and 
1;  a=0 is the Lasso penalty, a=1 is the ridge penalty.
   For many correlated predictors, a=.95 or thereabouts improves the 
performance of the lasso.
* convenient predict, plot, print, and coef methods
* variable-wise penalty modulation allows each variable to be penalized 
by a scalable amount; if zero that variable always enters
* glmnet uses a symmetric parametrization for multinomial, with 
constraints enforced by the penalization.

Other families such as poisson might appear in later versions of glmnet.

Examples of glmnet speed trials:
 
Newsgroup data: N=11,000, p=4 Million, two class logistic. 100 values 
along lasso path.   Time = 2mins
14 Class cancer data: N=144, p=16K, 14 class multinomial, 100 values 
along lasso path. Time = 30secs

Authors: Jerome Friedman, Trevor Hastie, Rob Tibshirani.

See our paper http://www-stat.stanford.edu/~hastie/Papers/glmnet.pdf for 
implementation details,
and comparisons with other related software.

-- 
--------------------------------------------------------------------
  Trevor Hastie                                  hastie at stanford.edu
  Professor & Chair, Department of Statistics, Stanford University
  Phone: (650) 725-2231 (Statistics)	         Fax: (650) 725-8977
	 (650) 498-5233 (Biostatistics)		 Fax: (650) 725-6951
  URL: http://www-stat.stanford.edu/~hastie
  address: room 104, Department of Statistics, Sequoia Hall
	          390 Serra Mall, Stanford University, CA 94305-4065



From patrick.mair at wu-wien.ac.at  Thu Jun  5 19:04:40 2008
From: patrick.mair at wu-wien.ac.at (Patrick Mair)
Date: Thu, 05 Jun 2008 10:04:40 -0700
Subject: [R-pkgs] smacof package for multidimensional scaling
Message-ID: <48481CA8.4050704@wu-wien.ac.at>

Dear UserR's,

The smacof package (see also our PsychoR repository on 
http://r-forge.r-project.org/projects/psychor/) is uploaded on CRAN.

This package provides the following approaches of multidimensional 
scaling (MDS) based on stress minimization by means of majorization 
(smacof): - Simple smacof on symmetric dissimilarity matrices
- smacof for rectangular matrices (unfolding models)
- smacof with constraints on the configuration (linear, unique, 
diagonal, or user-specified constraints; fitting simplex or circumplex)
- 3-way smacof for individual differences (including constraints for 
idioscal, indscal, and identity)
- Sphere projections (spherical smacof, primal and dual algorithm).

Each of these approaches is implemented in a metric and nonmetric manner 
including primary, secondary, and tertiary approaches for tie handling. 
Various 2- and 3D-plots are provided and a package vignette is included.

Patrick



From s.wood at bath.ac.uk  Mon Jun  9 15:34:33 2008
From: s.wood at bath.ac.uk (Simon Wood)
Date: Mon, 9 Jun 2008 14:34:33 +0100
Subject: [R-pkgs] Fwd: mgcv 1.4 on CRAN
Message-ID: <200806091434.33328.s.wood@bath.ac.uk>

mgcv 1.4 is now on CRAN. It includes new features to allow mgcv::gam to fit
almost any (quadratically) penalized GLM, plus some extra smoother classes.

New gam features
-------------------------

*  Linear functionals of smooths can be included in the gam linear predictor,
allowing, e.g., functional generalized linear models/signal regression,
smooths of interval data, etc.

* The parametric component of a model can be quadratically penalized, giving
easy access to gam's fitting and smoothing parameter selection methods, for
any model with a penalized glm structure.

* Smooths can be linked to have the same estimated smoothing parameter.

* `by' variables (used for varying coefficient models) can now be factor
variables, to enable easy conditioning of smooths on factors.

* The default p-values for smooth terms have been substantially improved.

* see ?gam.models and ?summary.gam for further details.

New smoothers
----------------------

* Eilers and Marx style P-splines are now built in, along with a cyclic
version. See ?p.spline.

* An adaptive smoother class has been added. See ?adaptive.smooth.

* The interface for adding user defined smooths has been modified and
simplified. See ?smooth.construct.

A fuller list of changes is at
http://cran.r-project.org/web/packages/mgcv/ChangeLog

--

> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283

-------------------------------------------------------

-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283



From felix at nfrac.org  Thu Jun 19 13:15:17 2008
From: felix at nfrac.org (Felix Andrews)
Date: Thu, 19 Jun 2008 21:15:17 +1000
Subject: [R-pkgs] playwith 0.8-55
Message-ID: <94730b8a0806190415g74a5496ev58890553cb11342f@mail.gmail.com>

playwith package version 0.8-55 is now on CRAN.
It provides a GTK+ interface for interacting with R plots.

Screenshots of some examples are online at:
http://code.google.com/p/playwith/wiki/Screenshots

Changes in Version 0.8-55

  o argument `parameters`: automatically constructs
    widgets to control parameter values appearing in the call.

  o default action when dragging on the plot is zoom.
    default action on right-click is zoomout.

  o whether to start in time.mode is determined by looking at
    the data: TRUE if the x data has a 'ts' or 'zoo' class.

  o restrict zooming to x axis in time.mode
    only if a time.vector was not specified.

  o concept of the "main function" which accepts typical plot
    arguments (xlim, ylim, main, etc) -- not necessarily the
    top-level call. By default, a depth-first search is used
    to find a function that accepts `xlim` or `...`.

  o callArg() now uses standard evaluation by default, rather than
    quoting its argument. Old code will need to be changed!

  o use RGtk2 rather than gWidgets for edit.call and edit.annotations
    because gWidgets is very slow.

  o reasonable guess for data points and labels with ggplot::qplot()

  o enabled pretty ggplot2 plots (print.ggplot with pretty=TRUE)
    if using grid package version >= 2.7
    (older versions had a problem with viewports being popped).

  o code reorganisation: split tools into separate files; ESS style.


The predecessor to this package, plotAndPlayGTK, has been moved to the
CRAN archive.

-- 
Felix Andrews / ???
PhD candidate
Integrated Catchment Assessment and Management Centre
The Fenner School of Environment and Society
The Australian National University (Building 48A), ACT 0200
Beijing Bag, Locked Bag 40, Kingston ACT 2604
http://www.neurofractal.org/felix/
3358 543D AAC6 22C2 D336 80D9 360B 72DD 3E4C F5D8



From adrian at maths.uwa.edu.au  Mon Jun 23 10:13:08 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Mon, 23 Jun 2008 16:13:08 +0800 (WST)
Subject: [R-pkgs] scuba 1.2-1
Message-ID: <60291.121.221.140.172.1214208788.squirrel@121.221.140.172>


	scuba 1.2-1

	** now with added Helium **

'scuba' is a contributed R package that performs theoretical calculations
about scuba diving --- dive profiles, decompression models,
gas toxicity and so on.

New features in version 1.2-1:

	. Breathing gases may now contain Helium
          as well as Oxygen and Nitrogen.

	. Decompression models now handle breathing gases
          containing Helium.

	. Haldane (diffusion compartment) models are now
		represented by objects of a special class "hm".

	. Dive profiles (objects of class "dive") can be
		modified more easily. You can change the breathing gas,
                modify the depth and duration of a dive,
                or cut-and-paste several dive profiles.

	. Bug fix in showstates().

New functions:

	ndl	Calculates No-Decompression Limits

	trimix	Creates a gas object representing trimix
		(oxygen/nitrogen/helium mixture)

	hm	Creates a new Haldane model (diffusion compartment model
		for decompression theory).

	pickmodel
		Selects one of the standard Haldane models.

	tanklist
	tanklist<-
		Extracts or modifies the breathing gases used in a dive.

	chop.dive
		Extracts part of a dive profile.

	depths.dive<-
	times.dive<-
	durations.dive<-
		Operators for modifying a dive profile.


Adrian Baddeley, 22 june 2008



From david.ardia at unifr.ch  Mon Jun 23 10:56:55 2008
From: david.ardia at unifr.ch (Ardia David)
Date: Mon, 23 Jun 2008 10:56:55 +0200
Subject: [R-pkgs] AdMit 1.00-02
Message-ID: <485F6557.8030709@unifr.ch>

'AdMit' 1.00-02 is a contributed R package which provides functions to 
perform the fitting of an
adaptive mixture of Student-t distributions to a target density through 
its kernel function.
The mixture approximation can then be used as the importance density
in importance sampling or as the candidate density in the 
Metropolis-Hastings algorithm to
obtain quantities of interest for the target density itself.

http://cran.at.r-project.org/web/packages/AdMit/index.html

-- 
David Ardia
H-building, room 11-26
Econometric Institute
Erasmus University
PO Box 1738
NL 3000 DR Rotterdam
The Netherlands
Phone: +31 (0)10 408 2269



From jayemerson at gmail.com  Wed Jun 25 15:09:14 2008
From: jayemerson at gmail.com (Jay Emerson)
Date: Wed, 25 Jun 2008 09:09:14 -0400
Subject: [R-pkgs] Package bigmemory now available on CRAN
Message-ID: <d4588dec0806250609h4530d0c9v2a666aa7708792ae@mail.gmail.com>

Package "bigmemory" is now available on CRAN.  A brief abstract follows:

Multi-gigabyte data sets challenge and frustrate R users even on
well-equipped hardware.
C/C++ and Fortran programming can be helpful, but is cumbersome for interactive
data analysis and lacks the flexibility and power of R's rich
statistical programming environment.
The new package bigmemory bridges this gap, implementing massive matrices
in memory (managed in R but implemented in C++) and supporting their
basic manipulation
and exploration. It is ideal for problems involving the analysis in R
of manageable
subsets of the data, or when an analysis is conducted mostly in C++.
In a Unix environment,
the data structure may be allocated to shared memory with transparent read
and write locking, allowing separate processes on the same computer to
share access to a
single copy of the data set. This opens the door for more powerful
parallel analyses and
data mining of massive data sets.

-- 
John W. Emerson (Jay)
Assistant Professor of Statistics
Department of Statistics
Yale University
http://www.stat.yale.edu/~jay



From spencer.graves at pdf.com  Mon Jul  7 04:48:49 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 06 Jul 2008 19:48:49 -0700
Subject: [R-pkgs] Functional Data Analysis, fda_1.2.4
Message-ID: <48718411.4050909@pdf.com>

Hi, All:

	  Version 1.2.4 of the Functional Data Analysis (fda) package is now 
available on CRAN.  In this version, both 'smooth.basis' and 
'smooth.basisPar' have been modified to make them easier to use.  They 
have more useful defaults and they return an object of class
'fdSmooth', with methods for 'plot', 'lines', and 'plotfit'.  In 
addition, there have also been improvements to the 'plotfit' function 
and the 'CanadianWeather' data.  Also, a function 'norder' has been
added, which returns the order of a B-spline.

	 Spencer Graves



From nkraemer at cs.tu-berlin.de  Thu Jul 10 17:28:19 2008
From: nkraemer at cs.tu-berlin.de (Nicole Kraemer)
Date: Thu, 10 Jul 2008 17:28:19 +0200
Subject: [R-pkgs] ppls: version 1.02 including a new data set
Message-ID: <48762A93.8080907@cs.tu-berlin.de>

Dear R users,

an update of the package ppls - Penalized Partial Least Squares - is now 
available on CRAN.

It implements the methods described in

N. Kr?mer, A.-L. Boulesteix, G. Tutz
"Penalized Partial Least Squares with Applications to B-Spline 
Transformations and Functional Data"
Chem. Intell. Lab. Sys. 2008
http://dx.doi.org/10.1016/j.chemolab.2008.06.009


Features of the package include

* the estimation of functional data with penalized PLS,
* the estimation of generalized additive models with penalized PLS based 
on spline transformations,
* model selection for both methods based on cross validation.

The most important changes since 1.01 are

(1) a more efficient implementation of the penalized PLS algorithm that 
decreases the run-time substantially,
(2) the inclusion of the data set "cookie" that contains measurements 
from quantitative near-infrared spectroscopy.

Best regards,

Nicole & Anne-Laure


-- 
Dr. Nicole Kr?mer
TU Berlin
Machine Learning/Intelligent Data Analysis	fon: (+49) 30 314 78627
Franklinstr. 28/29, 10587 Berlin, Germany	fax: (+49) 30 314 78622

web: http://ml.cs.tu-berlin.de/~nkraemer



From racinej at mcmaster.ca  Fri Jul 25 16:41:03 2008
From: racinej at mcmaster.ca (Jeffrey S. Racine)
Date: Fri, 25 Jul 2008 10:41:03 -0400
Subject: [R-pkgs] Package np version 0.20-0 released to CRAN
Message-ID: <1216996863.46684.28.camel@pc-racine1.economics.mcmaster.ca>

Dear R users,

An updated version of the np package has recently been uploaded to CRAN
(version 0.20-0). Version 0.20-0 is documented in

Tristen Hayfield and Jeffrey S. Racine (2008). Nonparametric
Econometrics: The np Package. Journal of Statistical Software 27(5). URL
http://www.jstatsoft.org/v27/i05/

and also in a vignette (vignette("np",package="np")). There is also a
FAQ located in the package browse directory (np_faq.pdf, also available
at http://socserv.mcmaster.ca/racine/np_faq.pdf).

A much more thorough treatment of the subject matter can be found in Li,
Q. and J. S. Racine (2007), Nonparametric Econometrics: Theory and
Practice, Princeton University Press, ISBN: 0691121613 (768 Pages) for
those who might be interested
(http://press.princeton.edu/titles/8355.html)

Information on the np package:

This package provides a variety of nonparametric (and semiparametric)
kernel methods that seamlessly handle a mix of continuous, unordered,
and ordered factor datatypes. We would like to gratefully acknowledge
support from  the Natural Sciences and Engineering Research Council of
Canada (NSERC:www.nserc.ca), the Social Sciences and Humanities Research
Council of Canada (SSHRC:www.sshrc.ca), and the Shared Hierarchical
Academic Research Computing Network (SHARCNET:www.sharcnet.ca).

Changes from 0.14-3 to 0.20-0

* npksum now supports an expanded set of kernels (including 
  convolution, derivative and integral), which can be selected
  via the 'operator' argument.
* automatic bandwidth searches are now performed when attempting to 
  evaluate on data without bandwidths.
* npsigtest interface brought in line with other functions.
* significance tests can now be performed on npreg outputs.
* added a vignette and faq.
* summary on npconmode now properly retrieves names from bandwidth 
  objects.
* fixed the 6th and 8th order epanechnikov kernels.
* fixed some quietness issues.
* npplot now returns data upon request for conditional densities.
* npreg and npcdens now take the appropriate limits in some 
  pathological cases.

We are grateful to John Fox, Achim Zeilies, Roger Koenker, and numerous
users for their valuable feedback which resulted in an improved version
of the package.

-- Jeffrey Racine & Tristen Hayfield.
-- 
Professor J. S. Racine         Phone:  (905) 525 9140 x 23825
Department of Economics        FAX:    (905) 521-8232
McMaster University            e-mail: racinej at mcmaster.ca
1280 Main St. W.,Hamilton,     URL:
http://www.economics.mcmaster.ca/racine/
Ontario, Canada. L8S 4M4

`The generation of random numbers is too important to be left to chance'



From ubk2101 at columbia.edu  Mon Jul 28 14:28:08 2008
From: ubk2101 at columbia.edu (Udaya B. Kogalur)
Date: Mon, 28 Jul 2008 08:28:08 -0400
Subject: [R-pkgs] randomSurvivalForest 3.5.0 now available
Message-ID: <38c08c270807280528t38900327w80eae921228f9284@mail.gmail.com>

Please find release 3.5.0 of the CRAN package "randomSurvivalForest"
now posted on CRAN.  Thank you.


ubk2101 at columbia.edu

Udaya B. Kogalur, Ph.D.
Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012

---------------------------------------------------------------------------------
CHANGES TO RELEASE 3.5.0

RELEASE 3.5.0 represents a significant upgrade in the functionality of
the product.  Key changes are as follows:

o A random version of all computed split rules is now available.  See
the documentation for more details.

o The ability to handle factors has been implemented.  If the factor
is ordered, then splits are similar to real valued variables.  If the
factor is unordered, a split will move a subset of the levels in the
parent node to the left daughter, and the complementary subset to the
right daughter.  All possible complementary pairs are considered and
apply to factors with an unlimited number of levels.  However, for
deterministic splitting there is an optimization check to ensure that
the number of splits is not greater than the number of complementary
pairs in a node (this internal check will be overridden in random
splitting mode if nsplit is set high enough).  Note that when
predicting on test data involving factors, the factor labels in the
test data must be the same as in the grow (training) data.  Consider
setting labels that are unique in the test data to missing.



From bertrand.iooss at cea.fr  Fri Aug  1 16:39:19 2008
From: bertrand.iooss at cea.fr (IOOSS Bertrand 165542)
Date: Fri, 1 Aug 2008 16:39:19 +0200
Subject: [R-pkgs]  sensitivity
Message-ID: <6AF7979EE40736408C94E7D414EBD62804B0CD59@THEZE.intra.cea.fr>

Hi All,

the new release v1.4-0 of the "sensitivity" package is now available on CRAN
The "sensitivity" package is devoted to factor screening and global sensitivity analysis
of numerical model output. 

Here are the new features list:

New functionalities:
	 * sequential bifurcation method (sb function) [VERSION ALPHA] 
       * 3D plot 3D for the Morris method (function plot3d.morris, needs the rgl package) 
       * simplex designs for Morris method (function morris) 
       * multidimensional Sobol indices (function sobol) 
       * argument return.var in sobol methods in order to have local variables
         which are not saved in the output object, for example the bootstrap replicates
	   (functions sobol and sobol2002) 
       * template files writing (function template.replace) 
       * new argument ylim to control the ordinate axis for graphics (src, pcc, sobol, sobol2002, fast)
 
Small changes in the functions:
       * several names of parameters and variables in the objects have changed 
       * function "srcpcc" has been divided in two functions: "src" and "pcc" 
       * function "sobol" has been divided in two functions: "sobol" (original 1993 method) and "sobol2002"
       * function "fast" has been renamed "fast99"
       * the space filling design optimization for the Morris design has been rearranged in order
	   to gain computing memory. Some C code additions will be done later. 
 

------------------------------------------------------------------
Bertrand Iooss
CEA Cadarache
DEN/CAD/DER/SESI/LCFR
13108 Saint Paul lez Durance
France

Laboratoire de Conduite et de Fiabilit? des R?acteurs
bertrand.iooss at cea.fr
Tel : (33/0) 4 42 25 72 73
Fax : (33/0) 4 42 25 24 08



From a.p.s.l.rouzic at bio.uio.no  Fri Aug  1 17:55:03 2008
From: a.p.s.l.rouzic at bio.uio.no (Arnaud Le Rouzic)
Date: Fri, 01 Aug 2008 17:55:03 +0200
Subject: [R-pkgs] New package: noia
Message-ID: <489331D7.8070607@bio.uio.no>

Hi the list,

A new version (0.92) of my package 'noia' will be available soon on CRAN 
mirrors, and I think it might be a good opportunity to introduce it 
shortly to the R community.

In summary: 'noia' will be of absolutely no interest for 99.99% of you. 
The 0.01% remaining are quantitative geneticists who are interested in 
measuring the effect of genes in a proper way.

Since some of you may want to know why it is worth to let this 'noia' 
package take a few bytes on the CRAN server, I will try to introduce 
very shortly the scientific problem. The rules that explain the 
transmission of genes between generations are well known since the end 
of the 19th century. One important consequence of these rules is that in 
all diploid organisms (having two copies of the genomes, i.e. most of 
them, including us), it is virtually impossible to produce an equal 
number of offspring of each "type" from non-inbred parents: you end up, 
most of the time, with frequencies such as 1/4 vs 3/4, or 7/16 vs 9/16, 
or many other combinations. For quantitative traits, the link between 
the genes and the characters is complex, and the effect of genes has to 
be measured through models that look like cross-factor ANOVA designs. 
Because of the unequal segregating ratios, these ANOVAs are highly 
unbalanced, with all well-known annoying consequences: correlations 
between effect estimates, non-orthogonal variance decomposition, etc.

For a long time, comparing estimates measured in differently designed 
populations was not considered as a big issue. However, the recent need 
of effective model selection procedures lead to the proposition of new 
models aiming to a (more or less) orthogonal decomposition of genetic 
effects. This package provides tools to perform linear regressions using 
various models, to manipulate the genetic effects, and to compute 
genotype to phenotype maps, i.e. the function explaining how the genes 
expresses a given character. In addition, the 'noia' package provides a 
tool to perform 'multilinear' regression, an attempt of non-linear 
genotype-phenotype mapping.

In summary, 'noia' is a wrapper for lm() and nls() functions in a very 
specific context: estimating the effects of genes on a given trait.

NB: 'noia' is useless if the location of the genes is not known. 
Locating the genes requires a QTL detection procedure, for which 
packages already exist (see Rqtl for instance).

Much more information can be found in scientific publications. Two are 
particularly relevant:

* This package and its functions are described in a recent paper:
Arnaud Le Rouzic and Jos? M. ?lvarez-Castro, Estimation of Genetic 
Effects and Genotype-Phenotype Maps, /Evolutionary Bioinformatics 
/2008:4 225-235.  http://la-press.com/article.php?article_id=887

* The corresponding statistical framework is extensively described in:
Jos? M. ?lvarez-Castro and ?rjan Carlborg, A unified model for 
functional and statistical epistasis and its application in QTL 
analysis, Genetics, Vol. 176, 1151-1167 2007. 
http://www.genetics.org/cgi/content/abstract/176/2/1151

Given the probable low impact of the package, I am not planning to 
follow the R help mailing list. However, my email address is everywhere 
in the manual, and I would be very happy to answer questions related to 
this package; so don't hesitate to forward potential questions or to 
encourage users to contact me directly.

Arnaud Le Rouzic.



From gregoire.pau at ebi.ac.uk  Thu Jul 31 19:11:30 2008
From: gregoire.pau at ebi.ac.uk (Gregoire Pau)
Date: Thu, 31 Jul 2008 18:11:30 +0100
Subject: [R-pkgs] hwriter - Writing R objects in HTML format
Message-ID: <4891F242.4090602@ebi.ac.uk>

Dear R community,

I'm pleased to announce the availability of hwriter v0.92 on CRAN.

hwriter is an easy-to-use package able to format and output R objects in 
HTML format. It supports advanced formatting, tables, CSS styling, 
images and provides a convenient mapping between R tables and HTML tables.

hwriter combines the simple syntax of the xtable package and the 
strength of HTML/CSS styling. Making a complex HTML template with 
images, nested tables and nested HTML components is particularly easy.

hwriter web page is written by itself, using 'example(hwriter)':
http://www.ebi.ac.uk/~gpau/hwriter/

Its CRAN page is http://cran.r-project.org/web/packages/hwriter/

Hoping this package will be useful to the R community,
Best regards,

Greg
-- 
Gregoire Pau
EMBL/EBI Cambridge, UK
http://www.ebi.ac.uk/~gpau



From jens.oehlschlaegel at truecluster.com  Mon Aug  4 10:12:56 2008
From: jens.oehlschlaegel at truecluster.com (=?iso-8859-15?Q?Jens_Oehlschl=E4gel?=)
Date: Mon, 04 Aug 2008 10:12:56 +0200
Subject: [R-pkgs] major release ff 2.0 (large atomic objects)
Message-ID: <1060702519@web.de>

Dear R community,

ff Version 2.0 is available on CRAN. Based on paging concepts from version 1.0, 
2.0 is a major redesign of this package for handling large datasets. 
We have implemented numerous enhancements and performance improvements to make 
this package suitable as a 'base' package for large data processing. 

The ff package provides atomic data structures that are stored on disk but 
behave (almost) as if they were in RAM by transparently mapping only a section 
(pagesize) in main memory - the effective virtual memory consumption per ff 
object.

In addition to the 'double' data type, ff objects now have support for
'logical', 'raw' and 'integer' atomic datatypes, plus close-to-atomic types 
like 'factor', 'POSIXct' or custom close-to-atomic types. In addition to fast 
vector access, ff now has native support for matrices and arrays with flexible 
dimorder (major column-order, major row-order and generalizations for arrays). 

While the raw data still gets stored on binary flat files in native encoding,
'ff' objects have been extended to carry their meta information as physical
and virtual attributes. ff objects have well-defined hybrid copying semantics, 
which gives rise to certain performance improvements through virtualization. 

The new ff objects can be stored and reopened across R sessions. Flat files can 
be shared by multiple 'ff' R objects (using different data en/de-coding 
schemes) in the same process or from multiple R processes to exploit 
parallelism. A wide choice of finalizer options allows to work with 'permanent'
files as well as creating/removing 'temporary' ff files completely transparent 
to the user. On certain OS/Filesystem combinations, the creation process of 
large atomic data sets has been speed-up dramatically using sparse file 
allocation.

Several access optimization techniques such as Hybrid Index Preprocessing and 
Virtualization are implemented to achieve good performance even with large 
datasets, for example virtual matrix transpose without touching a single byte 
on disk.

Further, to reduce disk I/O, the atomic data gets stored native and compact on
binary flat files i.e. logicals take up exactly 2 bits to represent TRUE, FALSE
and NA.

Beyond basic access functions, the ff package also provides compatibility 
functions that facilitate writing code for ff and ram objects and support for 
batch processing on ff objects (e.g. as.ram, as.ff, ffapply).

A package that supports convenient processing of large ff objects is in the 
making. R.ff will make the bigger part of R's basic functions available for ff 
objects through method dispatch and/or an evaluator that handles expressions 
which contain ff objects. 

NOTE: A professional extension is available from the authors, which integrates
      additional high-performance features neatly into the ff package. 
      The extension allows  efficient handling of symmetric matrices 
      and supports more packed data types: 
      boolean (1 bit), quad (2 bit unsigned), nibble (4 bit unsigned)
      , byte (1 byte signed with NAs), ubyte (1 byte unsigned)
      , short (2 byte signed with NAs), ushort (2 byte unsigned)
      , single (4 byte float with NAs). 
      For example 'quad' allows efficient storage of genomic data as an 
      'A','T','G','C' factor. The unsigned types support 'circular' arithmetic. 
 
P.S. If you are interested in ff 2.0 you might want to visit our presentation 
August 5th at JSM "High-Performance Processing of Large Data Sets via Memory 
Mapping: A Case Study in R And C++" or the official package presentation at 
UseR!2008 in Dortmund scheduled for August 13th. 

The ff authors
Daniel Adler <dadler at uni-goettingen.de>
Christian Gl?ser <christian_glaeser at gmx.de>
Oleg Nenadic <onenadi at uni-goettingen.de>
Jens Oehlschl?gel <Jens.Oehlschlaegel at truecluster.com>
Walter Zucchini <wzucchi at uni-goettingen.de>



From jfox at mcmaster.ca  Fri Aug  8 16:19:46 2008
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 8 Aug 2008 10:19:46 -0400
Subject: [R-pkgs] New version of Rcmdr package
Message-ID: <000801c8f961$cf529960$6df7cc20$@ca>

Dear R users,

A new version (1.4-0) of the Rcmdr package (providing a basic-statistics
graphical user interface to R) is now on CRAN. This is the annual update of
the package (apart from bug-fixes and minor changes). Updated Italian and
Russian translations are included with the package (courtesy, respectively,
of Stefano Calza and Alexey Shipunov); I'll submit minor updates as other
translations arrive.

The new version of the Rcmdr package has a number of new facilities (see the
CHANGES file installed with the package), the most important of which is
probably the ability of plug-in packages to remove (as well as add to) the
Rcmdr menus. This should permit individuals to use the Rcmdr infrastructure
to create GUIs for specialized applications.

As usual, comments, suggestions, and bug-reports are welcome.

John

------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox



From alexis at ci.tuwien.ac.at  Fri Aug  8 14:51:53 2008
From: alexis at ci.tuwien.ac.at (Alexandros Karatzoglou)
Date: Fri, 8 Aug 2008 14:51:53 +0200 (CEST)
Subject: [R-pkgs] kernlab version 0.9-7
Message-ID: <Pine.LNX.4.64.0808081432590.21158@elendil.ci.tuwien.ac.at>


kernlab version 0.9-7 is now online and incorporates :

  + a much improved fast implementation of string kernels "stringdot"
    based on suffix arrays.

  + a new kernel method kmmd() which implements a non-parametric kernel
    based two sample test.

The new kernlab version also includes many minor improvements and fixes.


Alexandros



From amlg at sun.ac.za  Wed Aug 13 12:04:20 2008
From: amlg at sun.ac.za (La Grange, AM)
Date: Wed, 13 Aug 2008 12:04:20 +0200
Subject: [R-pkgs] New package: BiplotGUI
Message-ID: <1218621860.6744.68.camel@anthony-laptop>

Dear R users,

I am pleased to announce the release of the new BiplotGUI package on
CRAN.

Biplots are graphs in which the samples and all the variables of a data
matrix are represented simultaneously. They can be very useful for
exploring multivariate data.

The BiplotGUI package allows users to construct and interact with
biplots as they are described in "Biplots" (Gower and Hand, 1996). In
such biplots, the samples are represented as points, while the variables
are represented as calibrated biplot axes. The representations are
similar to ordinary scatter plots, but with all the variables
represented at one time. 

Version 0.0-2 of the package has the following features:

* A graphical user interface (GUI), making it easy to use
* Support for different types of biplots (PCA, covariance/correlation,
CVA, regression, Procrustes, circular non-linear), both interpolative
and predictive
* Support for different scaling techniques (PCO, metric MDS, non-metric
MDS, semi-metric MDS)
* Various data transformations and distance metrics
* Additional descriptors (convex hulls, alpha-bags, point densities,
classification regions)
* Intermediate quantities for export back to R
* Diagnostics (graphs of convergence; point, group and axis
predictivities; Shepard diagrams)
* Interactivity (variable value prediction, zooming, point and axis
drag-and-drop, 3D biplots)
* Highly customisable graphics
* Import of data directly from Excel 1997-2003 files

The package can be downloaded from CRAN:
<http://cran.r-project.org/web/packages/BiplotGUI/index.html> or a
favourite mirror.

The project homepage is at <http://biplotgui.r-forge.r-project.org>. It
includes screenshots and example biplots. A manual is included within
the package itself, but is also available from the website.

At present, the package runs under Windows only. 


I would appreciate any feedback so that the package can be further
improved.


Thanks,

Anthony la Grange
Department of Statistics and Actuarial Science
Stellenbosch University
South Africa



From joseclaudio.faria at gmail.com  Mon Aug 18 17:44:28 2008
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Mon, 18 Aug 2008 12:44:28 -0300
Subject: [R-pkgs] New packages bpca: biplot (2d and 3d) and diagnostic tools
Message-ID: <c86bda880808180844s4e2d489dpe227423326529a1a@mail.gmail.com>

Dear R Community,

We am pleased to announce the release of the 'bcpa' package.  The
source code and binaries is now on CRAN
(http://cran.r-project.org/web/packages/bpca/index.html).

The bpca package implements biplot (2d and 3d) and diagnostic tools of
the quality of the reduction.
It depends R (>= 2.6.0), scatterplot3d, rgl and MASS packages.

Regards,
-- 
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica - prof. Titular
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
joseclaudio.faria at terra.com.br
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\



From rpeng at jhsph.edu  Thu Aug 28 04:35:24 2008
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 27 Aug 2008 22:35:24 -0400
Subject: [R-pkgs] filehash 2.0
Message-ID: <66f3bd910808271935ved14acdmcb5de37e8d83baee@mail.gmail.com>

I have just uploaded to CRAN version 2.0 of the 'filehash' package.
This version contains a major rewriting of many of the internals (much
rewritten in C) for the DB1 format, which is the default.  This
development has lead to better file locking for concurrent access and
faster reading and writing of data in general.

In addition to rewriting the internals, I have added two modules for a
stack and queue data structure, implemented using 'filehash'
databases.  These are mostly for my own amusement, but perhaps you
will find them useful also.

For users of the 'filehash' package I would appreciate any general
comments as well as any bug reports, particularly considering the
number of changes that were made to the internals this time around.

-roger

-- 
Roger D. Peng | http://www.biostat.jhsph.edu/~rpeng/



From chris.jackson at mrc-bsu.cam.ac.uk  Wed Aug 27 15:38:57 2008
From: chris.jackson at mrc-bsu.cam.ac.uk (Chris Jackson)
Date: Wed, 27 Aug 2008 14:38:57 +0100
Subject: [R-pkgs] New package: ``denstrip'' for compactly illustrating
	distributions
Message-ID: <48B558F1.4000806@mrc-bsu.cam.ac.uk>

Dear R users,

I'd like to announce a new package on CRAN called ``denstrip''.  It
implements ``density strips'' and other graphical methods for
illustrating and comparing distributions in a compact fashion.

Posterior distributions of parameters are often summarised using point
and line drawings of means and credible intervals.  This is common,
for example, in multiple regression or meta-analysis.  Density
strips generalise these to illustrate whole distributions.  Instead of a
point and line, a shaded strip indicates the density as proportional to
the darkness of the shading.  They taper to white at the end of the
strip, instead of terminating at a clear limit - this may discourage
casually categorising effects as ``significant'' if the line excludes
the null.

The shading idea generalises to ``density regions'' to show
uncertainty about continuously-varying quantities, such as predictions
from time series.  The package includes other functions for
illustrating distributions in ``one dimension'', such as varying-width
strips (similar to violin plots) and sectioned density plots.

If you're interested in reading more about these methods, I discuss
them in a forthcoming article in The American Statistician, ``Displaying
uncertainty with shading'', also available from

http://www.mrc-bsu.cam.ac.uk/personal/chris/papers/denstrip.pdf

Comments and suggestions for improvement of the package are welcome.

-- 
Christopher Jackson <chris.jackson at mrc-bsu.cam.ac.uk>
Research Statistician, MRC Biostatistics Unit, Institute of Public
Health, Robinson Way, Cambridge, UK, CB2 0SR. +44 (1223) 330381



From max.kuhn at pfizer.com  Sat Sep  6 03:10:39 2008
From: max.kuhn at pfizer.com (Max)
Date: Fri, 05 Sep 2008 21:10:39 -0400
Subject: [R-pkgs] New caret packages
Message-ID: <C4E750CF.254E%max.kuhn@pfizer.com>

New major versions of the caret packages (caret 3.37, caretLSF 1.23 and
caretNWS 0.23) have been uploaded to CRAN.

caret is a package for building and evaluating a wide variety of predictive
models. There are functions for pre-processing, tuning models using
resampling, visualizing the results, calculating performance and estimating
variable importance.  caretNWS and caretLSF are two parallel processing
versions that can reduce the training time when multiple compute nodes are
available.

The project is now hosted on R-Forge. The homepage is

   http://caret.r-forge.r-project.org/

The package currently includes model tuning/resampling for the following
models: lm, single trees (C4.5, rpart, ctree, logistic model trees), mars
(via earth), boosted models (ada, gbm, blackboost, glmboost, gamboost,
logitboost), bagged models (trees, earth, fda), randomforests (randomforest
and cforest), rule-based models (Ripper and M5 prime), discriminant models
(lda, fda, rda, ssda, slda), kernel methods (lssvm, ksvm, rvm, gausspr),
nnet, nnet with initial pca step, multinom, pls, plsda, gpls, nearest
shrunken centroids, the lasso, the elastic net, supervised pca, knn, lvq and
NaiveBayes.

Recent changes include:
 - Estimation of class probabilities from PLS discriminant analysis using
Bayes rule (in addition to softmax)
- Added predict.train and predit.list
- More lattice plots to visualize resampling results (xyplot, stripplot,
densitplot, histogram)
- User-specified performance metrics for resampling
- User-specified algorithms for determining the optimal tuning parameters
(instead of highest/lowest)
- A CHANGES files now exists to track the specifics of the version changes
 
Max



From tlumley at u.washington.edu  Tue Sep  9 23:17:03 2008
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 9 Sep 2008 14:17:03 -0700 (PDT)
Subject: [R-pkgs] survey package
Message-ID: <Pine.LNX.4.64.0809091409590.5729@homer23.u.washington.edu>


Version 3.9 of the survey package is now on CRAN.  Since the last 
announcement (version 3.6-11, about a year ago) the main changes are
  - Database-backed survey objects: the data can live in a SQLite (or other 
DBI-compatible) database and be loaded as needed.
  - Ordinal logistic regression
  - Support for the 'mitools' package and multiply-imputed data
  - Conditioning plots, transparent scatterplots, survival and CDF plots.

There is more information on the package web page at
http://faculty.washington.edu/tlumley/survey/

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From christophe.pouzat at gmail.com  Wed Sep 10 10:56:06 2008
From: christophe.pouzat at gmail.com (Christophe Pouzat)
Date: Wed, 10 Sep 2008 10:56:06 +0200
Subject: [R-pkgs] STAR (Spike Train Analysis with R) uploaded on CRAN
Message-ID: <79ff51fb0809100156o3498531y5ef28da153a23cd6@mail.gmail.com>

Hi all,

I've uploaded STAR (Spike Train Analysis with R) on CRAN two days ago.

The package is designed to analyze neuronal spike (action potential)
trains. It uses S3 classes and methods and makes heavy use of other
CRAN packages like gss, R2HTML, mgcv, survival.

* Analysis of both spontaneous and stimulus evoked activity is
implemented for single neuron spike trains as well as for many neurons
recorded simultaneously.
* Several bi variate duration distribution can be automatically fitted
to "spontaneous" spike trains. Tests for renewal processes are
implemented.
* A non-parametric, smoothing spline based, approach to the estimation
of the conditional intensity of the trains is also available (this
feature is under development).
* The full collection of Ogata's tests (1988, JASA, 83:9) for
point-process models is implemented and the data set used by him
(table 1 of the paper) is made available.
* A new goodness of fit test for point-process is also proposed based
on the fact that the martingale of the process plotted as a function
of the integrated conditional intensity starts behaving very quickly
as a standard Wiener process (if the model is correct). By the way I
have no clean and formal proof of the latter statement so anyone able
(and wiling) to give me some help on that is invited to send me an
email.
* Many data sets are included as well as vignette (covering only part
of the present functionalities) and several demos.

Any feed-back, comment, critic, is welcome.

Christophe

--
A Master Carpenter has many tools and is expert with most of them. If you
only know how to use a hammer, every problem starts to look like a nail.
Stay away from that trap.
Richard B Johnson.
--

Betweeen May and October I'll be mainly staying
in the Peter Kloppenburg's lab in Cologne, You can
call me there at: +49 (0)221 470 5207

Christophe Pouzat
Laboratoire de Physiologie Cerebrale
CNRS UMR 8118
UFR biomedicale de l'Universite Paris-Descartes
45, rue des Saints Peres
75006 PARIS
France

tel: +33 (0)1 42 86 38 28
fax: +33 (0)1 42 86 38 30
mobile: +33 (0)6 62 94 10 34
web: http://www.biomedicale.univ-paris5.fr/physcerv/C_Pouzat.html
sip:christophe.pouzat at ekiga.net



From daj025 at gmail.com  Thu Sep 11 18:46:21 2008
From: daj025 at gmail.com (David James)
Date: Thu, 11 Sep 2008 12:46:21 -0400
Subject: [R-pkgs] new RMySQL and new maintainer
Message-ID: <74c69e370809110946q3274adco196a99b5c34fe91a@mail.gmail.com>

Hello,

[This is a re-posting of a previous announcement; I believe the
original posting of a couple of days ago didn't go through.]

The latest version of RMySQL 0.6-1 is now in CRAN. Please see the NEWS
file for more details.

Also, I'm happy to announce that Jeff Horner
<jeff.horner at vanderbilt.edu> has kindly agreed to maintain RMySQL from
now on.   Please continue sending your comments, suggestions, bug
reports , patches, etc., to the R-sig-DB mailing list.

Regards,
--
David



From Matthias.Kohl at stamats.de  Mon Sep 15 12:14:50 2008
From: Matthias.Kohl at stamats.de (Matthias Kohl)
Date: Mon, 15 Sep 2008 12:14:50 +0200
Subject: [R-pkgs] RobASt-Packages
Message-ID: <48CE359A.4070505@stamats.de>

-----------------------------------------------------------------------------------------
Packages for the computation of optimally robust estimators
-----------------------------------------------------------------------------------------

We would like to announce the availability on CRAN (with possibly a
minor delay until on every mirror) of new versions of our packages for
the computation of optimally robust estimators; i.e., "RandVar",
"ROptEst", "RobLox" as well as a new package "RobAStBase" (not yet:
ROptRegTS and RobRex).

-----------------------------------------------------------------------------------------
Devel versions on R-forge
-----------------------------------------------------------------------------------------
The development of these packages is under r-forge project RobASt
(Robust Asymptotic Statistics):

http://r-forge.r-project.org/projects/robast/
http://robast.r-forge.r-project.org/

If you find this project interesting and would like to collaborate, you
are warmly welcome.

We look forward to receiving questions, comments and suggestions.

Matthias Kohl
Peter Ruckdeschel

-----------------------------------------------------------------------------------------
RandVar - Implementation of random variables (version 0.6.3)
-----------------------------------------------------------------------------------------
The package RandVar which includes an S4 implementation of random
variables together with the packages distr, distrEx and distrMod form
the basis of our packages on robust statistics.

-----------------------------------------------------------------------------------------
RobAStBase - Robust Asymptotic Statistics (version 0.1.0)
-----------------------------------------------------------------------------------------
This is a new package including some necessary S4 class infrastructure
like neighborhoods, influence curves and robust models.

-----------------------------------------------------------------------------------------
ROptEst - Optimally robust estimation (version 0.6.0)
-----------------------------------------------------------------------------------------
This is the main package for the optimally robust estimation in smoothly
(L2-differentiable) parametric models [optimal in the sense of the
shrinking neighborhood setup]. By using S4 classes and methods
the implementation so far covers the optimally robust estimation for
all(!) smoothly (L2-differentiable/differentiable in quadratic mean)
parametric models which are based on a univariate distribution. Many
well-known parametric (in particular, exponential) families (Binomial,
Poission, Normal, Gamma, Gumbel, ...) are L2-differentiable.
We include several
   +neighborhood types (convex contamination, total variation)
   +risks (MSE, Hampel, overshoot/undershoot),
   +bias-types (symmetric, one-sided, asymmetric)
   +norms (unstandardized, self-standardized, information-standardized)
for all these models.
After installation you find a folder "scripts" in the package directory
which includes many example scripts.
As the computation of optimally robust estimators involves several
steps, we -- in this new version -- added an interface function
"roptest" which can be used to perform all steps via one function.

-----------------------------------------------------------------------------------------
RobLox - Optimally robust influence curves for location and scale
(version 0.6.0)
-----------------------------------------------------------------------------------------
This package includes functions for the computation of many well known
influence curves (e.g., Huber-, Hampel-, Tukey-, Andrews-type) for
normal location and scale in the framework of our asymptotic setup.
Moreover, (and for us, more importantly) it includes the functions
"roblox", "rowRoblox" and "colRoblox" which can be used to compute
optimally robust estimators in case of normal location and scale. These
functions are optimized for speed and can be applied to large scale
problems like for instance gene expression data. Using rowRobLox the
computation for a 50000 x 20 matrix takes about 2 sec. on a Centrino Duo
with 1.66 GHz. As a comparison (all on the same system): using apply and
huberM (robustbase), resp. huber (MASS) takes about 168 sec. resp 197
sec., using apply and roblox takes about 16 minutes and using apply and
roptest (ROptEst) takes about 1 month.

-----------------------------------------------------------------------------------------
ROptRegTS - Optimally robust estimation for regression-type models
RobRex - Optimally robust influence curves for regression and scale
-----------------------------------------------------------------------------------------
These two packages which provide S4 classes and methods for the
computation of optimally robust estimators in regression-type models are
not yet adapted to the new implementation. If you are interested in
working with these packages you have to use the old versions of the
above packages which we are pleased to provide on request (the sources
can also be found in the CRAN archives). But, of course, we will try to
update these packages as soon as possible.

-- 
Dr. Matthias Kohl
www.stamats.de



From Achim.Zeileis at R-project.org  Tue Sep 16 18:52:39 2008
From: Achim.Zeileis at R-project.org (Achim Zeileis)
Date: Tue, 16 Sep 2008 18:52:39 +0200 (CEST)
Subject: [R-pkgs] AER 1.0-0: Applied Econometrics with R
Message-ID: <Pine.LNX.4.64.0809161847440.3883@paninaro.stat-math.wu-wien.ac.at>

Version 1.0-0 of the package "AER" for "Applied Econometrics with R" has been 
released to CRAN (http://CRAN.R-project.org/package=AER) a few weeks ago. 
It accompanies

   Applied Econometrics with R
   Christian Kleiber, Achim Zeileis
   http://www.springer.com/978-0-387-77316-2
   http://www.amazon.com/Applied-Econometrics-R-Use/dp/0387773169/

from Springer's useR! series.

This version contains a new package vignette
   vignette("AER", package = "AER")
providing an overview of the package. An extensive list of worked examples 
is available in a new set of demos
   demo(package = "AER")
which reproduce all the examples from the above book.

Many of the examples and demos in the AER package use other CRAN packages for 
econometric analyses of various data sets. A collection of some of these CRAN 
packages is presented in a recently published special volume of JSS:

   Econometrics in R
   Journal of Statistical Software
   Special Volume edited by Achim Zeileis and Roger Koenker
   http://www.jstatsoft.org/v27/

We hope that all these provide useful information for econometric analyses 
using R.



From vincent.goulet at act.ulaval.ca  Mon Sep 15 22:02:06 2008
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Mon, 15 Sep 2008 16:02:06 -0400
Subject: [R-pkgs] New version of actuar
Message-ID: <710886E8-95E7-46B0-B1F9-3FE42F218D9D@act.ulaval.ca>

=== actuar: An R Package for Actuarial Science ===

We are pleased to announce the immediate availability of version 1.0-0  
of actuar. This release follows publication of our papers in JSS (*)  
and R News (**). From the NEWS file:

Version 1.0-0
=============

NEW FEATURES

   o Improved support for regression credibility models. There is now
     an option to make the computations with the intercept at the
     barycenter of time. This assures that the credibility adjusted
     regression line (or plane, or ...) lies between the individual and
     collective ones. In addition, contracts without data are now
     supported like in other credibility models.

   o Argument 'right' for grouped.data() to allow intervals closed on
     the right (default) or on the left.

   o Method of quantile() for grouped data objects to compute the
     inverse of the ogive.

USER-VISIBLE CHANGES

   o cm() no longer returns the values of the unbiased estimators when
     method = "iterative".

   o Specification of regression models in cm() has changed: one should
     now provide the regression model as a formula and the regressors
     in a separate matrix or data frame.

   o Due to above change, predict.cm() now expects 'newdata' to be a
     data frame as for stats:::predict.lm().

   o Function bstraub() is no longer exported. Users are expected to
     use cm() as interface instead.

BUG FIXES

   o Functions r<foo>() are now more consistent in warning when NA's
     (specifically NaN's) are generated (as per the change in R 2.7.0).

   o frequency.portfolio was wrongly counting NAs.

   o Domain of pdfs returned by aggregateDist() now restricted to
     [0, 1].

   o Quantiles are now computed correctly (and more efficiently) in 0
     and 1 by quantile.aggregateDist().

   o coverage() no longer requires a cdf when it is not needed, namely
     when there is no deductible and no limit.


The CRAN page for the package is

	http://cran.r-project.org/package=actuar

The project's web site is

	http://www.actuar-project.org

Comments and contributions to the project are more than welcome.

(*) http://www.jstatsoft.org/v25/i07
(**) http://cran.r-project.org/doc/Rnews/Rnews_2008-1.pdf

---
   Vincent Goulet, Associate Professor
   ?cole d'actuariat
   Universit? Laval, Qu?bec
   Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From h.wickham at gmail.com  Tue Sep 30 16:55:31 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 30 Sep 2008 09:55:31 -0500
Subject: [R-pkgs] New package: plyr
Message-ID: <f8e6ff050809300755j4f516a98n9d4ed69f103be19d@mail.gmail.com>

plyr is a set of tools that solves a common set of problems: you need
to break a big problem down into manageable pieces, operate on each
pieces and then put all the pieces back together.  It's already
possible to do this with split and the apply functions, but plyr just
makes it all a bit easier with:

  * consistent names, arguments and outputs
  * input from and output to data.frames, matrices and lists
  * progress bars to keep track of long running operations
  * built-in error recovery
  * the choice of passing chunks as rows or as variables

plyr functions are named according to the type of object they input
(first letter) and output (second letter):

  * llply = from a list to a list
  * alply = from an array (or vector, or matrix) to a list
  * ldply = from a list to a data.frame
  * d_ply = from a data.frame, ignore output
  * and so on for llply, laply, ldply, l_ply, alply, aaply, adply,
a_ply, dlply, daply, dply, d_ply

plyr also provides:

  * m*ply which works in a similar way to mapply
  * r*ply which works in a similar way to replicate

You can find out more at http://had.co.nz/plyr/, including a 20 page
introductory guide, http://had.co.nz/plyr/plyr-intro.pdf.

Regards,

Hadley


-- 
http://had.co.nz/



From h.wickham at gmail.com  Sun Oct  5 17:41:35 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 5 Oct 2008 10:41:35 -0500
Subject: [R-pkgs] ggplot2 - version 0.7
Message-ID: <f8e6ff050810050841q4d7cf8cav777e9b096e4492c9@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the nearly 500
examples of ggplot in use.

ggplot2 0.7 introduces a new theming system which allows you to
control (almost) every aspect of the appearance of the plot.  This
system is documented in the book chapter "Polishing your plots for
publication", available from
http://had.co.nz/ggplot2/book/polishing.pdf.

Bugs fixed

* geom_boxplot: now displays outliers even if only one present
* geom_jitter: setting one jitter direction to 0 now works
* geom_segment: should now work correctly in all coordinate systems
(note that arrows only work in Cartesian coordinates)
* ggsave: correctly uses dpi for raster devices and default dpi
changed to 72 (thanks to Brian Ripley for pointing this out)
* ggsave: current device no longer closes if error occurs
* position_jitter: now works correctly with 0 jitter
* remove_missing: some statistics were calculated incorrectly when
missing values were present
* scales: extra scales ignored (again)
* scales: legends respect fixed parameters of the layer
* scales: legends won't appear when aesthetics are mapped to NULL, or
set to fixed value
* scales: xend and yend now transformed correctly
* scale_date: breaks are now rounded to correct position

New functionality

* geom_point: can now control colour and fill separately for point
glyphs with borders
* geom_step: now has parameter direction which can take values vh
(vertical then horizontal) or hv (horizontal then vertical) describing
the shape of the stairs
* qplot: new asp argument to set aspect ratio
* qplot: now captures the environment in which it was run, which
should make it much more robust at finding the variables you expect it
to find
* qplot: now treats any arguments wrapped in I() as parameters, not
aesthetics, e.g. qplot(mpg, wt, data=mtcars, colour = I("red")) or
qplot(mpg, wt, data=mtcars, size = I(5))
* scale_continuous: new minor_breaks argument to controls position of
minor breaks
* scale_discrete: new discrete position scales which make it possible
to manually position elements
* scale_gradientn: new colour scale which creates gradient between any
list of colours

More consistent interfaces

* can use color instead of colour, and old R names throughout ggplot2
* geom_jitter: Arguments changed to height and width to match other
position adjustments
* scales: any point outside of limits is dropped (this was previously
the behaviour for discrete scales, but not continuous scales)
* scales: limits are consistent across discrete and continuous scales
(limits c(1, NA) form no longer works for continuous scales)
* scales: order of legends reversed to match order of x axis (and to
be consistent with previous versions)
* scale_date: new limits argument to set axis limits
* scale_discrete: all discrete scales accept breaks argument
* scale_discrete: all discrete scales have limits and labels argument
to better control legends
* scale_discrete: character and logical vectors now reliably treated
as discrete scales
* stat_density2d, geom_density2d: density2d used consistently (instead
of density_2d in some places)

Improved aesthetics

* coord_polar: more tweaks to grid lines to enhance appearance
* coord_polar: new expand argument to control whether axes should be
expanded outside the range of the data
* geom_contour, geom_smooth, geom_quantile: now use blue lines
* position_stack, position_dodge: should be more informative if
conditions for stacking/dodging not met
* position_jitter: default amount of jittering tweaked to align with
boxplots etc.
* scales: background colour of legends key matches plot
* themes: Complete rewrite of theming system, see new book chapter for details
* themes: direct access to plot options via $ is now disabled

Improved documentation and error messages

* facet_grid: documentation improved
* qplot: Better error messages when needed variables are missing
* scale_discrete: improved error message for too many values in domain
* scale_size: improved documentation for discrete variables
* online documentation generally tweaked and primped to work a little
better and look a little nicer
* website now includes a search box
* links from rdoc now point to correct pages


-- 
http://had.co.nz/



From HDoran at air.org  Wed Oct  1 19:39:09 2008
From: HDoran at air.org (Doran, Harold)
Date: Wed, 1 Oct 2008 13:39:09 -0400
Subject: [R-pkgs] MiscPsycho 1.3 posted to CRAN
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE016E2328@DC1EXCL01.air.org>

An updated version of the Miscellaneous Psychometrics package has been
updated to CRAN. The following updates are included in the package:

1) An implementation of the Stocking-Lord procedure for linking test
scales.
2) An implementation of the Levenshtein algorithm for comparing
character strings
3) stringProbs, a function for computing the probability of a given
Levenshtein Distance
4) Three sources of documentation on all functions. There is complete
technical documentation on the functions used in MiscPsycho in the file
MP.pdf, the stocking-lord implementation is documented in
stock_lord.pdf, and a paper describing the Levenshtein algorithm and its
application in educational measurement is provided in levenshtein.pdf.
All of these are in the docs folder in the package distribution.

Any comments, reactions, critiques, are welcome.

Harold



From mathieu.pigeon at uclouvain.be  Fri Oct  3 11:24:14 2008
From: mathieu.pigeon at uclouvain.be (Mathieu Pigeon)
Date: Fri, 03 Oct 2008 11:24:14 +0200
Subject: [R-pkgs] New package: expert 1.0-0
Message-ID: <7.0.1.0.2.20081003111605.02113920@uclouvain.be>

expert: Modeling Without Data Using Expert Opinion

Expert opinion is a technique to do statistical modeling when data is
scarse (e.g. accidents in nuclear plants) or even absent, at least for
the analyst (e.g. confidential settlements in liability insurance).
Opinions on the distribution of the decision random variable is sought
from experts in the field. The experts give their opinion in the form
of a few quantiles for the decision variable and for a set of "seed
variables" for which the analyst knows the true quantiles. Results for
seed variables are compared to the true values and used to determine
the influence of each expert on the aggregated distribution. The
package supports three different ways to aggregate the information
provided by the experts in one final distribution:

1. the classical model of Cooke (1991);
2. the Bayesian model of Mendel and Sheridan (1989);
3. an ad-hoc procedure where the weight of each expert is pre-
determined by the analyst.

The main function of the package is expert(), a unified interface to
all three methods above. The package also provides a few utility
functions to display, plot or compute probabilities and quantiles from
the aggregated distribution returned by expert().


Best regards,

Mathieu Pigeon
Institut de Statistique
Universite Catholique de Louvain
Voie du Roman Pays, 20
1348 Louvain-la-Neuve
BELGIUM

E-mail address : mathieu.pigeon at uclouvain.be



From elff at uni-mannheim.de  Mon Oct  6 10:23:52 2008
From: elff at uni-mannheim.de (Martin Elff)
Date: Mon, 6 Oct 2008 10:23:52 +0200
Subject: [R-pkgs] New verision 0.95 of package 'memisc' released to CRAN
Message-ID: <200810061023.52293.POLMETH@artsci.wustl.edu>

Dear useRs,

I am pleased to announce the availability of version 0.95 of package 'memisc' 
on CRAN (http://cran.r-project.org/web/packages/memisc/).

'memisc' does not implement any new estimators, but focuses on providing an 
infrastructure for data analysis especially of survey data. It may be of 
interest to all those who have had to use a commercial package like SPSS or 
Stata in order to prepare data for analysis in R. I wrote this package to 
become independent from commercial software and to do everything in R, from 
data management to data analysis and presentation of analysis results. I hope 
that the package will be as useful for others as it has become for me. UseRs 
may want to check out the vignette "Analysing the American National Election 
Study of 1948" to see the package in action.

Feedback is more than welcome. Please to do not hesitate to inform me if you 
find any bugs in this package.


All the best,

Martin 

Package description:
=============================================================================================

Package: memisc
Type: Package
Title: Tools for Management of Survey Data, Graphics, Programming, Statistics, 
and Simulation
Version: 0.95-1
Date: 2008-10-1
Author: Martin Elff
Maintainer: Martin Elff <elff at uni-mannheim.de>
Description: One of the aims of this package is to make life easier for useRs
  who deal with survey data sets. It provides an infrastructure for the 
  management of survey data including value labels, definable missing values,
  recoding of variables, production of code books, and import of (subsets of)
  SPSS and Stata files. Further, it provides functionality to produce tables
  and data frames of arbitrary descriptive statistics and (almost)  
  publication-ready tables of regression model estimates. Also some 
  convenience tools for graphics, programming, and simulation are provided.
License: GPL-2
LazyLoad: Yes
Depends: lattice, grid, stats, methods, utils, MASS
URL: 
http://webrum.uni-mannheim.de/sowi/elff/content.php/EnglishVersion/MartinsRPackages

=============================================================================================

-- 
-------------------------------------------------
Dr. Martin Elff
Department of Social Sciences
University of Mannheim
A5, Room 328
68131 Mannheim
Germany

Phone: ++49-621-181-2093
Fax: ++49-621-181-2099
E-Mail: elff at sowi.uni-mannheim.de
Homepage: 
http://webrum.uni-mannheim.de/sowi/elff
http://www.sowi.uni-mannheim.de/lspwivs/
-------------------------------------------------

**********************************************************
             Political Methodology E-Mail List
   Editors: Melanie Goodrich, <melaniegoodrich at nyu.edu>
            Delia Bailey, <dbailey at wustl.edu>
**********************************************************
        Send messages to polmeth at artsci.wustl.edu
  To join the list, cancel your subscription, or modify
           your subscription settings visit:

          http://polmeth.wustl.edu/polmeth.php



From landronimirc at gmail.com  Thu Oct  9 19:59:17 2008
From: landronimirc at gmail.com (Liviu Andronic)
Date: Thu, 9 Oct 2008 19:59:17 +0200
Subject: [R-pkgs] release of RcmdrPlugin.Export 0.2-1
Message-ID: <68b1e2610810091059kd5f932ei3cecea503d3c9c91@mail.gmail.com>

Dear R users,

A new version of RcmdrPlugin.Export is currently available on CRAN.
The release introduces support for the "file" and "append" options of
print.xtable(). The new features make easier to include exported HTML
code into documents created with regular word-processing programmes,
such as .odt (OpenOffice.org) and .doc (Microsoft Word). The exported
LaTeX code can also be `Imported as File' into LyX documents.

As always, suggestions and bug reports are most welcome.

Regards,
Liviu



From jens.oehlschlaegel at truecluster.com  Fri Oct 10 18:08:51 2008
From: jens.oehlschlaegel at truecluster.com (=?iso-8859-15?Q?Jens_Oehlschl=E4gel?=)
Date: Fri, 10 Oct 2008 18:08:51 +0200
Subject: [R-pkgs] New package: bit 1.0
Message-ID: <1096847731@web.de>

Dear R community,

Package 'bit' Version 1.0 is available on CRAN. 
It provides bitmapped vectors of booleans (no NAs), 
coercion from and to logicals, integers and integer subscripts; 
fast boolean operators and fast summary statistics. 

With bit vectors you can store true binary booleans {FALSE,TRUE} at the expense 
of 1 bit only, on a 32 bit architecture this means factor 32 less RAM and 
factor 32 more speed on boolean operations. With this speed gain it even 
pays-off to convert to bit in order to avoid a single boolean operation on 
logicals or a single set operation on (longer) integer subscripts, the pay-off 
is dramatic when such components are used more than once. 

Reading from and writing to bit is approximately as fast as accessing standard 
logicals - mostly due to R's time for memory allocation. The package allows to 
work with pre-allocated memory for return values by calling .Call() directly: 
when evaluating the speed of C-access with pre-allocated vector memory, coping 
from bit to logical requires only 70% of the time for copying from logical to 
logical; and copying from logical to bit comes at a performance penalty of 150%.

Functions 'which' and 'xor' are made S3 generic, 'xor.default' is implemented 
much faster than in base R (this should go into base R).

The package has automated regression-tests and is hopefully useful for better
handling large datasets, together with packages 'rindex' and 'ff'.

Best regards


Jens Oehlschl?gel
Munich, 10.10.2008



From gregoire.pau at ebi.ac.uk  Tue Oct  7 21:13:27 2008
From: gregoire.pau at ebi.ac.uk (Gregoire Pau)
Date: Tue, 07 Oct 2008 20:13:27 +0100
Subject: [R-pkgs] hwriter - Writing R objects in HTML format
Message-ID: <48EBB4D7.4060607@ebi.ac.uk>

Dear R community,

I'm pleased to announce the availability of hwriter v0.93 on CRAN.

hwriter is an easy-to-use package able to format and output R objects in
HTML format. It supports advanced formatting, tables, CSS styling,
images and provides a convenient mapping between R tables and HTML tables.

hwriter combines the simple syntax of the xtable package and the
strength of HTML/CSS styling. Making a complex HTML template with
images, nested tables and nested HTML components is particularly easy.

hwriter project page (written by itself, using 'example(hwriter)'):
http://www.ebi.ac.uk/~gpau/hwriter/

Its CRAN page is http://cran.r-project.org/web/packages/hwriter/

Hoping this package will be useful to the R community,
Best regards,

Greg
-- 
Gregoire Pau
EMBL/EBI Cambridge, UK
http://www.ebi.ac.uk/~gpau



From madorazi at istat.it  Mon Oct 13 10:39:58 2008
From: madorazi at istat.it (Marcello D'Orazio)
Date: Mon, 13 Oct 2008 10:39:58 +0200
Subject: [R-pkgs] New package: StatMatch 0.4
Message-ID: <48F3095E.6050809@istat.it>

Dear useRs,

I am pleased to announce the availability of the new package 'StatMatch'
(version 0.4)
http://cran.at.r-project.org/web/packages/StatMatch/index.html


'StatMatch' contains some functions to perform Statistical Matching.
Statistical Matching methods aim at integrate two samples, referred to
the same target population, sharing a certain number of common variables
but without overlapping of the units.
Note that some functions in 'StatMatch' can also be used to impute
missing values in a data set.

Best Regards,
Marcello D'Orazio

-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 Marcello D'Orazio

 ISTAT       (Italian National Statistical Institute)		
 Via Cesare Balbo, 16 (1? piano, stanza 153)
 00184 ROMA  ITALY
 Tel.: +39 06 4673 2772
 Fax:  +39 06 4673 2955
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
________________________________________________________________________

 Legal Disclaimer:
 Any views expressed by the sender of this message are not necessarily
 those of the Italian National Statistical Institute.



From edd at debian.org  Wed Oct 15 04:41:37 2008
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 14 Oct 2008 21:41:37 -0500
Subject: [R-pkgs] New package RPostgreSQL 0.1.0
Message-ID: <18677.22625.526067.785258@ron.nulle.part>


       RPostgreSQL version 0.1.0

We are pround to announce the availability of the RPostgreSQL package on CRAN
and its mirrors.  This package provides an a DBI-compliant interface between
PostgreSQL and R.

RPostgreSQL was developed as part of the Google Summer of Code 2008 program
by Sameer Kumar Prayaga.

Some highlights:

  o  Implemented all the DBI features 

  o  Added support for transaction management 

  o  Added type mapping for dates & timestamps

Known bugs/deficiencies:

  o  Building on Windows unknown/untested. Feedback welcome

RPostgreSQL is hosted on Google Code, for more information see

   http://rpostgresql.googlecode.com/

For any suggestions and queries, please contact:

   Sameer Kumar Prayaga <sameer.bits at gmail.com>
   Dirk Eddelbuettel <edd at debian.org>

-- 
Three out of two people have difficulties with fractions.



From rmpruzek at yahoo.com  Tue Oct 14 20:02:24 2008
From: rmpruzek at yahoo.com (bob pruzek)
Date: Tue, 14 Oct 2008 11:02:24 -0700 (PDT)
Subject: [R-pkgs] New versions of two packages: granova and PSAgraphics
Message-ID: <895632.31528.qm@web63406.mail.re1.yahoo.com>

Dear R users,

This is to announce new versions of our packages granova and PSAgraphics, both now v.1.2.

granova derives from ?graphical analysis of variance.? The package consists of four functions that facilitate seeing basic data as well as standard summary statistics for various ANOVA applications. The functions are especially flexible, so they are able to handle widely different data specifications. Focus is directed to basic questions that drive methods, so that the graphics can help to learn how data play out in answer to question(s) posed by methods. Experience suggests these functions can be particularly helpful for students and non-statistician analysts, since they help understand the methods themselves, as well as the data. Dynamic graphics are used to depict two-way data. In all cases numerical results accompany the graphical displays. 

PSAgraphics aims chiefly to facilitate visualization of various results in the context of propensity score analysis. One set of functions concerns assessment of covariate balance, with respect to defined propensity scores; both numerical and graphical functions are provided. Two other functions help to understand PSA effects after adjustment for propensity scores. The functions have been designed to be flexible, and in all cases numerical results complement the graphic displays. 

Various documents and displays that illustrate graphic results for these methods are available; write rmp at  rmpruzek at yahoo.com . 

All comments, suggestions for improvement and bug-reports are solicited.

Bob Pruzek & James Helmreich








From ggrothendieck at gmail.com  Mon Oct 20 15:45:36 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 20 Oct 2008 09:45:36 -0400
Subject: [R-pkgs] New verion 0.3-7 of gsubfn package
Message-ID: <971536df0810200645m1c5e1f77ga408fc02e67f3f07@mail.gmail.com>

Version 0.3-7 of the gsubfn package is available on CRAN.
Changes to the package are:

- all known bugs have been fixed.

- in gsubfn and strapply the replacement object can be a
  list (or a function, formula, character string or proto
  object, as before).  In the case of a list, regexp matches
  are looked up in the list names and the corresponding list
  component used.

  # Example 1 - at string end replace M with e6 & G with e9
  gsubfn(".$", list(M = "e6", G = "e9"), c("19G", "32.5M"))

- the backref= argument in gsubfn now defaults to the
  negative of its prior default.  Thus by default if there
  are back references only they and not the entire match is
  passed to the user function.  (Although the changed
  default introduces an incompatibility with prior versions
  this incompatability is small because it only affects
  situations where back references are present in the
  regular expression _and_ backref= was not used. Since the
  previous default for backref= was not useful in that case
  there would be very few, if any, such instances.)  On the
  other hand, it does mean that the backref= argument can be
  omitted most cases now.

For more info, see home page and brief description below.
	http://gsubfn.googlecode.com

The gsubfn package - summary
============================

A seemingly small enhancement to R's gsub function, allowing
the replacement string to be a function, formula, list or
proto object gives surprising additional power allowing
parsing of strings by content rather than delimiters.  e.g.
extract numbers:

	# Example 2. Replace each number with its increment
	gsubfn("[0-9]+", ~ as.numeric(x) + 1, "90 and 17")

	# Example 3. extract numbers
	strapply("Over 90 stones in 17 places", "[0-9]+")

The optional function passed to gsubfn and strapply may be
specified using usual R function notation or by a formula
whose left hand side represents the arguments (defaulting to
variables appearing in right hand side) and whose right hand
side represents the body.  In order to extend this
functionality beyond gsubfn and strapply to the rest of R
any R function may be prefaced with fn$ like this:

	# Example 4. Integrate x^2
	fn$integrate(~ x^2, 0, 1)

It also supports quasi-perl style string interpolation:

	# Example 5. Quasi-perl style string interpolation
	fn$cat("pi = $pi and e = `exp(1)`\n")

match.funfn is an alternative to match.fun which allows
developers to add this functionality to their own functions
by simply replacing match.fun with match.funfn -- a one line
change.  In that case even the fn$ prefix is not needed.



From clement.calenge at oncfs.gouv.fr  Mon Oct 27 20:24:13 2008
From: clement.calenge at oncfs.gouv.fr (=?UTF-8?B?Q2zDqW1lbnQgQ2FsZW5nZQ==?=)
Date: Mon, 27 Oct 2008 20:24:13 +0100
Subject: [R-pkgs] adehabitat version 1.8
Message-ID: <4906155D.8020508@oncfs.gouv.fr>

Dear all,

I have uploaded to CRAN the version 1.8 of the package 'adehabitat'.
Significant changes are listed below:

* getverticeshr now relies on the function contourLines(), and returns
   smoother estimates of the kernel home range (see the help page).

* the new function kernelkc (and related functions) now allows the
   estimation of the utilization distribution in space and time of
   animals using the product kernel algorithm advocated by Keating and
   Cherry (Ecology, in press).

* the new function findmaxasc allows to find the local maxima on a map
   of class 'asc'. It can be potentially useful to identify the points
   of attraction in the home range of an animal (modes of the
   utilization distribution).

* the new functions engen2008I and engen2008II implements the method of
   Engen et al. (2008, Journal of Animal Ecology) for the study of
   habitat selection using multivariate data.

* The function dunnfa performs a factorial decomposition of the
   Mahalanobis distances in habitat selection studies. This method has
   been suggested by Prof. James Dunn as an alternative

* A new bug tracking system has been set up for adehabitat thanks to
   the great work of Paolo Cavallini (Faunalia). It is available at:
   https://www.faunalia.it/animove/trac/
   Any other project intended to manage, store, analyze animals
   movements can be added there, provided it is free and open source.

* Note that my e-mail adress has changed. It is now:
clement.calenge at oncfs.gouv.fr

Happy testing,


Cl?ment Calenge

-- 
Cl?ment CALENGE
Office national de la chasse et de la faune sauvage
Saint Benoist - 78610 Auffargis
tel. (33) 01.30.46.54.14



From Adrian.Baddeley at csiro.au  Mon Nov  3 09:08:17 2008
From: Adrian.Baddeley at csiro.au (Adrian Baddeley)
Date: Mon, 3 Nov 2008 17:08:17 +0900
Subject: [R-pkgs] scuba 1.2-2 posted
Message-ID: <490EB171.6070402@csiro.au>


        scuba 1.2-2

'scuba' is a contributed package that performs theoretical calculations
about scuba diving --- dive profiles, decompression models, gas toxicity
and so on.

New features in version 1.2-2:

        . Package vignette provides detailed explanations.

        . Improved handling of data from dive computers.

        . Gas switches (switching from one tank of breathing gas
          to another during the dive) are now easy to specify.

        . Relative tissue saturations can be computed easily

        . Eleven new datasets: real dive profiles

        . Dives with multiple tanks of breathing gas are now plotted
           using a different colour for each gas.

New functions:

        whichtank
        whichtank<-
                        Choice of breathing gas tank
                        at each waypoint during the dive

Improvements:

        dive
                For easier handling of data uploaded from dive computers,
                dive() now accepts elapsed time values in the formats
                "hh:mm:ss", and "mm:ss" where mm can exceed 60.

        plot.dive
                Dives with multiple tanks of breathing gas are now plotted
                using a different colour for each gas.

                The choice of colours is controlled by the
                argument 'col.gases'.

        haldane
                This function has a new argument 'relative'.
                If relative=TRUE, tissue saturations are computed
                as fractions of the surfacing M-value.

        ndl
                Improved numerical stability, in mixed-gas case.

                The return value of ndl now has an attribute
                which identifies the controlling tissue.

        showstates
                Improved plot labels.

Adrian Baddeley, 30 october 2008



From arne.henningsen at googlemail.com  Sat Nov  8 22:53:20 2008
From: arne.henningsen at googlemail.com (Arne Henningsen)
Date: Sat, 8 Nov 2008 22:53:20 +0100
Subject: [R-pkgs] New package "frontier" for Stochastic Frontier Analysis
	(SFA)
Message-ID: <200811082253.20567.arne.henningsen@googlemail.com>

Hi!

A few weeks ago, I have uploaded a new R package "frontier" for Stochastic 
Frontier Analysis (SFA) [1] to CRAN [2]. It includes the FORTRAN code of Tim 
Coelli's [3] software "Frontier 4.1" [4]. Hence, the R package "frontier" 
should have the same capabilities as "Frontier 4.1", i.e. Maximum Likelihood 
Estimation of Stochastic Frontier Production and Cost Functions. Two 
specifications are available: the error components specification with 
time-varying efficiencies (Battese and Coelli, 1992) [5] and a model 
specification in which the firm effects are directly influenced by a number 
of variables (Battese and Coelli, 1995) [6].
     The functions "front41WriteInput" and "front41ReadOutput" for creating 
input files for and reading output files of "Frontier 4.1" will be moved from 
the "micEcon" package [7] to the "frontier" package within a short time.
     The "frontier" package is developed on R-Forge [8]. All useRs and 
developeRs are invited to contribute to this package.

[1] http://en.wikipedia.org/wiki/Stochastic_Frontier_Analysis
[2] http://cran.r-project.org/web/packages/frontier/index.html
[3] http://www.uq.edu.au/economics/cepa/coelli.htm
[4] http://www.uq.edu.au/economics/cepa/frontier.htm
[5] Battese, G. E. & Coelli, T. J. (1992): Frontier Production Functions, 
Technical Efficiency and Panel Data: With Application to Paddy Farmers in 
India. Journal of Productivity Analysis, 3, p. 153-169.
[6] Battese, G. E. & Coelli, T. J. (1992) A Model for Technical Inefficiency 
Effects in a Stochastic Frontier Production Function for Panel Data. 
Empirical Economics, 20, p. 325-332.
[7] http://cran.r-project.org/web/packages/micEcon/index.html
[8] http://r-forge.r-project.org/projects/frontier/

Any hints, suggestions, and bug reports are welcome,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name



From mdsumner at utas.edu.au  Mon Nov 10 13:09:08 2008
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Mon, 10 Nov 2008 23:09:08 +1100
Subject: [R-pkgs] trip package: version 1.1-2
Message-ID: <49182464.8050005@utas.edu.au>

Hello,

A long overdue update to the 'trip' package is now on CRAN.

o New function forceConstraints() to impose the common problems found in 
track data of duplicated records, and duplicated time stamps.
o Bug fix to speedfilter() which would never finish for trips of 3 
locations.
o Clean up of trip methods to fix a bug that caused R CMD check to fail 
in 2.8.0.

Thanks to all who provide feedback for problems and ideas for improvements.

Regards,
Mike.



From cepardot at unal.edu.co  Sat Nov 15 23:19:58 2008
From: cepardot at unal.edu.co (Campo Elias Pardo Turriago)
Date: Sat, 15 Nov 2008 17:19:58 -0500
Subject: [R-pkgs] New Package FactoClass
Message-ID: <f6df8039264f.491f04be@unal.edu.co>

  new R package FactoClass to combine factorial methods and cluster
analysis is uploaded to CRAN. This package is implemented in order to perform a
multivariate exploration of a data table according to Lebart et al. (1995). We
use some ade4 functions (Chessel et al. 2004) to perform the factorial analysis
of the data and some stats functions in R to perform cluster methods.
Some new functions are programmed to make specific tasks and another old
ones are modified.


Campo-El?as PARDO
Departamento de Estad?stica
Universidad Nacional de Colombia - Bogot?



From felix at nfrac.org  Tue Nov 18 05:15:14 2008
From: felix at nfrac.org (Felix Andrews)
Date: Tue, 18 Nov 2008 15:15:14 +1100
Subject: [R-pkgs] latticist and playwith
Message-ID: <94730b8a0811172015l6c8dbd25l19388100b3540f53@mail.gmail.com>

A new package, *latticist*, is available now from CRAN.

Latticist is a graphical user interface for exploratory visualisation.
It is primarily an interface to the Lattice graphics system, but also
produces displays from the vcd package for categorical data.

Given a multivariate dataset (either a data frame or a table),
Latticist attempts to produce useful displays based on the properties
of the data. The user chooses variables for the plot axes, for
grouping, conditioning and subsetting. Some hypervariate displays are
also available. The plots can be customised by editing the calls used
to generate them.

A simple graphical user interface is available, built on the gWidgets
package. This requires one of the "toolkit implementations" to be
installed: currently gWidgetstcltk or gWidgetsRGtk2 (note, the
gWidgetsrJava toolkit is still in testing). Alternatively, Latticist
can be run as a toolbar extension to playwith. This brings many extra
features, such as dynamic zooming, identifying data points, etc.

A major new version of *playwith* is also available.

The playwith package provides a GTK+ graphical user interface for
editing and interacting with R plots. It has been redesigned, and the
GUI has been overhauled completely. The most prominent new features
are linked brushing, identifying co-variates of data points, dialogs
boxes for various settings, and a better API.

The websites for playwith and latticist include screenshots and demos.

http://latticist.googlecode.com/
http://playwith.googlecode.com/

Feedback welcome...

(and job offers? :-)
-- 
Felix Andrews / ???
http://www.neurofractal.org/felix/
3358 543D AAC6 22C2 D336  80D9 360B 72DD 3E4C F5D8



From pgilbert at bank-banque-canada.ca  Tue Nov 18 19:37:53 2008
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue, 18 Nov 2008 13:37:53 -0500
Subject: [R-pkgs] Packages for time series databases
Message-ID: <49230B81.2060604@bank-banque-canada.ca>

I recently put several packages for time series databases on CRAN. The 
main package, TSdbi, provides a common interface to time series 
databases. The objective is to define a standard interface so users can 
retrieve time series data from various sources with a simple, common, 
set of commands, and so programs can be written to be portable with 
respect to the data source. The SQL implementations also provide a 
database table design, so users needing to set up a time series database 
have a reasonably complete way to do this easily. The interface provides 
for a variety of options with respect to the representation of time 
series in R. There is also a (not yet well tested) mechanism to handle 
multilingual data documentation.

-TSdbi  is the main package.

-TSMySQL,  TSPostgreSQL, and  TSSQLite provide interfaces for these 
three SQL databases  (using RMySQL, RSQLite, and RPostgreSQL).

-TSodbc  provides an interface using RODBC (tested only with a 
PostgreSQL server).

-TSfame  provides an interface to Fame using the fame package.

-TSpadi  provides an interface to Fame using a (somewhat dated) padi server.

-TShistQuote  provides an interface to get.hist.quote.

Many thanks to the authors and maintainers of the underlying packages, 
and several people who have commented on early versions of the TS* packages.

Paul Gilbert
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

------------------------------------------------------------------------------------

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

From h.wickham at gmail.com  Fri Nov 21 13:53:31 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 21 Nov 2008 06:53:31 -0600
Subject: [R-pkgs] ggplot2 - version 0.8
Message-ID: <f8e6ff050811210453u2a5edd8dkcc0b8553872a1b81@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the nearly 500
examples of ggplot in use.  If you're interested, you can also sign up to
the ggplot2 mailing list at http://groups.google.com/group/ggplot2, or track
development at  http://github.com/hadley/ggplot2

ggplot2 0.8  (2008-11-18)
----------------------------------------

The two biggest new features in this release are the (long awaited)
ability to have scales that vary between facets, and a faceting system
that works like lattice (facet_wrap). From qplot, you can use
facet_wrap by specifying one sided formula (~ colour, as opposed to .
~ color). To see some potential uses for these new features, see the
"Positioning" chapter of the book or the documentation for facet_wrap
and facet_grid.  Implementing these changes has required a rewrite of
large parts of the coordinate systems code, so if anything seems
strange with non-Cartesian coordinate systems, please get in touch.

I've also made another round of tweaks to make the plots more
aesthetically pleasing.  This includes using a bright blue colour for
geoms used to add statistical summaries to plots (contour, smooth, and
quantiles), and tweaking the default colour scheme for the continuous
colour scale.  Please let me know what you think.  Remember that most
of these options are controllable with the theming system - see the
book chapter "Polishing your plots for publication".

Accompanying this new release of the package is an updated and
expanded version of the book.  The content of the book is now largely
complete (~170 pages), and over the coming months I will be working on
make it polished and easy to understand.  See
http://had.co.nz/ggplot2/book.  I love to hear your feedback about the
book, but at this point please don't bother reporting minor typos, I
would much rather hear about what you want to do, but can't figure out
from the book.

Other new features:

* geom_bin2d/stat_bin2d & geom_hex/stat_binhex: for 2d square and
hexagon binning, particularly useful for alleviating overplotting in
scatterplots
* geom_freqpoly: draws frequency polygons (= stat_bin + geom_line)
* scale_position: both discrete and continuous gain a new formatter
argument to control the default formatting of the axis labels.  See
also the handy numeric formatters: dollar, comma and percent
* the xlim and ylim functions now produce discrete scales when
appropriate, and generate a reverse scale if the minimum is greater
than the maximum

Improvements

* coord_map gains experimental axis labels
* facet_grid: new support for varying scales in rows and columns
* facet_wrap: new faceter which wraps a 1d ribbon of panels into 2d,
in a similar way to lattice
* geom_bin: gains a drop argument to control whether or not 0 count
bins should be removed
* geom_path and geom_line gain arrows argument to match geom_segment
* ggsave now checks that you are using it with a ggplot plot
* ggsave now produces postscript files that are suitable for embedding
in another document
* ggsave now recognises the .svg extension and will produce svg files,
if possible
* ggsave: default dpi changed to 300, on the assumption that you are
saving the plot for printing
* qplot: uses facet_wrap if formula looks like ~ a + b (as opposed to a ~ b)

Aesthetic tweaks

* geom_bar, geom_polygon, geom_rect, ...: default fill colour is now
much closer to black to match the defaults in other geoms (point,
line, etc)
* geom_line, geom_path, geom_segment: lines have squared ends
* geom_point, geom_pointrange and geom_boxplot: now use shape = 16
instead of 19.  This shape does not have a border from R 2.8 on, and
so will look better when displayed transparently.
* geom_contour, geom_density2d, geom_quantile and geom_smooth use a
bright blue colour for lines, to make them stand out when used with
black points
* scale_gradient: tweaked default colours to make more aesthetically pleasing
* theme: new theme setting panel.margin (a unit) controls gap between
panels in facetted plots (for both grid and wrap)
* theme_gray: removed black border around strips
* theme_bw: tweaks to make black and white theme look a little nicer

Bug fixes

* coord_cartesian now correctly clips instead of dropping points
outside of its limits
* facet_grid: margins now grouped correctly in default case
(non-aesthetic variables ignored when generating default group value)
* facet_grid: fix long standing bug when combining datasets with
different levels of facetting variable
* geom_smooth calls stat::predict explicitly to avoid conflicts with
packages that override predict for S4 model classes
* grid: correctly expose subcomponents of strips and axes
* mapping aesthetics to functions of stat output now works in a much
wider variety of cases
* order aesthetic should now work with bars (and in general more geoms)
* position_dodge now works with points and other geoms that lack xmin and xmax
* scale_area works once more
* scale_discrete_position: empty levels are no longer displayed by
default, if you want them, use breaks = levels(myfactor)
* scale_discrete_position: fixed bug when limits were set
* scale_discrete_position: more aesthetically pleasing expansion for a
wider ranges of plots (picks expansion based on whether or not geom
with width used, e.g. bars)
* scale_gradient*: axes are correctly labelled when a transformation is used
* scale_x_log10, scale_y_sqrt etc now correctly transform output from
statistics as well as raw data
* scale_z_* now removed because no longer used by anything
* stat_bin: correctly returns 0 when no observations in a bin (was
previously returning NA)
* stat_quantreg: deal with yet another new output format from quantreg
* stat_contour now has arguments to control the position of the
contours, rather than relying on the z scale
* theme: panel.empty setting removed as it is no longer used
* theme_grey now aliased to theme_gray
* theme_line: setting size works correctly
* theme_rect, theme_segment: size now measured in mm, to be consistent
with the rest of ggplot

Regards,

Hadley

-- 
http://had.co.nz/



From Mike.Prager at noaa.gov  Thu Nov 20 14:13:52 2008
From: Mike.Prager at noaa.gov (Michael H. Prager)
Date: Thu, 20 Nov 2008 08:13:52 -0500
Subject: [R-pkgs] Update of X2R (with FishGraph) at CRAN, 20 Nov 2008
Message-ID: <49256290.1070309@noaa.gov>

X2R is a bundle of three software libraries for passing complicated data 
structures from Fortran, C/C++, or AD Model Builder to R.  An update has 
been sent to CRAN and should be available from mirrors shortly. From the 
menu at the left of the CRAN home page, look under Software / Other. 

We also have updated FishGraph, a compatible set of R functions for 
examining output from fish population models.  

* * *

Changes in this Update

The update adds minor bug fixes only.  In For2R, nested lists are now 
handled correctly.  In FishGraph, correct axis units are now used in the 
CLD.plots (catch, landings, discards) routine.

* * *

More detail, for those interested:

X2R is three independent but related software libraries:  C2R, ADMB2R, 
and For2R (together, X2R). Each contains output routines to  simplify 
transfer of complicated data structures from models written in a 
compiled language to R (note 1). Through calls to X2R routines, the 
user's data is written as a structured ASCII file. That file can be read 
by R with a single dget() function call to create an R data object of 
type list. The list may contain components such as vectors, data frames, 
matrices, and other lists.

These are NOT R packages; rather they are subroutine libraries to be 
used with programmers' own modeling codes. Limited testing indicates 
compatibility with S-PLUS, as well (note 2).

Languages supported are Fortran 95 (with For2R), C and C++ (with C2R) 
and AD Model Builder (with ADMB2R) (note 3).  Source code and detailed 
users' manuals are supplied.

ADMB2R has been tested with ADMB versions 6.03 and 7.71 and recent 
versions of the gcc and Borland C++ compilers.

The compatible software FishGraph is a set of R functions providing 
exploratory and presentation graphics of fishery catch-at-age or 
catch-at-length models. By taking its data from an R list assumed to 
have a certain structure (diagram provided), FishGraph determines which 
graphs should be generated. The required data structure may be generated 
with X2R or within R itself and may contain any amount of additional 
data. Most FishGraph routines have options to control titles, colors, 
and reference lines. The combination of X2R and FishGraph allows 
automating graphics from routine fish stock assessments. The FishGraph 
functions can be modified or supplemented to reflect the needs of the 
analysis at hand.

X2R is supplied as files X2R.zip and X2R.tar.gz, which are equivalent.  
Version and release date are found in file  "VersionInfo.txt" in the 
root of each archive. The new version is dated November 19, 2008.

FishGraph (same CRAN directory) is supplied as a Windows installer.  We 
will gladly collaborate with anyone interested in adapting FishGraph to 
other operating systems.

This work has been tested and is regularly used by the authors. However, 
any software may contain bugs, and these works are classified by NOAA as 
"Experimental Products."  THIS SOFTWARE IS SUPPLIED WITH NO WARRANTY OF 
ANY KIND. The authors will endeavor to fix bugs promptly and to add 
requested features.  Send bug reports, suggestions, and extensions to

Michael H. Prager - mike.prager at noaa.gov
Southeast Fisheries Science Center
National Marine Fisheries Service, NOAA
101 Pivers Island Road
Beaufort, North Carolina 28516 USA


* Note 1. Use of product names (commercial or otherwise) does not imply 
endorsement or recommendation by any U.S. government agency, nor by the 
authors in their government capacities.
* Note 2. S-PLUS is a commercial product that requires licensing by the 
user.
* Note 3. AD Model Builder, formerly a commercial product, is now an 
open-source free-software project. See http://admb-project.org/.



From ronggui.huang at gmail.com  Mon Nov 24 07:39:11 2008
From: ronggui.huang at gmail.com (ronggui)
Date: Mon, 24 Nov 2008 14:39:11 +0800
Subject: [R-pkgs] RQDA-0.1.5 is released
Message-ID: <38b9f0350811232239p3e19a0feh112e53eee9376e84@mail.gmail.com>

RDQA is a package for Qualitative Data Analysis built upon R. It works
both on the Windows and Linux/FreeBSD platforms. RQDA is an
easy-to-use tool to assist in the analysis of textual data. At the
present, it supports only plain text format data. All the information
is stored in SQLite database via the R package of RSQLite. The GUI is
based on RGtk2, via the aid of gWidgetsRGtk2. It includes a number of
standard Computer-Aided Qualitative Data Analysis features. Besides,
it seamlessly integrated with R, which means that a) statistical
analysis on the coding is possible, and b) functions about data
manipulation and analysis can be easily extended by writing R
functions. To some extent, RQDA and R makes an integrated platform for
both quantitative and qualitative data analysis.

The current version should be regarded as Release Candidate Version, I
will test it preliminary under Chinese Windows  OS, but it should work
under Linux and FreeBSD.

By the GUI, it can:
# Import documents from plain text
# Support non-English documents, Simplified Chinese Character is
well-tested under Windows
# Character-level coding using codes
# Memos of documents, codes, coding, project, files and more
# Retrieval of coding
# Single-file (*.rqda) format, which is basically SQLite database.
Data are stored in UTF-8, so it should be portable
# Facilitator helps to categorize codes,which is key to theory
building. I deliberately avoid using tree-like categorization
# There is a case category, which is crucial feature to bridge
qualitative and quantative research
# Search information about selected case from the Internet vis popup menu
# Temporary delete files and codes
# Rename the files,code, code category, case and others

More information can be found in http://rqda.r-forge.r-project.org/

Comments and suggestions are welcome:)

-- 
HUANG Ronggui, Wincent
Tel: (00852) 3442 3832
Ph.D. Candidate, CityU of HK
Master of sociology, Fudan University, China
Bachelor of Social Work, Fudan University, China
Personal homepage: http://ronggui.huang.googlepages.com/



From dusa.adrian at gmail.com  Tue Nov 25 20:01:01 2008
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Tue, 25 Nov 2008 21:01:01 +0200
Subject: [R-pkgs] RQDA-0.1.5 is released
In-Reply-To: <38b9f0350811232239p3e19a0feh112e53eee9376e84@mail.gmail.com>
References: <38b9f0350811232239p3e19a0feh112e53eee9376e84@mail.gmail.com>
Message-ID: <200811252101.02073.dusa.adrian@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20081125/afd230d3/attachment-0001.pl>

From jfox at mcmaster.ca  Fri Nov 28 16:22:34 2008
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 28 Nov 2008 10:22:34 -0500
Subject: [R-pkgs] version 2.0-0 of the effects package
Message-ID: <001101c9516d$237253b0$6a56fb10$@ca>

Dear R users,

I'd like to announce version 2.0-0 of the effects package, which is now on
CRAN. The package constructs graphical and tabular "effect displays," e.g.,
of interactions, for several kinds of models. These displays are
generalizations of "adjusted" means in linear models. 

The major addition to the package is the ability to display terms in
multinomial and proportional-odds logit models (using results described in
Fox, J. and R. Andersen (2006), "Effect displays for multinomial and
proportional-odds logit models," Sociological Methodology 36, 225-255; the
original package was described in Fox, J. (2003), "Effect displays in R for
generalised linear models," Journal of Statistical Software 8:15, 1-27.)

The new version of the package is co-authored with Jangman Hong.

Regards,
 John

------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox



From edd at debian.org  Wed Dec  3 03:46:11 2008
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 2 Dec 2008 20:46:11 -0600
Subject: [R-pkgs] Rcpp package relaunched
Message-ID: <18741.62195.684768.963812@ron.nulle.part>


New Rcpp versions 0.6.0 and 0.6.1
---------------------------------
		
The Rcpp package provides C++ classes that greatly facilitate interfacing C
or C++ code in R packages using the .Call() interface provided by R.

Rcpp provides matching C++ classes for a large number of basic R data
types. Hence, a package author can keep his data in normal R data structure
without having to worry about translation or transfer to C++. At the same
time, the data structures can be accessed as easily at the C++ level, and
used in the normal manner.

The mapping of data types works in both directions. It is as straightforward
to pass data from R to C++, as it is it return data from C++ to R.  The
following two sections list supported data types.

Transfer from R to C++:
Standard R datatypes that are understood in C++ are
 o named lists containing numeric (i.e. floating point), integer,
   character, logical (i.e. boolean) or Date and Datetime (i.e. POSIXct at
   the microsecond granularity) arguments;
 o data frames containing numeric, integer, logical, character,
   Date, Datetime or Factor columns;
 o named vectors containing numeric or integer values,
 o vectors and matrices of different values
 o character strings

Transfer from C++ to R:
Standard C++ datatypes can be returned to R in a named list, the most
general data type in R.  Permissible components of the returns list
are the following C++ types:
 o double (scalar as well as vectors and vectors of vectors),
 o int (scalar as well as vectors and vectors of vectors), string,
 o STL vector types and vector<vector> types of int and double
 o STL vector of strings
 o internal Rcpp types RcppDate, RcppDateVector, RcppDatetime,
   RcppDatetimeVector, RcppStringVector, RcppVector of int or double,
   RcppMatrix of int or double, RcppFrame

Rcpp was initially written by Dominick Samperi as part of his contributions
to RQuantLib, and later released as a standalone package (under both the Rcpp
and RcppTemplate names).   Its development had ceased in late 2006.

As of November 2008, I have made new release with substantially expanded
documentation, simpler yet more comprehensive build structure leading to
easier use of Rcpp from other packages, and support for Windows, Linux and
Mac OS X (with special thanks to Simon for some extended cluebat waving).

More information for Rcpp can be found at
 o the package homepage at http://dirk.eddelbuettel.com/code/rcpp.html
 o the R-forge repository at https://r-forge.r-project.org/projects/rcpp/
 o the CRAN page at http://cran.r-project.org/web/packages/Rcpp/index.html

Regards,  Dirk
 
-- 
Three out of two people have difficulties with fractions.



From jeff.horner at vanderbilt.edu  Fri Dec  5 17:03:30 2008
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Fri, 05 Dec 2008 10:03:30 -0600
Subject: [R-pkgs] RMySQL 0.7-2 now available on CRAN
Message-ID: <493950D2.1090806@vanderbilt.edu>

Dear R users,

RMySQL 0.7-2 is now available on CRAN:

http://cran.r-project.org/web/packages/RMySQL/index.html

 From the NEWS file:

* New maintainer is Jeffrey Horner <jeff.horner at vanderbilt.edu>.

* We no longer distribute libmysql.dll. This library is now found
  either by reading the MYSQL_HOME environment variable or by reading
  the windows registry entries.

* Removed dependence on MySQL C function load_defaults() as it was
  meant for command-line tools, not for (re)connecting to a database.

* Fixed \r issue with dbWriteTable().

* Tests have been added and depend on proper values set in the
  environment variables MYSQL_DATABASE, MYSQL_USER, and
  MYSQL_PASSWD.

Best,

Jeff



From arne.henningsen at googlemail.com  Tue Dec  9 17:33:21 2008
From: arne.henningsen at googlemail.com (Arne Henningsen)
Date: Tue, 9 Dec 2008 11:33:21 -0500
Subject: [R-pkgs] SFA tools moved from micEcon to frontier
Message-ID: <200812091133.21668.arne.henningsen@googlemail.com>

Dear R users,

I would like to inform you that everything of the "micEcon" package that is 
related to Stochastic Frontier Analysis (SFA) has been moved to the "frontier" 
package, because this is a more appropriate place for the functions 
"front41WriteInput", "front41ReadOutput", and "front41Est", and the 
corresponding (S3) methods. The data sets "riceProdPhil" and "Coelli" have 
been removed from the "micEcon" package, because they were already included in 
the "frontier" package (the latter is named "front41Data" in the "frontier" 
package). The new "frontier" package (with the "front41..." functions) is 
available on CRAN now and the new "micEcon" package (without the "front41..." 
functions) will be available on CRAN in some time. Please use the meantime to 
update your code. 

Please don't hesitate to contact me if you have any questions 
or comments,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name/



From h.wickham at gmail.com  Sun Dec 14 21:38:36 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 14 Dec 2008 14:38:36 -0600
Subject: [R-pkgs] New version of ggplot2, 0.8.1
Message-ID: <f8e6ff050812141238y4dbf8079w37890ded03e5e060@mail.gmail.com>

ggplot2 ------------------------------------------------------------

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the nearly 500
examples of ggplot in use.  If you're interested, you can also sign up to
the ggplot2 mailing list at http://groups.google.com/group/ggplot2, or track
development at  http://github.com/hadley/ggplot2

ggplot2 0.8.1  (2008-12-12)
----------------------------------------

New features

* new labs, xlab & ylab functions for easily modifying axis labels and
legend titles
* qplot now guesses what geom you want based on the position
aesthetics that you provide:
  * both x & y: scatterplot
  * only x: histogram
  * only y: scatterplot of seq_along(y) vs y
* scale_datetime: a first attempt at a scale for date time objects of
class POSIXt

Aesthetic improvements

* legends should now work in cases where you have multiple layers the
use the same geom and have different aesthetic mappings
* theme: new theme setting legend.key.size determines size of keys in legend
* theme: new theme setting plot.margins to control the plot margins
* tweaks to plot and legend layout

Other minor improvements

* geom_point warns if missing values present in data and not displayed on plot
* geom_smooth gives a more accurate warning when you have incorrectly
specified the grouping
* geom_smooth will switch to an alternative smoothing method
(mgcv::gam(y ~ s(x, bs = "cr"))), when there are more than 1000
observations
* layers gain a legend argument, which allow you to force the layer
either into (TRUE) or out of (FALSE) the legend

Bug fixes

* coord_equal now calculates scales correctly again
* coord_flip: flips axes labels again too
* coord_trans fix bug where transformation incorrect
* facet_grid: fix bug where tick labels where being produced outside
the range of the axes
* facet_wrap: fixed bug with ncol = 1 or nrow = 1
* facet_wrap: labels correctly clipped to axis ranges
* facet_wrap: labels will match panels even when factor levels are not
in alphabetical order
* facet_wrap: now works when a layer doesn't contain every level of
the faceting variables
* geom_abline should now work in a wider variety of situations
* geom_smooth now gives correct asymmetric standard errors with
generalised linear models (thanks to Thierry Onkelinx)
* geom_vline and geom_hline now correctly transform their intercepts
if the scale is transformed
* geom_vline and geom_hline: now use xintercept and yintercept instead
of intercept
* legend.position and legend.justification work again
* position_dodge now works for any number of elements with smaller
widths, not just 2!
* scale_discrete_position: does a better job of calculating axis
limits when plotting a mixture of continuous and discrete values (e.g.
with geom_jitter)
* summary: tweaks to improve output


-- 
http://had.co.nz/



From chenshu at med.umich.edu  Mon Dec 15 20:14:21 2008
From: chenshu at med.umich.edu (Shu Chen)
Date: Mon, 15 Dec 2008 14:14:21 -0500
Subject: [R-pkgs] R CMD check on window XP
Message-ID: <4946663D.43DF.0027.0@med.umich.edu>

Hi, there,

I used R CMD check  to build my "ATGGS" package under window XP system. My R version is 2.7.2. But I encounter some problems. The log file is like:
**********************************************************************************
installing R.css in C:/ATGGS.Rcheck


---------- Making package ATGGS ------------
  adding build stamp to DESCRIPTION
  installing R files
  installing inst files
find: `C:/ATGGS.Rcheck/ATGGS/csvscripts': Permission denied
make[2]: *** [C:/ATGGS.Rcheck/ATGGS/inst] Error 1
make[1]: *** [all] Error 2
make: *** [pkg-ATGGS] Error 2
Can't read C:/ATGGS.Rcheck/ATGGS/auxData: Invalid argument at c:\R\R-27~1.2/bin/INSTALL line 434
Can't remove directory C:/ATGGS.Rcheck/ATGGS/auxData: Directory not empty at c:\R\R-27~1.2/bin/INSTALL line 434
Can't read C:/ATGGS.Rcheck/ATGGS/csvData: Invalid argument at c:\R\R-27~1.2/bin/INSTALL line 434
Can't remove directory C:/ATGGS.Rcheck/ATGGS/csvData: Directory not empty at c:\R\R-27~1.2/bin/INSTALL line 434
Can't read C:/ATGGS.Rcheck/ATGGS/csvscripts: Invalid argument at c:\R\R-27~1.2/bin/INSTALL line 434
Can't remove directory C:/ATGGS.Rcheck/ATGGS/csvscripts: Directory not empty at c:\R\R-27~1.2/bin/INSTALL line 434
Can't read C:/ATGGS.Rcheck/ATGGS/doc: Invalid argument at c:\R\R-27~1.2/bin/INSTALL line 434
Can't remove directory C:/ATGGS.Rcheck/ATGGS: Directory not empty at c:\R\R-27~1.2/bin/INSTALL line 434
*** Installation of ATGGS failed ***

Removing 'C:/ATGGS.Rcheck/ATGGS'

****************************************************************************************

I am not able to delete c:/ATGGS.Rcheck until I change the permission of the folder. I'm the admin of C driver. I have full control of all other folders under  C driver.


Thanks for help.

Sue



**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues



