From pls at mevik.net  Tue Jan  2 13:36:32 2007
From: pls at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik_and_Ron_Wehrens?=)
Date: Tue, 02 Jan 2007 13:36:32 +0100
Subject: [R-pkgs] pls version 2.0-0
Message-ID: <m0sleta9m7.fsf@bar.nemo-project.org>

Version 2.0-0 of the pls package is now available on CRAN.

The pls package implements partial least squares regression (PLSR) and
principal component regression (PCR).  Features of the package include

- Several plsr algorithms: orthogonal scores, kernel pls and simpls
- Flexible cross-validation
- A formula interface, with traditional methods like predict, coef,
  plot and summary
- Functions for extraction of scores and loadings, and calculation of
  (R)MSEP and R2
- Functions for plotting predictions, validation statistics,
  coefficients, scores, loadings, biplots and correlation loadings.

The main changes since 1.2-0 are

- There is now an options mechanism for selecting default fit algorithms.
  See ?pls.options.
- loadingplot() and coefplot() now try to be more intelligent when plotting
  x axis labels.
- The handling of factors in X has been improved, by changing the way the
  intercept is removed from the model matrix.
- All PLSR and PCR algorithms, as well as mvrCv(), have been optimised.
  Depending on the algorithm used, the size of the matrices, and the number
  of components used, one can expect from 5% to 65% reduction in
  computation time.
- Scaling of scores and loadings of kernel PLS and svd PCR algorithm has
  changed.  They are now scaled using the `classic' scaling found in
  oscorespls.
- The arguments `ncomp' now always means "number of components", and `comps'
  always means "component number".  The argument `cumulative' has been
  removed.
- A new data set 'gasoline' has been included.
- The 'NIR' and 'sensory' data sets have been renamed to 'yarn' and 'oliveoil'.


See the file CHANGES in the sources for all changes.

-- 
Bj?rn-Helge Mevik



From deepayan.sarkar at r-project.org  Tue Jan  2 20:03:09 2007
From: deepayan.sarkar at r-project.org (Deepayan Sarkar)
Date: Tue, 2 Jan 2007 11:03:09 -0800
Subject: [R-pkgs] rcompletion update
Message-ID: <eb555e660701021103w7b62ce07y9e452ecac2f65052@mail.gmail.com>

Hi,

The rcompletion package, originally intended to provide completion for
readline-based R interfaces, has undergone a number of changes.  These
changes are summarised below:

  o Reorganisation:

    - The package has been split into two.  All the completion code
      has been moved to a pure R package called 'rcompgen'.
      'rcompletion' now requires 'rcompgen' and simply provides
      readline bindings that uses 'rcompgen' to generate possible
      completions.  (Source packages are available on CRAN, binaries
      should be available soon.)

    - The purpose of this reorganisation is to allow other backends to
      use the completion facilities provided by 'rcompgen', hopefully
      avoiding duplication of effort.  I'm happy to add further
      infrastructure to 'rcompgen' if that is helpful.

    - as a proof of concept, .../examples/altesscomp.el contains code
      that provides an alternative (using 'rcompgen') to ESS's
      built-in completion mechanism.  It should be enough to include
      the contents of this file in ~/.emacs (please read the comments at
      the end before doing so).  The file is also available at

      http://rcompletion.googlecode.com/svn/trunk/rcompgen/inst/examples/altesscomp.el

      I am particularly interested in feedback from ESS users
      regarding how this compares with the default mechanism in terms
      of speed (especially in older machines).

  o Hosting:

    - The project is now hosted on Google Code, at
      http://code.google.com/p/rcompletion/

    - (For those interested, this now also hosts my R bash_completion
      script)


  o New completion features:

    - when the token is determined to be the first argument of
      library() or require(), completion is done on _installed_
      package names.  This is disabled by default since the first call
      to installed.packages() can be slow (especially when using
      remote file systems).

    - when the token is determined to be the first argument of data(),
      completion is done on available data sets.

    - tokens after a question mark (?) match aliases in help topics
      rather than object names.  So, for example, ?INST will complete
      to ?INSTALL even though there is no object named INSTALL.

    - the old behaviour of appending a left-parenthesis to function
      names has been disabled by default, since this requires
      evaluation of the mode of _all_ matches, which is undesirable
      for lazy-loaded symbols.

As always, comments and suggestions are most welcome.

-Deepayan



From sfalcon at fhcrc.org  Thu Jan  4 22:20:23 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 04 Jan 2007 13:20:23 -0800
Subject: [R-pkgs] RSQLite 0.4-18 sent to CRAN
Message-ID: <m2odpe32w8.fsf@fhcrc.org>

A new version of RSQLite has been pushed to CRAN.

In this version...

* Further integration of the manifest type system available since
  SQLite 3.  We now obtain the column type from the DB instead of
  pulling everything across as a character vector and calling
  type.convert.  This should improve performance and provide a more
  reliable interface to build on top of.  Note, however, that since
  type.convert is no longer called, return values will be different.
  In particular, text columns will come across as text, not factor.

* dbWriteTable has been refactored and no longer uses temp files.
  This resolves performance issues and line ending quandries on
  Windows.

* Fix for a bug in dbWriteTable when used to import text files; files
  lacking a trailing end of line marker can now be used.

Questions?  Send them to the r-sig-db mailing list.

Best Wishes,

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org



From daj025 at gmail.com  Fri Jan  5 04:38:34 2007
From: daj025 at gmail.com (David James)
Date: Thu, 4 Jan 2007 22:38:34 -0500
Subject: [R-pkgs] RMySQL 0.5-11 uploaded to CRAN
Message-ID: <74c69e370701041938g50c2147fn3cfb767fe219487b@mail.gmail.com>

Hello,

I've uploaded  version 0.5-11 of RMySQL into CRAN, and it should be available
soon.

>From the NEWS file:

Version 0.5-11

* Fixed a bug that would crash R with a failed mysql_real_connect().

* dbApply() is now working again (but still experimentally).

* Re-formatted the C code.

[0.5-9 through 0.5-10 were maintanance releases that Seth Falcon
kindly put out.]

Regards,

--
David



From h0125130 at wu-wien.ac.at  Thu Jan 11 11:52:23 2007
From: h0125130 at wu-wien.ac.at (Ingo Feinerer)
Date: Thu, 11 Jan 2007 11:52:23 +0100
Subject: [R-pkgs] tm 0.1 uploaded to CRAN
Message-ID: <45A616E7.9060404@wu-wien.ac.at>

Dear useRs,

a first version of tm has just been released on CRAN.

tm provides a sophisticated framework for text mining applications
within R.

It offers functionality for managing text documents, abstracts the
process of document manipulation and eases the usage of heterogeneous
text formats in R. An advanced metadata management is
implemented for collections of text documents to alleviate the usage
of large and with metadata enriched document sets.

With the package ships native support for handling
   *) the Reuters 21578 dataset,
   *) the Reuters Corpus Volume 1 dataset,
   *) Gmane RSS feeds,
   *) e-mails, and
   *) several classic file formats (e.g. plain text or CSV text).

tm provides easy access to preprocessing and manipulation mechanisms, like
   *) whitespace removal,
   *) stemming, or
   *) conversion between file formats (e.g., Reuters21578 to plain
   text).

Further a generic filter architecture is available in order to
   *) filter documents for certain criteria,
   *) or perform fulltext search.

The package supports the export from document collections to
term-document matrices as frequently used in the text mining
literature. This allows the straight-forward integration of existing
methods for classification, clustering, visualizations, etc.

The package is designed in a modular way to enable easy integration of
new file formats, parsers, transformations and filter operations.

Best regards,

Ingo Feinerer



From r.hankin at noc.soton.ac.uk  Fri Jan 12 14:22:45 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 12 Jan 2007 13:22:45 +0000
Subject: [R-pkgs] Dummy's guide to S4 methods: package Brobdingnag
Message-ID: <06676A7D-69A0-4443-B078-DA15E7767331@soc.soton.ac.uk>

Hello List.

please find uploaded to CRAN a new package, Brobdingnag.

This package does two things:

(1) allows computation of very large numbers using a logarithmic  
representation.

(2) provides a "Hello, World" example of S4 methods in use: there are  
two classes of object
   (brob and glub) and one virtual class (swift).  The package  
includes a vignette that is a
    step-by-step guide to using S4 methods in the context of an R  
package.


Enjoy

Robin

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From adrian at maths.uwa.edu.au  Mon Jan 15 07:05:48 2007
From: adrian at maths.uwa.edu.au (Adrian Baddeley)
Date: Mon, 15 Jan 2007 14:05:48 +0800
Subject: [R-pkgs] spatstat 1.11-0
Message-ID: <17835.6588.479880.317926@maths.uwa.edu.au>


	spatstat 1.11-0

Version 1.11-0 of package 'spatstat' is now available.

Spatstat is a package for the analysis of spatial data, 
mostly point pattern data. See <www.spatstat.org>

Important changes in version 1.11-0:

	New format for ppm objects (objects in old format are still handled).
	More stringent checking of function arguments.
	Improved handling of pixellation effects.
	Extensions to variance-covariance calculations for fitted models.

Adrian Baddeley and Rolf Turner



From peter.rossi at chicagogsb.edu  Thu Jan 18 16:42:21 2007
From: peter.rossi at chicagogsb.edu (Rossi, Peter E.)
Date: Thu, 18 Jan 2007 09:42:21 -0600
Subject: [R-pkgs] Version 2.0-9 of bayesm
Message-ID: <1E7B167439290641966EB161D433079801BE1A8D@GSBEX.gsb.uchicago.edu>

Version 2.0-9 of bayesm is now available on CRAN

changes include-

1. addition of rhierLinearMixture -- linear hierarchical models with a
mixture of normals prior
2. mixDenBi is now fully vectorized and run more than 10 times faster
3. minor documentation corrections have been made
4. rnmixGibbs allows the user to specify only one component
 
peter rossi



From enzo83 at wp.pl  Mon Jan 22 23:16:18 2007
From: enzo83 at wp.pl (Jakub Jurdziak)
Date: Mon, 22 Jan 2007 23:16:18 +0100
Subject: [R-pkgs] eval() parse() and problem with square brackets
Message-ID: <45B537B2.70807@wp.pl>

Hello,

i have problem with the following code (I'm using sqlQuery function from 
RODBC package):
eval(parse(text="g_1 <- sqlQuery(cnn_1, \"select aa from 
bb.[cc\\dd].ee\")")).

I get the error message:
"[RODBC] ERROR: Could not SQLExecDirect" 

"S0002 208 [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid object 
name 'bb.cc\dd.ee'."

It seems that R is replacing square brackets that are needed for 
database to execute query.

How can I force R to change its behavior and leave square brackets 
unchanged?

Any ideas appreciated

Kuba



From dusa.adrian at gmail.com  Tue Jan 23 12:28:08 2007
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Tue, 23 Jan 2007 13:28:08 +0200
Subject: [R-pkgs] version 0.3 of QCA
Message-ID: <200701231328.08930.dusa.adrian@gmail.com>


Dear list members,

A new version of the QCA package is now on CRAN.
The QCA package implements the Quine-McCluskey algorithm for boolean 
minimizations, according to the Qualitative Comparative Analysis.

Along with the additional improvements in version 0.3-1 (soon to be released 
on CRAN), this code is about 100 times faster than the previous "major" 
release (0.2-6). It can now reasonably work with 11 binary variables, finding 
a complete (and exact) solution in less than 2 minutes.

This dramatic increase in speed is due to using a mathematical reduction 
instead of an algorithmic one. This approach openes the way for _exact_ 
multi-value minimizations, and an even better (and faster) approach is 
searched for the future versions.

Best,
Adrian

-- 
Adrian Dusa
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101



From bates at stat.wisc.edu  Fri Jan 26 00:12:00 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 25 Jan 2007 17:12:00 -0600
Subject: [R-pkgs] New version of lme4 and new mailing list R-SIG-mixed-models
Message-ID: <40e66e0b0701251512p78612c2br31e32ea0411f301b@mail.gmail.com>

Version 0.9975-11 of the lme4 package has been uploaded to CRAN.  The
source package should be available on the mirrors in a day or two and
binary packages should follow soon after.

There are several changes in this release of the package.  The most
important is the availability of a development version of lmer called,
for the time being, lmer2.  At present lmer2 only fits linear mixed
models.  Generalized linear mixed models will be added "soon".
Furthermore there is no mcmcsamp method for a model fit by lmer2.
This deficiency will also be rectified "soon".  Once I have all the
capabilities and methods currently available for lmer also available
for the new representation I will remove the old representation and
rename lmer2 as lmer.

The current version of lmer will continue to be available throughout
the migration process.  You don't have to change anything about your
use of that function unless you want to try the new one.  It would be
a good idea, however, to save the data and the call to lmer in
addition to saving an lmer object, if you so choose, so that you can
recreate the fitted model when the development version becomes the
release version.

The package contains a vignette giving the details of the new implementation.

The reason I am releasing a development version in parallel with the
production version is because I would like feedback from useR's
regarding the development version.  In my experience, testing it
myself and with colleagues whom I visited recently, I have found that
lmer2 is faster and more reliable than the current lmer.  In
particular, on some difficult model fits I have been able to get
substantially better parameter estimates (i.e. the deviance at the
lmer2 estimates is perhaps 4 or 5 lower than that at the lmer
estimates) with lmer2 than I could with lmer.

If you have fit a linear mixed model using lmer and are willing to try
it with lmer2 I would appreciate your telling me if the parameter
estimates are comparable and which fit was faster (use system.time()
to check).  I'm primarily interested in models fit to large data sets
or "difficult" fits.

We have established a new mailing list, R-SIG-mixed-models, for
discussion of R software to fit mixed-effects models, especially lmer.
 See https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models for
information or to subscribe.

I know that I have said this before but this is the last time that I
am going to change the underlying representation.  Really - trust me -
this is the last time.  My theory of software development is expressed
in a line from an old blues song, "you just keep doing it wrong till
you do it right".  I'm convinced that this time I have it right.  That
statement sounds like "famous last words", doesn't it?  :-)



From charles.dupont at vanderbilt.edu  Mon Jan 29 18:11:19 2007
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Mon, 29 Jan 2007 11:11:19 -0600
Subject: [R-pkgs] Hmisc Version 3.1-2 uploaded to CRAN repository
Message-ID: <45BE2AB7.8030107@vanderbilt.edu>

Hmisc 3.1-2 has been uploaded to the CRAN incoming directory.

Change log
3.2-1 1/25/2007:
       Hmisc function 'ecdf' has been renamed 'Ecdf' to deconflict it
       with the existing 'ecdf' function in base.

       Fixed Bug in format.df that would create numbers with many
       trailing zeros.

       Added arguments 'math.row.names' and 'math.col.names' to
       indicate that the row or col names should be wrapped in the
       latex math environment.

       Fixed problem with 'histbackback' function.

-- 
Charles Dupont	Computer System Analyst		School of Medicine
		Department of Biostatistics	Vanderbilt University



From tobias.sing at gmail.com  Wed Jan 31 11:53:43 2007
From: tobias.sing at gmail.com (Tobias Sing)
Date: Wed, 31 Jan 2007 11:53:43 +0100
Subject: [R-pkgs] ROCR 1.0-2
Message-ID: <c3ca233a0701310253h458e88eam5d0a85ace4098fcc@mail.gmail.com>

Dear useRs,

an update of the ROCR package is available on CRAN.

ROCR helps in evaluating the performance of scoring classifiers using
ROC graphs, precision/recall plots, lift charts and many other
performance metrics.
For further information check http://rocr.bioinf.mpi-sb.mpg.de and
http://bioinformatics.oxfordjournals.org/cgi/reprint/21/20/3940

NEWS:
- added an optional parameter 'fpr.stop' to the performance measure 'auc',
  allowing to calculate the partial area under the ROC curve
  up to the false positive rate given by 'fpr.stop'.

- fixed bug in 'prediction' function which caused ROCR to halt
  in the context of a custom label.ordering (thanks to Roberto Perdisci
  for pointing out)

As usual, any feedback is more than welcome!
- Tobias


-- 
Tobias Sing
Computational Biology and Applied Algorithmics
Max Planck Institute for Informatics
Saarbrucken, Germany
Phone: +49 681 9325 315
Fax: +49 681 9325 399
http://www.tobiassing.net



From whitede at onid.orst.edu  Thu Feb  8 17:28:52 2007
From: whitede at onid.orst.edu (Denis White)
Date: Thu, 08 Feb 2007 08:28:52 -0800
Subject: [R-pkgs] new contributed package 'stream.net'
Message-ID: <1170952132.45cb4fc4dc5dc@webmail.oregonstate.edu>

New contributed package 'stream.net' is available on CRAN.

Description:   Functions with example data for creating, importing,
               attributing, analyzing, and displaying stream networks
               represented as binary trees.  Capabilities include
               importing network topology and attributes from GIS data,
               upstream and downstream distance matrices, stochastic
               network generation, segmentation of network into
               reaches, adding attributes to reaches with specified
               statistical distributions, interpolating reach
               attributes from sparse data, analyzing autocorrelation
               of reach attributes, and creating maps with legends of
               attribute data.  Target applications include dynamic
               fish modeling.

Denis White
US EPA
Corvallis, Oregon, USA



From ubk at kogalur-shear.com  Sun Feb 11 17:40:02 2007
From: ubk at kogalur-shear.com (K. B. Udaya)
Date: Sun, 11 Feb 2007 11:40:02 -0500
Subject: [R-pkgs] randomSurvivalForest 2.0.0 now available
Message-ID: <38c08c270702110840v72971cd4n9b9cc9117b65c38d@mail.gmail.com>

Dear useRs:

Release 2.0.0 of the randomSurvivalForest package is now available.

---------------------------------------------------------------------------------
CHANGES TO RELEASE 2.0.0

Release 2.0.0 represents a major upgrade in the functionality and stability
of the original 1.0.0 release.  Key changes are as follows:

o Two new splitting rules, 'logrankscore' and 'logrankapprox', added.

o Expanded output from 'rsf()'.  Now out-of-bag objects 'oob.ensemble' and
  'oob.mortality' are included in addition to the full ensemble objects
  'ensemble' and 'mortality'.

o Importance values for predictors can now be calculated (set
'importace = TRUE'
  in the initial 'rsf()' call).  Extended 'plot.error()' to print, as
well as plot,
  such values.

o Prediction on test data can now be implemented using 'rsf.predict()' (set
  'forest = TRUE' in the initial 'rsf()' call).

o Included option 'predictorWt' used for weighted sampling of predictors when
  growing a tree.

o Formula no longer restricted to main effects.  Formula for 'rsf' interpreted
  as in typical R applications.  However, users should be aware that including
  interactions or higher order terms in a formula may not be an optimal way to
  grow a forest.

o Three types of objects are generated in an RSF analysis: '(rsf, grow)',
  '(rsf, predict)' and '(rsf, forest)'.  Wrappers handle each type of object
  in different ways.

o Improved error checking in all wrappers.

o Extended 'plot.variable()' wrapper to generate partial plots for predictors.

o Improved control over trace output.  See the 'do.trace' option in 'rsf()'.

o Implements the Predictive Model Markup Language specification for an
  '(rsf, forest)' forest object.  PMML is an XML based language which
  provides a way for applications to define statistical and data mining
  models and to share models between PMML compliant applications.  More
  information about PMML and the Data Mining Group can be found at
  http://www.dmg.org.  Our implementation gives the user the ability to
  save the geometry of a forest as a PMML XML document for export or
  later retrieval.

---------------------------------------------------------------------------------

ubk2101 at columbia.edu

Udaya B. Kogalur, Ph.D.
Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012



From Graham.Williams at togaware.com  Tue Feb 13 20:58:02 2007
From: Graham.Williams at togaware.com (Graham Williams)
Date: Wed, 14 Feb 2007 06:58:02 +1100
Subject: [R-pkgs] New version of rattle released
Message-ID: <20070213195802.GA14089@athene.togaware.com>

A new version of Rattle (2.1.123), a Gnome-base GUI for data mining,
written copmletely in R, and available on GNU/Linux, Unix, Mac OSX, and
MS/Windows, has been released to CRAN.

There has been quite a lot of activity since the last update, including:

Transform:
        Now include basic imputation of missing values. More to follow.

Models: 
        Move to using ada for boosting.
        Better missing value handling for random forest
        Use arules package for market basket analysis
        Add more model visualisations

Export:
        RPart PMML export completed.
        PMML export has been separated out to its own package (pmml)

Complete change log available at

	http://rattle.togaware.com/changes.html

Rattle mailing list at

	http://groups.google.com/group/rattle-users

Regards,
Graham



From Graham.Williams at togaware.com  Wed Feb 14 10:41:40 2007
From: Graham.Williams at togaware.com (Graham Williams)
Date: Wed, 14 Feb 2007 20:41:40 +1100
Subject: [R-pkgs] New PMML package
Message-ID: <20070214094140.GA17839@athene.togaware.com>

A new package is now available on CRAN - pmml.

PMML is the Predictive Modelling Markup Language, and is accepted by a
number of large database and data warehouse systems (IBM DB2 and NCR
Teradata) for deployment of models as SQL.

The current package is an "early release" in that it is very basic (and
primarily supports the Rattle package). But it is a start! It currently
supports rpart classification trees and kmeans clusters.

Contributions of support for other models are welcome.

Regards,
Graham



From Graham.Williams at togaware.com  Wed Feb 14 11:00:10 2007
From: Graham.Williams at togaware.com (Graham Williams)
Date: Wed, 14 Feb 2007 21:00:10 +1100
Subject: [R-pkgs] New version of rattle released
Message-ID: <20070214100010.GA18511@athene.togaware.com>

A new version of Rattle (2.1.123), a Gnome-base GUI for data mining,
written completely in R, and available on GNU/Linux, Unix, Mac OSX, and
MS/Windows, has been released to CRAN.

There has been quite a lot of activity since the last update, including:

Transform:
        Now include basic imputation of missing values. More to follow.

Models: 
        Move to using ada for boosting.
        Better missing value handling for random forest
        Use arules package for market basket analysis
        Add more model visualisations

Export:
        RPart PMML export completed.
        PMML export has been separated out to its own package (pmml)

Complete change log available at

	http://rattle.togaware.com/changes.html

Rattle mailing list at

	http://groups.google.com/group/rattle-users

Regards,
Graham



From jtjokine at cc.helsinki.fi  Thu Feb 15 12:30:47 2007
From: jtjokine at cc.helsinki.fi (Jukka Jokinen)
Date: Thu, 15 Feb 2007 13:30:47 +0200 (EET)
Subject: [R-pkgs] New package 'drm' for repeated categorical data analysis
Message-ID: <Pine.OSF.4.58.0702121514210.426251@sirppi.helsinki.fi>

Dear useRs,

A new package 'drm', version 0.5-4, is available on CRAN.

The drm package provides functions for marginal regression analysis of
repeated (or otherwise clustered) binary, ordinal and nominal responses.
This package can be considered as a likelihood-based alternative to GEE
approach for marginal regression. In addition to regression modelling,
several temporal and latent variable models for the associations between
repeated responses can be specified. In other words, the package provides
joint regression and association modelling for repeated categorical data.

For longitudinal studies with dropout, the package also provides a
possibility to model the dropout mechanism by adding a selection model on
top of the joint regression and association model. This can be used to
explore the effect of dropout on the regression and association parameters
when dropout is considered nonignorable.

The novelty of the proposed approach is that there exists an explicit
solution for the joint distribution, and the parameterisation has an
inherent unit-sum constraint, which substantially facilitate maximum
likelihood fitting for datasets with large cluster sizes. For an
application to a binary response with 12 repeated measurements, see the
help-file of function drm.

For more information, see:
http://www.helsinki.fi/~jtjokine/drm/

Bug reports, comments or suggestions are welcome.

best,
Jukka Jokinen



From Mike.Prager at noaa.gov  Thu Mar  1 20:01:12 2007
From: Mike.Prager at noaa.gov (Michael H. Prager)
Date: Thu, 01 Mar 2007 14:01:12 -0500
Subject: [R-pkgs] Update of X2R sent to CRAN
Message-ID: <45E722F8.5060206@noaa.gov>

A new version of X2R has just been uploaded to CRAN.  It should be 
available at mirrors within a few days.

This contains revisions to the For2R component to fix a bug in which 
data frames were not written correctly if the user did not pass row labels.

The new version is supplied as files X2R.zip and X2R.tar.gz, which are 
equivalent.  The version can be identified from the contents of file 
"VersionInfo.txt" in the root of each archive.  The new version is dated 
March 1, 2007.

-----

 From the original announcement:

X2R is composed of three related software libraries: C2R,  ADMB2R, and 
For2R (together, X2R). Each contains output routines to simplify 
transfer of complicated data structures from models written in a 
compiled language to R.  The user's data can be written as a structured 
ASCII file which, when read by R (note 1) with a single dget() function 
call, will become an R data object of type list. The list, may contain 
components such as data frames, matrices, and other lists.

These are NOT R packages; rather they are subroutine libraries to be 
used with programmers' own modeling codes.  Limited testing indicates 
that they are compatible with S-PLUS, as well (note 1, note 2).

Languages supported are Fortran 95 (with For2R), C and C++ (with C2R) 
and AD Model Builder (with ADMB2R) (note 1, note 3).  Source code and 
users' manuals are supplied.

This work has been tested and used by the authors. However, any software 
may contain bugs, and these works are classified by NOAA as  
"Experimental Products."  Although the software is supplied with no 
warranty whatsoever, bug reports, suggestions, and extensions are 
solicited (send to Prager or Martin).  The authors will attempt to fix 
all bugs promptly and to add requested features.

Software is now available at CRAN,  http://cran.r-project.org/ .  Look 
under "Software / Other" for the current X2R distribution.


Michael H. Prager - mike.prager at noaa.gov
Andi Stephens
Southeast Fisheries Science Center
National Marine Fisheries Service, NOAA
101 Pivers Island Road
Beaufort, North Carolina 28516 USA

Jennifer L. Martin - jennifer.martin at noaa.gov
Northeast Fisheries Science Center
National Marine Fisheries Service, NOAA
166 Water Street
Woods Hole, Massachusetts 02543 USA


* Note 1.  Use of product names (commercial or otherwise) does not imply 
endorsement or recommendation by any U.S. government agency, nor by the 
authors in their government capacities.
* Note 2.  S-PLUS is a commercial product, released by Insightful 
Corporation.
* Note 3.  AD Model Builder is a commercial product, released by Otter 
Research.



From Peter.Rossi at chicagogsb.edu  Thu Mar  8 18:16:17 2007
From: Peter.Rossi at chicagogsb.edu (Rossi, Peter E.)
Date: Thu, 08 Mar 2007 11:16:17 -0600
Subject: [R-pkgs] Release 2.1-1 of bayesm
Message-ID: <1E7B167439290641966EB161D433079801EA928F@GSBEX.gsb.uchicago.edu>

 
Release 2.1-1 is now available on CRAN.

This release includes--
bayesm classes (some compatible with the mcmc class of coda) for output.
plot
and summary methods for these classes.

additional datasets including store-level panel data.

peter r
 
................................
 Peter E. Rossi
 Joseph T. and Bernice S. Lewis Professor of Marketing and Statistics
 Editor, Quantitative Marketing and Economics
 Rm 353, Graduate School of Business, U of Chicago
 5807 S. Woodlawn Ave, Chicago IL 60637
 Tel: (773) 702-7513   |   Fax: (773) 834-2081



From antonio.fabio at gmail.com  Fri Mar 23 15:15:24 2007
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Fri, 23 Mar 2007 15:15:24 +0100
Subject: [R-pkgs] RTisean 3.0-7 released
Message-ID: <b0808fdc0703230715k2178fdbdl32d0fe3bca0e8caf@mail.gmail.com>

Dear R users,
I've just uploaded to CRAN a new version of RTisean, the TISEAN-to-R interface.
This is now compatible with the recent, new 3.0.1 release of TISEAN [1].
This new TISEAN version is explicitely GPL-ed, and has some more
routines handling multivariate time series.

Bests,
Antonio, Fabio Di Narzo.

[1] http://idmc.blogspot.com/2007/03/tisean-300-is-out.html



From Mike.Prager at noaa.gov  Mon Apr 16 21:32:26 2007
From: Mike.Prager at noaa.gov (Michael H. Prager)
Date: Mon, 16 Apr 2007 15:32:26 -0400
Subject: [R-pkgs] Update of X2R sent to CRAN, 16 Apr 2007
Message-ID: <4623CF4A.3020100@noaa.gov>

X2R is a bundle of three software libraries allowing the user to pass 
structured data easily from Fortran, C/C++, or AD Model Builder to R.

An update to X2R has been sent to CRAN today and should be available at 
mirrors shortly. This fixes a bug in the ADMB2R and C2R components in 
which data frames were not written correctly when the user did not 
specify row names. Several other minor improvements also have been made.

The new version is supplied as files X2R.zip and X2R.tar.gz, which are 
equivalent.  The version and release date can be identified from the 
contents of file "VersionInfo.txt" in the root of each archive. The new 
version bears date April 16, 2007.

                                * * *

 From the original announcement:

X2R is composed of three related software libraries: C2R,  ADMB2R, and
For2R (together, X2R). Each contains output routines to simplify
transfer of complicated data structures from models written in a
compiled language to R.  The user's data can be written as a structured
ASCII file which, when read by R (note 1) with a single dget() function
call, will become an R data object of type list. The list, may contain
components such as data frames, matrices, and other lists.

These are NOT R packages; rather they are subroutine libraries to be
used with programmers' own modeling codes.  Limited testing indicates
that they are compatible with S-PLUS, as well (note 1, note 2).

Languages supported are Fortran 95 (with For2R), C and C++ (with C2R)
and AD Model Builder (with ADMB2R) (note 1, note 3).  Source code and
users' manuals are supplied.

This work has been tested and used by the authors. However, any software
may contain bugs, and these works are classified by NOAA as
"Experimental Products."  Although the software is supplied with no
warranty whatsoever, bug reports, suggestions, and extensions are
solicited (send to Prager or Martin).  The authors will attempt to fix
all bugs promptly and to add requested features.

Software is now available at CRAN,  http://cran.r-project.org/ .  Look
under "Software / Other" for the current X2R distribution.


Michael H. Prager - mike.prager at noaa.gov
Andi Stephens
Southeast Fisheries Science Center
National Marine Fisheries Service, NOAA
101 Pivers Island Road
Beaufort, North Carolina 28516 USA

Jennifer L. Martin - jennifer.martin at noaa.gov
Northeast Fisheries Science Center
National Marine Fisheries Service, NOAA
166 Water Street
Woods Hole, Massachusetts 02543 USA


* Note 1.  Use of product names (commercial or otherwise) does not imply
endorsement or recommendation by any U.S. government agency, nor by the
authors in their government capacities.
* Note 2.  S-PLUS is a commercial product, released by Insightful
Corporation.
* Note 3.  AD Model Builder is a commercial product, released by Otter
Research.



From vincent.goulet at act.ulaval.ca  Mon Apr 23 17:20:59 2007
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Mon, 23 Apr 2007 10:20:59 -0500
Subject: [R-pkgs] New version of actuar
Message-ID: <200704231120.59692.vincent.goulet@act.ulaval.ca>

UseRs,

actuar is a package for Actuarial Science. A rather preliminary
version (0.1-3) of the package has been available on CRAN since February 2006. 
We now announce the immediate availability of version 0.9-2 sporting a large 
number of new features. 

Non actuaries behold! There can be some features of interest for you, 
especially those related to new probability distribution and to the 
manipulation of grouped data.

Since I took the time to write a fairly detailed NEWS file, I'll let it speak 
for itself:

=== actuar: an R package for Actuarial Science ===

Version 0.9-2
=============

Major official update. This version is not backward compatible with
the 0.1-x series. Feature of the package can be split in the following
categories: loss distributions modeling, risk theory, credibility
theory.

NEW FEATURES -- LOSS DISTRIBUTIONS

o Functions {d,p,q,r}foo to compute the density function, cumulative
  distribution function, quantile function of, and to generate
  variates from, all probability distributions of Appendix A of
  Klugman et al. (2004), "Loss Models, Second Edition" (except the
  inverse gaussian) not already in R. Namely, this adds the following
  distributions (the root is what follows the 'd', 'p', 'q' or 'r' in
  function names):
  
  Distribution name          	Root        
  ------------------------- 		--------------  
   Burr			    	 	burr		  
   Generalized beta	     		genbeta	  
   Generalized Pareto	    	genpareto	  
   Inverse Burr		     	invburr	  
   Inverse exponential	     	invexp	  
   Inverse Pareto	     		invpareto	  
   Inverse paralogistic	     	invparalogis	  
   Inverse Weibull	     		invweibull	  
   Loggamma		     		loggamma	  
   Loglogistic		     		llogis	  
   Paralogistic		    	 	paralogis	  
   Pareto		     			pareto	  
   Single parameter Pareto   	pareto1	  
   Transformed beta	     	trbeta	  
   Transformed gamma	     	trgamma	  

  All functions are coded in C for efficiency purposes and should
  behave exactly like the functions in base R. For all distributions
  that have a scale parameter, the corresponding functions have 'rate
  = 1' and 'scale = 1/rate' arguments.

o Functions {m,lev}foo to compute the k-th raw (non-central) moment
  and k-th limited moment for all the probability distributions
  mentioned above, plus the following ones of base R: beta,
  exponential, gamma, lognormal and Weibull.

o Facilities to store and manipulate grouped data (stored in an
  interval-frequency fashion). Function grouped.data() creates a
  grouped data object similar to a data frame. Methods of "[", "[<-",
  mean() and hist() created for objects of class "grouped.data".

o Function ogive() --- with appropriate methods of knots(),
  plot(), print() and summary() --- to compute the ogive of grouped
  data. Usage is in every respect similar to ecdf().

o Function elev() to compute the empirical limited expected value of a
  sample of individual or grouped data.

o Function emm() to compute the k-th empirical raw (non-central)
  moment of a sample of individual or grouped data.

o Function mde() to compute minimum distance estimators from a sample
  of individual or grouped data using one of three distance measures:
  Cramer-von Mises (CvM), chi-square, layer average severity
  (LAS). Usage is similar to fitdistr() of package 'MASS'.

o Function coverage() to obtain the pdf or cdf of the payment per
  payment or payment per loss random variable under any combination of
  the following coverage modifications: ordinary of franchise
  deductible, policy limit, coinsurance, inflation. The result is a
  function that can be used in fitting models to data subject to such
  coverage modifications.

o Individual dental claims data set 'dental' and grouped dental claims
  data set 'gdental' of Klugman et al. (2004), "Loss Models, Second
  Edition".

NEW FEATURES -- RISK THEORY

o Function aggregateDist() returns a function to compute the
  cumulative distribution function of the total amount of claims
  random variable for an insurance portfolio using any of the
  following five methods:

  1. exact calculation by convolutions (using function convolve() of
     package 'stats';
  2. recursive calculation using Panjer's algorithm;
  3. normal approximation;
  4. normal power approximation;
  5. simulation.

  The modular conception of aggregateDist() allows for easy inclusion
  of additional methods. There are special methods of print(),
  summary(), quantile() and mean() for objects of class
  "aggregateDist".  The objects otherwise inherit from classes "ecdf"
  (for methods 1, 2 and 3) and "function".

  See also the "Deprecated, defunct or no backward compatibility"
  section below.

o Function discretize() to discretize a continuous distribution using
  any of the following four methods:

  1. upper discretization, where the discretized cdf is always above
     the true cdf;
  2. lower discretization, where the discretized cdf is always under
     the true cdf;
  3. rounding, where the true cdf passes through the midpoints of the
     intervals of the discretized cdf;
  4. first moment matching of the discretized and true distributions.

  Usage is similar to curve() of package 'graphics'. Again, the
  modular conception allows for easy inclusion of additional
  discretization methods.

NEW FEATURES -- CREDIBILITY THEORY

o Function simpf() can now simulate data for hierarchical portfolios
  of any number of levels. Model specification changed completely; see
  the "Deprecated, defunct or no backward compatibility" below. The
  function is also significantly (~10x) faster than the previous
  version.

o Generic function severity() defined mostly to provide a method for
  objects of class "simpf"; see below.

o Methods of aggregate(), frequency(), severity() and weights() to
  extract information from objects of class "simpf":

  1. aggregate() returns the matrix of aggregate claim amounts per
     node;
  2. frequency() returns the matrix of the number of claims per node;
  3. severity() returns the matrix of individual claim amounts per
     node;
  4. weights() returns the matrix of weights corresponding to the
     data.

  Summaries can be done in various ways; see ?simpf.summaries

o Function cm() (for "_c_redibility _m_odel") to compute structure
  parameters estimators for hierarchical credibility models, including
  the B?hlmann and B?hlmann-Straub models. Usage is similar to lm() of
  packages 'stats' in that the hierarchical structure is specified by
  means of a formula object and data is extracted from a matrix or
  data frame. There are special methods of print(), summary() for
  objects of class "cm". Credibility premiums are computed using a
  method of predict(); see below.

  For simple B?hlmann and B?hlmann-Straub models, bstraub() remains
  simpler to use and faster.

o Function bstraub() now returns an object of class "bstraub" for
  which there exist print and summary methods. The function no longer
  computes the credibility premiums; see the "Deprecated,
  defunct or no backward compatibility" below.

o Methods of predict() for objects of class "cm" and "bstraub" created
  to actually compute the credibility premiums of credibility
  models. Function predict.cm() can return the premiums for specific
  levels of a hierarchical portfolio only.

OTHER NEW FEATURES

o Function unroll() to unlist a list with a "dim" attribute of length
  0, 1 or 2 (that is, a vector or matrix of vectors) according
  to a specific dimension. Currently identical to severity.default()
  by lack of a better usage of the default method of severity().

o Three new demos corresponding to the three main fields of actuarial
  science covered by the package.

o French translations of the error and warning messages.

o The package now has a name space.

DEPRECATED, DEFUNCT OR NO BACKWARD COMPATIBILITY

o Function panjer(), although still present in the package, should no
  longer be used directly. Recursive calculation of the aggregate
  claim amount should be done with aggregateDist(). Further, the
  function is not backward compatible: model specification has
  changed, discretization of the claim amount distribution should now
  be done with discretize(), and the function now returns a function
  to compute the cdf instead of a simple vector of probabilities.

o Model specification for simpf() changed completely and is not
  backward compatible with previous versions of the package. The new
  scheme allows for much more general models.

o Function rearrangepf() is defunct and has been replaced by methods
  of aggregate(), frequency() and severity().

o Function bstraub() no longer computes the credibility premiums. One
  should now instead use predict() for this.

o The data set 'hachemeister' is no longer a list but rather a matrix
  with a state specification.


Version 0.1-3
=============

Fixed the dependency on R >= 2.1.0 since the package uses function
isTRUE().


Version 0.1-2
=============

- First public release.
- Fixed an important bug in bstraub(): when calculating the range of
  the weights matrix, NAs were not excluded.
- Miscellaneous documentation corrections.


Version 0.1-1
=============

- Initial release.
- Contains functions bstraub(), simpf(), rearrangepf() and panjer(),
  and the dataset hachemeister.

[There has been a very short lived version 0.9-1 on CRAN. Please ignore this 
version altogether.]

Collaboration is welcome. Please contact me directly.

-- 
  Vincent Goulet, Associate Professor
  ?cole d'actuariat
  Universit? Laval, Qu?bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From penel at biomserv.univ-lyon1.fr  Tue Apr 24 10:28:06 2007
From: penel at biomserv.univ-lyon1.fr (Simon Penel)
Date: Tue, 24 Apr 2007 10:28:06 +0200
Subject: [R-pkgs] new version of seqinR
Message-ID: <462DBF96.7090404@biomserv.univ-lyon1.fr>

Dear useRs,

The seqinR package  is a library of utilities to retrieve and analyse 
biological sequences.

A new version of seqinR, seqinR 1.0-7,  has been released on CRAN.

Here is a summary of changes:

o A new *experimental* function extractseqs() to download
  sequences thru zlib compressed sockets from an ACNUC server is released.
  Preliminary tests suggest that working with about 100,000 CDS is 
possible with
  a home ADSL connection. See the manual chapter 3 page 44 at
  http://pbil.univ-lyon1.fr/software/SeqinR/seqinr_1_0-7.pdf
  for some system.time() examples.

o As pointed by Emmanuel Prestat the URL used in dia.bactgensize() was no
  more available, this has been fixed in the current version.

o As pointed by Guy Perriere, the function oriloc() was no more compatible
  with glimmer 3.0 outputs. The function has gained a new argument
  glimmer.version defaulting to 3, but the value 2 is still functional for
  backward compatibility with old glimmer outputs.

o As pointed by Lionel Guy there was no default value for the as.string
  argument in the getSequence.SeqFastadna(). A default FALSE value is now
  present for backward compatibility with older code.

o New utility vectorized function stresc() to escape LaTeX special 
characters
  present in a string.

o New low level function readsmj() available.

o A new function readfirstrec() to get the record count of the specified 
ACNUC
  index file is now available.

o Function getType() called without arguments will now use the default 
ACNUC
  database to return available subsequence types.

o Function read.alignment() now also accepts file in addition to File as
  argument.

o A new function rearranged.oriloc() is available. This method, based on
  oriloc(), can be used to detect the effect of the replication 
mechanism on
  DNA base composition asymmetry, in prokaryotic chromosomes.

o New function extract.breakpoints(), used to extract breakpoints in 
rearranged
  nucleotide skews. This function uses the segmented package to define the
  position of the breakpoints.

o New function draw.rearranged.oriloc() available, to plot nucleotide skews
  on artificially rearranged prokaryotic chromosomes.

o New function gbk2g2.euk() available. Similarly to gbk2g2(), this function
  extracts the coding sequence annotations from a GenBank format file. This
  function is specifically designed for eukaryotic sequences, i.e. with 
introns.
  The output file will contain the coordinates of the exons, along with the
  name of the CDS to which they belong.

o After an e-mail by Marcelo Bertalan on 26 Mar 2007, a bug in oriloc() 
when
  the gbk argument was NULL was found and fixed by Anamaria Necsulea.

o Functions translate() and getTrans() have gained a new argument 
NAstring to
  represent untranslatable amino-acids, defaulting to character "X".

o There was a typo for the total number of printed bases in the ACNUC 
books:
  474,439 should be 526,506.

o Function invers() has been deleted.

o Functions translate(), getTrans() and comp() have gained a new argument
  ambiguous defaulting to FALSE allowing to handle ambiguous bases. If 
TRUE,
  ambiguous bases are taken into account so that for instance GGN is 
translated
  to Gly in the standard genetic code.

o New function amb() to return the list of nucleotide matching a given 
IUPAC
  nucleotide symbol.

o Function count() has gained a new argument alphabet so that oligopeptides
  counts are now possible. Thanks to Gabriel Valiente for this suggestion.
  The functions zscore(), rho() and summary.SeqFastadna() have also an 
argument
  alphabet which is forwarded to count().

Best,

the seqinR team

http://pbil.univ-lyon1.fr/software/SeqinR/seqinr_accueil.php


-- 
Simon Penel
Laboratoire de Biometrie et Biologie Evolutive           
Bat 711  -   CNRS UMR 5558  -    Universite Lyon 1              
43 bd du 11 novembre 1918 69622 Villeurbanne Cedex       
Tel:   04 72 43 29 04      Fax:  04 72 43 13 88
http://pbil.univ-lyon1.fr/members/penel



From jombart at biomserv.univ-lyon1.fr  Wed Apr 25 18:03:09 2007
From: jombart at biomserv.univ-lyon1.fr (Thibaut Jombart)
Date: Wed, 25 Apr 2007 18:03:09 +0200
Subject: [R-pkgs] new package adegenet
Message-ID: <462F7BBD.5040502@biomserv.univ-lyon1.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070425/87cdf118/attachment.pl>

From jthioulo at biomserv.univ-lyon1.fr  Thu Apr 26 17:34:43 2007
From: jthioulo at biomserv.univ-lyon1.fr (Jean Thioulouse)
Date: Thu, 26 Apr 2007 17:34:43 +0200
Subject: [R-pkgs] New version of ade4TkGUI
Message-ID: <p06240800c25674fa4314@[134.214.34.24]>

Dear UseRs,

Version 0.2-1 of the ade4TkGUI package (a GUI for the ade4 package)
is now available on CRAN. This version corrects a few bugs and has
the following new features :

- history management : commands executed in the GUI are now stored
in the R session history

- echo of commands on cosole : all commands (including these ones
issued in the dudi synthesis window) are now echoed to the console

- an interface for the "s.arrow" function has been added

- the interface for the s.label function has been modified to allow
(or disallow) label frames

- the interface of the "s.value" interface has been modified to
allow simultaneous drawing of all the variables in a dataframe

- a help page has been added for the "explore" function

- the presentation of the "explore" function had been improved

- the "ordiCLust" function has been added, to do cluster analysis
on multivariate analysis row scores, with several dynamic graphic
help tools (a help page is also available). See these screenshots :
http://pbil.univ-lyon1.fr/JTHome/ordiClust1.png
http://pbil.univ-lyon1.fr/JTHome/ordiClust2.png
http://pbil.univ-lyon1.fr/JTHome/ordiClust3.png

Thanks you to all the people who sent me remarks, advice, and bug
reports. Comments are still (and always) welcome.

Jean
-- 
Jean Thioulouse - Labo Biometrie et Biologie Evolutive,  UMR CNRS 5558
Universite Lyon 1, Batiment Mendel,   43 Boulevard du 11 Novembre 1918
69622 Villeurbanne Cedex - France    http://pbil.univ-lyon1.fr/JTHome/
Tel : (33) 4 72 43 27 56                      Fax : (33) 4 72 43 13 88
# msn: thioulouse at hotmail.com  #  jabber: jt69 #  .mac: j.thioulouse #



From charles.dupont at vanderbilt.edu  Fri Apr 27 16:20:22 2007
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Fri, 27 Apr 2007 09:20:22 -0500
Subject: [R-pkgs] Hmisc Version 3.3-2 is now in CRAN repository
Message-ID: <463206A6.7090401@vanderbilt.edu>

Hmisc Version 3.3-2 has been posted to the CRAN repository.

Change Log

3.3-2 4/26/2007
       Fixed bug with combine<- function not handling NULL values.

3.3-1 3/29/2007
       Created functions trunc.POSIXt, ceil.POSIXt, round.POSIXt to do
       those ops on POSIXt objects.  Removed chron versions of these
       functions.

       Placed Hmisc in a namespace

       Factored out category levels that are identical (and in the same
       order) for multiple variables.  Changed print and html methods
       accordingly, and made new default for html output,
       levelType='list'.

       new argument levelType in html.contents.data.frame

       enhanced html.data.frame to set column headings in h2

       added curtail option (default: FALSE) for type='regression' to
       set imputed values to the boundaries of real data if outside

       added datadensity argument to plot.aregImpute

       fixed bug with curtail, added datadensity argument to
       plot.aregImpute

       fixed typo related to bass argument

       fixed bug in latex.describe to translate underscores in variable
       names when listing those with all NAs

       fixed inmChoice by unclassing first argument when pasting

       handled underscore in dataset name in latex.describe by calling
       latexTranslate

       Finished addition of listunique and listnchar, handled listing
       of character values in latex.describe.*

       listunique and listnchar

       For listunique option ignored multiple white spaces, leading and
       trailing white spaces, and case in tabulating character strings.

       For listunique ignored leading and trailing white space,
       multiple white spaces, and case when tabulating character
       strings. Carriage returns without new lines are changed to a
       single space.

       Modified 'extracolheads' such that when cgroup and n.cgroup are
       used in a latex.summary.formula.reverse statement the extra N=
       columns line up correctly.

       added boot.method argument to implement approximate Bayesian
       bootstrap when group is not used

       'R/inc-dec.s' created 2 new functions 'inc<-' and 'dec<-'. 
'inc<-' increments
       'x' by value assigned to it.  'dec<-' does the same thing but 
decrements 'x'.

       'R/responseSummary.s' changed 'responseSummary' 'FUN' argument
       so that is it run on each row of the response instead of the
       whole of the response.

       'R/latexObject.s' changed names of constant escapes.

       'R/combine.s' functions to perform element wise combination.

       'R/print.char.list.s'  various code simplifications.

       Corrected extra escapes in latexSN function.  fixes #10.

3.2-1 1/25/2007:
       Hmisc function 'ecdf' has been renamed 'Ecdf' to deconflict it
       with the existing 'ecdf' function in base.

       Fixed Bug in format.df that would create numbers with many
       trailing zeros.

       Added arguments 'math.row.names' and 'math.col.names' to
       indicate that the row or col names should be wrapped in the
       latex math environment.

       Fixed problem with 'histbackback' function.

-- 
Charles Dupont	Computer System Analyst		School of Medicine
		Department of Biostatistics	Vanderbilt University



From Max.Kuhn at pfizer.com  Fri Apr 27 16:31:01 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Fri, 27 Apr 2007 10:31:01 -0400
Subject: [R-pkgs] New packages: contrast and desirability
Message-ID: <71257D09F114DA4A8E134DEAC70F25D308320A27@groamrexm03.amer.pfizer.com>

The contrast and desirability packages are available for all platforms
at cran.r-project.org (and coming soon to a mirror near you).

The contrast package extends Frank Harrell's contrast.Design function
for one degree of freedom contrasts of model parameters to other types
of models, such as lm, glm, lme, gls and geese models. Fold-changes are
also calculated for all contrasts. There is a package vignette that
shows examples for a basic two-way layout and a design with repeated
measures.

The desirability package contains S3 classes for multivariate
optimization using the desirability function approach of Harrington
(1965) using the functional forms described by Derringer and Suich
(1980). There are functions for maximization, minimization, hitting a
target, box constraints and a function for creating arbitrarily shaped
desirability equations. There is also a package vignette that shows an
example of a multi-response surface experiment. 

Please send me emails for suggestions and bug fixes at max.kuhn at
pfizer.com.

Max

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From ubk2101 at columbia.edu  Thu May  3 15:27:11 2007
From: ubk2101 at columbia.edu (K. B. Udaya)
Date: Thu, 3 May 2007 09:27:11 -0400
Subject: [R-pkgs] randomSurvivalForest 2.1.0 now available
Message-ID: <38c08c270705030627p5016722s6ccd1a85093eddf1@mail.gmail.com>

Dear useRs:

Release 2.1.0 of the randomSurvivalForest package is now available.
--------------------------------------------------------------------------------------------------
CHANGES TO RELEASE 2.1.0

Release 2.1.0 represents a minor upgrade of the product, and will not affect
most users of the prior version of the product.  Key changes are as follows:

o R 2.5.0 compliance issues and necessitated modifications.

o Modification of PMML representation of RSF forest output.  The RSF custom
extension has been moved from the DataDictionary node to a new
MiningBuildTask node.  Note that forests produced with Release 2.0.0 will
have to be regenerated using Release 2.1.0.  We apologize for the
inconvenience.

o Fast processing of data involving large numbers of predictors (as in
many genomic examples) by using the option big.data=TRUE.  This
option bypasses the huge overhead needed by R in creating design
matrices and parsing formula.  However, users should be aware of
some side effects.  See the RSF help file for more details.  Thanks
to Steven (Xi) Chen for pointing out the problem.

o Only the top 100 predictors are now printed to the terminal when
calling plot.error().  This deals with settings as above when one
might have thousands of predictors.

o Introduced a new wrapper "find.interaction()" for testing for
pairwise interactions between predictors.

-------------------------------------------------------------------------------------

ubk2101 at columbia.edu

Udaya B. Kogalur, Ph.D.
Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012



From ggrothendieck at gmail.com  Thu May  3 18:14:51 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 3 May 2007 12:14:51 -0400
Subject: [R-pkgs] Ryacas now on CRAN
Message-ID: <971536df0705030914j2a74bcb4l44099ae1425d2ae3@mail.gmail.com>

Ryacas is now available on CRAN.  (Previously it was
available on the Omegahat repository.)

Ryacas is an R package that provides an interface from R to
the yacas computer algebra system.   It can be used for
computer algebra, exact arithmetic, ASCII pretty printing
and R to TeX output. R, yacas and Ryacas are all free
software packages distributed under the GPL version 2.

Ryacas is written in R. It uses a recursive decent
R-to-yacas translator and an XML-based OpenMath yacas-to-R
translator. yacas is run as a second process to which
R communicates via a socket interface.

There are 8 different user level interfaces
(yacas.character, yacas.expression, yacas.function,
yacas.formula, Sym objects, Expr objects, yacmode and
runYacas).  Most users will primarily use Sym objects.

NEW INSTALLATION FOR WINDOWS USERS

A key change in moving to CRAN is that yacas.exe is no longer
part of the Ryacas distribution so that Windows users must
separately install yacas 1.0.63. :(  Non-windows users always
had to separately install yacas.  To simplify this somewhat
the yacasInstall() R command will download and install yacas from
within R on Windows:

	# Windows installation procedure
	install.packages("Ryacas", dep = TRUE)
	library(Ryacas)
	yacasInstall()

For non-windows users the installation procedure is the same as
before; namely, install yacas and then install the Ryacas R package.
yacasInstall is not available on non-Windows systems.  More
installation information is available on the Ryacas home page.

LINKS

Home Page (Overview, News, Installation, Sample Session, Links, SVN)
http://code.google.com/p/ryacas/

News (on source changes; not entirely same as home page news)
http://ryacas.googlecode.com/svn/trunk/inst/NEWS

Vignette (includes many examples)
http://ryacas.googlecode.com/svn/trunk/inst/doc/Ryacas.pdf


SAMPLE SESSION
(need fixed font email viewer to view correctly)

> library(Ryacas)

>
> # algebra
>
> library(Ryacas)
> x <- Sym('x')
> (x+1) * (x-1)
expression((x + 1) * (x - 1))
> Simplify("%")
expression(x^2 - 1)
> PrettyForm("%")
 2
x  - 1

>
> # calculus
>
> Integrate(x+tan(x), x)
expression(x^2/2 - log(cos(x)))

>
> # exact arithmetic
>
> yacas('12/24')
expression(1/2)

>
> # ASCII pretty printing
>
> exp(-x^2)/(cos(x)+exp(x))
expression(exp(-x^2)/(cos(x) + exp(x)))
> PrettyForm("%")
     /  /  2 \ \
  Exp\ -\ x  / /
-------------------
Cos( x ) + Exp( x )

>
> # matrix - yacas matrices are row-wise
>

> List(List(1,2),List(x,6))
expression(list(list(1, 2), list(x, 6)))
> PrettyForm("%")
/              \
| ( 1 ) ( 2 )  |
|              |
| ( x ) ( 6 )  |
\              /

>
> # output TeX
>
> k <- Sym('k')
> yacas(TeXForm((x+1)^2 + k^3), retclass = 'unquote')
$\left( x + 1\right)  ^{2} + k ^{3}$

>
> detach()
>

yacas was developed by Ayal Pinkus and other contributors.

Ryacas was developed by Rob Goedman, Gabor Grothendieck,
S?ren H?jsgaard and Ayal Pinkus.   Contact Rob for Mac
issues and Gabor for all other issues.



From tplate at acm.org  Fri May  4 04:46:08 2007
From: tplate at acm.org (Tony Plate)
Date: Thu, 03 May 2007 20:46:08 -0600
Subject: [R-pkgs] new package: RSVGTipsDevice: create SVG plots with
	tooltips & hyperlinks
Message-ID: <463A9E70.5070401@acm.org>

the DESCRIPTION file:

Package: RSVGTipsDevice
Version: 0.7.0
Date:    04/30/2007
Title:   An R SVG graphics device with dynamic tips and hyperlinks
Author:  Tony Plate <tplate at acm.org>, based on RSvgDevice by T Jake 
Luciani <jakeluciani at yahoo.com>
Maintainer: Tony Plate <tplate at acm.org>
Depends: R (>= 1.4)
Description: A graphics device for R that uses the w3.org xml standard
             for Scalable Vector Graphics.  This version supports
             tooltips with 1 to 3 lines, hyperlinks, and line styles.
License: GPL version 2 or newer. http://www.gnu.org/copyleft/gpl.html



From andreas_wittmann at gmx.de  Sun May  6 15:45:37 2007
From: andreas_wittmann at gmx.de (Andreas Wittmann)
Date: Sun, 06 May 2007 15:45:37 +0200
Subject: [R-pkgs] New Package Reliability
Message-ID: <463DDC01.5030406@gmx.de>

Dear R useRs,

A new package 'Reliability' is now available on CRAN. It is mainly a set 
of functions functions for estimating parameters in software reliability 
models. Only infinite failure models are implemented so far. 

This is the first version of the package.

The canonical reference is:
J.D. Musa, A. Iannino, and K. Okumoto. Software Reliability: 
Measurement, Prediction, Application. McGraw-Hill, 1987.

Michael R. Lyu. Handbook of Software Realibility Engineering. IEEE 
Computer Society Press, 1996.
http://www.cse.cuhk.edu.hk/~lyu/book/reliability/


Suggestions, bug reports and other comments are very welcome.


enjoy and best regards
Andreas



From dimitris.rizopoulos at med.kuleuven.be  Tue May  8 10:54:09 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 8 May 2007 10:54:09 +0200
Subject: [R-pkgs] package ltm -- version 0.8-0
Message-ID: <012401c7914e$7142d370$0540210a@www.domain>

Dear R-users,

I'd like to announce the release of the new version of package `ltm' 
(i.e., ltm_0.8-0 soon available from CRAN) for Item Response Theory 
analyses. This package provides a flexible framework for analyzing 
dichotomous and polytomous data under IRT, including the Rasch model, 
the Two-Parameter Logistic model, Birnbaum's Three-Parameter model, 
the Latent Trait model with up to two latent variables (allowing also 
for nonlinear terms), and Samejima's Graded Response model. 
Furthermore, supporting functions for descriptive statistics, 
goodness-of-fit, ability estimation and plotting are available.

New features include:

  * The new functions person.fit() and item.fit() compute p-values for 
person- and item-fit statistics for IRT models for dichotomous data. 
The `simulate.p.value' argument enables the computation of p-values 
based on a Monte Carlo procedure.

  * The new function unidimTest() checks the unidimensionality 
assumption for dichotomous data IRT models, using a Modified Parallel 
Analysis.

  * The new function testEquatingData() prepares data-sets for test 
equating by common items. In particular, two types of common item 
equating are included: alternate form equating (where common and 
unique items are analyzed simultaneously) and across sample equating 
(where different sets of unique items are analyzed separately based on 
previously calibrated anchor items).

  * grm() now works with the available cases when incomplete data 
(i.e., in the presence of NAs) are analyzed.

  * better algorithms, for Missing At Random missing data mechanisms, 
have been written for grm(), ltm(), rasch() and tpm().

  * a residuals() method has been added for `grm', `ltm', `rasch', and 
`tpm' objects that computes Pearson-type residuals.

  * factor.scores() and fitted() methods for classes `grm', `ltm', 
`rasch', and `tpm' allow now for NAs in the `resp.patterns' argument, 
enabling thus the computation of ability estimates and fitted values 
for incomplete response patterns.

  * the fitted() method now allows also for the computation of 
marginal and conditional (on the latent variable(s)) probabilities; 
this feature is controlled by the new `type' argument.

  * for more details and other news, check the CHANGES file that ships 
with the package.

More information as well as .R files illustrating the capabilities of 
the package can be found in the Rwiki page of `ltm' available at: 
http://wiki.r-project.org/rwiki/doku.php?id=packages:cran:ltm.

Future plans include the development of functions for fitting Bock's 
Nominal Response model and the option for Differential Item 
Functioning.

I'd like also to thank all users of `ltm' for providing valuable 
feedback, and welcome any additional feedback (questions, suggestions, 
bug-reports, etc.).

Best,
Dimitris


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From Ivailo.Partchev at uni-jena.de  Tue May  8 12:52:25 2007
From: Ivailo.Partchev at uni-jena.de (Ivailo Partchev)
Date: Tue, 08 May 2007 12:52:25 +0200
Subject: [R-pkgs] irtoys
Message-ID: <46405669.6000502@uni-jena.de>

I have just submitted irtoys_0.1.0, a package potentially useful for 
those working with IRT models. It can fit the 1PL, 2PL, and 3PL models 
through a simple and unified syntax, using either the R package ltm, 
Brad Hanson's ICL program, or the commercially available BILOG-MG. The 
purpose is basically to facilitate teaching, and especially comparisons 
across models and/or programs. Various graphs, item fit statistics, 
scaling methods, ability estimation, simulation facilities etc. are also 
included. Please notice that most options in estimating an IRT model are 
kept to the typical default values, and only a small, common subset of 
the ltm, ICL, and BILOG syntax is supported. Comments are very welcome.

Ivailo Partchev
Institute of Psychology
University of Jena
Germany



From HDoran at air.org  Tue May  8 17:59:22 2007
From: HDoran at air.org (Doran, Harold)
Date: Tue, 8 May 2007 11:59:22 -0400
Subject: [R-pkgs] MiscPsycho Package 1.0
Message-ID: <2323A6D37908A847A7C32F1E3662C80EBA0161@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070508/eb1b1c00/attachment.pl>

From milbo at sonic.net  Fri May 11 01:03:25 2007
From: milbo at sonic.net (Stephen Milborrow)
Date: Thu, 10 May 2007 16:03:25 -0700
Subject: [R-pkgs] New package "earth"
Message-ID: <000401c79357$9afe66b0$6401a8c0@DDV3JY61>

The "earth" package is now available on CRAN.

Earth builds models using Friedman's MARS.

Earth's principal advantages over the existing function mda::mars are that 
it is much faster and provides plotting and printing methods.  The general 
purpose model plotting function "plotmo" may also be useful to people who 
are not interested in earth itself.

Example:

> a <- earth(Volume ~ ., data = trees)
> summary(a, digits = 2)

Call:
earth(formula = Volume ~ ., data = trees)

Expression:
  23
  +  5.7 * pmax(0,  Girth - 13)
  -  2.9 * pmax(0,  13 - Girth)
  + 0.72 * pmax(0, Height - 76)

Number of cases: 31
Selected 4 of 5 terms, and 2 of 2 predictors
Number of terms at each degree of interaction: 1 3 (additive model)
GCV: 11     RSS: 213     GRSq: 0.96     RSq: 0.97


Regards,
Stephen Milborrow



From klaus.nordhausen at uta.fi  Wed May 16 08:45:12 2007
From: klaus.nordhausen at uta.fi (Klaus Nordhausen)
Date: Wed, 16 May 2007 09:45:12 +0300
Subject: [R-pkgs] new packages 'ICS' and 'ICSNP'
Message-ID: <464AA878.7010906@uta.fi>

Dear R useRs,

The new contributed packages 'ICS' and 'ICSNP' are available on CRAN.

Descriptions:

The 'ICS' package implements the 2 scatter matrix transformation to 
obtain an invariant coordinate system or independent components, 
depending on the underlying assumptions. The result of the 
transformation is an object of the S4 class ics which is provided by 
this package. Besides generic functions to create and work with ics 
objects the package contains also some scatter matrices and two tests 
for multinormality.


The 'ICSNP' package contains tools for nonparametric multivariate 
analysis, including the estimation of location and shape as well as some 
tests for location and independence. Shape matrices from this package 
can be used as one of the scatter matrices needed in the package ICS 
whereas the tests of this package can be used for testing in the 
framework of invariant coordinates or independent components obtained 
from the package ICS. The parametric Hotelling?s T test serves as a 
reference for the nonparametric location tests.

Suggestions, bug reports and other comments are very welcome.

Best wishes,

Klaus, Seija, Hannu and Dave

-- 
Klaus Nordhausen
Researcher
Tampere School of Public Health
FIN-33014 University of Tampere

phone:	+358 3 3551 7086
fax:	+358 3 3551 6057
e-mail:	Klaus.Nordhausen at uta.fi



From hastie at stanford.edu  Thu May 17 03:13:04 2007
From: hastie at stanford.edu (Trevor Hastie)
Date: Wed, 16 May 2007 18:13:04 -0700
Subject: [R-pkgs] New version 0.9-7 of lars package
Message-ID: <464BAC20.6000901@stanford.edu>

I uploaded a new version of the lars package to CRAN,
which incorporates some nontrivial changes.

1) lars now has normalize and intercept options, both defaulted to TRUE,
which means the variables are scaled to have unit euclidean norm, and
an intercept is included in the model. Either or both can be set to FALSE.

2) lars has an additional type = "stepwise" option;
    now the list is type=c("lasso", "lar", "forward.stagewise","stepwise")
This was included because it is trivial to implement, and useful for 
comparisons.
"Stepwise" is a version of forward stepwise regression, where the 
variable to
enter is the one most correlated with the residuals. This is not 
necessarily the
same as the forward stepwise implemented as part of step() in R, where the
variable entered is the one that, when included, reduces the RSS the most.

3) a method for summary() has been included, which gives an anova-type 
summary
of the sequence of steps.

4) The plot method for lars defaults to plotting coefficients against 
the relative
L1 norm of the coefficients. This was not done correctly in general for 
type "lar"
and "forward.stagewise", since the L1 norm does not change smoothly if
coefficients pass through zero. This has been fixed.

5) A smalll number of of other changes have been made, some in response 
to email
messages from users.
 
Thanks to Yann-Ael Le Borgne for pointing out the problem in (4) and 
proposing
a solution, and to Lukas Meier for reporting some bugs. Please let me 
know of any
new problems, or old ones not yet repaired.

Trevor Hastie

--------------------------------------------------------------------
  Trevor Hastie                                  hastie at stanford.edu
  Professor & Chair, Department of Statistics, Stanford University
  Phone: (650) 725-2231 (Statistics)	         Fax: (650) 725-8977
	 (650) 498-5233 (Biostatistics)		 Fax: (650) 725-6951
  URL: http://www-stat.stanford.edu/~hastie
  address: room 104, Department of Statistics, Sequoia Hall
	          390 Serra Mall, Stanford University, CA 94305-4065



From jfox at mcmaster.ca  Tue May 29 22:47:30 2007
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 29 May 2007 16:47:30 -0400
Subject: [R-pkgs] Rcmdr 1.3-0 and RcmdrPlugins.TeachingDemos
Message-ID: <20070529204734.WEHY13710.tomts25-srv.bellnexxia.net@JohnDesktop8300>

I'd like to announce a new version, 1.3-0, of the Rcmdr package. The Rcmdr
package provides a basic-statistics graphical user interface (GUI) to R. 

Beyond small changes and additions, this new version of the package makes
provision for "plug-ins" that permit extension of the Rcmdr GUI without
altering and rebuilding the Rcmdr source package or modifying the installed
package. An R Commander plug-in is an ordinary R package that (1) provides
extensions to the R Commander menus is a file named menus.txt located in the
package's etc directory; (2) provides call-back functions required by these
menus; and (3) in optional Log-Exceptions: and Models: fields in the
package's DESCRIPTION file, augments respectively the list of functions for
which printed output is suppressed and the list of model objects recognized
by the R Commander. The menus provided by a plug-in package are merged with
the standard Commander menus. 

Plug-in packages given in the R Commander plugins option (see ?Commander)
are automatically loaded when the Commander starts up. Plug-in packages may
also be loaded via the Commander "Tools -> Load Rcmdr plug-in(s)" menu; a
restart of the Commander is required to install the new menus. Finally,
loading a plug-in package when the Rcmdr is not loaded will load the Rcmdr
and activate the plug-in. 

An illustrative R Commander plug-in package, RcmdrPlugin.TeachingDemos
(providing a GUI to some of Greg Snow's TeachingDemos package), is now
available on CRAN. (I suggest using this naming convention -- RcmdrPlugin.*
-- so that plug-in packages will sort immediately below the Rcmdr package on
CRAN. This assumes, of course, that other people will be interested in
creating Rcmdr plugins!)

Because this is a new feature of the Rcmdr, feedback and suggestions would
be appreciated.

I'd like to acknowledge Richard Heiberger's suggestions for the design of
this plug-in facility.

John

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox



From Alejandro.JaraVallejos at med.kuleuven.be  Tue May 29 18:10:27 2007
From: Alejandro.JaraVallejos at med.kuleuven.be (Alejandro Jara Vallejos)
Date: Tue, 29 May 2007 18:10:27 +0200
Subject: [R-pkgs] DPpackage - New version
Message-ID: <20070529181027.3fturouitnogg0gs@webmail4.kuleuven.be>

Dear List:

I have uploaded version 1.0-4 of DPpackage on CRAN. Since the first  
version (1.0-0), I have not communicated the improvements of the  
package. I'll use this email to summarize its current status.

The name of the package is motivated by the Dirichlet process.  
However, DPpackage tries to be a general package for Bayesian  
nonparametric and semi-parametric data analysis. So far, the package  
includes models based on Dirichlet processes, Dirichlet process  
mixtures of normals, Polya trees, and Random Bernstein polynomials. A  
list of current functions is given next:

1) Density estimation: DPdensity (using DPM of normals), PTdensity  
(using Mixtures of Polya Trees), and BDPdensity (using  
Bernstein-Dirichlet prior). The first two functions allow uni- and  
multi-variate analysis.

2) Nonparametric random effects distributions in mixed effects models:

    2.1) DPlmm and DPMlmm, using a DP/MDP and DPM of normals prior,  
respectively, for the linear mixed effects model.

    2.2) DPglmm and DPMglmm, using a DP/MDP and DPM of normals prior,  
respectively, for generalized linear mixed effects models,  
respectively. The sampling(link) considered by these functions are  
binomial(logit,probit), poisson(log) and gamma(log).

    2.3) DPolmm and DPMolmm, using a DP/MDP and DPM of normals prior,  
respectively, for the probit-ordinal mixed effects models.

    2.4) DPrasch and FPTrasch, using a DP/MDP and finite PT/MPT  
(mixture of Polya Trees) prior for the Rasch model with binary  
sampling distribution, respectively.

    2.5) DPraschpoisson and FPTraschpoisson. The same as before (2.4)  
but with a Poisson sampling.

    2.6) DPmeta and DPMmeta for the random (mixed) effects  
meta-analysis models, using a DP/MDP and DPM of normals prior,  
respectively.

3) Binary regression with nonparametric link:

    3.1) CSDPbinary, using Newton, Czado and Chappell (1996)'s  
centrally standardized DP prior.

    3.2) DPbinary, using the regular DP prior for the inverse of the  
link function.

    3.3) FPTbinary, using a finite PT prior for the inverse of the  
link function.


4) AFT model for interval-censored data:

    4.1) DPsurvint, using a MDP prior for the baseline distribution.

5) ROC curve estimation:

    5.1) DProc, using DPM of normals.

6) Linear model with a nonparametric for the error distribution:

    6.1) PTlm, using MPT.

7) DP prior elicitation:

    7.1) DPelicit, using the exact and approximated formulas for the  
mean and variance of the number of clusters given the total mass  
parameter and the number of subjects.


Tim Hanson and Fernando Quintana have made contributions to the  
current version. I would also like to thank George Karabatsos for his  
input to the current status of the package and Peter Mueller for  
actively promoting the package.

Various other improvements have been motivated by questions asked by  
many people around the world. I would like to thank all of them too.

I welcome anyone who sends comments, suggestions, remarks, and  
particularly those who find bugs or mistakes in any part of the  
package or its documentation. DPpackage is an open source program for  
Bayesian nonparametric developments. All contributions are welcome.

Best regards,

Alejandro.


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From knoblauch at lyon.inserm.fr  Tue May 29 17:59:04 2007
From: knoblauch at lyon.inserm.fr (ken knoblauch)
Date: Tue, 29 May 2007 17:59:04 +0200
Subject: [R-pkgs] new packages psyphy and MLDS
Message-ID: <40119c691173b4fae2adff6bfabfe98a@lyon.inserm.fr>

New packages psyphy and MLDS are available on CRAN:

psyphy ncludes an assortment of functions
  useful in  analyzing data from pyschophysical experiments. It
   includes functions for calculating d' from several
   different experimental designs, links for mafc to be
   used with the binomial family in glm (and possibly
   other contexts) and selfStart functions for estimating gamma values
  for CRT (and possibley other RGB) screen calibration data.

MLDS implements analyses for Maximum Likelihood Difference Scaling.
Difference scaling is a method for scaling perceived super-threshold
differences. The package contains functions that allow the user to fit
the resulting data by maximum likelihood and to test the internal 
validity
of the estimated scale.   There are also example functions that might
be used to design and run a difference scaling experiment,

Any suggestioins, criticisms, bug-reports, etc. are always welcome.

Best,

Ken Knoblauch

-- 
Ken Knoblauch
Inserm U846
Institut Cellule Souche et Cerveau
D?partement Neurosciences Int?gratives
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.pizzerialesgemeaux.com/u846/



From rmh at temple.edu  Wed May 30 14:55:55 2007
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 30 May 2007 08:55:55 -0400 (EDT)
Subject: [R-pkgs] Revised Rcmdr.HH package
Message-ID: <20070530085555.CCV65389@po-d.temple.edu>

I posted a revised Rcmdr.HH_1.8-0 package on CRAN.

The Rcmdr.HH package adds additional menu items to the Rcmdr package by
John Fox.  Our introductory course at Temple University includes several
topics that were not addressed in the Rcmdr.  This revision uses the new
RcmdrPlugin technology that John announced a few days ago.

Rich



From calenge at biomserv.univ-lyon1.fr  Thu May 31 09:18:07 2007
From: calenge at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Thu, 31 May 2007 09:18:07 +0200
Subject: [R-pkgs] adehabitat version 1.6
Message-ID: <465E76AF.6080501@biomserv.univ-lyon1.fr>

Dear all,

I have just uploaded to CRAN the version 1.6 of the
package 'adehabitat'. Significant changes are
listed below:

* The package has been reorganized into four parts (see
?adehabitat-package for a description): (i) management of raster maps,
(ii) habitat selection / ecological niche analysis, (iii) home range
analysis, and (iv) analysis of animals trajects. The package contains
several demo files to allow an overview of these parts :
demo(rastermaps), demo(homerange), demo(managltraj),
demo(analysisltraj), demo(nichehs).

* the package now contains a new function allowing the exploration of
the ecological niche, which generalizes several factor analyses (ENFA,
MADIFA, ...) and is closely related to several methods (Mahalanobis
distances, selection ratios, etc.), named gnesfa() (see the examples of
the help page for the properties of this analysis).

* The class ltraj now distinguishes two types of trajects: type I (time
not recorded, e.g. tracks of animals in the snow) and type II (time
recorded, e.g. GPS monitoring). Trajects of type II may either be
"regular" (constant time lag between relocations) or not.

* Numerous example datasets have been added to the package to illustrate
the analysis of animals trajects: 4 porpoises, 6 albatross, 1 hooded
seal, 1 whale, 1 brown bear, two roe deer, two chamois, 4 ibex, 1
mouflon, 3 wild boar

* Many functions have been added to allow the management of animals
trajects within R: Some functions allow to handle the attributes or the
storage of the trajects  (typeII2typeI, typeI2typeII, sett0, cutltr,
is.regular, is.sd, mindistkeep, offsetdate, set.limits), other allow to
manage missing values and test their random distribution in the traject
(setNA, summaryNAltraj, plotNAltraj, runsNAltraj), other allow a
graphical exploration of the properties of the trajects (hist.ltraj,
plot.ltraj, plotltr, sliwinltr).

* Several functions now allow to test the independence of the
descriptive parameters in the trajects (indmove and wawotest for dx, dy
and dist, testang.ltraj for rel.angle and abs.angle)

* Several functions allow to simulate common models of trajects: the
correlated random walk (simm.crw), the brownian motion (simm.brown), the
arithmetic brownian motion (simm.mba), the Ornstein Uhlenbeck process
(simm.mou), the brownian bridge (simm.bb) and the Levy process (simm.levy).

* The function explore.kasc() provides a Tk interface for the
exploration of a multi-layer raster map of class "kasc"

* A partitioning algorithm (still under research) is also available to
partition a traject into segments with homogeneous properties (see the
help page of modpartltraj)

* The bugs in redisltraj and mcp.area have been corrected

Happy testing,


Cl?ment CALENGE
-- 
Cl?ment CALENGE
Laboratoire de Biom?trie et Biologie ?volutive
UMR CNRS 5558
43 Bd. 11 Nov. 1918
69622 Villeurbanne Cedex - France
Office national de la chasse et de la faune sauvage
95, rue Pierre Flourens
34000 Montpellier



From h.wickham at gmail.com  Mon Jun  4 07:14:18 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 4 Jun 2007 07:14:18 +0200
Subject: [R-pkgs] Beta version of ggplot2
In-Reply-To: <f8e6ff050706031018v119635f2m2f4a354cc332ccb6@mail.gmail.com>
References: <f8e6ff050706031018v119635f2m2f4a354cc332ccb6@mail.gmail.com>
Message-ID: <f8e6ff050706032214l29c9d5fft3ce2948caf44c496@mail.gmail.com>

Dear all,

I am pleased to announce the new beta release of ggplot2.  ggplot2 is
a plotting system for R, based on the grammar of graphics, which tries
to take the good parts of base and lattice graphics and none of the
bad parts.  It takes of many of the fiddly details that make plotting
a hassle (like drawing legends) as well as providing a powerful model
of graphics that makes it easy to produce complex multi-layered
graphics.

You can install ggplot2 from CRAN with the following code:
install.packages("ggplot2", dep=TRUE)

There have been a lot of changes to the syntax since the last version
of ggplot and I have renamed the package to ggplot2, so that you can
continue to use your existing code while you transition to the new
system.

As part of the release, I am working on a radically improved
documentation system, currently available at
http://had.co.nz/ggplot2/.  While I'm still working on the textual
explanations, I have mostly completed the examples, which are
displayed with both code and output.  There are over 480 example
graphics, so I hope you should be able to find an example
demonstrating whatever you need.  Any comments on the content and
display would be gratefully received.

In the next few days I will be adding the first chapters of the ggplot
book, which will provide a more systematic introduction to ggplot, the
theory behind it and more examples of its use.  The ggplot book will
be published with Springer, hopefully in Summer 2008.

The latest version of ggplot now provides a complete implementation of
the grammar of graphics, including new support for coordinate systems,
position adjustment (dodging, stacking and jittering).

This is a beta release, so there are still bugs in the code, and many
small aesthetic tweaks to be made.  If you encounter something that
doesn't work, doesn't make sense or you think could be improved,
please don't hesitate to contact me.

Again, you can find out more, and see hundreds of example graphics at
http://had.co.nz/ggplot2/.

Hadley

PS. If you are interested in learning more in person, have at look at
the courses available at http://lookingatdata.com.



From h.wickham at gmail.com  Mon Jun  4 07:14:40 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 4 Jun 2007 07:14:40 +0200
Subject: [R-pkgs] Updated reshape and ggplot
In-Reply-To: <f8e6ff050706031000l4b5bc719t4a9762a1be53103f@mail.gmail.com>
References: <f8e6ff050706031000l4b5bc719t4a9762a1be53103f@mail.gmail.com>
Message-ID: <f8e6ff050706032214n600cb830m3294ab88b050fc9d@mail.gmail.com>

Hi everyone,

This is a short announcement for the users of ggplot and reshape.  I
have just released new versions of each that fix bugs when used with R
2.5.0:

 * reshape was having problems with missing combinations of variables
 * errorbars in ggplot weren't working.

I've you've been having problems with either of these, please upgrade.

About ggplot
=====================

An implementation of the grammar of graphics in R.

ggplot is an implementation of the grammar of graphics in R. It
combines the advantages of both base and lattice graphics:
conditioning and shared axes are handled automatically, while
maintaining the ability to build up a plot step by step from multiple
data sources. It also implements a more sophisticated multidimensional
conditioning system and a consistent interface to map data to
aesthetic attributes.

Find out more at http://had.co.nz/ggplot

About reshape
=====================

Reshape is an R package for flexibly restructuring and aggregating
data. It is available on all platforms supported by R (Linux, OS X,
Windows, ...).  Reshape (hopefully) makes it easy to do what you have
been struggling to do with tapply, by, aggregate, xtabs, apply and
summarise. It is also useful for getting your data into the correct
structure for lattice or ggplot plots.

You can find out more at http://had.co.nz/reshape


Regards,

Hadley



From david.meyer at wu-wien.ac.at  Tue Jun  5 00:11:32 2007
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Tue, 05 Jun 2007 00:11:32 +0200
Subject: [R-pkgs] New package: relations
Message-ID: <46648E14.8000808@wu-wien.ac.at>

Dear useRs,

it is our great pleasure to announce the new package "relations" to
appear on all CRAN-mirrors soon.

This package provides data structures and methods for creating and
manipulating relations, relation ensembles, sets, and tuples. The
feature list includes:

* creation of relations by domain and graph/characteristic
function/incidences,

* extraction of characteristic function and graph,

* predicate functions for the most common standard characteristics,

* operators known from relational algebra theory (such as projection,
selection, cartesian product, joins, etc.),

* transitive/reflexive reduction and closure of a relation,

* relation ensembles for combining relations,

* fitters for determining (possibly all) consensus relations of a
relation ensemble including the Borda and Condorcet methods, as well as
exact solvers for minimizing a criterion function based on the symmetric
difference (Kemeny-Snell) metric.

* a simple plot method for Hasse-diagrams using RGraphviz.


Kurt and David



From Graham.Williams at togaware.com  Tue Jun  5 10:09:55 2007
From: Graham.Williams at togaware.com (Graham Williams)
Date: Tue, 5 Jun 2007 18:09:55 +1000
Subject: [R-pkgs] Package update: pmml version 1.1.1
Message-ID: <20070605080955.GA15345@athene.togaware.com>

Version 1.1.1 of the pmml package (PMML = Predictive Modelling Markup
Language) has been uploaded to CRAN. This version adds pmml.lm to
generate PMML for linear models (currently, without interactions).

The PMML package is part of the Rattle toolkit for data
mining. Further information from http://rattle.togaware.com.

Regards,
Graham



From dave at kanecap.com  Tue Jun  5 15:52:13 2007
From: dave at kanecap.com (David Kane)
Date: Tue, 5 Jun 2007 09:52:13 -0400
Subject: [R-pkgs] New Package on Lancet Surveys of Iraq Mortality
Message-ID: <18021.27277.958091.918392@gargle.gargle.HOWL>

Hello,

I have placed a package on CRAN about two surveys of mortality in Iraq
that were published in the Lancet.

http://cran.at.r-project.org/src/contrib/Descriptions/lancet.iraqmortality.html

> install.packages("lancet.iraqmortality")

...

> library(lancet.iraqmortality)
Loading required package: foreign
> ?lancet.iraqmortality
> vignette("mortality")

This is a rough version. Suggestions and feedback are welcome.

Dave Kane



From mfay at niaid.nih.gov  Wed Jun  6 15:34:50 2007
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 6 Jun 2007 09:34:50 -0400
Subject: [R-pkgs] R Package: ssanv - Sample size adjustments for
	nonadherence and variability of input parameters
Message-ID: <31DDB7BE4BF41D4888D41709C476B657062E7694@NIHCESMLBX5.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070606/dc0b3c9b/attachment.pl>

From mfay at niaid.nih.gov  Wed Jun  6 15:46:35 2007
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 6 Jun 2007 09:46:35 -0400
Subject: [R-pkgs] R package: Mchtest - Monte Carlo hypothesis testing
	allowing Sequential Stopping
Message-ID: <31DDB7BE4BF41D4888D41709C476B657062E7695@NIHCESMLBX5.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070606/d0c6991b/attachment.pl>

From mfay at niaid.nih.gov  Wed Jun  6 15:50:52 2007
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 6 Jun 2007 09:50:52 -0400
Subject: [R-pkgs] New Package: rateratio.test
Message-ID: <31DDB7BE4BF41D4888D41709C476B657062E7696@NIHCESMLBX5.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070606/d1b1dce4/attachment.pl>

From h.wickham at gmail.com  Mon Jun 11 07:42:03 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 11 Jun 2007 07:42:03 +0200
Subject: [R-pkgs] Updated ggplot2 package (beta version)
Message-ID: <f8e6ff050706102242g399410b3kd34744ac2a44854f@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
none of the bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2

Changes in version 0.5.1 ------------------------------

 * new chapter in book and changes to package to make it possible to
customise every aspect of ggplot display using grid

 * a new economic data set to help demonstrate line, path and area plots

 * many bug fixes reported by beta testers

Hadley



From h.wickham at gmail.com  Tue Jun 19 09:07:26 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 19 Jun 2007 09:07:26 +0200
Subject: [R-pkgs] ggplot2 0.5.2
Message-ID: <f8e6ff050706190007v2c236c2dn3ddb5de02d4b879d@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
none of the bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2

Changes in version 0.5.2 ------------------------------

* add argument to position dodge so it's now possible to accurately
dodge things with different widths to their physical widths
* added median summary
* new examples:
	* logistic regression example in stat_smooth
* bugs fixed:
	* evaluation of arguments to layer is no longer delayed
	* can use categorical xseq with stat_smooth
	* x and y axes named incorrectly (thanks to Dieter Menne for spotting this)
	* can now pass position objects to qplot
	* y jitter calculated correctly, and jittered data rescales axis now
	* removed silly legend from quantile plot
	* extra arguments not being passed on to geoms/stats
	* fixed bug in stat_summary when summarising a factor
	* fixed bugs in stat_summary, geom_ribbon, and coord_trans examples



From lawremi at iastate.edu  Tue Jun 19 15:10:35 2007
From: lawremi at iastate.edu (Michael Lawrence)
Date: Tue, 19 Jun 2007 08:10:35 -0500
Subject: [R-pkgs] RGtk2 2.10.x series available
Message-ID: <509e0620706190610ra4f82fdv1f547ef7d3323777@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070619/8ab78a9f/attachment.pl>

From adrian at maths.uwa.edu.au  Thu Jun 21 09:15:26 2007
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Thu, 21 Jun 2007 15:15:26 +0800 (WST)
Subject: [R-pkgs] spatstat version 2
Message-ID: <35219.130.95.98.17.1182410126.squirrel@130.95.98.17>

              SPATSTAT version 2

Spatstat is an R package for the statistical analysis of spatial data.

A preliminary announcement about the forthcoming Version 2 of spatstat
is available here:
    <www.spatstat.org/spatstat/spatstat2.html>



From Max.Kuhn at pfizer.com  Thu Jun 21 16:50:40 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Thu, 21 Jun 2007 10:50:40 -0400
Subject: [R-pkgs] odfWeave version 0.5.9 released
Message-ID: <71257D09F114DA4A8E134DEAC70F25D308B55763@groamrexm03.amer.pfizer.com>

A new version of odfWeave has been released to CRAN. This is a
significant change to the package internals. It now uses the XML library
instead of a bunch of regular expressions.

New features include:

   - Captions for tables and figures
   - Functions to insert page breaks and to change the page layout
   - Style objects for frames and pages

Bug fixes include:

   - Parsing of arguments for graphics devices
   - Misc issues with bulleted lists

There is also a 30 page manual in the examples sub-directory that
describes the various style element and their values, with almost 50
code chunks for illustration.

Thanks to Steve Weston, Nathan Coulter, Sarah Goslee and Ralf Herold.

Send me any questions or comments,

Max

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From luyizhao at fas.harvard.edu  Wed Jun 27 16:07:42 2007
From: luyizhao at fas.harvard.edu (luyizhao at fas.harvard.edu)
Date: Wed, 27 Jun 2007 10:07:42 -0400
Subject: [R-pkgs] New package "tradeCosts"
Message-ID: <1182953262.46826f2e64b47@webmail.fas.harvard.edu>

We would like to announce the availability of the 'tradeCosts' package
in R for analysing transaction costs of trading.  Version 0.1-0 is now available
on CRAN.  To take a look, you can:

> install.packages("tradeCosts")
...
> vignette("tradeCosts")

and play around.

This is the first and very basic version of a package that we hope to
expand over the next few months.

The cost analysis this package performs is currently very basic.  We
are releasing this version with the goal of getting feedback from
potential users on what functionality they would like to see in future
releases of the tradecosts package.

Aaron Schwartz
Luyi Zhao



From mildenbe at statistik.uni-dortmund.de  Thu Jun 28 15:26:28 2007
From: mildenbe at statistik.uni-dortmund.de (Thoralf Mildenberger)
Date: Thu, 28 Jun 2007 15:26:28 +0200
Subject: [R-pkgs] new package benchden 1.0.0 : benchmark densities for
 nonparametric density estimation
Message-ID: <4683B704.50406@statistik.uni-dortmund.de>

The new package "benchden" 1.0.0 implements 28 benchmark densities for
nonparametric density estimation that were introduced by A. Berlinet and
L. Devroye ("A Comparison of Kernel Density Estimates", Pub. Inst. Stat.
Univ. Paris, XXXVIII, fasc. 3, 1994, 3-59,
http://cg.scs.carleton.ca/~luc/devs.html ). This collection includes a
variety of densities with different degrees of smoothness, different
tail behaviour, different number of modes, with and without infinite 
peaks and also some standard densities like the normal and the uniform. 
There is also a small intersection (e.g. the claw density) with the 
collection of normal mixtures introduced by Marron and Wand and 
implemented in R in the package "nor1mix".
Similar to the test bed functions by Donoho and Johnstone (Blocks, Bumps
etc.) commonly used in regression or the "Peppers" and "Lena" images
popular in image analysis, the densities in this collection should be 
useful for testing and comparing new and existing density estimators.
"benchden" 1.0.0 contains functions for the generation of random
variates as well as density-, distribution- and quantile-functions.
Everything is implemented in typical R-style and the package should
reduce the programming effort needed for simulation studies in
nonparametric density estimation. It also allows for better
reproducibility of the results.

Thoralf Mildenberger, Henrike Weinert and Sebastian Tiemeyer



From h.wickham at gmail.com  Sun Jul  1 17:58:54 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 1 Jul 2007 17:58:54 +0200
Subject: [R-pkgs] Clusterfly
Message-ID: <f8e6ff050707010858h7f4b925eu7e5fbecb5a6479f9@mail.gmail.com>

clusterfly
http://had.co.nz/clusterfly/

Typically, there is somewhat of a divide between statistics and
visualisation software. Statistics software, particularly R, provides
implementation of cutting edge research methods, but limited graphics.
Visualisation software will provide sophisticated visual interfaces,
but few statistical algorithms. The clusterfly package presents some
early experimentation aimed at overcoming this deficiency by linking R
and GGobi. Cluster analysis was chosen as it is an exploratory method
that needs sophisticated visualisation and statistical algorithms.

Clusterfly provides some tools that work with all clustering
algorithms, and some that are tailored for particular ones.  Generic
tools allow you to animate between clusterings (see ?cfly_animate) and
produce common static graphics (?cfly_dist, ?cfly_pcp).  Specific
algorithms are available for:

* Self organising maps (aka Kohonen neural networks), ?ggobi.som.
Displays the self organising map/net in the original space of the
data.

* Hierarchical clustering, ?hierfly. Connects data points with lines
like a dendrogram, but in the high-dimensional space of the original
data

 * Model based clustering, ?mefly. Adds ellipsoids from the
multivariate normal distributions the clusters are based on

You will need GGobi (http://www.ggobi.org) and rggobi
(http://www.ggobi.org/rggobi) installed to be able to use clusterfly.

Regards,

Hadley



From h.wickham at gmail.com  Sun Jul  8 21:10:49 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 8 Jul 2007 21:10:49 +0200
Subject: [R-pkgs] Scagnostics - scatterplot diagnostics
Message-ID: <f8e6ff050707081210n29e29847y372e02fd220c5d3b@mail.gmail.com>

The scagnostics package implements the graph theoretic scagnostics
described by Leland Wilkinson, Anushka Anand and Robert Grossman
(http://www.ncdm.uic.edu/publications/files/proc-094.pdf), building on
an old idea of Tukey's to define indices of "interestingness" to help
guide the search for interesting features in the pair-wise
scatterplots of a highly multivariate dataset.

The scagnostics package currently only supports two methods, one which
computes the scagnostics for a pair of variables, and the other for
all pairs of variables in a data.frame.

If you are attending the JSM, there is a session on scagnostics.
Details are available at http://tinyurl.com/324yb5

(The package has just been added to CRAN, it may be a couple of days
before it is available on your local mirror)

Regards,

Hadley



From h.wickham at gmail.com  Mon Jul  9 11:12:28 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 9 Jul 2007 11:12:28 +0200
Subject: [R-pkgs] ggplot 0.5.4
Message-ID: <f8e6ff050707090212r7925d60ck2ece466d98500731@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the over 500
examples of ggplot in use.

Changes in version 0.5.4 ------------------------------

* border now drawn on top of geoms, instead of below - this results in
better appearance when adjusting scale limits
* ggplot() + aes() now modifies existing default aesthetic mapping,
rather than overwriting
* polished examples in facet_grid

Changes in version 0.5.3 ------------------------------

* added experimental scatterplot matrix, see ?plotmatrix
* added new border.colour and grid.minor.colour options for better
control over plot appearance
* updated theme_bw to do better when drawing a plot with white background
* better default colour choices for gradients (and more discussion in examples)
* fixed bug in ScaleGradient2 where scales with different positive and
negative ranges were not scaled correctly
* allow expressions as result from strip.text
* fixed rare bug in geom_vline and geom_hline
* fixed example in geom_abline
* tweaked display of multiline axis labels

Regards,

Hadley



From david.meyer at wu-wien.ac.at  Mon Jul  9 15:49:29 2007
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Mon, 09 Jul 2007 15:49:29 +0200
Subject: [R-pkgs] New package "proxy" for distances and similiarities
Message-ID: <46923CE9.4090802@wu-wien.ac.at>

Dear useRs,

a new package for computing distance and similarity matrices made it to 
CRAN, and will propagate to the mirrors soon.

It includes an enhanced version of "dist()" with support for more than 
40 popular similarity and distance measures, both for auto- and 
cross-distances. Some important ones are implemented in C.

The proximity measures are stored in a registry which can easily be 
queried and extended by users at run-time. For adding a new measure, the 
simplest way is to provide the distance measure as a small R function, 
the package code will do the loops on the C code level to create the 
proximity matrix. It is of course also possible to use more efficient C 
implementations---either for the distance measure alone, or the whole 
matrix computation.

Input data is not restricted to matrices: provided the proximity measure 
can handle it, lists and data frames are also accepted.

The formulas for binary proximities can conveniently be specified in the 
a/b/c/d/n format, where the number of concordant/discordant pairs is 
precomputed on the C code level.

We are currently working on support for sparse data.

This is also a "Call for Measures": if you feel that a particular 
similarity of distance measure is missing, please send the formula and a 
reference (or, ideally, the whole registry entry) to one of the package 
maintainers who will happily add it.

David and Christian.



From edd at debian.org  Mon Jul  9 18:41:55 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 9 Jul 2007 11:41:55 -0500
Subject: [R-pkgs] CRANberries -- An RSS feed about New and Updated CRAN
	packages
Message-ID: <18066.25939.77583.800991@basebud.nulle.part>


Announcing CRANberries -- An RSS feed about New and Updated CRAN packages

A new RSS feed [1] is now available that summarizes uploads to CRAN.  This
makes it possibly to quickly obtain concise information about which (of the
now over one thousand !!) packages were added or updated at CRAN and its
mirrors.

To this end, two basic variants are provided:
 - a feed for new packages where we display the DESCRIPTION file
 - a feed for updated packages where we display the output of diffstat(1) 
   between the old and new source tar archives.
  
As the URLs for these are in a hierarchy, one can subscribe to both or
individual feeds.  The URLs are as follows:

   Everything
	http://dirk.eddelbuettel.com/cranberries/index.rss

   Just CRAN (so far the same as All)
	http://dirk.eddelbuettel.com/cranberries/cran/index.rss

   New CRAN packages
	http://dirk.eddelbuettel.com/cranberries/cran/new/index.rss

   Updated CRAN packages
	http://dirk.eddelbuettel.com/cranberries/cran/updated/index.rss

but the easiest way may just be to subscribe to Elijah's wonderful 'Planet R'
feed aggregator which already sources the 'Everything' variant above.  Beside
giving you lots of other R information, it also points to a more reliable
back-end than my small server at home.

Lastly, I could add other repositories. However, to provide updates in the
current format, my code relies on some CRAN features not available on all
other repos (i.e an Archive/ section with old tarballs, and the various
Descriptions/$package.DESCRIPTION files).

For the technically inclined, this is implemented using a few lines of R
executed by littler [2] storing data via R/DBI in a SQLite db and writing
simple text files that are then aggregated by the Blosxom [3] blog engine.

Comments, questions, criticism most welcome.

Best regards,  Dirk

[1] See the Wikipedia entry at http://en.wikipedia.org/wiki/Rss if that term
    is unfamiliar. RSS feeds can be read in web browsers, numerous stand-alone
    applications, or web-services such as Google Reader.

[2] See http://dirk.eddelbuettel.com/code/littler.html

[3] See http://blosxom.sourceforge.net/ and http://blosxom.sourceforge.net/
    but not that Blosxom development seems to have ceased. There are many 
    alternatives such as PyBlosxom and Nanoblogger.


-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison



From h.wickham at gmail.com  Mon Jul  9 19:23:21 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 9 Jul 2007 19:23:21 +0200
Subject: [R-pkgs] Reshape version 0.8
Message-ID: <f8e6ff050707091023j2818c1d6gcfb763e1c5e81b09@mail.gmail.com>

Reshape version 0.8
http://had.co.nz/reshape

Reshape is an R package for flexibly restructuring and aggregating
data.  It's inspired by Excel's pivot tables, and it (hopefully) makes
it very easy to get your data into the shape that you want.  You can find out
more at http://had.co.nz/reshape

This version brings a few minor changes to make the output more
attractive and less surprising.  If you have any code that relies on
the exact output structure you might need to tweak it a little.

* preserve.na renamed to na.rm to be consistent with other R functions

* Column names are no longer automatically converted to valid R names.
You may need to use `` (those are backticks) to access these names.

* Margins now displayed with (all) instead of NA

* melt.array can now deal with cases where there are partial dimnames
- Thanks to Roberto Ugoccioni

 * Added the Smiths dataset to the package

 * Fixed a bug when displaying margins with multiple result variables

Regards,

Hadley



From david.meyer at wu-wien.ac.at  Wed Jul 11 00:49:20 2007
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Wed, 11 Jul 2007 00:49:20 +0200
Subject: [R-pkgs] package "relations" updated
Message-ID: <46940CF0.5040205@wu-wien.ac.at>

Dear useRs,

Version 0.2 of package "relations" appeared on CRAN and is currently 
propagating to the mirrors. In addition to some bug fixes, the new 
release includes:

   o an introductory vignette showing the main features;

   o new SD fitters for the C ("complete") and A ("antisymmetric")
     families of relations;

   o a fitter for Copeland's method;

   o the relation_classes() function to extract and pretty-print
     (ordered) classes from preferences and equivalences;

   o the function relation_violations() to compute a measure of
     remoteness from a specified property (e.g., symmetry,
     transitivity, etc.).

David and Kurt.





-- 
Dr. David Meyer
Department of Information Systems and Operations

Vienna University of Economics and Business Administration
Augasse 2-6, A-1090 Wien, Austria, Europe
Tel: +43-1-313 36 4393
Fax: +43-1-313 36 90 4393
HP:  http://wi.wu-wien.ac.at/~meyer/



From aaron.king at umich.edu  Tue Jul 24 14:05:19 2007
From: aaron.king at umich.edu (Aaron King)
Date: Tue, 24 Jul 2007 08:05:19 -0400
Subject: [R-pkgs] New package: pomp,
	inference for partially-observed Markov processes
Message-ID: <200707240805.19285.aaron.king@umich.edu>

To: cran at r-project.org
Subject: New package: pomp, inference for partially-observed Markov processes

The new package 'pomp' is built around a very general realization of nonlinear 
partially-observed Markov processes (AKA state-space models, nonlinear 
stochastic dynamical systems). The user provides functions specifying the 
model's process and measurement components. The package's algorithms are 
built on top of these functions. 

At the moment, algorithms are provided for particle filtering (AKA sequential 
importance sampling or sequential Monte Carlo) and the likelihood 
maximization by iterated filtering (MIF) method of Ionides, Breto, and King 
(PNAS, 103:18438-18443, 2006). Future support for a variety of other 
algorithms is envisioned. A working group of the National Center for 
Ecological Analysis and Synthesis (NCEAS), "Inference for Mechanistic 
Models", is currently implementing additional methods for this package.

Simple worked examples are provided in the form of a 
vignette, "random_walk_example".

The package is provided under the GPL. Contributions are welcome, as are 
comments, suggestions, examples, and bug reports.

The development of this package has been aided by support from the U.S. N.S.F 
(Grants #EF-0545276, #EF-0430120) and by the "Inference for Mechanistic 
Models" Working Group supported by the National Center for Ecological 
Analysis and Synthesis, a Center funded by NSF (Grant #DEB-0553768), the 
University of California, Santa Barbara, and the State of California.



-- 
Aaron A. King, Ph.D.
Ecology & Evolutionary Biology
University of Michigan
http://www.umich.edu/~kingaa
GPG Public Key: 0x2B00840F



From Peter.Ruckdeschel at uni-bayreuth.de  Mon Jul 30 13:35:15 2007
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Mon, 30 Jul 2007 13:35:15 +0200
Subject: [R-pkgs] New versions for the distr-family of packages and of
	package startupmsg
Message-ID: <46ADCCF3.4010207@uni-bayreuth.de>

We would like to announce the availability on CRAN (with possibly a minor delay until on
every mirror) of new versions of our packages in the "distrXXX"-family (version 1.9),
i.e.; "distr", "distrEx", "distrSim", "distrTEst", and "distrDoc"
      as well as of package for managing startup messages, "startupmsg" (0.5).
[all of them require R >= 2.2.0]
-----------------------------------------------------------------------------------------
********************************* Changes ***********************************************
of "distr" (1.9), "distrEx" (1.9), "distrSim" (1.9), "distrTEst" (1.9), "distrDoc" (1.9)
*****************************************************************************************
-----------------------------------------------------------------------------------------
There are major changes in "distr" and "distrEx" from this release on;
the more important ones can be inspected at

http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR

and the pages linked to on this page.

Special thanks go to Spencer Graves for spotting some errors in 1.8 (which
should be fixed by now) and to G.Jay Kerns for detecting some further bugs
and providing code for exact kurtosis and skewness functionals.

After package installation you may also have a look at NEWS("<pkg-name>") for each of the
packages mentioned in this mail.
-----------------------------------------------------------------------------------------
********************************* Changes ***********************************************
of "startupmsg" (0.5)
*****************************************************************************************
-----------------------------------------------------------------------------------------
This may be interesting to those annoyed by our "chatty" startup messages ;-)

-> From this version on, you may use suppressPackageStartupMessages() to suppress the
   startup-messages issued by our packages---

compare http://tolstoy.newcastle.edu.au/R/e2/devel/07/04/3039.html
-----------------------------------------------------------------------------------------
Short Descriptions
-----------------------------------------------------------------------------------------
************ "distr":
"distr" is to provide a conceptual treatment of random variables
(r.v.'s) by means of S4--classes. A virtual mother class "Distribution"
is introduced.
All distributions of the "stats" package are implemented as subclasses of
either "AbscontDistribution" or "DiscreteDistribution".

Using these classes, we also provide (default) methods to automatically
generate the image distributions under unary mathematical operations as
well as a general convolution algorithm.
-----------------------------------------------------------------------------------------
************ "distrSim":
Classes and methods are provided for a standardized treatment of
simulations (also under contaminations) .
-----------------------------------------------------------------------------------------
************ "distrTEst":
Classes and methods are provided for a standardized treatment of
the evaluation of statistical procedures (up to now only estimators)
at data/simulations
-----------------------------------------------------------------------------------------
************ "distrEx":
This package provides some extensions to package "distr" like:
* extreme value distribution classes,
* expectations
+in the form E(X) for the expectation of X where X is some
distribution or
+in the form E(X,f) for the expectation of f(X) where X is
some distribution and f some function in X,
* further functionals: var, sd, IQR, mad, median, kurtosis, skewness
* truncated moments
* distances between distributions
(Hellinger, Kolmogorov, total variation, "convex contamination")
* conditional distributions in factorized form
* conditional expectations in factorized form
-----------------------------------------------------------------------------------------
************ "distrDoc":
"distrDoc" provides a common vignette to the distrXXX family
-----------------------------------------------------------------------------------------
************ "startupmsg":
provides utilities for start-up messages for packages
-----------------------------------------------------------------------------------------

We look forward to receiving questions, comments and suggestions

Peter Ruckdeschel
Matthias Kohl
Thomas Stabla
Florian Camphausen



From ubk2101 at columbia.edu  Tue Jul 31 14:03:58 2007
From: ubk2101 at columbia.edu (Udaya B. Kogalur)
Date: Tue, 31 Jul 2007 08:03:58 -0400
Subject: [R-pkgs] randomSurvivalForest 3.0.0 now available
In-Reply-To: <38c08c270707291256l41912585qde16fc1c2d8385b1@mail.gmail.com>
References: <38c08c270707291256l41912585qde16fc1c2d8385b1@mail.gmail.com>
Message-ID: <38c08c270707310503t5ecdd95cwe7c54423248dbbb0@mail.gmail.com>

Dear useRs:

Release 3.0.0 of the randomSurvivalForest, an ensemble tree method for
the analysis of right censored survival data,  package is now
available.

---------------------------------------------------------------------------------
CHANGES TO RELEASE 3.0.0

Release 3.0.0 represents a major upgrade in the functionality of the
2.x releases.  Key changes are as follows:

o Missing data can be imputed in both grow and predict mode.  This
  applies to variables as well as time and censoring outcome values.
  Values are imputed dynamically as the tree is grown using a new tree
  imputation methodology.  This produces an imputed forest which can be
  used for prediction purposes on test data sets with missing data.

o Importance values for variables are returned in predict mode when test
  data contains outcomes as well as variables.

o Fixed some bugs in plot.variable().  Thanks to Andy J. Minn for
pointing this out.

o Minor modification of PMML representation of RSF forest output to accomodate
  imputation.  The method of random seed chain recovery has been altered.
  Note that forests produced with prior releases will have to be
  regenerated using this release.  We apologize for the inconvenience.

---------------------------------------------------------------------------------

Thanks.

ubk

ubk2101 at columbia.edu

Udaya B. Kogalur, Ph.D.
Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012



From ggrothendieck at gmail.com  Wed Aug  1 02:43:29 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 31 Jul 2007 20:43:29 -0400
Subject: [R-pkgs] New R package sqldf
Message-ID: <971536df0707311743y201acba8ocaff55d803dd5269@mail.gmail.com>

sqldf is an R package for running SQL select
statements on one or more R data frames. It is
optimized for convenience making it useful
for ad hoc queries against R data frames.

Given an SQL select statement whose tables
are the names of R data frames it:

- sets up the database (by default it transparently
  sets up an in memory SQLite database using RSQLite;
  however, MySQL via RMySQL, can be specified as an
  alternative.  MySQL has not been tested.)
- imports the data frames found in SQL select
  statement into the database
- runs the SQL select statement
- outputs the result back to a data frame
- uses a heuristic to assign the appropriate column
  classes to the result
- removes the database

so that all the user has to do is issue a one line
function call with one argument, the select
statement.

Here is an example which processes an SQL select
statement whose functionality is similar to the R
aggregate function.  Note that although the iris
dataset (which is built into R) uses the name
Sepal.Length the R database interface, DBI, converts
that to Sepal_Length.  Just install the sqldf package
from CRAN and type these two lines into R without
the > prompts:

> library(sqldf)
> sqldf("select Species, avg(Sepal_Length) from iris group by Species")

     Species avg(Sepal_Length)
1     setosa             5.006
2 versicolor             5.936
3  virginica             6.588

As can be seen from the example, there is:
- no database setup
- no importing and exporting into the database
- no coercing of the returned columns to the
  appropriate class (in most cases)

It can be used:
- as an alternate syntax for data frame manipulation
- learning SQL if you know R
- learning R if you know SQL

The sqldf package has a single function, sqldf.  More
information is available by issuing the command ?sqldf
from within R.  More examples and useful links are
available at the sqldf home page:

http://code.google.com/p/sqldf/



From felix at nfrac.org  Thu Aug  2 03:40:20 2007
From: felix at nfrac.org (Felix Andrews)
Date: Thu, 2 Aug 2007 11:40:20 +1000
Subject: [R-pkgs] new package plotAndPlayGTK
Message-ID: <94730b8a0708011840k36455658s35fe0056467d2245@mail.gmail.com>

Package plotAndPlayGTK provides a graphical user interface for R
plots. Wrap it around your plot commands, like playwith(plot(mydata)).
A window pops up with a Cairo plot device and a toolbar with buttons
to interact with the plot. The default buttons allow you to add
persistent labels to data points, zoom in and out and around, save the
plot to a file, and so on. Furthermore, you can edit the plot call on
the fly. There are buttons to work with multiple panels and pages of a
Lattice plot. For multi-variate scatterplots ('splom' only) there is a
"brush" function, and for 3D plots ('wireframe' / 'cloud' only) there
is a simple zoom and rotate.

New buttons can also be defined; actually any GTK+ widget can be added
to the toolbar. An example is given of a numeric input widget to
choose a number of clusters to show.

Note: code to generate the plot will need to be wrapped up into a
single call with some standard arguments, and the interaction features
do not work well with multiple-plot layouts in traditional graphics.
As yet it does not work with grid-based plots other than Lattice (such
as ggplot2), but button handlers could be written. This package is
based on RGtk2, and so requires the GTK+ libraries.

v0.8.42 is on CRAN.

http://code.google.com/p/plotandplay-gtk/

-- 
Felix Andrews / ???
PhD candidate
Integrated Catchment Assessment and Management Centre
The Fenner School of Environment and Society
The Australian National University (Building 48A), ACT 0200
Beijing Bag, Locked Bag 40, Kingston ACT 2604
http://www.neurofractal.org/felix/
xmpp:foolish.android at gmail.com
3358 543D AAC6 22C2 D336  80D9 360B 72DD 3E4C F5D8



From tlumley at u.washington.edu  Sat Aug  4 22:12:35 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 4 Aug 2007 13:12:35 -0700 (PDT)
Subject: [R-pkgs] surveyNG (and survey)
Message-ID: <Pine.LNX.4.43.0708041312350.21274@hymn09.u.washington.edu>


'surveyNG' version 0.3 is on CRAN.

 This package provides experimental features for survey analysis that may be incorporated in the survey package in the future. Currently there are facilities for analysis of complex surveys using (possibly large) data sets stored in a SQLite database. However, analysis facilities for these SQL-backed survey designs are rather more limited than in the 'survey' package.

Version 0.3 adds hexagonal binning plots and kernel smoothing.


Also, the 'survey' package hasn't been announced on this list since version 2.9 in 2005 and verison 3.6-11 was recently posted.  It provides fairly comprehensive facilities for analysis of complex survey designs.  Major additions since 2.9 are calibration estimators (aka GREG or generalized raking), simple two-phase designs, and smoothing.


     -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From h.wickham at gmail.com  Tue Aug 14 21:05:26 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 14 Aug 2007 14:05:26 -0500
Subject: [R-pkgs] 'fda' 1.2.2 is now available on CRAN.
Message-ID: <f8e6ff050708141205k6bc36e6cm49a9bb5ac3e5cb2e@mail.gmail.com>

The fda package supports "Functional Data Analysis" and "Applied
Functional Data Analysis" by Bernard Silverman and James Ramsay.
Functional data analysis, which lots of us like to call "FDA", is
about the analysis of information on curves or functions. FDA is a
collection statistical techniques for answering questions like, "What
are the main ways in which the curves vary from one to another?" In
fact, most of the questions and problems associated with multivariate
data (PCA, LDA, clustering, ...) have functional counterparts. More
information about FDA can be found at
http://www.psych.mcgill.ca/misc/fda/.

This version (and the previous 1.2.1) includes bug fixes plus a
"scripts" subdirectory with R code to reproduce some of the analyses
in the two functional data analysis books by Ramsay and Silverman and
a "Continuously Stirred Tank Reactor (CSTR)" simulation discussed in a
Ramsay, et al., discussion paper to appear soon in the Journal of the
Royal Statistical Society-series B.

It also includes the draft of a presentation on "fda in Matlab & R"
(in PowerPoint and Adobe Acrobat PDF formats) for the UseR! 2007
conference this Friday, Aug. 10, 1:55 - 2:20 PM in Ames, IA.

Regards

Hadley Wickham
James Ramsey
Spencer Graves



From jeff.horner at vanderbilt.edu  Wed Aug 22 01:02:31 2007
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Tue, 21 Aug 2007 18:02:31 -0500
Subject: [R-pkgs] brew 1.0-1
Message-ID: <46CB6F07.7050104@vanderbilt.edu>

brew implements a templating framework for mixing text and R code for 
report generation. brew template syntax is similar to PHP, Ruby's erb 
module, Java Server Pages, and Python's psp module.

brew is written in R with no package dependencies, and it's not just for 
the web. It can be used as an alternative to Sweave in a limited 
context. See the brew-test-1.brew file in the distribution for some 
salient differences between the two. brew can also complement Sweave 
since it can be written to do conditional inclusion of or loop over 
Sweave code chunks.

The 1.0-1 version should show up on the CRAN mirrors shortly, but in the 
mean time it can be got from:

http://www.rforge.net/brew/

Best,

Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner



From luke at stat.uiowa.edu  Mon Aug 27 14:30:33 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 27 Aug 2007 07:30:33 -0500 (CDT)
Subject: [R-pkgs] proftools package now available from CRAN
Message-ID: <Pine.LNX.4.64.0708270729320.2888@nokomis.stat.uiowa.edu>

 		PROFILE OUTPUT PROCESSING TOOLS FOR R
                 =====================================


This package provides some simple tools for examining Rprof output
and, in particular, extracting and viewing call graph information.
Call graph information, including which direct calls where observed
and how much time was spent in these calls, can be very useful in
identifying performance bottlenecks.

One important caution: because of lazy evaluation a nested call
f(g(x)) will appear on the profile call stack as if g had been called
by f or one of f's callees, because it is the point at which the value
of g(x) is first needed that triggers the evaluation.


EXPORTED FUNCTIONS

The package exports five functions:

     readProfileData reads the data in the file produced by Rprof into a
         data structure used by the other functions in the package.
         The format of the data structure is subject to change.

     flatProfile is similar to summaryRprof.  It returns either a
         matrix with output analogous to gprof's flat profile or a
         matrix like the by.total component returned by summaryRprof;
         which is returned depends on the value of an optional second
         argument.

     printProfileCallGraph produces a printed representation of the
         call graph.  It is analogous to the call graph produced by
         gprof with a few minor changes.  Reading the gprof manual
         section on the call graph should help understanding this
         output.  The output is similar enough to gprof output for the
         cgprof (http://mvertes.free.fr/) script to be able to produce
         a call graph via Graphviz.

     profileCallGraph2Dot prints out a Graphviz .dot file representing
         the profile graph.  Times spent in calls can be mapped to node
         and edge colors.  The resulting files can then be viewed with
         the Graphviz command line tools.

     plotProfileCallGraph uses the graph and Rgraphviz packages to
         produce call graph visualizations within R.  You will need to
         install these packages to use this function.


A SIMPLE EXAMPLE

Collect profile information  for the examples for glm:

           Rprof("glm.out")
           example(glm)
           Rprof()
           pd <- readProfileData("glm.out")

Obtain flat profile information:

           flatProfile(pd)
           flatProfile(pd, FALSE)

Obtain a printed call graph on the standard output:

           printProfileCallGraph(pd)

If you have the cgprof script and the Graphviz command line tools
available on a UNIX-like system, then you can save the printed graph
to a file,

           printProfileCallGraph(pd, "glm.graph")

and either use

           cgprof -TX glm.graph

to display the graph in the interactive graph viewer dotty, or use

           cgprof -Tps glm.graph > glm.ps
           gv glm.ps

to create a PostScript version of the call graph and display it with
gv.

Instead of using the printed graph and cgprof you can use create a
Graphviz .dot file representation of the call graph with

           profileCallGraph2Dot(pd, filename = "glm.dot", score = "total")

and view the graph interactively with dotty using

           dotty glm.dot

or as a postscript file with

           dot -Tps glm.dot > glm.ps
           gv glm.ps

Finally, if you have the graph package from CRAN and the Rgraphviz
package from Bioconductor installed, then you can view the call graph
within R using

           plotProfileCallGraph(pd, score = "total")

The default settings for this version need some work.]


OPEN ISSUES

My intention was to handle cycles roughly the same way that gprof
does.  I am not completely sure that I have managed to do this; I am
also not completely sure this is the best approach.

The graphs produced by cgprof and by plotProfileGraph and friends when
mergeEdges is false differ a bit.  I think this is due to the
heuristics of cgprof not handling cycle entries ideally and that the
plotProfileGraph graphs are actually closer to what is wanted.  When
mergeEdges is true the resulting graphs are DAGs, which simplifies
interpretation, but at the cost of lumping all cycle members together.

gprof provides options for pruning graph printouts by omitting
specified nodes.  It may be useful to allow this here as well.

Probably more use should be made of the graph package.


IMPLEMENTATION NOTES

The implementation is extremely crude (a real mess would be more
accurate) and will hopefully be improved over time--at this point it
is more of an existence proof than a final product.

Performance is less than ideal, though using these tools it was
possible to identify some problem points and speed up computing the
profile data by a factor of two (in other words, it may be bad now but
it used to be worse).  More careful design of the data structures and
memoizing calculations that are now repeated is likely to improve
performance substantially.




-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From h.wickham at gmail.com  Sun Sep  2 18:53:46 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 2 Sep 2007 11:53:46 -0500
Subject: [R-pkgs] ggplot2 - version 0.5.5
Message-ID: <f8e6ff050709020953r248fd0d5l8edcee4466d23acf@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the over 500
examples of ggplot in use.


Changes in version 0.5.5
----------------------------------------

Improvements:
	* ggplot now gives rather more helpful errors if you have
misspecified a variable name in the aesthetic mapping
	* changed default hline and vline intercepts to 0
	* added "count" output variable from stat_density for creating
stacked/conditional density plots
	* added parameters to geom_boxplot to control appearance of outlying points
	* overriding aesthetics with fixed values that have already been set
with aesthetics now actually works
	* slightly better names for xaxis and yaxis grobs
	* added aes_string function to make it easier to construction
aesthetic mapping specifications in functions
	* continuous scales now have labels argument so that you can manually
specify labels if desired
	* stat_density now calculates densities on a common grid across
groups.  This means that position_fill and position_stack now work
properly
	* if numeric, legend labels right aligned
	* polar coordinates much improved, and with better examples

Documentation:
	* fixed argument documentation for qplot
	* added (very) rudimentary documentation about what functions return
	* documentation now lists extra variables created by statistics

Bug fixes:
	* coord_flip now works with segment and all interval geoms
	* geom_errorbar now works in all coordinate systems
	* derived y axes (eg. on histogram) are now labelled correctly
	* fixed bug in stat_quantile caused by new output format from predict.rq
	* fixed bug if x or y are constant
	* fixed bug in histogram where sometimes lowest bar was omitted
	* fixed bug in stat_qq which prevent setting aesthetics
	* fixed bug in qplot(..., geom="density", position="identity")
	* fixed stat_qq so that unnecessary arguments are no longer passed to
the distribution function

Subtractions:
	* removed grid argument from ggsave, replaced by ggtheme(theme_bw)
	* removed add argument from qplot


Regards,

Hadley

-- 
http://had.co.nz/



From calenge at biomserv.univ-lyon1.fr  Mon Sep  3 09:31:47 2007
From: calenge at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Mon, 03 Sep 2007 09:31:47 +0200
Subject: [R-pkgs] adehabitat version 1.7
Message-ID: <46DBB863.3000300@biomserv.univ-lyon1.fr>

Dear all,

I have uploaded to CRAN the version 1.7 of the package 'adehabitat'. 
Significant changes are listed below:

* The Brownian bridge kernel estimation algorithm has been greatly 
improved. It now takes more than 80% less time than the previous 
version. A new function "liker" has also been added, which estimates the 
one of the two smoothing parameters of the bridge kernel using a maximum 
likelihood approach (recommended in Horn et al., Ecology, in press). 
Examples of the help page demonstrate the use and interest of this 
function. Comparison between kernelbb and the Visual basic algorithm 
provided in the paper of Horn et al. returned consistent results.

* The function kernelUD has also been improved. It now takes more than 
50% less time than the previous version. In addition the "grid" argument 
of this function, now also allows a list of objects of class "asc" to be 
passed as grid where the UD should be estimated.

Happy testing,

Cl?ment Calenge.

-- 
Cl?ment CALENGE
LBBE - UMR CNRS 5558 - Universit? Claude Bernard Lyon 1 - FRANCE
tel. (+33) 04.72.43.27.57
fax. (+33) 04.72.43.13.88



From weeksjp at gmail.com  Wed Sep  5 18:15:11 2007
From: weeksjp at gmail.com (Jonathan Weeks)
Date: Wed, 5 Sep 2007 10:15:11 -0600
Subject: [R-pkgs] New R package plink for separate calibration IRT linking
Message-ID: <8a7634360709050915s3c13221at4a82775b9e208098@mail.gmail.com>

The first version of the package plink has been uploaded to CRAN.

plink is a package for conducting unidimensional IRT scaling and chain
linking for multiple groups for single-format or mixed-format common
items. The package supports eight IRT models and four calibration
methods.

Dichotomous Models:
1PL, 2PL, 3PL

Polytomous Models:
-Graded response model
-Partial credit model
-Generalized partial credit model
-Nominal response model
-Multiple-choice model

Calibration Methods:
-Mean/Mean
-Mean/Sigma
-Haebara
-Stocking-Lord

Any combination of dichotomous and polytomous items can be supplied
with intermingled unique and common items for as many items and groups
as system memory allows. Linking constants are computed and returned
for all the calibration methods, and (if desired) ability and/or item
parameters can be rescaled and returned using any of the estimated
linking constants.

Any of the included groups can be specified as the base scale, the
characteristic curve methods can use symmetric or non-symmetric
optimization, various scoring functions can be supplied for the
Stocking-Lord method, and there is great flexibility in specifying
thetas and theta weights to be integrated over in the characteristic
curve methods.

In addition to computing linking constants and rescaling ability and
item parameters, the methods in the package can be used to compute
item/category response probabilities and create plots of item/category
characteristic curves.

The package is designed to allow for a variety of formats for the item
parameters including vectors, lists, matrices, and other objects
(irt.pars and sep.pars) available in the package. Item parameters and
calibration output can be summarized, and descriptive statistics for
the item parameters can be displayed as well.

Getting Started:
Running the separate calibration is typically a two-step process. The
first step is to format the item parameters for processing with the
function 'plink'. Parameters should be formatted as either an object
of class 'irt.pars' with multiple groups, a set of 'irt.pars' objects,
or a set of 'sep.pars' objects.  Once in this format, response
probabilities can be computed using the functions 'drm', 'gpcm',
'grm', 'mcm', or 'nrm' or linking constants can be computed using
'plink'.

The functions 'as.irt.pars', 'sep.pars', and 'combine.pars' can be
used to create the 'irt.pars' and 'sep.pars' objects. 'summary' can be
used to summarize item parameters (including descriptive statistics)
and linking constants, and 'plot' can be used to create item/category
characteristic curves.

I am currently working on a vignette; however, the documentation
contains extensive examples. The best documentation to start with is
help(as.irt.pars) and help(plink).

Although this is the first version of this package, I have gone
through extensive debugging and validation, so there should be few, if
any bugs. Many of the examples (and the associated output) can be
found in published articles or books, and the output from the various
calibration methods has been checked against other available linking
software.

I hope this will be a useful package for those interested in test
linking. I invite any comments and suggestions.

Take care

-- 
Jonathan Weeks
Doctoral Candidate
School of Education
University of Colorado, Boulder
weeksjp at gmail.com
303-517-9666



From dusa.adrian at gmail.com  Mon Sep 10 01:21:24 2007
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Mon, 10 Sep 2007 02:21:24 +0300
Subject: [R-pkgs] QCA version 0.4-5
Message-ID: <200709100221.24440.dusa.adrian@gmail.com>


QCA implements the Qualitative Comparative Analysis using a boolean 
minimization algorithm for data coded with presence/absence of the causal 
conditions that affects a phenomenon of interest.

This new release has an experimental function that obtains the same exact 
solutions as the main minimization function, using a shortcut instead of the 
classical complete and exhaustive algorithm. This new function is faster and 
uses significantly less memory (50 MB compared to 1.5 GB for large datasets).

It should appear soon on CRAN, feedback is welcome.


-- 
Adrian Dusa
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101



From tplate at acm.org  Mon Sep 10 23:16:28 2007
From: tplate at acm.org (Tony Plate)
Date: Mon, 10 Sep 2007 15:16:28 -0600
Subject: [R-pkgs] new package 'trackObjs' - mirror objects to files,
 provide summaries & modification times
Message-ID: <46E5B42C.4040805@acm.org>

 From ?trackObjs:

Overview of trackObjs package

Description:

      The trackObjs package sets up a link between R objects in memory
      and files on disk so that objects are automatically resaved to
      files when they are changed.  R objects in files are read in on
      demand and do not consume memory prior to being referenced.  The
      trackObjs package also tracks times when objects are created and
      modified, and caches some basic characteristics of objects to
      allow for fast summaries of objects.

      Each object is stored in a separate RData file using the standard
      format as used by 'save()', so that objects can be manually picked
      out of or added to the trackObjs database if needed.

      Tracking works by replacing a tracked variable by an
      'activeBinding', which when accessed looks up information in an
      associated 'tracking environment' and reads or writes the
      corresponding RData file and/or gets or assigns the variable in
      the tracking environment.

Details:

      There are three main reasons to use the 'trackObjs' package:

         *  conveniently handle many moderately-large objects that would
            collectively exhaust memory or be inconvenient to manage in
            files by manually using 'save()' and 'load()'

         *  keep track of creation and modification times on objects

         *  get fast summaries of basic characteristics of objects -
            class, size, dimension, etc.

      There is an option to control whether tracked objects are cached
      in memory as well as being stored on disk.  By default, objects
      are not cached.  To save time when working with collections of
      objects that will all fit in memory, turn on caching with
      'track.options(cache=TRUE)', or start tracking with
      'track.start(..., cache=TRUE)'.

      Here is a brief example of tracking some variables in the global
      environment:


      > library(trackObjs)
      > track.start("tmp1")
      > x <- 123                  # Not yet tracked
      > track(x)                  # Variable 'x' is now tracked
      > track(y <- matrix(1:6, ncol=2)) # 'y' is assigned & tracked
      > z1 <- list("a", "b", "c")
      > z2 <- Sys.time()
      > track(list=c("z1", "z2")) # Track a bunch of variables
      > track.summary(size=F)     # See a summary of tracked vars
                  class    mode extent length            modified TA TW
      x         numeric numeric    [1]      1 2007-09-07 08:50:58  0  1
      y          matrix numeric  [3x2]      6 2007-09-07 08:50:58  0  1
      z1           list    list  [[3]]      3 2007-09-07 08:50:58  0  1
      z2 POSIXt,POSIXct numeric    [1]      1 2007-09-07 08:50:58  0  1
      > # (TA="total accesses", TW="total writes")
      > ls(all=TRUE)
      [1] "x"  "y"  "z1" "z2"
      > track.stop()              # Stop tracking
      > ls(all=TRUE)
      character(0)
      >
      > # Restart using the tracking dir -- the variables reappear
      > track.start("tmp1") # Start using the tracking dir again
     > ls(all=TRUE)
      [1] "x"  "y"  "z1" "z2"
      > track.summary(size=F)
                  class    mode extent length            modified TA TW
      x         numeric numeric    [1]      1 2007-09-07 08:50:58  0  1
      y          matrix numeric  [3x2]      6 2007-09-07 08:50:58  0  1
      z1           list    list  [[3]]      3 2007-09-07 08:50:58  0  1
      z2 POSIXt,POSIXct numeric    [1]      1 2007-09-07 08:50:58  0  1
      > track.stop()
      >
      > # the files in the tracking directory:
      > list.files("tmp1", all=TRUE)
      [1] "."                    ".."
      [3] "filemap.txt"          ".trackingSummary.rda"
      [5] "x.rda"                "y.rda"
      [7] "z1.rda"               "z2.rda"
      >

      There are several points to note:

         *  The global environment is the default environment for
            tracking - it is possible to track variables in other
            environments, but that environment must be supplied as an
            argument to the track functions.

         *  Vars must be explicitly 'track()'ed - newly created objects
            are not tracked.  (This is not a "feature", but there is
            currently no way of automatically tracking newly created
            objects - this is on the wishlist.)  Thus, it is possible
            for variables in a tracked environment to either tracked or
            untracked.

         *  When tracking is stopped, all tracked variables are saved on
            disk and will be no longer accessible until tracking is
            started again.

         *  The objects are stored each in their own file in the
            tracking dir, in the format used by 'save()'/'load()' (RData
            files).

List of basic functions and common calling patterns:

      Six functions cover the majority of common usage of the trackObjs
      package:

         *  'track.start(dir=...)': start tracking the global
            environment, with files saved in 'dir'

         *  'track.stop()': stop tracking (any unsaved tracked variables
            are saved to disk and all tracked variables become
            unavailable until tracking starts again)

         *  'track(x)': start tracking 'x' - 'x' in the global
            environment is replaced by an active binding and 'x' is
            saved in its corresponding file in the tracking directory
            and, if caching is on, in the tracking environment

         *  'track(x <- value)': start tracking 'x'

         *  'track(list=c('x', 'y'))': start tracking specified
            variables

         *  'track(all=TRUE)': start tracking all untracked variables in
            the global environment

         *  'untrack(x)': stop tracking variable 'x' - the R object 'x'
            is put back as an ordinary object in the global environment

         *  'untrack(all=TRUE)': stop tracking all variables in the
            global environment (but tracking is still set up)

         *  'untrack(list=...)': stop tracking specified variables

         *  'track.summary()': print a summary of the basic
            characteristics of tracked variables: name, class, extent,
            and creation, modification and access times.

         *  'track.remove(x)': completely remove all traces of 'x' from
            the global environment, tracking environment and tracking
            directory.   Note that if variable 'x' in the global
            environment is tracked, 'remove(x)' will make 'x' an
            "orphaned" variable: 'remove(x)' will just remove the active
            binding from the global environment, and leave 'x' in the
            tracked environment and on file, and 'x' will reappear after
            restarting tracking.

Complete list of functions and common calling patterns:

      The 'trackObjs' package provides many additional functions for
      controlling how tracking is performed (e.g., whether or not
      tracked variables are cached in memory), examining the state of
      tracking (show which variables are tracked, untracked, orphaned,
      masked, etc.) and repairing tracking environments and databases
      that have become inconsistent or incomplete (this may result from
      resource limitiations, e.g., being unable to write a save file due
      to lack of disk space, or from manual tinkering, e.g., dropping a
      new save file into a tracking directory.)

[truncated here -- see ?trackObjs]

-- Tony Plate

PS: to give credit where due, the end of ?trackObjs says:

References:
      Roger D. Peng. Interacting with data using the filehash package. R
      News, 6(4):19-24, October 2006.
      'http://cran.r-project.org/doc/Rnews' and
      'http://sandybox.typepad.com/software'

      David E. Brahm. Delayed data packages. R News, 2(3):11-12,
      December 2002.  'http://cran.r-project.org/doc/Rnews'

See Also:
      [...]
      Inspriation from the packages 'g.data' and 'filehash'.



From adrian at maths.uwa.edu.au  Tue Sep 11 05:05:34 2007
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Tue, 11 Sep 2007 11:05:34 +0800 (WST)
Subject: [R-pkgs] scuba 1.1-8
Message-ID: <60074.124.182.61.237.1189479934.squirrel@124.182.61.237>

Version 1.1-8 of package 'scuba' has been uploaded to CRAN.

'scuba' is a package for scuba diving calculations and decompression
models. It supports dive profiles (tables, plotting etc), analysis of dive
profiles using decompression models, gas toxicity calculations, and gas
usage calculations.

New features in version 1.1-8:
     . support for dive profiles uploaded from a dive computer
     . new dataset: dive profile from a wreck dive on nitrox
     . bug fix in oxygen toxicity calculations

Adrian Baddeley



From mfay at niaid.nih.gov  Wed Sep 12 21:26:09 2007
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 12 Sep 2007 15:26:09 -0400
Subject: [R-pkgs] New package: hbim - Hill/Bliss Independence Model for
	Multicomponent Vaccines
Message-ID: <31DDB7BE4BF41D4888D41709C476B657062E780D@NIHCESMLBX5.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070912/1a5d93f5/attachment.pl>

From adrian at stats.gla.ac.uk  Thu Sep 27 11:40:39 2007
From: adrian at stats.gla.ac.uk (Adrian Bowman)
Date: Thu, 27 Sep 2007 10:40:39 +0100
Subject: [R-pkgs] New version (2.2) of the sm package
Message-ID: <1EA97626-87BD-4ED0-BD9B-25C350AE0CAB@stats.gla.ac.uk>

The sm package (by Adrian Bowman and Adelchi Azzalini) implements a
variety of nonparametric smoothing techniques, centred on nonparametric
regression for one or two covariates and density estimation for up to
three variables.  A new version of the package is now available on CRAN.

In an earlier unannounced version (2.1), a variety of methods of  
bandwidth
selection were added, with default settings to allow particularly simple
function calls.

In the new version (2.2), interactive control panels are available for
the main functions (sm.regression and sm.density), using the rpanel  
package
(which itself is based on tcltk).  In addition, the rgl package is used
to provide rotatable three-dimensional plots, where these are  
appropriate.
The details of how these functions operate are available in the help  
files
(including the help file for sm.options) and in the examples.  However,
the broad principle is that a control panel is activated by adding the
argument
       panel = TRUE
and an rgl plot is created by adding the argument
       display = "rgl"

Adrian Bowman



From antoinelucas at gmail.com  Thu Oct  4 19:00:09 2007
From: antoinelucas at gmail.com (Antoine)
Date: Thu, 4 Oct 2007 19:00:09 +0200
Subject: [R-pkgs] Amap new release
Message-ID: <20071004190009.1d47f726@antoine.domainelocal.fr>



A new major version of Amap package is available on CRAN.

For this major release, all clustering code has been rewritten in C++.

Amap implements several tools in the field of clustering and robust statistics.

New features are:
   * clustering possible in float precision (less memory needs)
   * new rank-based metric: Kendall distance, use for both matrix distance computation, K-means, and hierachical clustering.


Best.

	Antoine.



From pineda at zoology.ubc.ca  Thu Oct  4 22:34:24 2007
From: pineda at zoology.ubc.ca (Mario Pineda-Krch)
Date: Thu, 04 Oct 2007 13:34:24 -0700
Subject: [R-pkgs] New version of GillespieSSA package uploaded to CRAN
Message-ID: <47054E50.4030300@zoology.ubc.ca>

Dear useRs,

A new version of the package GillespieSSA (0.3-1) has been uploaded to 
CRAN.

The GillespieSSA package (Gillespie's Stochastic Simulation Algorithm) 
provides a simple to use, versatile, and extensible interface to a 
number of Monte Carlo implementations of the stochastic simulation 
algorithm (SSA) and is intended for scientists, teachers, and students 
alike.

The SSA is a numerical procedure for generating statistically correct 
trajectories of finite well-mixed populations in continuous time. The 
methods currently implemented are: the Direct method, Explicit 
tau-leaping, Binomial tau-leaping, and Optimized tau-leaping. The 
package also provides a library of molecular, ecological and 
epidemiological example models (as demos) that can easily be customized 
and extended. Currently the following models are included, 
Decaying-Dimerization Reaction Set, Linear Molecular Chain System, 
single-species logistic growth model, Lotka predator-prey model, 
Rosenzweig-MacArthur predator-prey model, and Kermack-McKendrick SIR model.

The release consists of several bug fixes, improved documentation, and a 
revised more 'R-like' management of model parameters.

A vignette providing a tutorial of basic SSA theory, usage of the 
package using additional example models is currently being finalized. 
Although it is not part of this release a preprint is available upon 
request.

Comments are welcome,
Mario Pineda-Krch

-----------------------------------------------------------
Mario Pineda-Krch, Post Doctoral Fellow

Center for Animal Disease Modeling and Surveillance (CADMS)
University Of California, Davis, CA 95616, U.S.A.

Phone: (530) 297-4621
Fax:   (530) 297-4618
Email: pineda at zoology.ubc.ca
URL :  http://pineda-krch.com



From Max.Kuhn at pfizer.com  Fri Oct  5 20:33:37 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Fri, 5 Oct 2007 14:33:37 -0400
Subject: [R-pkgs] new packages: caret, caretLSF and caretNWS
Message-ID: <71257D09F114DA4A8E134DEAC70F25D309B8C303@groamrexm03.amer.pfizer.com>

Three more packages will be showing up on your mirror soon.

The caret package (short for "Classification And REgression Training")
aims to simplify the model building process. The package has functions
for

  - data splitting: balanced train/test splits, cross-validation and
bootstrapping sampling functions. There is also a function for maximum
dissimilarity sampling.

  - pre-processing: simple centering/scaling, filter methods for highly
correlated predictors, identification of linear combinations, removal of
"near zero variance" predictors and the "spatial-sign" transformation
function for predictors.

  - model building: the train function provides a common interface to 27
model types. Models can be tuned over complexity parameters using
resampling methods. A few functions also exist for plotting the results
from the tuning process.

  - bagged versions of mars (via the earth package) and fda models.

  - partial least squares classification model (based on the pls
package).

  - yet another knn function (this one returns the vote proportions for
all the classes) based on the functions in MASS and ipred.

  - a variable importance class and methods for a variety of models
(e.g. trees, pls, mars, etc) in addition to model-free methods.

  - RMA-type normalization methods for oligo arrays that can be used on
a per sample basis. These functions are well suited for normalizing
chips individually using information from the training set samples.

Three vignettes come with the package and include several examples. A
few example data sets, mostly from quantitative structure-activity
relationship (QSAR) experiments, are also contained in the package.

The other two packages, caretLSF and caretNWS, provide alternate
versions of caret's train function that can be executed in parallel
using the Rlsf and nws packages, respectively. For example, if
bootstrapping is used to tune a model, the B models can be split over M
different nodes. For caretNWS, either the free nws package or the
commercial version (nwsPro) can be used. The commercial version offers
fault tolerance features (as well as support). Email
info at revolution-computing.com instead of me for more information about
nwsPro or nws.

Thanks to Steve Weston, Jed Wing and Andre Williams who contributed to
these packages.

Please send me emails at max dot kuhn at pfizer dot com for questions,
suggestions or bugs. 

Max



From nkraemer at cs.tu-berlin.de  Tue Oct  9 15:55:01 2007
From: nkraemer at cs.tu-berlin.de (=?ISO-8859-15?Q?Nicole_Kr=E4mer?=)
Date: Tue, 09 Oct 2007 15:55:01 +0200
Subject: [R-pkgs] new package ppls
Message-ID: <470B8835.1010204@cs.tu-berlin.de>

A new package ppls is now available on CRAN.

The ppls package implements penalized Partial Leasts Squares (PLS). In a 
nutshell, supervised dimensionality reduction via PLS is combined with 
penalization techniques. Features of the package include


* estimation of linear regression models with penalized PLS,
* estimation of generalized additive models with penalized PLS based on 
splines transformations,
* model selection for both methods based on cross validation.


For more information on penalized PLS, see

http://ml.cs.tu-berlin.de/~nkraemer/papers/preprint_penalizedPLS.pdf

Please send an email to nkraemer at cs dot tu-berlin dot de for any 
comments, suggestions, or reports on bugs.

Regards,

Nicole & Anne-Laure


-- 
Dr. Nicole Kr?mer
TU Berlin
Machine Learning/Intelligent Data Analysis	fon: (+49) 30 314 78627
Franklinstr. 28/29, 10587 Berlin, Germany	fax: (+49) 30 314 78622

web: http://ml.cs.tu-berlin.de/~nkraemer



From kate at few.vu.nl  Mon Oct 15 13:41:44 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Mon, 15 Oct 2007 13:41:44 +0200 (CEST)
Subject: [R-pkgs] new package 'nnls'
Message-ID: <Pine.GSO.4.56.0710151339320.9860@laurel.few.vu.nl>

A new package 'nnls' is now available on CRAN.

The package provides an R interface to the Lawson-Hanson NNLS algorithm
for non-negative least squares that solves the least squares problem A x =
b with the constraint x >= 0.

The Lawson-Hanson NNLS algorithm was published in

Lawson CL, Hanson RJ (1974). Solving Least Squares Problems. Prentice
Hall, Englewood Cliffs, NJ.

Lawson CL, Hanson RJ (1995). Solving Least Squares Problems. Classics in
Applied Mathematics. SIAM, Philadelphia.

and is available as Fortran77 code on Netlib (file lawson-hanson/all). The
'nnls' package interfaces to this code.

Included in the examples section of the function 'nnls' is a test problem
comparing NNLS to the L-BFGS-B method of 'optim' and to the 'solve.QP'
function of the package 'quadprog'.  NNLS is shown to be faster and
slightly more accurate than these more general purpose algorithms for the
test problem examined.

I do not have access to S-PLUS or the S-PLUS source, but the help page for
the S-SPLUS function 'nnls.fit' references Lawson and Hanson (1974), and
is probably close to the port here.  I have not written any methods for
printing or summaries, and only return the solution x. On request, I can
modify this behavior.

I would be interested in suggestions, bug reports, and other comments.

Kate Mullen

----
Katharine Mullen
mail: Department of Physics and Astronomy, Faculty of Sciences
Vrije Universiteit Amsterdam, de Boelelaan 1081
1081 HV Amsterdam, The Netherlands
room: T.1.06
tel: +31 205987870
fax: +31 205987992
e-mail: kate at nat.vu.nl
homepage: http://www.nat.vu.nl/~kate/



From david.meyer at wu-wien.ac.at  Tue Oct 16 13:16:12 2007
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Tue, 16 Oct 2007 13:16:12 +0200
Subject: [R-pkgs] New package: sets
Message-ID: <47149D7C.2070908@wu-wien.ac.at>

Dear useRs,

The new 'sets' package made it to CRAN, supporting:

o data structures for sets, fuzzy sets, multisets, and fuzzy multisets
o the use of (most) R objects as elements
o standard set operations (union, intersection, complement, Cartesian 
product, power set, ...)
o support for several fuzzy logic systems

An introductory vignette is also available.

David and Kurt.



From deleeuw at stat.ucla.edu  Thu Oct 18 03:19:29 2007
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Wed, 17 Oct 2007 18:19:29 -0700
Subject: [R-pkgs] homals-0.9.0
Message-ID: <8A098B38-DA56-40F8-91D2-D8FE34C955BC@stat.ucla.edu>

homals-0.9.0 is on CRAN -- by Jan de Leeuw and Patrick Mair

This package implements the methods discussed in Gifi, Nonlinear  
Multivariate
Analysis, Wiley, 1990. In the Gifi terminology it covers homals,  
princals,
canals, morals, criminals, and overals. The R implementation fills  
several
gaps in Gifi, adding multiple ordinal, numerical, and polynomial data
transformations. Differences with previous CRAN version:

a. More R-like with S3 classes, namespace, print, plot, plot3d,  
summary, predict methods

b. (Much) better documented functions and data sets

c. Dynamic three-d plot using rgl

d. Static three-d plot using scatterplot3d

e. Predict method that counts "correct" classifications

f. Many bugs fixed

A paper describing the technique and implementation, with many examples,
is almost ready. There is a preprint at http://gifi.stat.ucla.edu/homalsR.pdf
Intermediate updates by svn from http://r-forge.r-project.org/projects/psychor/

==========================================================
Jan de Leeuw, 11667 Steinhoff Rd, Frazier Park, CA 93225
home 661-245-1725 skype 661-347-0667 global 254-381-4905
.mac: jdeleeuw +++  aim: deleeuwjan +++ skype: j_deleeuw
==========================================================
                 Many nights on the road
        and not dead yet ---
                the end of autumn.       (Basho 1644-1694)



From david.meyer at wu-wien.ac.at  Thu Oct 18 11:44:47 2007
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Thu, 18 Oct 2007 11:44:47 +0200
Subject: [R-pkgs] upgrade: relations
Message-ID: <47172B0F.7090804@wu-wien.ac.at>

Dear useRs,


a new version of the 'relations' package has appeared on CRAN. New 
features include:

   o support for fuzzy relations added

   o support for sets moved to separate 'sets' package

   o new SD fitters for the S ("symmetric") and M ("matches") families

   o fitters for Cook-Seiford method and Euclidean consensus added

   o fitters can now use a sparse constraint matrix representation

   o relations are now subsettable

   o relation_choice() for choosing "winner" objects based on an ensemble
     of relations between these

   o new summary method for relations which computes all implemented
     predicates

Best,

David and Kurt.



From h.wickham at gmail.com  Mon Oct 22 00:07:01 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 21 Oct 2007 17:07:01 -0500
Subject: [R-pkgs] ggplot2 - version 0.5.6
Message-ID: <f8e6ff050710211507p40df755dtced3fa3158cebc8b@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the over 500
examples of ggplot in use.

Changes in version 0.5.6
----------------------------------------

Improved error messages and other notifications:
  * all geoms and position adjustments should now give an informative
error message when required aesthetics are missing
  * better error messages if data not a data frame, or mapping not
created by aes or aes_string
  * better errors for qplot when variables missing or data invalid
  * better error if somehow you are missing necessary scales
  * stat_bin informs you of the default choice of binwidth
  * stat_smooth gives helpful error messages for common problems
  * printing a geom now displays the data set that it uses (if not the default)

Other improvements:
  * colour and fill legends now surround by background plot colour
  * can now draw arrow heads with geom_segment, and have added an
example demonstrating drawing a vector field
  * density plots should always include 0 on y axis
  * default boxplot outlier changed colour to black
  * stat_smooth supports categorical variables a little better
  * implemented hash methods for all ggplot objects.  This is the
first step in making it easier for me to compare all examples between
versions for quality control purposes

New data:
  * seals, contributed by David Brillinger and Charlotte Wickham, used
for vector field example

Bug fixes:
  * geoms hline, vline and abline now all work correctly when a
grouping variable is used
  * block histograms (where individuals are identifiable) now work correctly
  * all ggplot objects should now print properly from the command line
  * fixed bug in geom_path when only 1 point
  * segments geom now works correctly for more coordinate systems
  * order variables in scatterplot matrix by order of variables in data.frame
  * geom_density deals with missing values correctly when displaying
scaled densities
  * fixed bug in calculating categorical ranges
  * fixed bug in drawing error bars

Subtractions
  * now relies on R 2.6
  * removed grid.gedit and grid.gremove, and code replaced by grid.ls


-- 
http://had.co.nz/



From pls at mevik.net  Fri Oct 26 13:28:05 2007
From: pls at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik_and_Ron_Wehrens?=)
Date: Fri, 26 Oct 2007 13:28:05 +0200
Subject: [R-pkgs] pls version 2.1-0
Message-ID: <m0tzoe2jzu.fsf@bar.nemo-project.org>


Version 2.1-0 of the pls package is now available on CRAN.

The pls package implements partial least squares regression (PLSR) and
principal component regression (PCR).  Features of the package include

- Several plsr algorithms: orthogonal scores, kernel pls, wide kernel
  pls, and simpls
- Flexible cross-validation
- A formula interface, with traditional methods like predict, coef,
  plot and summary
- Functions for extraction of scores and loadings, and calculation of
  (R)MSEP and R2
- Functions for plotting predictions, validation statistics,
  coefficients, scores, loadings, and correlation loadings.

The main changes since 2.0-0 are

- Jackknife variance estimation of regression coefficients has been added.

- The `wide kernel' PLS algorithm has been implemented.  It is faster than the
  other algorithms for very wide data.

- The definition of R^2 has been changed to  1 - SSE/SST for all estimators,
  so R2() will give different results for test sets and
  cross-validation compared to pls < 2.1-0.  Also, the internal
  calculations have been reorganised.

- The plot functions for coefficients, predictions and validation results
  (R2, (R)MSEP) have gained an argument `main' to set the main title of the
  plot.

- plots that go over several pages now only set `par(ask = TRUE)' if the plot
  device is interactive (suggested by Kevin Wright).

- mvr() and mvrCv() now check for near zero standard deviation when autoscaling
  (`scale = TRUE')


See the file CHANGES in the sources for all changes.

-- 
Bj?rn-Helge Mevik and Ron Wehrens



From gregory.warnes at mac.com  Thu Nov  1 19:05:44 2007
From: gregory.warnes at mac.com (Gregory Warnes)
Date: Thu, 1 Nov 2007 14:05:44 -0400
Subject: [R-pkgs] SASxport v. 1.2.0
In-Reply-To: <4722294E.30207@quantpharm.com>
References: <470E2BF5.7070307@metrumrg.com> <4722294E.30207@quantpharm.com>
Message-ID: <DF714C74-B5EC-475F-9E7D-CF035DDB36A4@mac.com>


SASxport Version 1.2.0 is now available
---------------------------------------

The SASxport package provides R with full support for reading
and writing SAS xport format files.

Version 1.2.0 corrects a critical issues with storage of negative
numbers, as well as adding additional improvements to the handling
of SAS display and input format specifications.  With these
enhancements, both reading and writing SAS transport files is
almost lossless*.

SASxport 1.2.0 is available _now_ at

	http://random-technologies-llc.com/products/SASxport/

and will become available on your favorite CRAN repository shortly.

For additional information and commercial support packages, please
visit the Random Technologies web site:

	http://random-technologies-llc.com/products/SASxport/

-Greg

Gregory R. Warnes, Ph.D
Chief Scientist
Random Technologies, LLC.

----

(*) Only information that cannot be stored in a SAS xport format file
     is lost: variable names are uppercased and truncated at 8
     characters, missing values for character string variables are
     converted to empty strings,  and numeric values outside of the SAS
     xport format numeric floating point range are converted to missing
     values.



From greg at warnes.net  Fri Nov  2 20:47:26 2007
From: greg at warnes.net (Gregory. R. Warnes)
Date: Fri, 2 Nov 2007 15:47:26 -0400
Subject: [R-pkgs] gplots 2.5.0
Message-ID: <AA61BDD3-CB47-441E-8E1E-372050754BA1@rochester.edu>


Announcing gplots 2.5.0
---------------------------------

gplots provides additional plotting functions, including several  
enhanced versions of base R functions.

Provided functions include:
	balloonplot, bandplot, barplot2, boxplot.n, colorpanel, heatmap.2,
	hist2d, lowess, ooplot, overplot, plot.lm2, plotCI, plotmeans,
	qqnorm.aov, residplot, rich.color, sinkplot, smartlegend, space,
         textplot, wapply


Changes in 2.5.0
-----------------------

New Features:

- textplot() now converts tab characters to spaces before processing to
   avoid problems with computing height and width of text that includes
   tabs.

- Add col2rgb() function to convert color names to rgb hex codes

Bug Fixes:

- Correct balloonplot.default to properly show specified x and y axis
   labels when explicitly provided

- R/balloonplot.R: Correct error in balloonplot when z contains NA  
values.

- Fix typos and code/doc mismatches identified by the latest R CMD check

Other:

- Clarify GPL version



From greg at random-technologies-llc.com  Sat Nov 10 00:05:07 2007
From: greg at random-technologies-llc.com (Gregory R. Warnes)
Date: Fri, 9 Nov 2007 18:05:07 -0500
Subject: [R-pkgs] SASxport v. 1.2.2
In-Reply-To: <4722294E.30207@quantpharm.com>
References: <470E2BF5.7070307@metrumrg.com> <4722294E.30207@quantpharm.com>
Message-ID: <DA158979-1950-4319-BB70-4B245D995090@random-technologies-llc.com>


SASxport Version 1.2.2 is now available
---------------------------------------

The SASxport package provides R with full support for reading
and writing SAS xport format files.

Version 1.2.2 corrects problems on 64 bit versions of R.

SASxport 1.2.2 is available _now_ at

	http://random-technologies-llc.com/products/SASxport/

and will become available on your favorite CRAN repository shortly.

For additional information and commercial support packages, please
visit the Random Technologies web site:

	http://random-technologies-llc.com/products/SASxport/

-Greg

Gregory R. Warnes, Ph.D
Chief Scientist
Random Technologies, LLC.



From vincent.goulet at act.ulaval.ca  Fri Nov 16 19:30:19 2007
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Fri, 16 Nov 2007 13:30:19 -0500
Subject: [R-pkgs] New version of actuar
Message-ID: <7F1B6E66-613E-4A93-AF0D-4F6D66BE4307@act.ulaval.ca>

UseRs,

Version 0.9-4 of actuar should be making its way to CRAN mirrors. The  
main highlights of this new version are speed enhancements for a few  
functions, support for phase-type distributions and functions for ruin  
theory.

The relevant section of the NEWS file follows

Version 0.9-4
=============

Maintenance and new features release.

NEW FEATURES -- LOSS DISTRIBUTIONS

   o Functions mgffoo() to compute the moment (or cumulant if 'log =
     TRUE') generating function of the following distributions:
     chi-square, exponential, gamma, inverse gaussian (from package
     SuppDists), inverse gamma, normal, uniform and phase-type (see
     below).

   o Functions mfoo() to compute the raw moments of all the probability
     distributions supported in the package and the following of base
     R: chi-square, exponential, gamma, inverse gaussian (from package
     SuppDists), inverse gamma, normal, uniform.

   o Functions {d,p,mgf,m,r}phtype() to compute the probability density
     function, cumulative distribution function, moment generating
     function, raw moments of, and to generate variates from,
     phase-type distributions.

NEW FEATURES -- RISK THEORY

   o Function VaR() with a method for objects of class "aggregateDist"
     to compute the Value at Risk of a distribution.

   o Function CTE() with a method for objects of class "aggregateDist"
     to compute the Conditional Tail Expectation of a distribution.

   o Function adjCoef() to compute the adjustment coefficient in ruin
     theory. If proportional or excess-of-loss reinsurance is included
     in the model, adjCoef() returns a function to compute the
     adjustment coefficient for given limits. A plot method is also
     included.

   o Function ruin() returns a function to compute the infinite time
     probability of ruin for given initial surpluses in the
     Cram?r-Lundberg and Sparre Andersen models. Most calculations are
     done using the cdf of phase-type distributions as per Asmussen and
     Rolski (1991).

   o Calculations of the aggregate claim distribution using the
     recursive method much faster now that recursions are done in C.

NEW FEATURES -- CREDIBILITY THEORY

   o Modular rewrite of cm(): the function now calls internal functions
     to carry calculations for each supported credibility model. This
     is more efficient.

   o Basic support for the regression model of Hachemeister in function
     cm().

   o For the hierarchical credibility model: support for the variance
     components estimators of B?hlmann and Gisler (2005) and Ohlsson
     (2005). Support remains for iterative pseudo-estimators.

   o Calculations of iterative pseudo-estimators in hierarchical
     credibility are much faster now that they are done in C.

OTHER NEW FEATURES

   o Four new vignettes: introduction to the package and presentation
     of the features in loss distributions, risk theory and credibility
     theory.

   o Portfolio simulation material of the "credibility" demo moved to
     demo "simulation".

USER-VISIBLE CHANGES

   o Argument 'approx.lin' of quantile.aggregateDist() renamed
     'smooth'.

   o Function aggregateDist() gains a 'maxit' argument for the maximum
     number of recursions when using Panjer's algorithm. This is to
     avoid infinite recursion when the cumulative distribution
     function does not converge to 1.

   o Function cm() gains a 'maxit' argument for the maximum number of
     iterations in pseudo-estimators calculations.

   o Methods of aggregate(), frequency(), severity() and weights() for
     objects of class "simpf" gain two new arguments:

     1. 'classification'; when TRUE, the columns giving the
        classification structure of the portfolio are excluded from the
        result. This eases calculation of loss ratios (aggregate claim
        amounts divided by the weights);

     2. 'prefix'; specifies a prefix to use in column names, with
         sensible defaults to avoid name clashes for data and weight
         columns.

BUG FIXES

   o The way weights had to be specified for the "chi-square" method of
     mde() to give expected results was very unintuitive. The fix has
     no effect when using the default weights.

   o The empirical step function returned by the "recursive" and
     "convolution" methods of aggregateDist() now correctly returns 1
     when evaluated past its largest knot.

DEPRECATED

   o Direct usage of bstraub() is now deprecated in favor of cm(). The
     function will remain in the package since it is used internally by
     cm(), but it will not be exported in future releases of the
     package. The current format of the results is also deprecated.


---
   Vincent Goulet, Associate Professor
   ?cole d'actuariat
   Universit? Laval, Qu?bec
   Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From groemping at tfh-berlin.de  Fri Nov 23 21:08:43 2007
From: groemping at tfh-berlin.de (=?ISO-8859-1?Q?Ulrike_Gr=F6mping?=)
Date: Fri, 23 Nov 2007 21:08:43 +0100
Subject: [R-pkgs] Major update to package relimpo: Version 2.0
Message-ID: <20071123195655.M80989@tfh-berlin.de>

Dear userRs,

Version 2.0 of package relaimpo is on CRAN (and on my homepage with an
additional metric for non-US users). It contains several major improvements: 
- usage of factors
- incorporation of interactions (for metric lmg only)
- incorporation of observation weights
- application to data from complex surveys
- processing of multiply imputed data
The latter two points are somewhat experimental - of course, feedback is very
welcome.

Regards, Ulrike

****************************** 
 Prof. Dr. Ulrike Gr?mping 
 Fachbereich II 
 TFH Berlin 
 Luxemburger Str. 10 
 13353 Berlin 
 mail: groemping at tfh-berlin.de 
 www: www.tfh-berlin.de/~groemp/



From GPetris at uark.edu  Wed Nov 28 19:14:22 2007
From: GPetris at uark.edu (Giovanni Petris)
Date: Wed, 28 Nov 2007 12:14:22 -0600 (CST)
Subject: [R-pkgs] Package dlm version 0.8-1
Message-ID: <200711281814.lASIEMYo009315@definetti.ddns.uark.edu>


I uploaded a new version of package dlm to CRAN. 

dlm provides functions for maximum likelihood, Kalman filtering and
smoothing, and Bayesian analysis of Gaussian linear state space
models, also known as Dynamic Linear Models.  

The most important visible changes from the previous version are the
following.

1) Missing values are now allowed in the observations.

2) Extractor and replacement functions for the matrices defining a dlm
   are now available.

3) The function for Kalman smoothing, "dlmSmooth", can take as
   arguments a data vector and a dlm object. Previously the argument
   had to be the output from "dlmFilter".

4) In addition to the "+" method function for objects of class "dlm",
   used to build complex models from simple components, all having the
   same dimensionality of the observation vector, there is now an
   outer sum, "%+%", which creates a joint model from independent
   dlm's. This is useful to specify models for multivariate
   observations. 

5) Minimal support for Markov chain Monte Carlo output analysis has
   been added, with functions "mcmcSD", "mcmcMean", "ergMean". 

Thanks to Michael Lavine for suggesting the outer sum in (4).

Please let me know of any problems. Comments and suggestions are
very welcome. 

Giovanni Petris

-- 

Giovanni Petris  <GPetris at uark.edu>
Department of Mathematical Sciences
University of Arkansas - Fayetteville
http://definetti.uark.edu/~gpetris/



From Max.Kuhn at pfizer.com  Thu Nov 29 15:25:26 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Thu, 29 Nov 2007 09:25:26 -0500
Subject: [R-pkgs] New versions of the caret (3.08) and caretLSF (1.12)
	packages
Message-ID: <71257D09F114DA4A8E134DEAC70F25D30A45AF33@groamrexm03.amer.pfizer.com>

New versions of the caret (3.08) and caretLSF (1.12) packages have been
released. 

caret (short for "Classification And REgression Training") aims to
simplify the model building process. The package has functions for data
splitting, pre-processing and model tuning, as well as other
miscellaneous functions. 

In the new versions:

   - The elasticnet and the lasso (from the enet package) have been
added

   - mars and fda models are now fit using the earth package. Instead of
using nk as a tuning parameter, these models now use the default nk from
the training set and tunes over nprune. This mimics the process used by
earth/mars/fda more closely.

   - A bug was fixed with leave-one-out cross-validation.

   - For some models, the calculations in the train function are much
more efficient. Wherever possible, caret tries to avoid re-fitting
models if it can get predictions from sub-models. For example, an object
for a boosted tree with 500 trees can often be used to get predictions
for any boosted tree with less than 500 trees. The affected models are:
pls, plsda, earth, rpart, gbm, gamboost, glmboost, blackboost, ctree,
pam, enet and lasso.


The caretLSF package is a parallel processing version of caret. The
other caret package, caretNWS, will be updated to work with the new
version of caret shortly.

Please email me at max dot kuhn at pfizer dot com with any questions or
comments

Max



From kate at few.vu.nl  Mon Dec  3 20:41:55 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Mon, 3 Dec 2007 20:41:55 +0100 (CET)
Subject: [R-pkgs] new package 'bvls', update of 'nnls'
Message-ID: <Pine.GSO.4.56.0712032032140.15974@laurel.few.vu.nl>

A new package 'bvls' is available on CRAN.

The package provides an R interface to the Stark-Parker algorithm for
bounded-variable least squares (BVLS) that solves A x = b with the
constraint l <= x <= u under least squares criteria, where l,x,u \in R^n,
b \in R^m and A is an m \times n matrix.

The Stark-Parker BVLS algorithm was published in

 Stark PB, Parker RL (1995). Bounded-variable least-squares: an
 algorithm and applications, Computational Statistics, 10, 129-141.

The packages interfaces the Fortran77 code distributed via the statlib
on-line software repository at Carnegie Mellon University
(http://lib.stat.cmu.edu/general/bvls), modified very slightly for
compatibility with the gfortran compiler.  Stark and Parker have agreed to
distribution under GPL version 2 or newer.

The function 'bvls::bvls' returns an object of (S3) class 'bvls', which
has methods for 'coefficients', 'fitted.values', 'deviance' and
'residuals'.

====

Version 1.1 of the package 'nnls' is available on CRAN.
Changes between Version 1.0 and 1.1:

	o The function 'nnls::nnls' returns an object of (S3) class
	  'nnls', which has methods for 'coefficients',
	  'fitted.values', 'deviance' and 'residuals'

	o The function 'nnnpls::nnnpls' allows each element of x to be
	  constrained to either a non-positive or a non-negative value

----
Katharine Mullen
mail: Department of Physics and Astronomy, Faculty of Sciences
Vrije Universiteit Amsterdam, de Boelelaan 1081
1081 HV Amsterdam, The Netherlands
room: T.1.06
tel: +31 205987870
fax: +31 205987992
e-mail: kate at nat.vu.nl
homepage: http://www.nat.vu.nl/~kate/



From h.wickham at gmail.com  Fri Dec  7 20:02:05 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 7 Dec 2007 13:02:05 -0600
Subject: [R-pkgs] fda, version 1.2.3
Message-ID: <f8e6ff050712071102o58d7de95iaf491b11e016652e@mail.gmail.com>

fda 1.2.3
========================

Version 1.2.3 of the fda package has just been released. This version adds to
previous versions a script to create most of the figures of chapter 6 of
"Applied Functional Data Analysis" by Ramsay and Silverman. Other changes
offer simpler calls to time warping / registration and functional principal
component functions.

The fda package supports the books "Functional Data Analysis" and "Applied
Functional Data Analysis" by Bernard Silverman and James Ramsay. Functional
data analysis, which lots of us like to call "FDA", is about the analysis of
information on curves or functions. FDA is a collection statistical techniques
for answering questions like, "What are the main ways in which the curves vary
from one to another?" In fact, most of the questions and problems associated
with multivariate data (PCA, LDA, clustering, ...) have functional
counterparts. More information about FDA can be found at
http://www.psych.mcgill.ca/misc/fda/.

Regards

Hadley Wickham
James Ramsey
Spencer Graves



From penel at biomserv.univ-lyon1.fr  Wed Dec 12 15:59:10 2007
From: penel at biomserv.univ-lyon1.fr (Simon Penel)
Date: Wed, 12 Dec 2007 15:59:10 +0100
Subject: [R-pkgs] New version of seqinR  released
Message-ID: <475FF73E.8080606@biomserv.univ-lyon1.fr>

Dear useRs,

the seqinR package contains utilities to import and analyze biological
sequence data. For a general introduction see this document:
http://pbil.univ-lyon1.fr/software/SeqinR//vignette.pdf

Please do not use r-help for questions about seqinR or r-bugs
for bug report about seqinR. Use instead the seqinR diffusion list:
http://pbil.univ-lyon1.fr/software/SeqinR//mailing.php?lang=eng

A new version of seqinR, seqinR 1.1-4, has been released on CRAN.
Here is a summary of changes:

o There is a new chapter to explain how to set up a
  local ACNUC server on Unix-like platforms.

o Function GC() has gained a new argument NA.GC
  defaulting to NA to say what should be returned when the
  GC content cannot be computed from data (for instance with a
  sequence like NNNNNNNNNNNN). The argument oldGC is now
  deprecated and a warning is issued. Functions GC1(),
  GC2(), GC3() are now simple wrappers for the
  more general GCpos() function. The new argument frame
  allows to take the frame into account for CDS.

o Function read.fasta() now supports comment lines
  starting by a semicolon character in FASTA files. An example
  of such a file is provided in sequences/legacy.fasta.
  The argument File is now deprecated. There is
  a new argument seqonly to import just the sequences
  without names, annotations and coercion attempts. There is
  a new argument strip.desc to remove the leading
  '>' character in annotations (as in function readFASTA
  from the Biostrings package). The FASTA file
  example someORF.fsa from Biostrings is also added
  for comparisons.

o Function read.alignment() has gained a new argument
  forceToLower defaulting to TRUE to force lower case in
  the character of the sequence (this is for a smoother interaction
  with the package ape). The argument File is now
  deprecated and a warning is issued when used instead of file.
  The example in the function kaks() has been corrected
  to avoid this warning when reading the example files.

o The details of the socket connection are no more stored in
  the slot socket for objects of class seqAcnucWeb:
  this slot is now deleted. As a consequence, the argument
  socket in function as.SeqAcnucWeb() has been
  removed and there is now a new
  argument socket = "auto" in functions getAnnot(),
  getFrag(), geyKeyword(), getLocation(),
  and getSequence(). The default value "auto" means
  that the details of the socket connection are taken automatically
  when necessary from the last opened bank. The size of local lists
  of sequences is reduced by about a third now as compared to the
  previous version.

o New dataset m16j and waterabs added.

o Generic functions getAnnot(), getFrag(), getKeyword(),
  getLength(), getLocation(), getName(), getSequence() and
  getTrans() have gained methods to handle objects from class list
  and class qaw.

o Functions getAttributsocket() and getNumber.socket()
  are now deprecated, a warning is issued.

o There is a new appendix in which all the examples protected
  by a dontrun statment are forced to be executed.

o New low level utility functions related to an ACNUC server:
  acnucclose(), quitacnuc(), clientid(), countfreelists(),
  knowndbs(), autosocket(), countsubseqs(), savelist(),
  ghelp(), modifylist(), getlistate(), setlistname(),
  residuecount(), isenum(), prettyseq(), gfrag(),
  print.seqAcnucWeb()

o Utility function parser.socket() has been optimized and
  is about four times faster now. This decreases the time
  needed by the query() function.

Best,

the seqinR team

-- 
Simon Penel
Laboratoire de Biometrie et Biologie Evolutive           Bat 711  -   CNRS UMR 5558  -    Universite Lyon 1              43 bd du 11 novembre 1918 69622 Villeurbanne Cedex       Tel:   04 72 43 29 04      Fax:  04 72 43 13 88
http://lbbe.univ-lyon1.fr/-Penel-Simon-.html?lang=fr
http://pbil.univ-lyon1.fr/members/penel



From KKIII at Indiana.Edu  Thu Dec 13 20:13:39 2007
From: KKIII at Indiana.Edu (Ken Kelley)
Date: Thu, 13 Dec 2007 14:13:39 -0500
Subject: [R-pkgs] New version of MBESS released
Message-ID: <86b533e90712131113y3104de23x9028456d2f7d8466@mail.gmail.com>

Hello useRs,

MBESS (Methods for the Behavioral, Educational, and Social Sciences)
has recently been released and should be on all of the mirrors by now
(with binaries for Mac and Windows:
http://cran.r-project.org/src/contrib/Descriptions/MBESS.html).

The major contribution of MBESS is confidence intervals for
noncentrality parameters (t, F, and chi-square) and standardized
effect sizes (e.g., the standardized mean and mean difference, R^2 for
random or fixed effects, the coefficient of variation, the root mean
square error of approximation, standardized regression coefficients)
as well as sample size planning from the accuracy in parameter
estimation (AIPE) approach, where the width of the observed confidence
intervals is of interest (in addition to or instead of the power
analytic approach to sample size planning).

This is the 10th release of MBESS and it is version number is now 1.0.0.

Detailed information about MBESS is available in the current issue of
Behavior Research Methods
(http://www.psychonomic.org/BRMIC/contents.htm) as well as Journal of
Statistical Software (http://www.jstatsoft.org/v20/i08).

Take care,
Ken

-- 
Ken Kelley, Ph.D.
Indiana University
Inquiry Methodology Program
201 North Rose Avenue, Suite 4000
Bloomington, Indiana 47405

Phone: 812-856-8330 / Fax: 812-856-8333
Email: KKIII at Indiana.Edu
Internet: http://www.indiana.edu/~kenkel



From ahenningsen at email.uni-kiel.de  Tue Dec 18 17:15:57 2007
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Tue, 18 Dec 2007 17:15:57 +0100
Subject: [R-pkgs] New version of systemfit (not backward compatible)
Message-ID: <200712181715.57597.ahenningsen@email.uni-kiel.de>

Dear R users,

the systemfit package contains functions for fitting systems of simultaneous 
equations by various estimation methods (e.g. OLS, SUR, 2SLS, 3SLS). 
Currently version 0.8 of systemfit is available on CRAN. However, shortly we 
will upload version 1.0, which is NOT BACKWARD COMPATIBLE. The changes that 
broke backward compatibility were necessary to make systemfit() more similar 
to standard regression tools in R such as lm(). We hope that the usage of 
systemfit() is more intuitive for R users now. We will continue to maintain 
the 0.8 branch so that users can still use the old version if they do not 
want to update their R scripts. Both versions are and will be available for 
download from systemfit's website:
   http://www.systemfit.org/
which is a shortcut to 
   http://www.uni-kiel.de/agrarpol/ahenningsen/systemfit/

A paper that describes the (new version of the) systemfit package is 
forthcoming in the Journal of Statistical Software (JSS). A preprint of this 
paper is available on systemfit's website:
   http://www.systemfit.org/systemfit_paper_1.0.pdf

The following list summarizes the most important changes 
from version 0.8 to 1.0:
- some names of systemfit()'s arguments have changed to make it more 
  similar to standard regression tools in R
- the order of systemfit()'s arguments has changed to make it more 
  similar to standard regression tools in R
- the names of the elements in the object returned by systemfit() have 
  changed to make it more similar to lm()
- added several methods for systemfit objects that are generally 
  available for standard regression tools in R
- restrictions on the coefficients can be specified symbolically now
- the functionality of systemfitClassic() has been integrated into systemfit()
- replaced ftest.systemfit() and waldtest.systemfit() by the method
  linear.hypothesis()
- systemfit now uses the "Matrix" package for matrix calculations (this 
  makes the estimation of large models and large data sets much faster)
- improved checking of the arguments so that error messages are more 
  helpful now

We thank two anonymous referees of the JSS, Achim Zeileis, John Fox, William 
H. Greene, Ott Toomet, Duncan Murdoch, Martin Maechler, Duglas Bates and 
several (other) systemfit users for their answers, comments, and/or 
suggestions that helped us to improve the systemfit package.

Feedback is always welcome!
Arne & Jeff

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445 or +49-4349-914871
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From racinej at mcmaster.ca  Tue Dec 18 21:30:03 2007
From: racinej at mcmaster.ca (Jeffrey S. Racine)
Date: Tue, 18 Dec 2007 15:30:03 -0500
Subject: [R-pkgs] Update of the np package (version 0.14-1)
Message-ID: <1198009803.37146.29.camel@pc-racine1.mcmaster.ca>

Dear R users,

An updated version of the np package has recently been uploaded to CRAN
(version 0.14-1). 

The package is briefly described in a recent issue of Rnews (October,
2007, http://cran.r-project.org/doc/Rnews/Rnews_2007-2.pdf) for those
who might be interested.

A somewhat more detailed paper that describes the np package is
forthcoming in the Journal of Statistical Software
(http://www.jstatsoft.org) for those might be interested.

A much more thorough treatment of the subject matter can be found in Li,
Q. and J. S. Racine (2007), Nonparametric Econometrics: Theory and
Practice, Princeton University Press, ISBN: 0691121613 (768 Pages) for
those who might be interested
(http://press.princeton.edu/titles/8355.html)

Information on the np package:

This package provides a variety of nonparametric (and semiparametric)
kernel methods that seamlessly handle a mix of continuous, unordered,
and ordered factor datatypes. We would like to gratefully acknowledge
support from  the Natural Sciences and Engineering Research Council of
Canada (NSERC:www.nserc.ca), the Social Sciences and Humanities Research
Council of Canada (SSHRC:www.sshrc.ca), and the Shared Hierarchical
Academic Research Computing Network (SHARCNET:www.sharcnet.ca).

Changes from version 0.13-1 to 0.14-1:

* now use optim rather than nlm for minimisation in single index and
smooth coefficient models
* fixed bug in klein-spady objective function
* regression standard errors are now available in the case of no
  continuous variables
* summary should look prettier, print additional information
* tidied up lingering issues with out-of-sample data and conditional
modes
* fixed error when plotting asymptotic errors with conditional densities
* fixed a bug in npplot with partially linear regressions and 
plot.behavior='data' or 'plot-data'
* maximum default number of multistarts is now set to 5
* least-squares cross-validation of conditional densities uses a new,
 faster algorithm
* new, faster algorithm for least-squares cross-validation for both 
local-constant and local linear regressions.
   The estimator has changed somewhat: both cross-validation and
   the estimator use a method of shrinking towards the local constant
   estimator rather than the standard ridge approach that shrinks
   towards zero
* optimised smooth coefficient code, added ridging
* fixed bug in uniform CDF kernel
* fixed bug where npindexbw would ignore bandwidth.compute = FALSE and
   compute bandwidths when supplied with a preexisting bw object
* now can handle estimation out of discrete support.
* summary would misreport the values of discrete scale factors which
   were computed with bwscaling = TRUE

We are grateful to John Fox, Achim Zeilies, Roger Koenker, and numerous
users for their valuable feedback which resulted in an improved version
of the package.

-- Jeffrey Racine & Tristen Hayfield.

-- 
Professor J. S. Racine         Phone:  (905) 525 9140 x 23825
Department of Economics        FAX:    (905) 521-8232
McMaster University            e-mail: racinej at mcmaster.ca
1280 Main St. W.,Hamilton,     URL:
http://www.economics.mcmaster.ca/racine/
Ontario, Canada. L8S 4M4

`The generation of random numbers is too important to be left to chance'



From tplate at acm.org  Sun Dec 23 02:33:06 2007
From: tplate at acm.org (Tony Plate)
Date: Sat, 22 Dec 2007 18:33:06 -0700
Subject: [R-pkgs] new version of trackObjs
Message-ID: <476DBAD2.1020700@acm.org>

The trackObjs package stores objects in files on disk so that files are
automatically rewritten when objects are changed, and so
that objects are accessible but do not occupy memory until
they are accessed. Also tracks times when objects are created
and modified, and caches some basic characteristics of objects
to allow for fast summaries of objects.

This version trackObjs_0.8-0 fixes some bugs:

     o   Fixed faulty detection of conflicting existing objects
         when starting to track to an existing directory.

     o   Replaced environment on function that is in the active
         binding for a tracked object.  Previously, that function
         could, if constructed via track(obj <- value), have a
         copy of the tracked object in its environment, which would
         stay present taking up memory even if the object was
         flushed out of the tracking environment.

     o   Fixed bug that stopped track.stop(all=TRUE) from working

-- Tony Plate



From deleeuw at stat.ucla.edu  Sun Dec 23 18:57:08 2007
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sun, 23 Dec 2007 09:57:08 -0800
Subject: [R-pkgs] anacor: yet another ca package
Message-ID: <E99D0798-917F-4C4B-A951-C25D86A3175F@stat.ucla.edu>

anacor-0.9.0 is on CRAN (by De Leeuw and Mair)

anacor does correspondence analysis and canonical correspondence
analysis. It can make row plots, column plots,
joint plots, Benz?cri plots, regression plots,
and transformation plots. Where appropriate, plots can
be in 3d using either rgl or scatterplot3d. Row and
column points can be in standard scaling, Benz?cri
scaling, Goodman scaling, row-centroid, or column-centroid
scaling.

The summary method writes out a table with the chi-square
(inertia) decomposition, it also writes out the singular
values, and their asymptotic standard errors under multinomial
sampling. Plots of the category quantifications (row scores
and column scores) can be made optionally with asymptotic
confidence ellipses, again based on multinomial sampling.

The package contain various utilities to switch data formats,
in particular to transform data frames to Burt matrices,
to indicator matrices, and even to fuzzy indicator matrices
using B-spline bases.

The vignette for the package (not added yet) is a paper
also submitted to the special psychoR issue of JSS. You
can get a preprint at

http://idisk.mac.com/jdeleeuw-Public/psychoR/anacor.zip

The psychoR directory also has the anacor package, the
homals package, and the homals paper. smacof (many forms
of multidimensional scaling) is next.

==========================================================
Jan de Leeuw, 11667 Steinhoff Rd, Frazier Park, CA 93225
home 661-245-1725 mobile 661-231-5416 work 310-825-9550
.mac: jdeleeuw +++  aim: deleeuwjan +++ skype: j_deleeuw
==========================================================
          There is no worse screen to block out
    the spirit than confidence in our own intelligence.
                                    ---- John Calvin.



From pls at mevik.net  Tue Jan  2 13:36:32 2007
From: pls at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik_and_Ron_Wehrens?=)
Date: Tue, 02 Jan 2007 13:36:32 +0100
Subject: [R-pkgs] pls version 2.0-0
Message-ID: <m0sleta9m7.fsf@bar.nemo-project.org>

Version 2.0-0 of the pls package is now available on CRAN.

The pls package implements partial least squares regression (PLSR) and
principal component regression (PCR).  Features of the package include

- Several plsr algorithms: orthogonal scores, kernel pls and simpls
- Flexible cross-validation
- A formula interface, with traditional methods like predict, coef,
  plot and summary
- Functions for extraction of scores and loadings, and calculation of
  (R)MSEP and R2
- Functions for plotting predictions, validation statistics,
  coefficients, scores, loadings, biplots and correlation loadings.

The main changes since 1.2-0 are

- There is now an options mechanism for selecting default fit algorithms.
  See ?pls.options.
- loadingplot() and coefplot() now try to be more intelligent when plotting
  x axis labels.
- The handling of factors in X has been improved, by changing the way the
  intercept is removed from the model matrix.
- All PLSR and PCR algorithms, as well as mvrCv(), have been optimised.
  Depending on the algorithm used, the size of the matrices, and the number
  of components used, one can expect from 5% to 65% reduction in
  computation time.
- Scaling of scores and loadings of kernel PLS and svd PCR algorithm has
  changed.  They are now scaled using the `classic' scaling found in
  oscorespls.
- The arguments `ncomp' now always means "number of components", and `comps'
  always means "component number".  The argument `cumulative' has been
  removed.
- A new data set 'gasoline' has been included.
- The 'NIR' and 'sensory' data sets have been renamed to 'yarn' and 'oliveoil'.


See the file CHANGES in the sources for all changes.

-- 
Bj?rn-Helge Mevik



From deepayan.sarkar at r-project.org  Tue Jan  2 20:03:09 2007
From: deepayan.sarkar at r-project.org (Deepayan Sarkar)
Date: Tue, 2 Jan 2007 11:03:09 -0800
Subject: [R-pkgs] rcompletion update
Message-ID: <eb555e660701021103w7b62ce07y9e452ecac2f65052@mail.gmail.com>

Hi,

The rcompletion package, originally intended to provide completion for
readline-based R interfaces, has undergone a number of changes.  These
changes are summarised below:

  o Reorganisation:

    - The package has been split into two.  All the completion code
      has been moved to a pure R package called 'rcompgen'.
      'rcompletion' now requires 'rcompgen' and simply provides
      readline bindings that uses 'rcompgen' to generate possible
      completions.  (Source packages are available on CRAN, binaries
      should be available soon.)

    - The purpose of this reorganisation is to allow other backends to
      use the completion facilities provided by 'rcompgen', hopefully
      avoiding duplication of effort.  I'm happy to add further
      infrastructure to 'rcompgen' if that is helpful.

    - as a proof of concept, .../examples/altesscomp.el contains code
      that provides an alternative (using 'rcompgen') to ESS's
      built-in completion mechanism.  It should be enough to include
      the contents of this file in ~/.emacs (please read the comments at
      the end before doing so).  The file is also available at

      http://rcompletion.googlecode.com/svn/trunk/rcompgen/inst/examples/altesscomp.el

      I am particularly interested in feedback from ESS users
      regarding how this compares with the default mechanism in terms
      of speed (especially in older machines).

  o Hosting:

    - The project is now hosted on Google Code, at
      http://code.google.com/p/rcompletion/

    - (For those interested, this now also hosts my R bash_completion
      script)


  o New completion features:

    - when the token is determined to be the first argument of
      library() or require(), completion is done on _installed_
      package names.  This is disabled by default since the first call
      to installed.packages() can be slow (especially when using
      remote file systems).

    - when the token is determined to be the first argument of data(),
      completion is done on available data sets.

    - tokens after a question mark (?) match aliases in help topics
      rather than object names.  So, for example, ?INST will complete
      to ?INSTALL even though there is no object named INSTALL.

    - the old behaviour of appending a left-parenthesis to function
      names has been disabled by default, since this requires
      evaluation of the mode of _all_ matches, which is undesirable
      for lazy-loaded symbols.

As always, comments and suggestions are most welcome.

-Deepayan



From sfalcon at fhcrc.org  Thu Jan  4 22:20:23 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 04 Jan 2007 13:20:23 -0800
Subject: [R-pkgs] RSQLite 0.4-18 sent to CRAN
Message-ID: <m2odpe32w8.fsf@fhcrc.org>

A new version of RSQLite has been pushed to CRAN.

In this version...

* Further integration of the manifest type system available since
  SQLite 3.  We now obtain the column type from the DB instead of
  pulling everything across as a character vector and calling
  type.convert.  This should improve performance and provide a more
  reliable interface to build on top of.  Note, however, that since
  type.convert is no longer called, return values will be different.
  In particular, text columns will come across as text, not factor.

* dbWriteTable has been refactored and no longer uses temp files.
  This resolves performance issues and line ending quandries on
  Windows.

* Fix for a bug in dbWriteTable when used to import text files; files
  lacking a trailing end of line marker can now be used.

Questions?  Send them to the r-sig-db mailing list.

Best Wishes,

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org



From daj025 at gmail.com  Fri Jan  5 04:38:34 2007
From: daj025 at gmail.com (David James)
Date: Thu, 4 Jan 2007 22:38:34 -0500
Subject: [R-pkgs] RMySQL 0.5-11 uploaded to CRAN
Message-ID: <74c69e370701041938g50c2147fn3cfb767fe219487b@mail.gmail.com>

Hello,

I've uploaded  version 0.5-11 of RMySQL into CRAN, and it should be available
soon.

>From the NEWS file:

Version 0.5-11

* Fixed a bug that would crash R with a failed mysql_real_connect().

* dbApply() is now working again (but still experimentally).

* Re-formatted the C code.

[0.5-9 through 0.5-10 were maintanance releases that Seth Falcon
kindly put out.]

Regards,

--
David



From h0125130 at wu-wien.ac.at  Thu Jan 11 11:52:23 2007
From: h0125130 at wu-wien.ac.at (Ingo Feinerer)
Date: Thu, 11 Jan 2007 11:52:23 +0100
Subject: [R-pkgs] tm 0.1 uploaded to CRAN
Message-ID: <45A616E7.9060404@wu-wien.ac.at>

Dear useRs,

a first version of tm has just been released on CRAN.

tm provides a sophisticated framework for text mining applications
within R.

It offers functionality for managing text documents, abstracts the
process of document manipulation and eases the usage of heterogeneous
text formats in R. An advanced metadata management is
implemented for collections of text documents to alleviate the usage
of large and with metadata enriched document sets.

With the package ships native support for handling
   *) the Reuters 21578 dataset,
   *) the Reuters Corpus Volume 1 dataset,
   *) Gmane RSS feeds,
   *) e-mails, and
   *) several classic file formats (e.g. plain text or CSV text).

tm provides easy access to preprocessing and manipulation mechanisms, like
   *) whitespace removal,
   *) stemming, or
   *) conversion between file formats (e.g., Reuters21578 to plain
   text).

Further a generic filter architecture is available in order to
   *) filter documents for certain criteria,
   *) or perform fulltext search.

The package supports the export from document collections to
term-document matrices as frequently used in the text mining
literature. This allows the straight-forward integration of existing
methods for classification, clustering, visualizations, etc.

The package is designed in a modular way to enable easy integration of
new file formats, parsers, transformations and filter operations.

Best regards,

Ingo Feinerer



From r.hankin at noc.soton.ac.uk  Fri Jan 12 14:22:45 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 12 Jan 2007 13:22:45 +0000
Subject: [R-pkgs] Dummy's guide to S4 methods: package Brobdingnag
Message-ID: <06676A7D-69A0-4443-B078-DA15E7767331@soc.soton.ac.uk>

Hello List.

please find uploaded to CRAN a new package, Brobdingnag.

This package does two things:

(1) allows computation of very large numbers using a logarithmic  
representation.

(2) provides a "Hello, World" example of S4 methods in use: there are  
two classes of object
   (brob and glub) and one virtual class (swift).  The package  
includes a vignette that is a
    step-by-step guide to using S4 methods in the context of an R  
package.


Enjoy

Robin

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From adrian at maths.uwa.edu.au  Mon Jan 15 07:05:48 2007
From: adrian at maths.uwa.edu.au (Adrian Baddeley)
Date: Mon, 15 Jan 2007 14:05:48 +0800
Subject: [R-pkgs] spatstat 1.11-0
Message-ID: <17835.6588.479880.317926@maths.uwa.edu.au>


	spatstat 1.11-0

Version 1.11-0 of package 'spatstat' is now available.

Spatstat is a package for the analysis of spatial data, 
mostly point pattern data. See <www.spatstat.org>

Important changes in version 1.11-0:

	New format for ppm objects (objects in old format are still handled).
	More stringent checking of function arguments.
	Improved handling of pixellation effects.
	Extensions to variance-covariance calculations for fitted models.

Adrian Baddeley and Rolf Turner



From peter.rossi at chicagogsb.edu  Thu Jan 18 16:42:21 2007
From: peter.rossi at chicagogsb.edu (Rossi, Peter E.)
Date: Thu, 18 Jan 2007 09:42:21 -0600
Subject: [R-pkgs] Version 2.0-9 of bayesm
Message-ID: <1E7B167439290641966EB161D433079801BE1A8D@GSBEX.gsb.uchicago.edu>

Version 2.0-9 of bayesm is now available on CRAN

changes include-

1. addition of rhierLinearMixture -- linear hierarchical models with a
mixture of normals prior
2. mixDenBi is now fully vectorized and run more than 10 times faster
3. minor documentation corrections have been made
4. rnmixGibbs allows the user to specify only one component
 
peter rossi



From enzo83 at wp.pl  Mon Jan 22 23:16:18 2007
From: enzo83 at wp.pl (Jakub Jurdziak)
Date: Mon, 22 Jan 2007 23:16:18 +0100
Subject: [R-pkgs] eval() parse() and problem with square brackets
Message-ID: <45B537B2.70807@wp.pl>

Hello,

i have problem with the following code (I'm using sqlQuery function from 
RODBC package):
eval(parse(text="g_1 <- sqlQuery(cnn_1, \"select aa from 
bb.[cc\\dd].ee\")")).

I get the error message:
"[RODBC] ERROR: Could not SQLExecDirect" 

"S0002 208 [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid object 
name 'bb.cc\dd.ee'."

It seems that R is replacing square brackets that are needed for 
database to execute query.

How can I force R to change its behavior and leave square brackets 
unchanged?

Any ideas appreciated

Kuba



From dusa.adrian at gmail.com  Tue Jan 23 12:28:08 2007
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Tue, 23 Jan 2007 13:28:08 +0200
Subject: [R-pkgs] version 0.3 of QCA
Message-ID: <200701231328.08930.dusa.adrian@gmail.com>


Dear list members,

A new version of the QCA package is now on CRAN.
The QCA package implements the Quine-McCluskey algorithm for boolean 
minimizations, according to the Qualitative Comparative Analysis.

Along with the additional improvements in version 0.3-1 (soon to be released 
on CRAN), this code is about 100 times faster than the previous "major" 
release (0.2-6). It can now reasonably work with 11 binary variables, finding 
a complete (and exact) solution in less than 2 minutes.

This dramatic increase in speed is due to using a mathematical reduction 
instead of an algorithmic one. This approach openes the way for _exact_ 
multi-value minimizations, and an even better (and faster) approach is 
searched for the future versions.

Best,
Adrian

-- 
Adrian Dusa
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101



From bates at stat.wisc.edu  Fri Jan 26 00:12:00 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 25 Jan 2007 17:12:00 -0600
Subject: [R-pkgs] New version of lme4 and new mailing list R-SIG-mixed-models
Message-ID: <40e66e0b0701251512p78612c2br31e32ea0411f301b@mail.gmail.com>

Version 0.9975-11 of the lme4 package has been uploaded to CRAN.  The
source package should be available on the mirrors in a day or two and
binary packages should follow soon after.

There are several changes in this release of the package.  The most
important is the availability of a development version of lmer called,
for the time being, lmer2.  At present lmer2 only fits linear mixed
models.  Generalized linear mixed models will be added "soon".
Furthermore there is no mcmcsamp method for a model fit by lmer2.
This deficiency will also be rectified "soon".  Once I have all the
capabilities and methods currently available for lmer also available
for the new representation I will remove the old representation and
rename lmer2 as lmer.

The current version of lmer will continue to be available throughout
the migration process.  You don't have to change anything about your
use of that function unless you want to try the new one.  It would be
a good idea, however, to save the data and the call to lmer in
addition to saving an lmer object, if you so choose, so that you can
recreate the fitted model when the development version becomes the
release version.

The package contains a vignette giving the details of the new implementation.

The reason I am releasing a development version in parallel with the
production version is because I would like feedback from useR's
regarding the development version.  In my experience, testing it
myself and with colleagues whom I visited recently, I have found that
lmer2 is faster and more reliable than the current lmer.  In
particular, on some difficult model fits I have been able to get
substantially better parameter estimates (i.e. the deviance at the
lmer2 estimates is perhaps 4 or 5 lower than that at the lmer
estimates) with lmer2 than I could with lmer.

If you have fit a linear mixed model using lmer and are willing to try
it with lmer2 I would appreciate your telling me if the parameter
estimates are comparable and which fit was faster (use system.time()
to check).  I'm primarily interested in models fit to large data sets
or "difficult" fits.

We have established a new mailing list, R-SIG-mixed-models, for
discussion of R software to fit mixed-effects models, especially lmer.
 See https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models for
information or to subscribe.

I know that I have said this before but this is the last time that I
am going to change the underlying representation.  Really - trust me -
this is the last time.  My theory of software development is expressed
in a line from an old blues song, "you just keep doing it wrong till
you do it right".  I'm convinced that this time I have it right.  That
statement sounds like "famous last words", doesn't it?  :-)



From charles.dupont at vanderbilt.edu  Mon Jan 29 18:11:19 2007
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Mon, 29 Jan 2007 11:11:19 -0600
Subject: [R-pkgs] Hmisc Version 3.1-2 uploaded to CRAN repository
Message-ID: <45BE2AB7.8030107@vanderbilt.edu>

Hmisc 3.1-2 has been uploaded to the CRAN incoming directory.

Change log
3.2-1 1/25/2007:
       Hmisc function 'ecdf' has been renamed 'Ecdf' to deconflict it
       with the existing 'ecdf' function in base.

       Fixed Bug in format.df that would create numbers with many
       trailing zeros.

       Added arguments 'math.row.names' and 'math.col.names' to
       indicate that the row or col names should be wrapped in the
       latex math environment.

       Fixed problem with 'histbackback' function.

-- 
Charles Dupont	Computer System Analyst		School of Medicine
		Department of Biostatistics	Vanderbilt University



From tobias.sing at gmail.com  Wed Jan 31 11:53:43 2007
From: tobias.sing at gmail.com (Tobias Sing)
Date: Wed, 31 Jan 2007 11:53:43 +0100
Subject: [R-pkgs] ROCR 1.0-2
Message-ID: <c3ca233a0701310253h458e88eam5d0a85ace4098fcc@mail.gmail.com>

Dear useRs,

an update of the ROCR package is available on CRAN.

ROCR helps in evaluating the performance of scoring classifiers using
ROC graphs, precision/recall plots, lift charts and many other
performance metrics.
For further information check http://rocr.bioinf.mpi-sb.mpg.de and
http://bioinformatics.oxfordjournals.org/cgi/reprint/21/20/3940

NEWS:
- added an optional parameter 'fpr.stop' to the performance measure 'auc',
  allowing to calculate the partial area under the ROC curve
  up to the false positive rate given by 'fpr.stop'.

- fixed bug in 'prediction' function which caused ROCR to halt
  in the context of a custom label.ordering (thanks to Roberto Perdisci
  for pointing out)

As usual, any feedback is more than welcome!
- Tobias


-- 
Tobias Sing
Computational Biology and Applied Algorithmics
Max Planck Institute for Informatics
Saarbrucken, Germany
Phone: +49 681 9325 315
Fax: +49 681 9325 399
http://www.tobiassing.net



From whitede at onid.orst.edu  Thu Feb  8 17:28:52 2007
From: whitede at onid.orst.edu (Denis White)
Date: Thu, 08 Feb 2007 08:28:52 -0800
Subject: [R-pkgs] new contributed package 'stream.net'
Message-ID: <1170952132.45cb4fc4dc5dc@webmail.oregonstate.edu>

New contributed package 'stream.net' is available on CRAN.

Description:   Functions with example data for creating, importing,
               attributing, analyzing, and displaying stream networks
               represented as binary trees.  Capabilities include
               importing network topology and attributes from GIS data,
               upstream and downstream distance matrices, stochastic
               network generation, segmentation of network into
               reaches, adding attributes to reaches with specified
               statistical distributions, interpolating reach
               attributes from sparse data, analyzing autocorrelation
               of reach attributes, and creating maps with legends of
               attribute data.  Target applications include dynamic
               fish modeling.

Denis White
US EPA
Corvallis, Oregon, USA



From ubk at kogalur-shear.com  Sun Feb 11 17:40:02 2007
From: ubk at kogalur-shear.com (K. B. Udaya)
Date: Sun, 11 Feb 2007 11:40:02 -0500
Subject: [R-pkgs] randomSurvivalForest 2.0.0 now available
Message-ID: <38c08c270702110840v72971cd4n9b9cc9117b65c38d@mail.gmail.com>

Dear useRs:

Release 2.0.0 of the randomSurvivalForest package is now available.

---------------------------------------------------------------------------------
CHANGES TO RELEASE 2.0.0

Release 2.0.0 represents a major upgrade in the functionality and stability
of the original 1.0.0 release.  Key changes are as follows:

o Two new splitting rules, 'logrankscore' and 'logrankapprox', added.

o Expanded output from 'rsf()'.  Now out-of-bag objects 'oob.ensemble' and
  'oob.mortality' are included in addition to the full ensemble objects
  'ensemble' and 'mortality'.

o Importance values for predictors can now be calculated (set
'importace = TRUE'
  in the initial 'rsf()' call).  Extended 'plot.error()' to print, as
well as plot,
  such values.

o Prediction on test data can now be implemented using 'rsf.predict()' (set
  'forest = TRUE' in the initial 'rsf()' call).

o Included option 'predictorWt' used for weighted sampling of predictors when
  growing a tree.

o Formula no longer restricted to main effects.  Formula for 'rsf' interpreted
  as in typical R applications.  However, users should be aware that including
  interactions or higher order terms in a formula may not be an optimal way to
  grow a forest.

o Three types of objects are generated in an RSF analysis: '(rsf, grow)',
  '(rsf, predict)' and '(rsf, forest)'.  Wrappers handle each type of object
  in different ways.

o Improved error checking in all wrappers.

o Extended 'plot.variable()' wrapper to generate partial plots for predictors.

o Improved control over trace output.  See the 'do.trace' option in 'rsf()'.

o Implements the Predictive Model Markup Language specification for an
  '(rsf, forest)' forest object.  PMML is an XML based language which
  provides a way for applications to define statistical and data mining
  models and to share models between PMML compliant applications.  More
  information about PMML and the Data Mining Group can be found at
  http://www.dmg.org.  Our implementation gives the user the ability to
  save the geometry of a forest as a PMML XML document for export or
  later retrieval.

---------------------------------------------------------------------------------

ubk2101 at columbia.edu

Udaya B. Kogalur, Ph.D.
Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012



From Graham.Williams at togaware.com  Tue Feb 13 20:58:02 2007
From: Graham.Williams at togaware.com (Graham Williams)
Date: Wed, 14 Feb 2007 06:58:02 +1100
Subject: [R-pkgs] New version of rattle released
Message-ID: <20070213195802.GA14089@athene.togaware.com>

A new version of Rattle (2.1.123), a Gnome-base GUI for data mining,
written copmletely in R, and available on GNU/Linux, Unix, Mac OSX, and
MS/Windows, has been released to CRAN.

There has been quite a lot of activity since the last update, including:

Transform:
        Now include basic imputation of missing values. More to follow.

Models: 
        Move to using ada for boosting.
        Better missing value handling for random forest
        Use arules package for market basket analysis
        Add more model visualisations

Export:
        RPart PMML export completed.
        PMML export has been separated out to its own package (pmml)

Complete change log available at

	http://rattle.togaware.com/changes.html

Rattle mailing list at

	http://groups.google.com/group/rattle-users

Regards,
Graham



From Graham.Williams at togaware.com  Wed Feb 14 10:41:40 2007
From: Graham.Williams at togaware.com (Graham Williams)
Date: Wed, 14 Feb 2007 20:41:40 +1100
Subject: [R-pkgs] New PMML package
Message-ID: <20070214094140.GA17839@athene.togaware.com>

A new package is now available on CRAN - pmml.

PMML is the Predictive Modelling Markup Language, and is accepted by a
number of large database and data warehouse systems (IBM DB2 and NCR
Teradata) for deployment of models as SQL.

The current package is an "early release" in that it is very basic (and
primarily supports the Rattle package). But it is a start! It currently
supports rpart classification trees and kmeans clusters.

Contributions of support for other models are welcome.

Regards,
Graham



From Graham.Williams at togaware.com  Wed Feb 14 11:00:10 2007
From: Graham.Williams at togaware.com (Graham Williams)
Date: Wed, 14 Feb 2007 21:00:10 +1100
Subject: [R-pkgs] New version of rattle released
Message-ID: <20070214100010.GA18511@athene.togaware.com>

A new version of Rattle (2.1.123), a Gnome-base GUI for data mining,
written completely in R, and available on GNU/Linux, Unix, Mac OSX, and
MS/Windows, has been released to CRAN.

There has been quite a lot of activity since the last update, including:

Transform:
        Now include basic imputation of missing values. More to follow.

Models: 
        Move to using ada for boosting.
        Better missing value handling for random forest
        Use arules package for market basket analysis
        Add more model visualisations

Export:
        RPart PMML export completed.
        PMML export has been separated out to its own package (pmml)

Complete change log available at

	http://rattle.togaware.com/changes.html

Rattle mailing list at

	http://groups.google.com/group/rattle-users

Regards,
Graham



From jtjokine at cc.helsinki.fi  Thu Feb 15 12:30:47 2007
From: jtjokine at cc.helsinki.fi (Jukka Jokinen)
Date: Thu, 15 Feb 2007 13:30:47 +0200 (EET)
Subject: [R-pkgs] New package 'drm' for repeated categorical data analysis
Message-ID: <Pine.OSF.4.58.0702121514210.426251@sirppi.helsinki.fi>

Dear useRs,

A new package 'drm', version 0.5-4, is available on CRAN.

The drm package provides functions for marginal regression analysis of
repeated (or otherwise clustered) binary, ordinal and nominal responses.
This package can be considered as a likelihood-based alternative to GEE
approach for marginal regression. In addition to regression modelling,
several temporal and latent variable models for the associations between
repeated responses can be specified. In other words, the package provides
joint regression and association modelling for repeated categorical data.

For longitudinal studies with dropout, the package also provides a
possibility to model the dropout mechanism by adding a selection model on
top of the joint regression and association model. This can be used to
explore the effect of dropout on the regression and association parameters
when dropout is considered nonignorable.

The novelty of the proposed approach is that there exists an explicit
solution for the joint distribution, and the parameterisation has an
inherent unit-sum constraint, which substantially facilitate maximum
likelihood fitting for datasets with large cluster sizes. For an
application to a binary response with 12 repeated measurements, see the
help-file of function drm.

For more information, see:
http://www.helsinki.fi/~jtjokine/drm/

Bug reports, comments or suggestions are welcome.

best,
Jukka Jokinen



From Mike.Prager at noaa.gov  Thu Mar  1 20:01:12 2007
From: Mike.Prager at noaa.gov (Michael H. Prager)
Date: Thu, 01 Mar 2007 14:01:12 -0500
Subject: [R-pkgs] Update of X2R sent to CRAN
Message-ID: <45E722F8.5060206@noaa.gov>

A new version of X2R has just been uploaded to CRAN.  It should be 
available at mirrors within a few days.

This contains revisions to the For2R component to fix a bug in which 
data frames were not written correctly if the user did not pass row labels.

The new version is supplied as files X2R.zip and X2R.tar.gz, which are 
equivalent.  The version can be identified from the contents of file 
"VersionInfo.txt" in the root of each archive.  The new version is dated 
March 1, 2007.

-----

 From the original announcement:

X2R is composed of three related software libraries: C2R,  ADMB2R, and 
For2R (together, X2R). Each contains output routines to simplify 
transfer of complicated data structures from models written in a 
compiled language to R.  The user's data can be written as a structured 
ASCII file which, when read by R (note 1) with a single dget() function 
call, will become an R data object of type list. The list, may contain 
components such as data frames, matrices, and other lists.

These are NOT R packages; rather they are subroutine libraries to be 
used with programmers' own modeling codes.  Limited testing indicates 
that they are compatible with S-PLUS, as well (note 1, note 2).

Languages supported are Fortran 95 (with For2R), C and C++ (with C2R) 
and AD Model Builder (with ADMB2R) (note 1, note 3).  Source code and 
users' manuals are supplied.

This work has been tested and used by the authors. However, any software 
may contain bugs, and these works are classified by NOAA as  
"Experimental Products."  Although the software is supplied with no 
warranty whatsoever, bug reports, suggestions, and extensions are 
solicited (send to Prager or Martin).  The authors will attempt to fix 
all bugs promptly and to add requested features.

Software is now available at CRAN,  http://cran.r-project.org/ .  Look 
under "Software / Other" for the current X2R distribution.


Michael H. Prager - mike.prager at noaa.gov
Andi Stephens
Southeast Fisheries Science Center
National Marine Fisheries Service, NOAA
101 Pivers Island Road
Beaufort, North Carolina 28516 USA

Jennifer L. Martin - jennifer.martin at noaa.gov
Northeast Fisheries Science Center
National Marine Fisheries Service, NOAA
166 Water Street
Woods Hole, Massachusetts 02543 USA


* Note 1.  Use of product names (commercial or otherwise) does not imply 
endorsement or recommendation by any U.S. government agency, nor by the 
authors in their government capacities.
* Note 2.  S-PLUS is a commercial product, released by Insightful 
Corporation.
* Note 3.  AD Model Builder is a commercial product, released by Otter 
Research.



From Peter.Rossi at chicagogsb.edu  Thu Mar  8 18:16:17 2007
From: Peter.Rossi at chicagogsb.edu (Rossi, Peter E.)
Date: Thu, 08 Mar 2007 11:16:17 -0600
Subject: [R-pkgs] Release 2.1-1 of bayesm
Message-ID: <1E7B167439290641966EB161D433079801EA928F@GSBEX.gsb.uchicago.edu>

 
Release 2.1-1 is now available on CRAN.

This release includes--
bayesm classes (some compatible with the mcmc class of coda) for output.
plot
and summary methods for these classes.

additional datasets including store-level panel data.

peter r
 
................................
 Peter E. Rossi
 Joseph T. and Bernice S. Lewis Professor of Marketing and Statistics
 Editor, Quantitative Marketing and Economics
 Rm 353, Graduate School of Business, U of Chicago
 5807 S. Woodlawn Ave, Chicago IL 60637
 Tel: (773) 702-7513   |   Fax: (773) 834-2081



From antonio.fabio at gmail.com  Fri Mar 23 15:15:24 2007
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Fri, 23 Mar 2007 15:15:24 +0100
Subject: [R-pkgs] RTisean 3.0-7 released
Message-ID: <b0808fdc0703230715k2178fdbdl32d0fe3bca0e8caf@mail.gmail.com>

Dear R users,
I've just uploaded to CRAN a new version of RTisean, the TISEAN-to-R interface.
This is now compatible with the recent, new 3.0.1 release of TISEAN [1].
This new TISEAN version is explicitely GPL-ed, and has some more
routines handling multivariate time series.

Bests,
Antonio, Fabio Di Narzo.

[1] http://idmc.blogspot.com/2007/03/tisean-300-is-out.html



From Mike.Prager at noaa.gov  Mon Apr 16 21:32:26 2007
From: Mike.Prager at noaa.gov (Michael H. Prager)
Date: Mon, 16 Apr 2007 15:32:26 -0400
Subject: [R-pkgs] Update of X2R sent to CRAN, 16 Apr 2007
Message-ID: <4623CF4A.3020100@noaa.gov>

X2R is a bundle of three software libraries allowing the user to pass 
structured data easily from Fortran, C/C++, or AD Model Builder to R.

An update to X2R has been sent to CRAN today and should be available at 
mirrors shortly. This fixes a bug in the ADMB2R and C2R components in 
which data frames were not written correctly when the user did not 
specify row names. Several other minor improvements also have been made.

The new version is supplied as files X2R.zip and X2R.tar.gz, which are 
equivalent.  The version and release date can be identified from the 
contents of file "VersionInfo.txt" in the root of each archive. The new 
version bears date April 16, 2007.

                                * * *

 From the original announcement:

X2R is composed of three related software libraries: C2R,  ADMB2R, and
For2R (together, X2R). Each contains output routines to simplify
transfer of complicated data structures from models written in a
compiled language to R.  The user's data can be written as a structured
ASCII file which, when read by R (note 1) with a single dget() function
call, will become an R data object of type list. The list, may contain
components such as data frames, matrices, and other lists.

These are NOT R packages; rather they are subroutine libraries to be
used with programmers' own modeling codes.  Limited testing indicates
that they are compatible with S-PLUS, as well (note 1, note 2).

Languages supported are Fortran 95 (with For2R), C and C++ (with C2R)
and AD Model Builder (with ADMB2R) (note 1, note 3).  Source code and
users' manuals are supplied.

This work has been tested and used by the authors. However, any software
may contain bugs, and these works are classified by NOAA as
"Experimental Products."  Although the software is supplied with no
warranty whatsoever, bug reports, suggestions, and extensions are
solicited (send to Prager or Martin).  The authors will attempt to fix
all bugs promptly and to add requested features.

Software is now available at CRAN,  http://cran.r-project.org/ .  Look
under "Software / Other" for the current X2R distribution.


Michael H. Prager - mike.prager at noaa.gov
Andi Stephens
Southeast Fisheries Science Center
National Marine Fisheries Service, NOAA
101 Pivers Island Road
Beaufort, North Carolina 28516 USA

Jennifer L. Martin - jennifer.martin at noaa.gov
Northeast Fisheries Science Center
National Marine Fisheries Service, NOAA
166 Water Street
Woods Hole, Massachusetts 02543 USA


* Note 1.  Use of product names (commercial or otherwise) does not imply
endorsement or recommendation by any U.S. government agency, nor by the
authors in their government capacities.
* Note 2.  S-PLUS is a commercial product, released by Insightful
Corporation.
* Note 3.  AD Model Builder is a commercial product, released by Otter
Research.



From vincent.goulet at act.ulaval.ca  Mon Apr 23 17:20:59 2007
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Mon, 23 Apr 2007 10:20:59 -0500
Subject: [R-pkgs] New version of actuar
Message-ID: <200704231120.59692.vincent.goulet@act.ulaval.ca>

UseRs,

actuar is a package for Actuarial Science. A rather preliminary
version (0.1-3) of the package has been available on CRAN since February 2006. 
We now announce the immediate availability of version 0.9-2 sporting a large 
number of new features. 

Non actuaries behold! There can be some features of interest for you, 
especially those related to new probability distribution and to the 
manipulation of grouped data.

Since I took the time to write a fairly detailed NEWS file, I'll let it speak 
for itself:

=== actuar: an R package for Actuarial Science ===

Version 0.9-2
=============

Major official update. This version is not backward compatible with
the 0.1-x series. Feature of the package can be split in the following
categories: loss distributions modeling, risk theory, credibility
theory.

NEW FEATURES -- LOSS DISTRIBUTIONS

o Functions {d,p,q,r}foo to compute the density function, cumulative
  distribution function, quantile function of, and to generate
  variates from, all probability distributions of Appendix A of
  Klugman et al. (2004), "Loss Models, Second Edition" (except the
  inverse gaussian) not already in R. Namely, this adds the following
  distributions (the root is what follows the 'd', 'p', 'q' or 'r' in
  function names):
  
  Distribution name          	Root        
  ------------------------- 		--------------  
   Burr			    	 	burr		  
   Generalized beta	     		genbeta	  
   Generalized Pareto	    	genpareto	  
   Inverse Burr		     	invburr	  
   Inverse exponential	     	invexp	  
   Inverse Pareto	     		invpareto	  
   Inverse paralogistic	     	invparalogis	  
   Inverse Weibull	     		invweibull	  
   Loggamma		     		loggamma	  
   Loglogistic		     		llogis	  
   Paralogistic		    	 	paralogis	  
   Pareto		     			pareto	  
   Single parameter Pareto   	pareto1	  
   Transformed beta	     	trbeta	  
   Transformed gamma	     	trgamma	  

  All functions are coded in C for efficiency purposes and should
  behave exactly like the functions in base R. For all distributions
  that have a scale parameter, the corresponding functions have 'rate
  = 1' and 'scale = 1/rate' arguments.

o Functions {m,lev}foo to compute the k-th raw (non-central) moment
  and k-th limited moment for all the probability distributions
  mentioned above, plus the following ones of base R: beta,
  exponential, gamma, lognormal and Weibull.

o Facilities to store and manipulate grouped data (stored in an
  interval-frequency fashion). Function grouped.data() creates a
  grouped data object similar to a data frame. Methods of "[", "[<-",
  mean() and hist() created for objects of class "grouped.data".

o Function ogive() --- with appropriate methods of knots(),
  plot(), print() and summary() --- to compute the ogive of grouped
  data. Usage is in every respect similar to ecdf().

o Function elev() to compute the empirical limited expected value of a
  sample of individual or grouped data.

o Function emm() to compute the k-th empirical raw (non-central)
  moment of a sample of individual or grouped data.

o Function mde() to compute minimum distance estimators from a sample
  of individual or grouped data using one of three distance measures:
  Cramer-von Mises (CvM), chi-square, layer average severity
  (LAS). Usage is similar to fitdistr() of package 'MASS'.

o Function coverage() to obtain the pdf or cdf of the payment per
  payment or payment per loss random variable under any combination of
  the following coverage modifications: ordinary of franchise
  deductible, policy limit, coinsurance, inflation. The result is a
  function that can be used in fitting models to data subject to such
  coverage modifications.

o Individual dental claims data set 'dental' and grouped dental claims
  data set 'gdental' of Klugman et al. (2004), "Loss Models, Second
  Edition".

NEW FEATURES -- RISK THEORY

o Function aggregateDist() returns a function to compute the
  cumulative distribution function of the total amount of claims
  random variable for an insurance portfolio using any of the
  following five methods:

  1. exact calculation by convolutions (using function convolve() of
     package 'stats';
  2. recursive calculation using Panjer's algorithm;
  3. normal approximation;
  4. normal power approximation;
  5. simulation.

  The modular conception of aggregateDist() allows for easy inclusion
  of additional methods. There are special methods of print(),
  summary(), quantile() and mean() for objects of class
  "aggregateDist".  The objects otherwise inherit from classes "ecdf"
  (for methods 1, 2 and 3) and "function".

  See also the "Deprecated, defunct or no backward compatibility"
  section below.

o Function discretize() to discretize a continuous distribution using
  any of the following four methods:

  1. upper discretization, where the discretized cdf is always above
     the true cdf;
  2. lower discretization, where the discretized cdf is always under
     the true cdf;
  3. rounding, where the true cdf passes through the midpoints of the
     intervals of the discretized cdf;
  4. first moment matching of the discretized and true distributions.

  Usage is similar to curve() of package 'graphics'. Again, the
  modular conception allows for easy inclusion of additional
  discretization methods.

NEW FEATURES -- CREDIBILITY THEORY

o Function simpf() can now simulate data for hierarchical portfolios
  of any number of levels. Model specification changed completely; see
  the "Deprecated, defunct or no backward compatibility" below. The
  function is also significantly (~10x) faster than the previous
  version.

o Generic function severity() defined mostly to provide a method for
  objects of class "simpf"; see below.

o Methods of aggregate(), frequency(), severity() and weights() to
  extract information from objects of class "simpf":

  1. aggregate() returns the matrix of aggregate claim amounts per
     node;
  2. frequency() returns the matrix of the number of claims per node;
  3. severity() returns the matrix of individual claim amounts per
     node;
  4. weights() returns the matrix of weights corresponding to the
     data.

  Summaries can be done in various ways; see ?simpf.summaries

o Function cm() (for "_c_redibility _m_odel") to compute structure
  parameters estimators for hierarchical credibility models, including
  the B?hlmann and B?hlmann-Straub models. Usage is similar to lm() of
  packages 'stats' in that the hierarchical structure is specified by
  means of a formula object and data is extracted from a matrix or
  data frame. There are special methods of print(), summary() for
  objects of class "cm". Credibility premiums are computed using a
  method of predict(); see below.

  For simple B?hlmann and B?hlmann-Straub models, bstraub() remains
  simpler to use and faster.

o Function bstraub() now returns an object of class "bstraub" for
  which there exist print and summary methods. The function no longer
  computes the credibility premiums; see the "Deprecated,
  defunct or no backward compatibility" below.

o Methods of predict() for objects of class "cm" and "bstraub" created
  to actually compute the credibility premiums of credibility
  models. Function predict.cm() can return the premiums for specific
  levels of a hierarchical portfolio only.

OTHER NEW FEATURES

o Function unroll() to unlist a list with a "dim" attribute of length
  0, 1 or 2 (that is, a vector or matrix of vectors) according
  to a specific dimension. Currently identical to severity.default()
  by lack of a better usage of the default method of severity().

o Three new demos corresponding to the three main fields of actuarial
  science covered by the package.

o French translations of the error and warning messages.

o The package now has a name space.

DEPRECATED, DEFUNCT OR NO BACKWARD COMPATIBILITY

o Function panjer(), although still present in the package, should no
  longer be used directly. Recursive calculation of the aggregate
  claim amount should be done with aggregateDist(). Further, the
  function is not backward compatible: model specification has
  changed, discretization of the claim amount distribution should now
  be done with discretize(), and the function now returns a function
  to compute the cdf instead of a simple vector of probabilities.

o Model specification for simpf() changed completely and is not
  backward compatible with previous versions of the package. The new
  scheme allows for much more general models.

o Function rearrangepf() is defunct and has been replaced by methods
  of aggregate(), frequency() and severity().

o Function bstraub() no longer computes the credibility premiums. One
  should now instead use predict() for this.

o The data set 'hachemeister' is no longer a list but rather a matrix
  with a state specification.


Version 0.1-3
=============

Fixed the dependency on R >= 2.1.0 since the package uses function
isTRUE().


Version 0.1-2
=============

- First public release.
- Fixed an important bug in bstraub(): when calculating the range of
  the weights matrix, NAs were not excluded.
- Miscellaneous documentation corrections.


Version 0.1-1
=============

- Initial release.
- Contains functions bstraub(), simpf(), rearrangepf() and panjer(),
  and the dataset hachemeister.

[There has been a very short lived version 0.9-1 on CRAN. Please ignore this 
version altogether.]

Collaboration is welcome. Please contact me directly.

-- 
  Vincent Goulet, Associate Professor
  ?cole d'actuariat
  Universit? Laval, Qu?bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From penel at biomserv.univ-lyon1.fr  Tue Apr 24 10:28:06 2007
From: penel at biomserv.univ-lyon1.fr (Simon Penel)
Date: Tue, 24 Apr 2007 10:28:06 +0200
Subject: [R-pkgs] new version of seqinR
Message-ID: <462DBF96.7090404@biomserv.univ-lyon1.fr>

Dear useRs,

The seqinR package  is a library of utilities to retrieve and analyse 
biological sequences.

A new version of seqinR, seqinR 1.0-7,  has been released on CRAN.

Here is a summary of changes:

o A new *experimental* function extractseqs() to download
  sequences thru zlib compressed sockets from an ACNUC server is released.
  Preliminary tests suggest that working with about 100,000 CDS is 
possible with
  a home ADSL connection. See the manual chapter 3 page 44 at
  http://pbil.univ-lyon1.fr/software/SeqinR/seqinr_1_0-7.pdf
  for some system.time() examples.

o As pointed by Emmanuel Prestat the URL used in dia.bactgensize() was no
  more available, this has been fixed in the current version.

o As pointed by Guy Perriere, the function oriloc() was no more compatible
  with glimmer 3.0 outputs. The function has gained a new argument
  glimmer.version defaulting to 3, but the value 2 is still functional for
  backward compatibility with old glimmer outputs.

o As pointed by Lionel Guy there was no default value for the as.string
  argument in the getSequence.SeqFastadna(). A default FALSE value is now
  present for backward compatibility with older code.

o New utility vectorized function stresc() to escape LaTeX special 
characters
  present in a string.

o New low level function readsmj() available.

o A new function readfirstrec() to get the record count of the specified 
ACNUC
  index file is now available.

o Function getType() called without arguments will now use the default 
ACNUC
  database to return available subsequence types.

o Function read.alignment() now also accepts file in addition to File as
  argument.

o A new function rearranged.oriloc() is available. This method, based on
  oriloc(), can be used to detect the effect of the replication 
mechanism on
  DNA base composition asymmetry, in prokaryotic chromosomes.

o New function extract.breakpoints(), used to extract breakpoints in 
rearranged
  nucleotide skews. This function uses the segmented package to define the
  position of the breakpoints.

o New function draw.rearranged.oriloc() available, to plot nucleotide skews
  on artificially rearranged prokaryotic chromosomes.

o New function gbk2g2.euk() available. Similarly to gbk2g2(), this function
  extracts the coding sequence annotations from a GenBank format file. This
  function is specifically designed for eukaryotic sequences, i.e. with 
introns.
  The output file will contain the coordinates of the exons, along with the
  name of the CDS to which they belong.

o After an e-mail by Marcelo Bertalan on 26 Mar 2007, a bug in oriloc() 
when
  the gbk argument was NULL was found and fixed by Anamaria Necsulea.

o Functions translate() and getTrans() have gained a new argument 
NAstring to
  represent untranslatable amino-acids, defaulting to character "X".

o There was a typo for the total number of printed bases in the ACNUC 
books:
  474,439 should be 526,506.

o Function invers() has been deleted.

o Functions translate(), getTrans() and comp() have gained a new argument
  ambiguous defaulting to FALSE allowing to handle ambiguous bases. If 
TRUE,
  ambiguous bases are taken into account so that for instance GGN is 
translated
  to Gly in the standard genetic code.

o New function amb() to return the list of nucleotide matching a given 
IUPAC
  nucleotide symbol.

o Function count() has gained a new argument alphabet so that oligopeptides
  counts are now possible. Thanks to Gabriel Valiente for this suggestion.
  The functions zscore(), rho() and summary.SeqFastadna() have also an 
argument
  alphabet which is forwarded to count().

Best,

the seqinR team

http://pbil.univ-lyon1.fr/software/SeqinR/seqinr_accueil.php


-- 
Simon Penel
Laboratoire de Biometrie et Biologie Evolutive           
Bat 711  -   CNRS UMR 5558  -    Universite Lyon 1              
43 bd du 11 novembre 1918 69622 Villeurbanne Cedex       
Tel:   04 72 43 29 04      Fax:  04 72 43 13 88
http://pbil.univ-lyon1.fr/members/penel



From jombart at biomserv.univ-lyon1.fr  Wed Apr 25 18:03:09 2007
From: jombart at biomserv.univ-lyon1.fr (Thibaut Jombart)
Date: Wed, 25 Apr 2007 18:03:09 +0200
Subject: [R-pkgs] new package adegenet
Message-ID: <462F7BBD.5040502@biomserv.univ-lyon1.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070425/87cdf118/attachment-0001.pl>

From jthioulo at biomserv.univ-lyon1.fr  Thu Apr 26 17:34:43 2007
From: jthioulo at biomserv.univ-lyon1.fr (Jean Thioulouse)
Date: Thu, 26 Apr 2007 17:34:43 +0200
Subject: [R-pkgs] New version of ade4TkGUI
Message-ID: <p06240800c25674fa4314@[134.214.34.24]>

Dear UseRs,

Version 0.2-1 of the ade4TkGUI package (a GUI for the ade4 package)
is now available on CRAN. This version corrects a few bugs and has
the following new features :

- history management : commands executed in the GUI are now stored
in the R session history

- echo of commands on cosole : all commands (including these ones
issued in the dudi synthesis window) are now echoed to the console

- an interface for the "s.arrow" function has been added

- the interface for the s.label function has been modified to allow
(or disallow) label frames

- the interface of the "s.value" interface has been modified to
allow simultaneous drawing of all the variables in a dataframe

- a help page has been added for the "explore" function

- the presentation of the "explore" function had been improved

- the "ordiCLust" function has been added, to do cluster analysis
on multivariate analysis row scores, with several dynamic graphic
help tools (a help page is also available). See these screenshots :
http://pbil.univ-lyon1.fr/JTHome/ordiClust1.png
http://pbil.univ-lyon1.fr/JTHome/ordiClust2.png
http://pbil.univ-lyon1.fr/JTHome/ordiClust3.png

Thanks you to all the people who sent me remarks, advice, and bug
reports. Comments are still (and always) welcome.

Jean
-- 
Jean Thioulouse - Labo Biometrie et Biologie Evolutive,  UMR CNRS 5558
Universite Lyon 1, Batiment Mendel,   43 Boulevard du 11 Novembre 1918
69622 Villeurbanne Cedex - France    http://pbil.univ-lyon1.fr/JTHome/
Tel : (33) 4 72 43 27 56                      Fax : (33) 4 72 43 13 88
# msn: thioulouse at hotmail.com  #  jabber: jt69 #  .mac: j.thioulouse #



From charles.dupont at vanderbilt.edu  Fri Apr 27 16:20:22 2007
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Fri, 27 Apr 2007 09:20:22 -0500
Subject: [R-pkgs] Hmisc Version 3.3-2 is now in CRAN repository
Message-ID: <463206A6.7090401@vanderbilt.edu>

Hmisc Version 3.3-2 has been posted to the CRAN repository.

Change Log

3.3-2 4/26/2007
       Fixed bug with combine<- function not handling NULL values.

3.3-1 3/29/2007
       Created functions trunc.POSIXt, ceil.POSIXt, round.POSIXt to do
       those ops on POSIXt objects.  Removed chron versions of these
       functions.

       Placed Hmisc in a namespace

       Factored out category levels that are identical (and in the same
       order) for multiple variables.  Changed print and html methods
       accordingly, and made new default for html output,
       levelType='list'.

       new argument levelType in html.contents.data.frame

       enhanced html.data.frame to set column headings in h2

       added curtail option (default: FALSE) for type='regression' to
       set imputed values to the boundaries of real data if outside

       added datadensity argument to plot.aregImpute

       fixed bug with curtail, added datadensity argument to
       plot.aregImpute

       fixed typo related to bass argument

       fixed bug in latex.describe to translate underscores in variable
       names when listing those with all NAs

       fixed inmChoice by unclassing first argument when pasting

       handled underscore in dataset name in latex.describe by calling
       latexTranslate

       Finished addition of listunique and listnchar, handled listing
       of character values in latex.describe.*

       listunique and listnchar

       For listunique option ignored multiple white spaces, leading and
       trailing white spaces, and case in tabulating character strings.

       For listunique ignored leading and trailing white space,
       multiple white spaces, and case when tabulating character
       strings. Carriage returns without new lines are changed to a
       single space.

       Modified 'extracolheads' such that when cgroup and n.cgroup are
       used in a latex.summary.formula.reverse statement the extra N=
       columns line up correctly.

       added boot.method argument to implement approximate Bayesian
       bootstrap when group is not used

       'R/inc-dec.s' created 2 new functions 'inc<-' and 'dec<-'. 
'inc<-' increments
       'x' by value assigned to it.  'dec<-' does the same thing but 
decrements 'x'.

       'R/responseSummary.s' changed 'responseSummary' 'FUN' argument
       so that is it run on each row of the response instead of the
       whole of the response.

       'R/latexObject.s' changed names of constant escapes.

       'R/combine.s' functions to perform element wise combination.

       'R/print.char.list.s'  various code simplifications.

       Corrected extra escapes in latexSN function.  fixes #10.

3.2-1 1/25/2007:
       Hmisc function 'ecdf' has been renamed 'Ecdf' to deconflict it
       with the existing 'ecdf' function in base.

       Fixed Bug in format.df that would create numbers with many
       trailing zeros.

       Added arguments 'math.row.names' and 'math.col.names' to
       indicate that the row or col names should be wrapped in the
       latex math environment.

       Fixed problem with 'histbackback' function.

-- 
Charles Dupont	Computer System Analyst		School of Medicine
		Department of Biostatistics	Vanderbilt University



From Max.Kuhn at pfizer.com  Fri Apr 27 16:31:01 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Fri, 27 Apr 2007 10:31:01 -0400
Subject: [R-pkgs] New packages: contrast and desirability
Message-ID: <71257D09F114DA4A8E134DEAC70F25D308320A27@groamrexm03.amer.pfizer.com>

The contrast and desirability packages are available for all platforms
at cran.r-project.org (and coming soon to a mirror near you).

The contrast package extends Frank Harrell's contrast.Design function
for one degree of freedom contrasts of model parameters to other types
of models, such as lm, glm, lme, gls and geese models. Fold-changes are
also calculated for all contrasts. There is a package vignette that
shows examples for a basic two-way layout and a design with repeated
measures.

The desirability package contains S3 classes for multivariate
optimization using the desirability function approach of Harrington
(1965) using the functional forms described by Derringer and Suich
(1980). There are functions for maximization, minimization, hitting a
target, box constraints and a function for creating arbitrarily shaped
desirability equations. There is also a package vignette that shows an
example of a multi-response surface experiment. 

Please send me emails for suggestions and bug fixes at max.kuhn at
pfizer.com.

Max

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From ubk2101 at columbia.edu  Thu May  3 15:27:11 2007
From: ubk2101 at columbia.edu (K. B. Udaya)
Date: Thu, 3 May 2007 09:27:11 -0400
Subject: [R-pkgs] randomSurvivalForest 2.1.0 now available
Message-ID: <38c08c270705030627p5016722s6ccd1a85093eddf1@mail.gmail.com>

Dear useRs:

Release 2.1.0 of the randomSurvivalForest package is now available.
--------------------------------------------------------------------------------------------------
CHANGES TO RELEASE 2.1.0

Release 2.1.0 represents a minor upgrade of the product, and will not affect
most users of the prior version of the product.  Key changes are as follows:

o R 2.5.0 compliance issues and necessitated modifications.

o Modification of PMML representation of RSF forest output.  The RSF custom
extension has been moved from the DataDictionary node to a new
MiningBuildTask node.  Note that forests produced with Release 2.0.0 will
have to be regenerated using Release 2.1.0.  We apologize for the
inconvenience.

o Fast processing of data involving large numbers of predictors (as in
many genomic examples) by using the option big.data=TRUE.  This
option bypasses the huge overhead needed by R in creating design
matrices and parsing formula.  However, users should be aware of
some side effects.  See the RSF help file for more details.  Thanks
to Steven (Xi) Chen for pointing out the problem.

o Only the top 100 predictors are now printed to the terminal when
calling plot.error().  This deals with settings as above when one
might have thousands of predictors.

o Introduced a new wrapper "find.interaction()" for testing for
pairwise interactions between predictors.

-------------------------------------------------------------------------------------

ubk2101 at columbia.edu

Udaya B. Kogalur, Ph.D.
Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012



From ggrothendieck at gmail.com  Thu May  3 18:14:51 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 3 May 2007 12:14:51 -0400
Subject: [R-pkgs] Ryacas now on CRAN
Message-ID: <971536df0705030914j2a74bcb4l44099ae1425d2ae3@mail.gmail.com>

Ryacas is now available on CRAN.  (Previously it was
available on the Omegahat repository.)

Ryacas is an R package that provides an interface from R to
the yacas computer algebra system.   It can be used for
computer algebra, exact arithmetic, ASCII pretty printing
and R to TeX output. R, yacas and Ryacas are all free
software packages distributed under the GPL version 2.

Ryacas is written in R. It uses a recursive decent
R-to-yacas translator and an XML-based OpenMath yacas-to-R
translator. yacas is run as a second process to which
R communicates via a socket interface.

There are 8 different user level interfaces
(yacas.character, yacas.expression, yacas.function,
yacas.formula, Sym objects, Expr objects, yacmode and
runYacas).  Most users will primarily use Sym objects.

NEW INSTALLATION FOR WINDOWS USERS

A key change in moving to CRAN is that yacas.exe is no longer
part of the Ryacas distribution so that Windows users must
separately install yacas 1.0.63. :(  Non-windows users always
had to separately install yacas.  To simplify this somewhat
the yacasInstall() R command will download and install yacas from
within R on Windows:

	# Windows installation procedure
	install.packages("Ryacas", dep = TRUE)
	library(Ryacas)
	yacasInstall()

For non-windows users the installation procedure is the same as
before; namely, install yacas and then install the Ryacas R package.
yacasInstall is not available on non-Windows systems.  More
installation information is available on the Ryacas home page.

LINKS

Home Page (Overview, News, Installation, Sample Session, Links, SVN)
http://code.google.com/p/ryacas/

News (on source changes; not entirely same as home page news)
http://ryacas.googlecode.com/svn/trunk/inst/NEWS

Vignette (includes many examples)
http://ryacas.googlecode.com/svn/trunk/inst/doc/Ryacas.pdf


SAMPLE SESSION
(need fixed font email viewer to view correctly)

> library(Ryacas)

>
> # algebra
>
> library(Ryacas)
> x <- Sym('x')
> (x+1) * (x-1)
expression((x + 1) * (x - 1))
> Simplify("%")
expression(x^2 - 1)
> PrettyForm("%")
 2
x  - 1

>
> # calculus
>
> Integrate(x+tan(x), x)
expression(x^2/2 - log(cos(x)))

>
> # exact arithmetic
>
> yacas('12/24')
expression(1/2)

>
> # ASCII pretty printing
>
> exp(-x^2)/(cos(x)+exp(x))
expression(exp(-x^2)/(cos(x) + exp(x)))
> PrettyForm("%")
     /  /  2 \ \
  Exp\ -\ x  / /
-------------------
Cos( x ) + Exp( x )

>
> # matrix - yacas matrices are row-wise
>

> List(List(1,2),List(x,6))
expression(list(list(1, 2), list(x, 6)))
> PrettyForm("%")
/              \
| ( 1 ) ( 2 )  |
|              |
| ( x ) ( 6 )  |
\              /

>
> # output TeX
>
> k <- Sym('k')
> yacas(TeXForm((x+1)^2 + k^3), retclass = 'unquote')
$\left( x + 1\right)  ^{2} + k ^{3}$

>
> detach()
>

yacas was developed by Ayal Pinkus and other contributors.

Ryacas was developed by Rob Goedman, Gabor Grothendieck,
S?ren H?jsgaard and Ayal Pinkus.   Contact Rob for Mac
issues and Gabor for all other issues.



From tplate at acm.org  Fri May  4 04:46:08 2007
From: tplate at acm.org (Tony Plate)
Date: Thu, 03 May 2007 20:46:08 -0600
Subject: [R-pkgs] new package: RSVGTipsDevice: create SVG plots with
	tooltips & hyperlinks
Message-ID: <463A9E70.5070401@acm.org>

the DESCRIPTION file:

Package: RSVGTipsDevice
Version: 0.7.0
Date:    04/30/2007
Title:   An R SVG graphics device with dynamic tips and hyperlinks
Author:  Tony Plate <tplate at acm.org>, based on RSvgDevice by T Jake 
Luciani <jakeluciani at yahoo.com>
Maintainer: Tony Plate <tplate at acm.org>
Depends: R (>= 1.4)
Description: A graphics device for R that uses the w3.org xml standard
             for Scalable Vector Graphics.  This version supports
             tooltips with 1 to 3 lines, hyperlinks, and line styles.
License: GPL version 2 or newer. http://www.gnu.org/copyleft/gpl.html



From andreas_wittmann at gmx.de  Sun May  6 15:45:37 2007
From: andreas_wittmann at gmx.de (Andreas Wittmann)
Date: Sun, 06 May 2007 15:45:37 +0200
Subject: [R-pkgs] New Package Reliability
Message-ID: <463DDC01.5030406@gmx.de>

Dear R useRs,

A new package 'Reliability' is now available on CRAN. It is mainly a set 
of functions functions for estimating parameters in software reliability 
models. Only infinite failure models are implemented so far. 

This is the first version of the package.

The canonical reference is:
J.D. Musa, A. Iannino, and K. Okumoto. Software Reliability: 
Measurement, Prediction, Application. McGraw-Hill, 1987.

Michael R. Lyu. Handbook of Software Realibility Engineering. IEEE 
Computer Society Press, 1996.
http://www.cse.cuhk.edu.hk/~lyu/book/reliability/


Suggestions, bug reports and other comments are very welcome.


enjoy and best regards
Andreas



From dimitris.rizopoulos at med.kuleuven.be  Tue May  8 10:54:09 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 8 May 2007 10:54:09 +0200
Subject: [R-pkgs] package ltm -- version 0.8-0
Message-ID: <012401c7914e$7142d370$0540210a@www.domain>

Dear R-users,

I'd like to announce the release of the new version of package `ltm' 
(i.e., ltm_0.8-0 soon available from CRAN) for Item Response Theory 
analyses. This package provides a flexible framework for analyzing 
dichotomous and polytomous data under IRT, including the Rasch model, 
the Two-Parameter Logistic model, Birnbaum's Three-Parameter model, 
the Latent Trait model with up to two latent variables (allowing also 
for nonlinear terms), and Samejima's Graded Response model. 
Furthermore, supporting functions for descriptive statistics, 
goodness-of-fit, ability estimation and plotting are available.

New features include:

  * The new functions person.fit() and item.fit() compute p-values for 
person- and item-fit statistics for IRT models for dichotomous data. 
The `simulate.p.value' argument enables the computation of p-values 
based on a Monte Carlo procedure.

  * The new function unidimTest() checks the unidimensionality 
assumption for dichotomous data IRT models, using a Modified Parallel 
Analysis.

  * The new function testEquatingData() prepares data-sets for test 
equating by common items. In particular, two types of common item 
equating are included: alternate form equating (where common and 
unique items are analyzed simultaneously) and across sample equating 
(where different sets of unique items are analyzed separately based on 
previously calibrated anchor items).

  * grm() now works with the available cases when incomplete data 
(i.e., in the presence of NAs) are analyzed.

  * better algorithms, for Missing At Random missing data mechanisms, 
have been written for grm(), ltm(), rasch() and tpm().

  * a residuals() method has been added for `grm', `ltm', `rasch', and 
`tpm' objects that computes Pearson-type residuals.

  * factor.scores() and fitted() methods for classes `grm', `ltm', 
`rasch', and `tpm' allow now for NAs in the `resp.patterns' argument, 
enabling thus the computation of ability estimates and fitted values 
for incomplete response patterns.

  * the fitted() method now allows also for the computation of 
marginal and conditional (on the latent variable(s)) probabilities; 
this feature is controlled by the new `type' argument.

  * for more details and other news, check the CHANGES file that ships 
with the package.

More information as well as .R files illustrating the capabilities of 
the package can be found in the Rwiki page of `ltm' available at: 
http://wiki.r-project.org/rwiki/doku.php?id=packages:cran:ltm.

Future plans include the development of functions for fitting Bock's 
Nominal Response model and the option for Differential Item 
Functioning.

I'd like also to thank all users of `ltm' for providing valuable 
feedback, and welcome any additional feedback (questions, suggestions, 
bug-reports, etc.).

Best,
Dimitris


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From Ivailo.Partchev at uni-jena.de  Tue May  8 12:52:25 2007
From: Ivailo.Partchev at uni-jena.de (Ivailo Partchev)
Date: Tue, 08 May 2007 12:52:25 +0200
Subject: [R-pkgs] irtoys
Message-ID: <46405669.6000502@uni-jena.de>

I have just submitted irtoys_0.1.0, a package potentially useful for 
those working with IRT models. It can fit the 1PL, 2PL, and 3PL models 
through a simple and unified syntax, using either the R package ltm, 
Brad Hanson's ICL program, or the commercially available BILOG-MG. The 
purpose is basically to facilitate teaching, and especially comparisons 
across models and/or programs. Various graphs, item fit statistics, 
scaling methods, ability estimation, simulation facilities etc. are also 
included. Please notice that most options in estimating an IRT model are 
kept to the typical default values, and only a small, common subset of 
the ltm, ICL, and BILOG syntax is supported. Comments are very welcome.

Ivailo Partchev
Institute of Psychology
University of Jena
Germany



From HDoran at air.org  Tue May  8 17:59:22 2007
From: HDoran at air.org (Doran, Harold)
Date: Tue, 8 May 2007 11:59:22 -0400
Subject: [R-pkgs] MiscPsycho Package 1.0
Message-ID: <2323A6D37908A847A7C32F1E3662C80EBA0161@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070508/eb1b1c00/attachment-0001.pl>

From milbo at sonic.net  Fri May 11 01:03:25 2007
From: milbo at sonic.net (Stephen Milborrow)
Date: Thu, 10 May 2007 16:03:25 -0700
Subject: [R-pkgs] New package "earth"
Message-ID: <000401c79357$9afe66b0$6401a8c0@DDV3JY61>

The "earth" package is now available on CRAN.

Earth builds models using Friedman's MARS.

Earth's principal advantages over the existing function mda::mars are that 
it is much faster and provides plotting and printing methods.  The general 
purpose model plotting function "plotmo" may also be useful to people who 
are not interested in earth itself.

Example:

> a <- earth(Volume ~ ., data = trees)
> summary(a, digits = 2)

Call:
earth(formula = Volume ~ ., data = trees)

Expression:
  23
  +  5.7 * pmax(0,  Girth - 13)
  -  2.9 * pmax(0,  13 - Girth)
  + 0.72 * pmax(0, Height - 76)

Number of cases: 31
Selected 4 of 5 terms, and 2 of 2 predictors
Number of terms at each degree of interaction: 1 3 (additive model)
GCV: 11     RSS: 213     GRSq: 0.96     RSq: 0.97


Regards,
Stephen Milborrow



From klaus.nordhausen at uta.fi  Wed May 16 08:45:12 2007
From: klaus.nordhausen at uta.fi (Klaus Nordhausen)
Date: Wed, 16 May 2007 09:45:12 +0300
Subject: [R-pkgs] new packages 'ICS' and 'ICSNP'
Message-ID: <464AA878.7010906@uta.fi>

Dear R useRs,

The new contributed packages 'ICS' and 'ICSNP' are available on CRAN.

Descriptions:

The 'ICS' package implements the 2 scatter matrix transformation to 
obtain an invariant coordinate system or independent components, 
depending on the underlying assumptions. The result of the 
transformation is an object of the S4 class ics which is provided by 
this package. Besides generic functions to create and work with ics 
objects the package contains also some scatter matrices and two tests 
for multinormality.


The 'ICSNP' package contains tools for nonparametric multivariate 
analysis, including the estimation of location and shape as well as some 
tests for location and independence. Shape matrices from this package 
can be used as one of the scatter matrices needed in the package ICS 
whereas the tests of this package can be used for testing in the 
framework of invariant coordinates or independent components obtained 
from the package ICS. The parametric Hotelling?s T test serves as a 
reference for the nonparametric location tests.

Suggestions, bug reports and other comments are very welcome.

Best wishes,

Klaus, Seija, Hannu and Dave

-- 
Klaus Nordhausen
Researcher
Tampere School of Public Health
FIN-33014 University of Tampere

phone:	+358 3 3551 7086
fax:	+358 3 3551 6057
e-mail:	Klaus.Nordhausen at uta.fi



From hastie at stanford.edu  Thu May 17 03:13:04 2007
From: hastie at stanford.edu (Trevor Hastie)
Date: Wed, 16 May 2007 18:13:04 -0700
Subject: [R-pkgs] New version 0.9-7 of lars package
Message-ID: <464BAC20.6000901@stanford.edu>

I uploaded a new version of the lars package to CRAN,
which incorporates some nontrivial changes.

1) lars now has normalize and intercept options, both defaulted to TRUE,
which means the variables are scaled to have unit euclidean norm, and
an intercept is included in the model. Either or both can be set to FALSE.

2) lars has an additional type = "stepwise" option;
    now the list is type=c("lasso", "lar", "forward.stagewise","stepwise")
This was included because it is trivial to implement, and useful for 
comparisons.
"Stepwise" is a version of forward stepwise regression, where the 
variable to
enter is the one most correlated with the residuals. This is not 
necessarily the
same as the forward stepwise implemented as part of step() in R, where the
variable entered is the one that, when included, reduces the RSS the most.

3) a method for summary() has been included, which gives an anova-type 
summary
of the sequence of steps.

4) The plot method for lars defaults to plotting coefficients against 
the relative
L1 norm of the coefficients. This was not done correctly in general for 
type "lar"
and "forward.stagewise", since the L1 norm does not change smoothly if
coefficients pass through zero. This has been fixed.

5) A smalll number of of other changes have been made, some in response 
to email
messages from users.
 
Thanks to Yann-Ael Le Borgne for pointing out the problem in (4) and 
proposing
a solution, and to Lukas Meier for reporting some bugs. Please let me 
know of any
new problems, or old ones not yet repaired.

Trevor Hastie

--------------------------------------------------------------------
  Trevor Hastie                                  hastie at stanford.edu
  Professor & Chair, Department of Statistics, Stanford University
  Phone: (650) 725-2231 (Statistics)	         Fax: (650) 725-8977
	 (650) 498-5233 (Biostatistics)		 Fax: (650) 725-6951
  URL: http://www-stat.stanford.edu/~hastie
  address: room 104, Department of Statistics, Sequoia Hall
	          390 Serra Mall, Stanford University, CA 94305-4065



From jfox at mcmaster.ca  Tue May 29 22:47:30 2007
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 29 May 2007 16:47:30 -0400
Subject: [R-pkgs] Rcmdr 1.3-0 and RcmdrPlugins.TeachingDemos
Message-ID: <20070529204734.WEHY13710.tomts25-srv.bellnexxia.net@JohnDesktop8300>

I'd like to announce a new version, 1.3-0, of the Rcmdr package. The Rcmdr
package provides a basic-statistics graphical user interface (GUI) to R. 

Beyond small changes and additions, this new version of the package makes
provision for "plug-ins" that permit extension of the Rcmdr GUI without
altering and rebuilding the Rcmdr source package or modifying the installed
package. An R Commander plug-in is an ordinary R package that (1) provides
extensions to the R Commander menus is a file named menus.txt located in the
package's etc directory; (2) provides call-back functions required by these
menus; and (3) in optional Log-Exceptions: and Models: fields in the
package's DESCRIPTION file, augments respectively the list of functions for
which printed output is suppressed and the list of model objects recognized
by the R Commander. The menus provided by a plug-in package are merged with
the standard Commander menus. 

Plug-in packages given in the R Commander plugins option (see ?Commander)
are automatically loaded when the Commander starts up. Plug-in packages may
also be loaded via the Commander "Tools -> Load Rcmdr plug-in(s)" menu; a
restart of the Commander is required to install the new menus. Finally,
loading a plug-in package when the Rcmdr is not loaded will load the Rcmdr
and activate the plug-in. 

An illustrative R Commander plug-in package, RcmdrPlugin.TeachingDemos
(providing a GUI to some of Greg Snow's TeachingDemos package), is now
available on CRAN. (I suggest using this naming convention -- RcmdrPlugin.*
-- so that plug-in packages will sort immediately below the Rcmdr package on
CRAN. This assumes, of course, that other people will be interested in
creating Rcmdr plugins!)

Because this is a new feature of the Rcmdr, feedback and suggestions would
be appreciated.

I'd like to acknowledge Richard Heiberger's suggestions for the design of
this plug-in facility.

John

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox



From Alejandro.JaraVallejos at med.kuleuven.be  Tue May 29 18:10:27 2007
From: Alejandro.JaraVallejos at med.kuleuven.be (Alejandro Jara Vallejos)
Date: Tue, 29 May 2007 18:10:27 +0200
Subject: [R-pkgs] DPpackage - New version
Message-ID: <20070529181027.3fturouitnogg0gs@webmail4.kuleuven.be>

Dear List:

I have uploaded version 1.0-4 of DPpackage on CRAN. Since the first  
version (1.0-0), I have not communicated the improvements of the  
package. I'll use this email to summarize its current status.

The name of the package is motivated by the Dirichlet process.  
However, DPpackage tries to be a general package for Bayesian  
nonparametric and semi-parametric data analysis. So far, the package  
includes models based on Dirichlet processes, Dirichlet process  
mixtures of normals, Polya trees, and Random Bernstein polynomials. A  
list of current functions is given next:

1) Density estimation: DPdensity (using DPM of normals), PTdensity  
(using Mixtures of Polya Trees), and BDPdensity (using  
Bernstein-Dirichlet prior). The first two functions allow uni- and  
multi-variate analysis.

2) Nonparametric random effects distributions in mixed effects models:

    2.1) DPlmm and DPMlmm, using a DP/MDP and DPM of normals prior,  
respectively, for the linear mixed effects model.

    2.2) DPglmm and DPMglmm, using a DP/MDP and DPM of normals prior,  
respectively, for generalized linear mixed effects models,  
respectively. The sampling(link) considered by these functions are  
binomial(logit,probit), poisson(log) and gamma(log).

    2.3) DPolmm and DPMolmm, using a DP/MDP and DPM of normals prior,  
respectively, for the probit-ordinal mixed effects models.

    2.4) DPrasch and FPTrasch, using a DP/MDP and finite PT/MPT  
(mixture of Polya Trees) prior for the Rasch model with binary  
sampling distribution, respectively.

    2.5) DPraschpoisson and FPTraschpoisson. The same as before (2.4)  
but with a Poisson sampling.

    2.6) DPmeta and DPMmeta for the random (mixed) effects  
meta-analysis models, using a DP/MDP and DPM of normals prior,  
respectively.

3) Binary regression with nonparametric link:

    3.1) CSDPbinary, using Newton, Czado and Chappell (1996)'s  
centrally standardized DP prior.

    3.2) DPbinary, using the regular DP prior for the inverse of the  
link function.

    3.3) FPTbinary, using a finite PT prior for the inverse of the  
link function.


4) AFT model for interval-censored data:

    4.1) DPsurvint, using a MDP prior for the baseline distribution.

5) ROC curve estimation:

    5.1) DProc, using DPM of normals.

6) Linear model with a nonparametric for the error distribution:

    6.1) PTlm, using MPT.

7) DP prior elicitation:

    7.1) DPelicit, using the exact and approximated formulas for the  
mean and variance of the number of clusters given the total mass  
parameter and the number of subjects.


Tim Hanson and Fernando Quintana have made contributions to the  
current version. I would also like to thank George Karabatsos for his  
input to the current status of the package and Peter Mueller for  
actively promoting the package.

Various other improvements have been motivated by questions asked by  
many people around the world. I would like to thank all of them too.

I welcome anyone who sends comments, suggestions, remarks, and  
particularly those who find bugs or mistakes in any part of the  
package or its documentation. DPpackage is an open source program for  
Bayesian nonparametric developments. All contributions are welcome.

Best regards,

Alejandro.


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From knoblauch at lyon.inserm.fr  Tue May 29 17:59:04 2007
From: knoblauch at lyon.inserm.fr (ken knoblauch)
Date: Tue, 29 May 2007 17:59:04 +0200
Subject: [R-pkgs] new packages psyphy and MLDS
Message-ID: <40119c691173b4fae2adff6bfabfe98a@lyon.inserm.fr>

New packages psyphy and MLDS are available on CRAN:

psyphy ncludes an assortment of functions
  useful in  analyzing data from pyschophysical experiments. It
   includes functions for calculating d' from several
   different experimental designs, links for mafc to be
   used with the binomial family in glm (and possibly
   other contexts) and selfStart functions for estimating gamma values
  for CRT (and possibley other RGB) screen calibration data.

MLDS implements analyses for Maximum Likelihood Difference Scaling.
Difference scaling is a method for scaling perceived super-threshold
differences. The package contains functions that allow the user to fit
the resulting data by maximum likelihood and to test the internal 
validity
of the estimated scale.   There are also example functions that might
be used to design and run a difference scaling experiment,

Any suggestioins, criticisms, bug-reports, etc. are always welcome.

Best,

Ken Knoblauch

-- 
Ken Knoblauch
Inserm U846
Institut Cellule Souche et Cerveau
D?partement Neurosciences Int?gratives
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.pizzerialesgemeaux.com/u846/



From rmh at temple.edu  Wed May 30 14:55:55 2007
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 30 May 2007 08:55:55 -0400 (EDT)
Subject: [R-pkgs] Revised Rcmdr.HH package
Message-ID: <20070530085555.CCV65389@po-d.temple.edu>

I posted a revised Rcmdr.HH_1.8-0 package on CRAN.

The Rcmdr.HH package adds additional menu items to the Rcmdr package by
John Fox.  Our introductory course at Temple University includes several
topics that were not addressed in the Rcmdr.  This revision uses the new
RcmdrPlugin technology that John announced a few days ago.

Rich



From calenge at biomserv.univ-lyon1.fr  Thu May 31 09:18:07 2007
From: calenge at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Thu, 31 May 2007 09:18:07 +0200
Subject: [R-pkgs] adehabitat version 1.6
Message-ID: <465E76AF.6080501@biomserv.univ-lyon1.fr>

Dear all,

I have just uploaded to CRAN the version 1.6 of the
package 'adehabitat'. Significant changes are
listed below:

* The package has been reorganized into four parts (see
?adehabitat-package for a description): (i) management of raster maps,
(ii) habitat selection / ecological niche analysis, (iii) home range
analysis, and (iv) analysis of animals trajects. The package contains
several demo files to allow an overview of these parts :
demo(rastermaps), demo(homerange), demo(managltraj),
demo(analysisltraj), demo(nichehs).

* the package now contains a new function allowing the exploration of
the ecological niche, which generalizes several factor analyses (ENFA,
MADIFA, ...) and is closely related to several methods (Mahalanobis
distances, selection ratios, etc.), named gnesfa() (see the examples of
the help page for the properties of this analysis).

* The class ltraj now distinguishes two types of trajects: type I (time
not recorded, e.g. tracks of animals in the snow) and type II (time
recorded, e.g. GPS monitoring). Trajects of type II may either be
"regular" (constant time lag between relocations) or not.

* Numerous example datasets have been added to the package to illustrate
the analysis of animals trajects: 4 porpoises, 6 albatross, 1 hooded
seal, 1 whale, 1 brown bear, two roe deer, two chamois, 4 ibex, 1
mouflon, 3 wild boar

* Many functions have been added to allow the management of animals
trajects within R: Some functions allow to handle the attributes or the
storage of the trajects  (typeII2typeI, typeI2typeII, sett0, cutltr,
is.regular, is.sd, mindistkeep, offsetdate, set.limits), other allow to
manage missing values and test their random distribution in the traject
(setNA, summaryNAltraj, plotNAltraj, runsNAltraj), other allow a
graphical exploration of the properties of the trajects (hist.ltraj,
plot.ltraj, plotltr, sliwinltr).

* Several functions now allow to test the independence of the
descriptive parameters in the trajects (indmove and wawotest for dx, dy
and dist, testang.ltraj for rel.angle and abs.angle)

* Several functions allow to simulate common models of trajects: the
correlated random walk (simm.crw), the brownian motion (simm.brown), the
arithmetic brownian motion (simm.mba), the Ornstein Uhlenbeck process
(simm.mou), the brownian bridge (simm.bb) and the Levy process (simm.levy).

* The function explore.kasc() provides a Tk interface for the
exploration of a multi-layer raster map of class "kasc"

* A partitioning algorithm (still under research) is also available to
partition a traject into segments with homogeneous properties (see the
help page of modpartltraj)

* The bugs in redisltraj and mcp.area have been corrected

Happy testing,


Cl?ment CALENGE
-- 
Cl?ment CALENGE
Laboratoire de Biom?trie et Biologie ?volutive
UMR CNRS 5558
43 Bd. 11 Nov. 1918
69622 Villeurbanne Cedex - France
Office national de la chasse et de la faune sauvage
95, rue Pierre Flourens
34000 Montpellier



From h.wickham at gmail.com  Mon Jun  4 07:14:18 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 4 Jun 2007 07:14:18 +0200
Subject: [R-pkgs] Beta version of ggplot2
In-Reply-To: <f8e6ff050706031018v119635f2m2f4a354cc332ccb6@mail.gmail.com>
References: <f8e6ff050706031018v119635f2m2f4a354cc332ccb6@mail.gmail.com>
Message-ID: <f8e6ff050706032214l29c9d5fft3ce2948caf44c496@mail.gmail.com>

Dear all,

I am pleased to announce the new beta release of ggplot2.  ggplot2 is
a plotting system for R, based on the grammar of graphics, which tries
to take the good parts of base and lattice graphics and none of the
bad parts.  It takes of many of the fiddly details that make plotting
a hassle (like drawing legends) as well as providing a powerful model
of graphics that makes it easy to produce complex multi-layered
graphics.

You can install ggplot2 from CRAN with the following code:
install.packages("ggplot2", dep=TRUE)

There have been a lot of changes to the syntax since the last version
of ggplot and I have renamed the package to ggplot2, so that you can
continue to use your existing code while you transition to the new
system.

As part of the release, I am working on a radically improved
documentation system, currently available at
http://had.co.nz/ggplot2/.  While I'm still working on the textual
explanations, I have mostly completed the examples, which are
displayed with both code and output.  There are over 480 example
graphics, so I hope you should be able to find an example
demonstrating whatever you need.  Any comments on the content and
display would be gratefully received.

In the next few days I will be adding the first chapters of the ggplot
book, which will provide a more systematic introduction to ggplot, the
theory behind it and more examples of its use.  The ggplot book will
be published with Springer, hopefully in Summer 2008.

The latest version of ggplot now provides a complete implementation of
the grammar of graphics, including new support for coordinate systems,
position adjustment (dodging, stacking and jittering).

This is a beta release, so there are still bugs in the code, and many
small aesthetic tweaks to be made.  If you encounter something that
doesn't work, doesn't make sense or you think could be improved,
please don't hesitate to contact me.

Again, you can find out more, and see hundreds of example graphics at
http://had.co.nz/ggplot2/.

Hadley

PS. If you are interested in learning more in person, have at look at
the courses available at http://lookingatdata.com.



From h.wickham at gmail.com  Mon Jun  4 07:14:40 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 4 Jun 2007 07:14:40 +0200
Subject: [R-pkgs] Updated reshape and ggplot
In-Reply-To: <f8e6ff050706031000l4b5bc719t4a9762a1be53103f@mail.gmail.com>
References: <f8e6ff050706031000l4b5bc719t4a9762a1be53103f@mail.gmail.com>
Message-ID: <f8e6ff050706032214n600cb830m3294ab88b050fc9d@mail.gmail.com>

Hi everyone,

This is a short announcement for the users of ggplot and reshape.  I
have just released new versions of each that fix bugs when used with R
2.5.0:

 * reshape was having problems with missing combinations of variables
 * errorbars in ggplot weren't working.

I've you've been having problems with either of these, please upgrade.

About ggplot
=====================

An implementation of the grammar of graphics in R.

ggplot is an implementation of the grammar of graphics in R. It
combines the advantages of both base and lattice graphics:
conditioning and shared axes are handled automatically, while
maintaining the ability to build up a plot step by step from multiple
data sources. It also implements a more sophisticated multidimensional
conditioning system and a consistent interface to map data to
aesthetic attributes.

Find out more at http://had.co.nz/ggplot

About reshape
=====================

Reshape is an R package for flexibly restructuring and aggregating
data. It is available on all platforms supported by R (Linux, OS X,
Windows, ...).  Reshape (hopefully) makes it easy to do what you have
been struggling to do with tapply, by, aggregate, xtabs, apply and
summarise. It is also useful for getting your data into the correct
structure for lattice or ggplot plots.

You can find out more at http://had.co.nz/reshape


Regards,

Hadley



From david.meyer at wu-wien.ac.at  Tue Jun  5 00:11:32 2007
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Tue, 05 Jun 2007 00:11:32 +0200
Subject: [R-pkgs] New package: relations
Message-ID: <46648E14.8000808@wu-wien.ac.at>

Dear useRs,

it is our great pleasure to announce the new package "relations" to
appear on all CRAN-mirrors soon.

This package provides data structures and methods for creating and
manipulating relations, relation ensembles, sets, and tuples. The
feature list includes:

* creation of relations by domain and graph/characteristic
function/incidences,

* extraction of characteristic function and graph,

* predicate functions for the most common standard characteristics,

* operators known from relational algebra theory (such as projection,
selection, cartesian product, joins, etc.),

* transitive/reflexive reduction and closure of a relation,

* relation ensembles for combining relations,

* fitters for determining (possibly all) consensus relations of a
relation ensemble including the Borda and Condorcet methods, as well as
exact solvers for minimizing a criterion function based on the symmetric
difference (Kemeny-Snell) metric.

* a simple plot method for Hasse-diagrams using RGraphviz.


Kurt and David



From Graham.Williams at togaware.com  Tue Jun  5 10:09:55 2007
From: Graham.Williams at togaware.com (Graham Williams)
Date: Tue, 5 Jun 2007 18:09:55 +1000
Subject: [R-pkgs] Package update: pmml version 1.1.1
Message-ID: <20070605080955.GA15345@athene.togaware.com>

Version 1.1.1 of the pmml package (PMML = Predictive Modelling Markup
Language) has been uploaded to CRAN. This version adds pmml.lm to
generate PMML for linear models (currently, without interactions).

The PMML package is part of the Rattle toolkit for data
mining. Further information from http://rattle.togaware.com.

Regards,
Graham



From dave at kanecap.com  Tue Jun  5 15:52:13 2007
From: dave at kanecap.com (David Kane)
Date: Tue, 5 Jun 2007 09:52:13 -0400
Subject: [R-pkgs] New Package on Lancet Surveys of Iraq Mortality
Message-ID: <18021.27277.958091.918392@gargle.gargle.HOWL>

Hello,

I have placed a package on CRAN about two surveys of mortality in Iraq
that were published in the Lancet.

http://cran.at.r-project.org/src/contrib/Descriptions/lancet.iraqmortality.html

> install.packages("lancet.iraqmortality")

...

> library(lancet.iraqmortality)
Loading required package: foreign
> ?lancet.iraqmortality
> vignette("mortality")

This is a rough version. Suggestions and feedback are welcome.

Dave Kane



From mfay at niaid.nih.gov  Wed Jun  6 15:34:50 2007
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 6 Jun 2007 09:34:50 -0400
Subject: [R-pkgs] R Package: ssanv - Sample size adjustments for
	nonadherence and variability of input parameters
Message-ID: <31DDB7BE4BF41D4888D41709C476B657062E7694@NIHCESMLBX5.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070606/dc0b3c9b/attachment-0001.pl>

From mfay at niaid.nih.gov  Wed Jun  6 15:46:35 2007
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 6 Jun 2007 09:46:35 -0400
Subject: [R-pkgs] R package: Mchtest - Monte Carlo hypothesis testing
	allowing Sequential Stopping
Message-ID: <31DDB7BE4BF41D4888D41709C476B657062E7695@NIHCESMLBX5.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070606/d0c6991b/attachment-0001.pl>

From mfay at niaid.nih.gov  Wed Jun  6 15:50:52 2007
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 6 Jun 2007 09:50:52 -0400
Subject: [R-pkgs] New Package: rateratio.test
Message-ID: <31DDB7BE4BF41D4888D41709C476B657062E7696@NIHCESMLBX5.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070606/d1b1dce4/attachment-0001.pl>

From h.wickham at gmail.com  Mon Jun 11 07:42:03 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 11 Jun 2007 07:42:03 +0200
Subject: [R-pkgs] Updated ggplot2 package (beta version)
Message-ID: <f8e6ff050706102242g399410b3kd34744ac2a44854f@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
none of the bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2

Changes in version 0.5.1 ------------------------------

 * new chapter in book and changes to package to make it possible to
customise every aspect of ggplot display using grid

 * a new economic data set to help demonstrate line, path and area plots

 * many bug fixes reported by beta testers

Hadley



From h.wickham at gmail.com  Tue Jun 19 09:07:26 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 19 Jun 2007 09:07:26 +0200
Subject: [R-pkgs] ggplot2 0.5.2
Message-ID: <f8e6ff050706190007v2c236c2dn3ddb5de02d4b879d@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
none of the bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2

Changes in version 0.5.2 ------------------------------

* add argument to position dodge so it's now possible to accurately
dodge things with different widths to their physical widths
* added median summary
* new examples:
	* logistic regression example in stat_smooth
* bugs fixed:
	* evaluation of arguments to layer is no longer delayed
	* can use categorical xseq with stat_smooth
	* x and y axes named incorrectly (thanks to Dieter Menne for spotting this)
	* can now pass position objects to qplot
	* y jitter calculated correctly, and jittered data rescales axis now
	* removed silly legend from quantile plot
	* extra arguments not being passed on to geoms/stats
	* fixed bug in stat_summary when summarising a factor
	* fixed bugs in stat_summary, geom_ribbon, and coord_trans examples



From lawremi at iastate.edu  Tue Jun 19 15:10:35 2007
From: lawremi at iastate.edu (Michael Lawrence)
Date: Tue, 19 Jun 2007 08:10:35 -0500
Subject: [R-pkgs] RGtk2 2.10.x series available
Message-ID: <509e0620706190610ra4f82fdv1f547ef7d3323777@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070619/8ab78a9f/attachment-0001.pl>

From adrian at maths.uwa.edu.au  Thu Jun 21 09:15:26 2007
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Thu, 21 Jun 2007 15:15:26 +0800 (WST)
Subject: [R-pkgs] spatstat version 2
Message-ID: <35219.130.95.98.17.1182410126.squirrel@130.95.98.17>

              SPATSTAT version 2

Spatstat is an R package for the statistical analysis of spatial data.

A preliminary announcement about the forthcoming Version 2 of spatstat
is available here:
    <www.spatstat.org/spatstat/spatstat2.html>



From Max.Kuhn at pfizer.com  Thu Jun 21 16:50:40 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Thu, 21 Jun 2007 10:50:40 -0400
Subject: [R-pkgs] odfWeave version 0.5.9 released
Message-ID: <71257D09F114DA4A8E134DEAC70F25D308B55763@groamrexm03.amer.pfizer.com>

A new version of odfWeave has been released to CRAN. This is a
significant change to the package internals. It now uses the XML library
instead of a bunch of regular expressions.

New features include:

   - Captions for tables and figures
   - Functions to insert page breaks and to change the page layout
   - Style objects for frames and pages

Bug fixes include:

   - Parsing of arguments for graphics devices
   - Misc issues with bulleted lists

There is also a 30 page manual in the examples sub-directory that
describes the various style element and their values, with almost 50
code chunks for illustration.

Thanks to Steve Weston, Nathan Coulter, Sarah Goslee and Ralf Herold.

Send me any questions or comments,

Max

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From luyizhao at fas.harvard.edu  Wed Jun 27 16:07:42 2007
From: luyizhao at fas.harvard.edu (luyizhao at fas.harvard.edu)
Date: Wed, 27 Jun 2007 10:07:42 -0400
Subject: [R-pkgs] New package "tradeCosts"
Message-ID: <1182953262.46826f2e64b47@webmail.fas.harvard.edu>

We would like to announce the availability of the 'tradeCosts' package
in R for analysing transaction costs of trading.  Version 0.1-0 is now available
on CRAN.  To take a look, you can:

> install.packages("tradeCosts")
...
> vignette("tradeCosts")

and play around.

This is the first and very basic version of a package that we hope to
expand over the next few months.

The cost analysis this package performs is currently very basic.  We
are releasing this version with the goal of getting feedback from
potential users on what functionality they would like to see in future
releases of the tradecosts package.

Aaron Schwartz
Luyi Zhao



From mildenbe at statistik.uni-dortmund.de  Thu Jun 28 15:26:28 2007
From: mildenbe at statistik.uni-dortmund.de (Thoralf Mildenberger)
Date: Thu, 28 Jun 2007 15:26:28 +0200
Subject: [R-pkgs] new package benchden 1.0.0 : benchmark densities for
 nonparametric density estimation
Message-ID: <4683B704.50406@statistik.uni-dortmund.de>

The new package "benchden" 1.0.0 implements 28 benchmark densities for
nonparametric density estimation that were introduced by A. Berlinet and
L. Devroye ("A Comparison of Kernel Density Estimates", Pub. Inst. Stat.
Univ. Paris, XXXVIII, fasc. 3, 1994, 3-59,
http://cg.scs.carleton.ca/~luc/devs.html ). This collection includes a
variety of densities with different degrees of smoothness, different
tail behaviour, different number of modes, with and without infinite 
peaks and also some standard densities like the normal and the uniform. 
There is also a small intersection (e.g. the claw density) with the 
collection of normal mixtures introduced by Marron and Wand and 
implemented in R in the package "nor1mix".
Similar to the test bed functions by Donoho and Johnstone (Blocks, Bumps
etc.) commonly used in regression or the "Peppers" and "Lena" images
popular in image analysis, the densities in this collection should be 
useful for testing and comparing new and existing density estimators.
"benchden" 1.0.0 contains functions for the generation of random
variates as well as density-, distribution- and quantile-functions.
Everything is implemented in typical R-style and the package should
reduce the programming effort needed for simulation studies in
nonparametric density estimation. It also allows for better
reproducibility of the results.

Thoralf Mildenberger, Henrike Weinert and Sebastian Tiemeyer



From h.wickham at gmail.com  Sun Jul  1 17:58:54 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 1 Jul 2007 17:58:54 +0200
Subject: [R-pkgs] Clusterfly
Message-ID: <f8e6ff050707010858h7f4b925eu7e5fbecb5a6479f9@mail.gmail.com>

clusterfly
http://had.co.nz/clusterfly/

Typically, there is somewhat of a divide between statistics and
visualisation software. Statistics software, particularly R, provides
implementation of cutting edge research methods, but limited graphics.
Visualisation software will provide sophisticated visual interfaces,
but few statistical algorithms. The clusterfly package presents some
early experimentation aimed at overcoming this deficiency by linking R
and GGobi. Cluster analysis was chosen as it is an exploratory method
that needs sophisticated visualisation and statistical algorithms.

Clusterfly provides some tools that work with all clustering
algorithms, and some that are tailored for particular ones.  Generic
tools allow you to animate between clusterings (see ?cfly_animate) and
produce common static graphics (?cfly_dist, ?cfly_pcp).  Specific
algorithms are available for:

* Self organising maps (aka Kohonen neural networks), ?ggobi.som.
Displays the self organising map/net in the original space of the
data.

* Hierarchical clustering, ?hierfly. Connects data points with lines
like a dendrogram, but in the high-dimensional space of the original
data

 * Model based clustering, ?mefly. Adds ellipsoids from the
multivariate normal distributions the clusters are based on

You will need GGobi (http://www.ggobi.org) and rggobi
(http://www.ggobi.org/rggobi) installed to be able to use clusterfly.

Regards,

Hadley



From h.wickham at gmail.com  Sun Jul  8 21:10:49 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 8 Jul 2007 21:10:49 +0200
Subject: [R-pkgs] Scagnostics - scatterplot diagnostics
Message-ID: <f8e6ff050707081210n29e29847y372e02fd220c5d3b@mail.gmail.com>

The scagnostics package implements the graph theoretic scagnostics
described by Leland Wilkinson, Anushka Anand and Robert Grossman
(http://www.ncdm.uic.edu/publications/files/proc-094.pdf), building on
an old idea of Tukey's to define indices of "interestingness" to help
guide the search for interesting features in the pair-wise
scatterplots of a highly multivariate dataset.

The scagnostics package currently only supports two methods, one which
computes the scagnostics for a pair of variables, and the other for
all pairs of variables in a data.frame.

If you are attending the JSM, there is a session on scagnostics.
Details are available at http://tinyurl.com/324yb5

(The package has just been added to CRAN, it may be a couple of days
before it is available on your local mirror)

Regards,

Hadley



From h.wickham at gmail.com  Mon Jul  9 11:12:28 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 9 Jul 2007 11:12:28 +0200
Subject: [R-pkgs] ggplot 0.5.4
Message-ID: <f8e6ff050707090212r7925d60ck2ece466d98500731@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the over 500
examples of ggplot in use.

Changes in version 0.5.4 ------------------------------

* border now drawn on top of geoms, instead of below - this results in
better appearance when adjusting scale limits
* ggplot() + aes() now modifies existing default aesthetic mapping,
rather than overwriting
* polished examples in facet_grid

Changes in version 0.5.3 ------------------------------

* added experimental scatterplot matrix, see ?plotmatrix
* added new border.colour and grid.minor.colour options for better
control over plot appearance
* updated theme_bw to do better when drawing a plot with white background
* better default colour choices for gradients (and more discussion in examples)
* fixed bug in ScaleGradient2 where scales with different positive and
negative ranges were not scaled correctly
* allow expressions as result from strip.text
* fixed rare bug in geom_vline and geom_hline
* fixed example in geom_abline
* tweaked display of multiline axis labels

Regards,

Hadley



From david.meyer at wu-wien.ac.at  Mon Jul  9 15:49:29 2007
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Mon, 09 Jul 2007 15:49:29 +0200
Subject: [R-pkgs] New package "proxy" for distances and similiarities
Message-ID: <46923CE9.4090802@wu-wien.ac.at>

Dear useRs,

a new package for computing distance and similarity matrices made it to 
CRAN, and will propagate to the mirrors soon.

It includes an enhanced version of "dist()" with support for more than 
40 popular similarity and distance measures, both for auto- and 
cross-distances. Some important ones are implemented in C.

The proximity measures are stored in a registry which can easily be 
queried and extended by users at run-time. For adding a new measure, the 
simplest way is to provide the distance measure as a small R function, 
the package code will do the loops on the C code level to create the 
proximity matrix. It is of course also possible to use more efficient C 
implementations---either for the distance measure alone, or the whole 
matrix computation.

Input data is not restricted to matrices: provided the proximity measure 
can handle it, lists and data frames are also accepted.

The formulas for binary proximities can conveniently be specified in the 
a/b/c/d/n format, where the number of concordant/discordant pairs is 
precomputed on the C code level.

We are currently working on support for sparse data.

This is also a "Call for Measures": if you feel that a particular 
similarity of distance measure is missing, please send the formula and a 
reference (or, ideally, the whole registry entry) to one of the package 
maintainers who will happily add it.

David and Christian.



From edd at debian.org  Mon Jul  9 18:41:55 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 9 Jul 2007 11:41:55 -0500
Subject: [R-pkgs] CRANberries -- An RSS feed about New and Updated CRAN
	packages
Message-ID: <18066.25939.77583.800991@basebud.nulle.part>


Announcing CRANberries -- An RSS feed about New and Updated CRAN packages

A new RSS feed [1] is now available that summarizes uploads to CRAN.  This
makes it possibly to quickly obtain concise information about which (of the
now over one thousand !!) packages were added or updated at CRAN and its
mirrors.

To this end, two basic variants are provided:
 - a feed for new packages where we display the DESCRIPTION file
 - a feed for updated packages where we display the output of diffstat(1) 
   between the old and new source tar archives.
  
As the URLs for these are in a hierarchy, one can subscribe to both or
individual feeds.  The URLs are as follows:

   Everything
	http://dirk.eddelbuettel.com/cranberries/index.rss

   Just CRAN (so far the same as All)
	http://dirk.eddelbuettel.com/cranberries/cran/index.rss

   New CRAN packages
	http://dirk.eddelbuettel.com/cranberries/cran/new/index.rss

   Updated CRAN packages
	http://dirk.eddelbuettel.com/cranberries/cran/updated/index.rss

but the easiest way may just be to subscribe to Elijah's wonderful 'Planet R'
feed aggregator which already sources the 'Everything' variant above.  Beside
giving you lots of other R information, it also points to a more reliable
back-end than my small server at home.

Lastly, I could add other repositories. However, to provide updates in the
current format, my code relies on some CRAN features not available on all
other repos (i.e an Archive/ section with old tarballs, and the various
Descriptions/$package.DESCRIPTION files).

For the technically inclined, this is implemented using a few lines of R
executed by littler [2] storing data via R/DBI in a SQLite db and writing
simple text files that are then aggregated by the Blosxom [3] blog engine.

Comments, questions, criticism most welcome.

Best regards,  Dirk

[1] See the Wikipedia entry at http://en.wikipedia.org/wiki/Rss if that term
    is unfamiliar. RSS feeds can be read in web browsers, numerous stand-alone
    applications, or web-services such as Google Reader.

[2] See http://dirk.eddelbuettel.com/code/littler.html

[3] See http://blosxom.sourceforge.net/ and http://blosxom.sourceforge.net/
    but not that Blosxom development seems to have ceased. There are many 
    alternatives such as PyBlosxom and Nanoblogger.


-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison



From h.wickham at gmail.com  Mon Jul  9 19:23:21 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 9 Jul 2007 19:23:21 +0200
Subject: [R-pkgs] Reshape version 0.8
Message-ID: <f8e6ff050707091023j2818c1d6gcfb763e1c5e81b09@mail.gmail.com>

Reshape version 0.8
http://had.co.nz/reshape

Reshape is an R package for flexibly restructuring and aggregating
data.  It's inspired by Excel's pivot tables, and it (hopefully) makes
it very easy to get your data into the shape that you want.  You can find out
more at http://had.co.nz/reshape

This version brings a few minor changes to make the output more
attractive and less surprising.  If you have any code that relies on
the exact output structure you might need to tweak it a little.

* preserve.na renamed to na.rm to be consistent with other R functions

* Column names are no longer automatically converted to valid R names.
You may need to use `` (those are backticks) to access these names.

* Margins now displayed with (all) instead of NA

* melt.array can now deal with cases where there are partial dimnames
- Thanks to Roberto Ugoccioni

 * Added the Smiths dataset to the package

 * Fixed a bug when displaying margins with multiple result variables

Regards,

Hadley



From david.meyer at wu-wien.ac.at  Wed Jul 11 00:49:20 2007
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Wed, 11 Jul 2007 00:49:20 +0200
Subject: [R-pkgs] package "relations" updated
Message-ID: <46940CF0.5040205@wu-wien.ac.at>

Dear useRs,

Version 0.2 of package "relations" appeared on CRAN and is currently 
propagating to the mirrors. In addition to some bug fixes, the new 
release includes:

   o an introductory vignette showing the main features;

   o new SD fitters for the C ("complete") and A ("antisymmetric")
     families of relations;

   o a fitter for Copeland's method;

   o the relation_classes() function to extract and pretty-print
     (ordered) classes from preferences and equivalences;

   o the function relation_violations() to compute a measure of
     remoteness from a specified property (e.g., symmetry,
     transitivity, etc.).

David and Kurt.





-- 
Dr. David Meyer
Department of Information Systems and Operations

Vienna University of Economics and Business Administration
Augasse 2-6, A-1090 Wien, Austria, Europe
Tel: +43-1-313 36 4393
Fax: +43-1-313 36 90 4393
HP:  http://wi.wu-wien.ac.at/~meyer/



From aaron.king at umich.edu  Tue Jul 24 14:05:19 2007
From: aaron.king at umich.edu (Aaron King)
Date: Tue, 24 Jul 2007 08:05:19 -0400
Subject: [R-pkgs] New package: pomp,
	inference for partially-observed Markov processes
Message-ID: <200707240805.19285.aaron.king@umich.edu>

To: cran at r-project.org
Subject: New package: pomp, inference for partially-observed Markov processes

The new package 'pomp' is built around a very general realization of nonlinear 
partially-observed Markov processes (AKA state-space models, nonlinear 
stochastic dynamical systems). The user provides functions specifying the 
model's process and measurement components. The package's algorithms are 
built on top of these functions. 

At the moment, algorithms are provided for particle filtering (AKA sequential 
importance sampling or sequential Monte Carlo) and the likelihood 
maximization by iterated filtering (MIF) method of Ionides, Breto, and King 
(PNAS, 103:18438-18443, 2006). Future support for a variety of other 
algorithms is envisioned. A working group of the National Center for 
Ecological Analysis and Synthesis (NCEAS), "Inference for Mechanistic 
Models", is currently implementing additional methods for this package.

Simple worked examples are provided in the form of a 
vignette, "random_walk_example".

The package is provided under the GPL. Contributions are welcome, as are 
comments, suggestions, examples, and bug reports.

The development of this package has been aided by support from the U.S. N.S.F 
(Grants #EF-0545276, #EF-0430120) and by the "Inference for Mechanistic 
Models" Working Group supported by the National Center for Ecological 
Analysis and Synthesis, a Center funded by NSF (Grant #DEB-0553768), the 
University of California, Santa Barbara, and the State of California.



-- 
Aaron A. King, Ph.D.
Ecology & Evolutionary Biology
University of Michigan
http://www.umich.edu/~kingaa
GPG Public Key: 0x2B00840F



From Peter.Ruckdeschel at uni-bayreuth.de  Mon Jul 30 13:35:15 2007
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Mon, 30 Jul 2007 13:35:15 +0200
Subject: [R-pkgs] New versions for the distr-family of packages and of
	package startupmsg
Message-ID: <46ADCCF3.4010207@uni-bayreuth.de>

We would like to announce the availability on CRAN (with possibly a minor delay until on
every mirror) of new versions of our packages in the "distrXXX"-family (version 1.9),
i.e.; "distr", "distrEx", "distrSim", "distrTEst", and "distrDoc"
      as well as of package for managing startup messages, "startupmsg" (0.5).
[all of them require R >= 2.2.0]
-----------------------------------------------------------------------------------------
********************************* Changes ***********************************************
of "distr" (1.9), "distrEx" (1.9), "distrSim" (1.9), "distrTEst" (1.9), "distrDoc" (1.9)
*****************************************************************************************
-----------------------------------------------------------------------------------------
There are major changes in "distr" and "distrEx" from this release on;
the more important ones can be inspected at

http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR

and the pages linked to on this page.

Special thanks go to Spencer Graves for spotting some errors in 1.8 (which
should be fixed by now) and to G.Jay Kerns for detecting some further bugs
and providing code for exact kurtosis and skewness functionals.

After package installation you may also have a look at NEWS("<pkg-name>") for each of the
packages mentioned in this mail.
-----------------------------------------------------------------------------------------
********************************* Changes ***********************************************
of "startupmsg" (0.5)
*****************************************************************************************
-----------------------------------------------------------------------------------------
This may be interesting to those annoyed by our "chatty" startup messages ;-)

-> From this version on, you may use suppressPackageStartupMessages() to suppress the
   startup-messages issued by our packages---

compare http://tolstoy.newcastle.edu.au/R/e2/devel/07/04/3039.html
-----------------------------------------------------------------------------------------
Short Descriptions
-----------------------------------------------------------------------------------------
************ "distr":
"distr" is to provide a conceptual treatment of random variables
(r.v.'s) by means of S4--classes. A virtual mother class "Distribution"
is introduced.
All distributions of the "stats" package are implemented as subclasses of
either "AbscontDistribution" or "DiscreteDistribution".

Using these classes, we also provide (default) methods to automatically
generate the image distributions under unary mathematical operations as
well as a general convolution algorithm.
-----------------------------------------------------------------------------------------
************ "distrSim":
Classes and methods are provided for a standardized treatment of
simulations (also under contaminations) .
-----------------------------------------------------------------------------------------
************ "distrTEst":
Classes and methods are provided for a standardized treatment of
the evaluation of statistical procedures (up to now only estimators)
at data/simulations
-----------------------------------------------------------------------------------------
************ "distrEx":
This package provides some extensions to package "distr" like:
* extreme value distribution classes,
* expectations
+in the form E(X) for the expectation of X where X is some
distribution or
+in the form E(X,f) for the expectation of f(X) where X is
some distribution and f some function in X,
* further functionals: var, sd, IQR, mad, median, kurtosis, skewness
* truncated moments
* distances between distributions
(Hellinger, Kolmogorov, total variation, "convex contamination")
* conditional distributions in factorized form
* conditional expectations in factorized form
-----------------------------------------------------------------------------------------
************ "distrDoc":
"distrDoc" provides a common vignette to the distrXXX family
-----------------------------------------------------------------------------------------
************ "startupmsg":
provides utilities for start-up messages for packages
-----------------------------------------------------------------------------------------

We look forward to receiving questions, comments and suggestions

Peter Ruckdeschel
Matthias Kohl
Thomas Stabla
Florian Camphausen



From ubk2101 at columbia.edu  Tue Jul 31 14:03:58 2007
From: ubk2101 at columbia.edu (Udaya B. Kogalur)
Date: Tue, 31 Jul 2007 08:03:58 -0400
Subject: [R-pkgs] randomSurvivalForest 3.0.0 now available
In-Reply-To: <38c08c270707291256l41912585qde16fc1c2d8385b1@mail.gmail.com>
References: <38c08c270707291256l41912585qde16fc1c2d8385b1@mail.gmail.com>
Message-ID: <38c08c270707310503t5ecdd95cwe7c54423248dbbb0@mail.gmail.com>

Dear useRs:

Release 3.0.0 of the randomSurvivalForest, an ensemble tree method for
the analysis of right censored survival data,  package is now
available.

---------------------------------------------------------------------------------
CHANGES TO RELEASE 3.0.0

Release 3.0.0 represents a major upgrade in the functionality of the
2.x releases.  Key changes are as follows:

o Missing data can be imputed in both grow and predict mode.  This
  applies to variables as well as time and censoring outcome values.
  Values are imputed dynamically as the tree is grown using a new tree
  imputation methodology.  This produces an imputed forest which can be
  used for prediction purposes on test data sets with missing data.

o Importance values for variables are returned in predict mode when test
  data contains outcomes as well as variables.

o Fixed some bugs in plot.variable().  Thanks to Andy J. Minn for
pointing this out.

o Minor modification of PMML representation of RSF forest output to accomodate
  imputation.  The method of random seed chain recovery has been altered.
  Note that forests produced with prior releases will have to be
  regenerated using this release.  We apologize for the inconvenience.

---------------------------------------------------------------------------------

Thanks.

ubk

ubk2101 at columbia.edu

Udaya B. Kogalur, Ph.D.
Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012



From ggrothendieck at gmail.com  Wed Aug  1 02:43:29 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 31 Jul 2007 20:43:29 -0400
Subject: [R-pkgs] New R package sqldf
Message-ID: <971536df0707311743y201acba8ocaff55d803dd5269@mail.gmail.com>

sqldf is an R package for running SQL select
statements on one or more R data frames. It is
optimized for convenience making it useful
for ad hoc queries against R data frames.

Given an SQL select statement whose tables
are the names of R data frames it:

- sets up the database (by default it transparently
  sets up an in memory SQLite database using RSQLite;
  however, MySQL via RMySQL, can be specified as an
  alternative.  MySQL has not been tested.)
- imports the data frames found in SQL select
  statement into the database
- runs the SQL select statement
- outputs the result back to a data frame
- uses a heuristic to assign the appropriate column
  classes to the result
- removes the database

so that all the user has to do is issue a one line
function call with one argument, the select
statement.

Here is an example which processes an SQL select
statement whose functionality is similar to the R
aggregate function.  Note that although the iris
dataset (which is built into R) uses the name
Sepal.Length the R database interface, DBI, converts
that to Sepal_Length.  Just install the sqldf package
from CRAN and type these two lines into R without
the > prompts:

> library(sqldf)
> sqldf("select Species, avg(Sepal_Length) from iris group by Species")

     Species avg(Sepal_Length)
1     setosa             5.006
2 versicolor             5.936
3  virginica             6.588

As can be seen from the example, there is:
- no database setup
- no importing and exporting into the database
- no coercing of the returned columns to the
  appropriate class (in most cases)

It can be used:
- as an alternate syntax for data frame manipulation
- learning SQL if you know R
- learning R if you know SQL

The sqldf package has a single function, sqldf.  More
information is available by issuing the command ?sqldf
from within R.  More examples and useful links are
available at the sqldf home page:

http://code.google.com/p/sqldf/



From felix at nfrac.org  Thu Aug  2 03:40:20 2007
From: felix at nfrac.org (Felix Andrews)
Date: Thu, 2 Aug 2007 11:40:20 +1000
Subject: [R-pkgs] new package plotAndPlayGTK
Message-ID: <94730b8a0708011840k36455658s35fe0056467d2245@mail.gmail.com>

Package plotAndPlayGTK provides a graphical user interface for R
plots. Wrap it around your plot commands, like playwith(plot(mydata)).
A window pops up with a Cairo plot device and a toolbar with buttons
to interact with the plot. The default buttons allow you to add
persistent labels to data points, zoom in and out and around, save the
plot to a file, and so on. Furthermore, you can edit the plot call on
the fly. There are buttons to work with multiple panels and pages of a
Lattice plot. For multi-variate scatterplots ('splom' only) there is a
"brush" function, and for 3D plots ('wireframe' / 'cloud' only) there
is a simple zoom and rotate.

New buttons can also be defined; actually any GTK+ widget can be added
to the toolbar. An example is given of a numeric input widget to
choose a number of clusters to show.

Note: code to generate the plot will need to be wrapped up into a
single call with some standard arguments, and the interaction features
do not work well with multiple-plot layouts in traditional graphics.
As yet it does not work with grid-based plots other than Lattice (such
as ggplot2), but button handlers could be written. This package is
based on RGtk2, and so requires the GTK+ libraries.

v0.8.42 is on CRAN.

http://code.google.com/p/plotandplay-gtk/

-- 
Felix Andrews / ???
PhD candidate
Integrated Catchment Assessment and Management Centre
The Fenner School of Environment and Society
The Australian National University (Building 48A), ACT 0200
Beijing Bag, Locked Bag 40, Kingston ACT 2604
http://www.neurofractal.org/felix/
xmpp:foolish.android at gmail.com
3358 543D AAC6 22C2 D336  80D9 360B 72DD 3E4C F5D8



From tlumley at u.washington.edu  Sat Aug  4 22:12:35 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 4 Aug 2007 13:12:35 -0700 (PDT)
Subject: [R-pkgs] surveyNG (and survey)
Message-ID: <Pine.LNX.4.43.0708041312350.21274@hymn09.u.washington.edu>


'surveyNG' version 0.3 is on CRAN.

 This package provides experimental features for survey analysis that may be incorporated in the survey package in the future. Currently there are facilities for analysis of complex surveys using (possibly large) data sets stored in a SQLite database. However, analysis facilities for these SQL-backed survey designs are rather more limited than in the 'survey' package.

Version 0.3 adds hexagonal binning plots and kernel smoothing.


Also, the 'survey' package hasn't been announced on this list since version 2.9 in 2005 and verison 3.6-11 was recently posted.  It provides fairly comprehensive facilities for analysis of complex survey designs.  Major additions since 2.9 are calibration estimators (aka GREG or generalized raking), simple two-phase designs, and smoothing.


     -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From h.wickham at gmail.com  Tue Aug 14 21:05:26 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 14 Aug 2007 14:05:26 -0500
Subject: [R-pkgs] 'fda' 1.2.2 is now available on CRAN.
Message-ID: <f8e6ff050708141205k6bc36e6cm49a9bb5ac3e5cb2e@mail.gmail.com>

The fda package supports "Functional Data Analysis" and "Applied
Functional Data Analysis" by Bernard Silverman and James Ramsay.
Functional data analysis, which lots of us like to call "FDA", is
about the analysis of information on curves or functions. FDA is a
collection statistical techniques for answering questions like, "What
are the main ways in which the curves vary from one to another?" In
fact, most of the questions and problems associated with multivariate
data (PCA, LDA, clustering, ...) have functional counterparts. More
information about FDA can be found at
http://www.psych.mcgill.ca/misc/fda/.

This version (and the previous 1.2.1) includes bug fixes plus a
"scripts" subdirectory with R code to reproduce some of the analyses
in the two functional data analysis books by Ramsay and Silverman and
a "Continuously Stirred Tank Reactor (CSTR)" simulation discussed in a
Ramsay, et al., discussion paper to appear soon in the Journal of the
Royal Statistical Society-series B.

It also includes the draft of a presentation on "fda in Matlab & R"
(in PowerPoint and Adobe Acrobat PDF formats) for the UseR! 2007
conference this Friday, Aug. 10, 1:55 - 2:20 PM in Ames, IA.

Regards

Hadley Wickham
James Ramsey
Spencer Graves



From jeff.horner at vanderbilt.edu  Wed Aug 22 01:02:31 2007
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Tue, 21 Aug 2007 18:02:31 -0500
Subject: [R-pkgs] brew 1.0-1
Message-ID: <46CB6F07.7050104@vanderbilt.edu>

brew implements a templating framework for mixing text and R code for 
report generation. brew template syntax is similar to PHP, Ruby's erb 
module, Java Server Pages, and Python's psp module.

brew is written in R with no package dependencies, and it's not just for 
the web. It can be used as an alternative to Sweave in a limited 
context. See the brew-test-1.brew file in the distribution for some 
salient differences between the two. brew can also complement Sweave 
since it can be written to do conditional inclusion of or loop over 
Sweave code chunks.

The 1.0-1 version should show up on the CRAN mirrors shortly, but in the 
mean time it can be got from:

http://www.rforge.net/brew/

Best,

Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner



From luke at stat.uiowa.edu  Mon Aug 27 14:30:33 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 27 Aug 2007 07:30:33 -0500 (CDT)
Subject: [R-pkgs] proftools package now available from CRAN
Message-ID: <Pine.LNX.4.64.0708270729320.2888@nokomis.stat.uiowa.edu>

 		PROFILE OUTPUT PROCESSING TOOLS FOR R
                 =====================================


This package provides some simple tools for examining Rprof output
and, in particular, extracting and viewing call graph information.
Call graph information, including which direct calls where observed
and how much time was spent in these calls, can be very useful in
identifying performance bottlenecks.

One important caution: because of lazy evaluation a nested call
f(g(x)) will appear on the profile call stack as if g had been called
by f or one of f's callees, because it is the point at which the value
of g(x) is first needed that triggers the evaluation.


EXPORTED FUNCTIONS

The package exports five functions:

     readProfileData reads the data in the file produced by Rprof into a
         data structure used by the other functions in the package.
         The format of the data structure is subject to change.

     flatProfile is similar to summaryRprof.  It returns either a
         matrix with output analogous to gprof's flat profile or a
         matrix like the by.total component returned by summaryRprof;
         which is returned depends on the value of an optional second
         argument.

     printProfileCallGraph produces a printed representation of the
         call graph.  It is analogous to the call graph produced by
         gprof with a few minor changes.  Reading the gprof manual
         section on the call graph should help understanding this
         output.  The output is similar enough to gprof output for the
         cgprof (http://mvertes.free.fr/) script to be able to produce
         a call graph via Graphviz.

     profileCallGraph2Dot prints out a Graphviz .dot file representing
         the profile graph.  Times spent in calls can be mapped to node
         and edge colors.  The resulting files can then be viewed with
         the Graphviz command line tools.

     plotProfileCallGraph uses the graph and Rgraphviz packages to
         produce call graph visualizations within R.  You will need to
         install these packages to use this function.


A SIMPLE EXAMPLE

Collect profile information  for the examples for glm:

           Rprof("glm.out")
           example(glm)
           Rprof()
           pd <- readProfileData("glm.out")

Obtain flat profile information:

           flatProfile(pd)
           flatProfile(pd, FALSE)

Obtain a printed call graph on the standard output:

           printProfileCallGraph(pd)

If you have the cgprof script and the Graphviz command line tools
available on a UNIX-like system, then you can save the printed graph
to a file,

           printProfileCallGraph(pd, "glm.graph")

and either use

           cgprof -TX glm.graph

to display the graph in the interactive graph viewer dotty, or use

           cgprof -Tps glm.graph > glm.ps
           gv glm.ps

to create a PostScript version of the call graph and display it with
gv.

Instead of using the printed graph and cgprof you can use create a
Graphviz .dot file representation of the call graph with

           profileCallGraph2Dot(pd, filename = "glm.dot", score = "total")

and view the graph interactively with dotty using

           dotty glm.dot

or as a postscript file with

           dot -Tps glm.dot > glm.ps
           gv glm.ps

Finally, if you have the graph package from CRAN and the Rgraphviz
package from Bioconductor installed, then you can view the call graph
within R using

           plotProfileCallGraph(pd, score = "total")

The default settings for this version need some work.]


OPEN ISSUES

My intention was to handle cycles roughly the same way that gprof
does.  I am not completely sure that I have managed to do this; I am
also not completely sure this is the best approach.

The graphs produced by cgprof and by plotProfileGraph and friends when
mergeEdges is false differ a bit.  I think this is due to the
heuristics of cgprof not handling cycle entries ideally and that the
plotProfileGraph graphs are actually closer to what is wanted.  When
mergeEdges is true the resulting graphs are DAGs, which simplifies
interpretation, but at the cost of lumping all cycle members together.

gprof provides options for pruning graph printouts by omitting
specified nodes.  It may be useful to allow this here as well.

Probably more use should be made of the graph package.


IMPLEMENTATION NOTES

The implementation is extremely crude (a real mess would be more
accurate) and will hopefully be improved over time--at this point it
is more of an existence proof than a final product.

Performance is less than ideal, though using these tools it was
possible to identify some problem points and speed up computing the
profile data by a factor of two (in other words, it may be bad now but
it used to be worse).  More careful design of the data structures and
memoizing calculations that are now repeated is likely to improve
performance substantially.




-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From h.wickham at gmail.com  Sun Sep  2 18:53:46 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 2 Sep 2007 11:53:46 -0500
Subject: [R-pkgs] ggplot2 - version 0.5.5
Message-ID: <f8e6ff050709020953r248fd0d5l8edcee4466d23acf@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the over 500
examples of ggplot in use.


Changes in version 0.5.5
----------------------------------------

Improvements:
	* ggplot now gives rather more helpful errors if you have
misspecified a variable name in the aesthetic mapping
	* changed default hline and vline intercepts to 0
	* added "count" output variable from stat_density for creating
stacked/conditional density plots
	* added parameters to geom_boxplot to control appearance of outlying points
	* overriding aesthetics with fixed values that have already been set
with aesthetics now actually works
	* slightly better names for xaxis and yaxis grobs
	* added aes_string function to make it easier to construction
aesthetic mapping specifications in functions
	* continuous scales now have labels argument so that you can manually
specify labels if desired
	* stat_density now calculates densities on a common grid across
groups.  This means that position_fill and position_stack now work
properly
	* if numeric, legend labels right aligned
	* polar coordinates much improved, and with better examples

Documentation:
	* fixed argument documentation for qplot
	* added (very) rudimentary documentation about what functions return
	* documentation now lists extra variables created by statistics

Bug fixes:
	* coord_flip now works with segment and all interval geoms
	* geom_errorbar now works in all coordinate systems
	* derived y axes (eg. on histogram) are now labelled correctly
	* fixed bug in stat_quantile caused by new output format from predict.rq
	* fixed bug if x or y are constant
	* fixed bug in histogram where sometimes lowest bar was omitted
	* fixed bug in stat_qq which prevent setting aesthetics
	* fixed bug in qplot(..., geom="density", position="identity")
	* fixed stat_qq so that unnecessary arguments are no longer passed to
the distribution function

Subtractions:
	* removed grid argument from ggsave, replaced by ggtheme(theme_bw)
	* removed add argument from qplot


Regards,

Hadley

-- 
http://had.co.nz/



From calenge at biomserv.univ-lyon1.fr  Mon Sep  3 09:31:47 2007
From: calenge at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Mon, 03 Sep 2007 09:31:47 +0200
Subject: [R-pkgs] adehabitat version 1.7
Message-ID: <46DBB863.3000300@biomserv.univ-lyon1.fr>

Dear all,

I have uploaded to CRAN the version 1.7 of the package 'adehabitat'. 
Significant changes are listed below:

* The Brownian bridge kernel estimation algorithm has been greatly 
improved. It now takes more than 80% less time than the previous 
version. A new function "liker" has also been added, which estimates the 
one of the two smoothing parameters of the bridge kernel using a maximum 
likelihood approach (recommended in Horn et al., Ecology, in press). 
Examples of the help page demonstrate the use and interest of this 
function. Comparison between kernelbb and the Visual basic algorithm 
provided in the paper of Horn et al. returned consistent results.

* The function kernelUD has also been improved. It now takes more than 
50% less time than the previous version. In addition the "grid" argument 
of this function, now also allows a list of objects of class "asc" to be 
passed as grid where the UD should be estimated.

Happy testing,

Cl?ment Calenge.

-- 
Cl?ment CALENGE
LBBE - UMR CNRS 5558 - Universit? Claude Bernard Lyon 1 - FRANCE
tel. (+33) 04.72.43.27.57
fax. (+33) 04.72.43.13.88



From weeksjp at gmail.com  Wed Sep  5 18:15:11 2007
From: weeksjp at gmail.com (Jonathan Weeks)
Date: Wed, 5 Sep 2007 10:15:11 -0600
Subject: [R-pkgs] New R package plink for separate calibration IRT linking
Message-ID: <8a7634360709050915s3c13221at4a82775b9e208098@mail.gmail.com>

The first version of the package plink has been uploaded to CRAN.

plink is a package for conducting unidimensional IRT scaling and chain
linking for multiple groups for single-format or mixed-format common
items. The package supports eight IRT models and four calibration
methods.

Dichotomous Models:
1PL, 2PL, 3PL

Polytomous Models:
-Graded response model
-Partial credit model
-Generalized partial credit model
-Nominal response model
-Multiple-choice model

Calibration Methods:
-Mean/Mean
-Mean/Sigma
-Haebara
-Stocking-Lord

Any combination of dichotomous and polytomous items can be supplied
with intermingled unique and common items for as many items and groups
as system memory allows. Linking constants are computed and returned
for all the calibration methods, and (if desired) ability and/or item
parameters can be rescaled and returned using any of the estimated
linking constants.

Any of the included groups can be specified as the base scale, the
characteristic curve methods can use symmetric or non-symmetric
optimization, various scoring functions can be supplied for the
Stocking-Lord method, and there is great flexibility in specifying
thetas and theta weights to be integrated over in the characteristic
curve methods.

In addition to computing linking constants and rescaling ability and
item parameters, the methods in the package can be used to compute
item/category response probabilities and create plots of item/category
characteristic curves.

The package is designed to allow for a variety of formats for the item
parameters including vectors, lists, matrices, and other objects
(irt.pars and sep.pars) available in the package. Item parameters and
calibration output can be summarized, and descriptive statistics for
the item parameters can be displayed as well.

Getting Started:
Running the separate calibration is typically a two-step process. The
first step is to format the item parameters for processing with the
function 'plink'. Parameters should be formatted as either an object
of class 'irt.pars' with multiple groups, a set of 'irt.pars' objects,
or a set of 'sep.pars' objects.  Once in this format, response
probabilities can be computed using the functions 'drm', 'gpcm',
'grm', 'mcm', or 'nrm' or linking constants can be computed using
'plink'.

The functions 'as.irt.pars', 'sep.pars', and 'combine.pars' can be
used to create the 'irt.pars' and 'sep.pars' objects. 'summary' can be
used to summarize item parameters (including descriptive statistics)
and linking constants, and 'plot' can be used to create item/category
characteristic curves.

I am currently working on a vignette; however, the documentation
contains extensive examples. The best documentation to start with is
help(as.irt.pars) and help(plink).

Although this is the first version of this package, I have gone
through extensive debugging and validation, so there should be few, if
any bugs. Many of the examples (and the associated output) can be
found in published articles or books, and the output from the various
calibration methods has been checked against other available linking
software.

I hope this will be a useful package for those interested in test
linking. I invite any comments and suggestions.

Take care

-- 
Jonathan Weeks
Doctoral Candidate
School of Education
University of Colorado, Boulder
weeksjp at gmail.com
303-517-9666



From dusa.adrian at gmail.com  Mon Sep 10 01:21:24 2007
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Mon, 10 Sep 2007 02:21:24 +0300
Subject: [R-pkgs] QCA version 0.4-5
Message-ID: <200709100221.24440.dusa.adrian@gmail.com>


QCA implements the Qualitative Comparative Analysis using a boolean 
minimization algorithm for data coded with presence/absence of the causal 
conditions that affects a phenomenon of interest.

This new release has an experimental function that obtains the same exact 
solutions as the main minimization function, using a shortcut instead of the 
classical complete and exhaustive algorithm. This new function is faster and 
uses significantly less memory (50 MB compared to 1.5 GB for large datasets).

It should appear soon on CRAN, feedback is welcome.


-- 
Adrian Dusa
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101



From tplate at acm.org  Mon Sep 10 23:16:28 2007
From: tplate at acm.org (Tony Plate)
Date: Mon, 10 Sep 2007 15:16:28 -0600
Subject: [R-pkgs] new package 'trackObjs' - mirror objects to files,
 provide summaries & modification times
Message-ID: <46E5B42C.4040805@acm.org>

 From ?trackObjs:

Overview of trackObjs package

Description:

      The trackObjs package sets up a link between R objects in memory
      and files on disk so that objects are automatically resaved to
      files when they are changed.  R objects in files are read in on
      demand and do not consume memory prior to being referenced.  The
      trackObjs package also tracks times when objects are created and
      modified, and caches some basic characteristics of objects to
      allow for fast summaries of objects.

      Each object is stored in a separate RData file using the standard
      format as used by 'save()', so that objects can be manually picked
      out of or added to the trackObjs database if needed.

      Tracking works by replacing a tracked variable by an
      'activeBinding', which when accessed looks up information in an
      associated 'tracking environment' and reads or writes the
      corresponding RData file and/or gets or assigns the variable in
      the tracking environment.

Details:

      There are three main reasons to use the 'trackObjs' package:

         *  conveniently handle many moderately-large objects that would
            collectively exhaust memory or be inconvenient to manage in
            files by manually using 'save()' and 'load()'

         *  keep track of creation and modification times on objects

         *  get fast summaries of basic characteristics of objects -
            class, size, dimension, etc.

      There is an option to control whether tracked objects are cached
      in memory as well as being stored on disk.  By default, objects
      are not cached.  To save time when working with collections of
      objects that will all fit in memory, turn on caching with
      'track.options(cache=TRUE)', or start tracking with
      'track.start(..., cache=TRUE)'.

      Here is a brief example of tracking some variables in the global
      environment:


      > library(trackObjs)
      > track.start("tmp1")
      > x <- 123                  # Not yet tracked
      > track(x)                  # Variable 'x' is now tracked
      > track(y <- matrix(1:6, ncol=2)) # 'y' is assigned & tracked
      > z1 <- list("a", "b", "c")
      > z2 <- Sys.time()
      > track(list=c("z1", "z2")) # Track a bunch of variables
      > track.summary(size=F)     # See a summary of tracked vars
                  class    mode extent length            modified TA TW
      x         numeric numeric    [1]      1 2007-09-07 08:50:58  0  1
      y          matrix numeric  [3x2]      6 2007-09-07 08:50:58  0  1
      z1           list    list  [[3]]      3 2007-09-07 08:50:58  0  1
      z2 POSIXt,POSIXct numeric    [1]      1 2007-09-07 08:50:58  0  1
      > # (TA="total accesses", TW="total writes")
      > ls(all=TRUE)
      [1] "x"  "y"  "z1" "z2"
      > track.stop()              # Stop tracking
      > ls(all=TRUE)
      character(0)
      >
      > # Restart using the tracking dir -- the variables reappear
      > track.start("tmp1") # Start using the tracking dir again
     > ls(all=TRUE)
      [1] "x"  "y"  "z1" "z2"
      > track.summary(size=F)
                  class    mode extent length            modified TA TW
      x         numeric numeric    [1]      1 2007-09-07 08:50:58  0  1
      y          matrix numeric  [3x2]      6 2007-09-07 08:50:58  0  1
      z1           list    list  [[3]]      3 2007-09-07 08:50:58  0  1
      z2 POSIXt,POSIXct numeric    [1]      1 2007-09-07 08:50:58  0  1
      > track.stop()
      >
      > # the files in the tracking directory:
      > list.files("tmp1", all=TRUE)
      [1] "."                    ".."
      [3] "filemap.txt"          ".trackingSummary.rda"
      [5] "x.rda"                "y.rda"
      [7] "z1.rda"               "z2.rda"
      >

      There are several points to note:

         *  The global environment is the default environment for
            tracking - it is possible to track variables in other
            environments, but that environment must be supplied as an
            argument to the track functions.

         *  Vars must be explicitly 'track()'ed - newly created objects
            are not tracked.  (This is not a "feature", but there is
            currently no way of automatically tracking newly created
            objects - this is on the wishlist.)  Thus, it is possible
            for variables in a tracked environment to either tracked or
            untracked.

         *  When tracking is stopped, all tracked variables are saved on
            disk and will be no longer accessible until tracking is
            started again.

         *  The objects are stored each in their own file in the
            tracking dir, in the format used by 'save()'/'load()' (RData
            files).

List of basic functions and common calling patterns:

      Six functions cover the majority of common usage of the trackObjs
      package:

         *  'track.start(dir=...)': start tracking the global
            environment, with files saved in 'dir'

         *  'track.stop()': stop tracking (any unsaved tracked variables
            are saved to disk and all tracked variables become
            unavailable until tracking starts again)

         *  'track(x)': start tracking 'x' - 'x' in the global
            environment is replaced by an active binding and 'x' is
            saved in its corresponding file in the tracking directory
            and, if caching is on, in the tracking environment

         *  'track(x <- value)': start tracking 'x'

         *  'track(list=c('x', 'y'))': start tracking specified
            variables

         *  'track(all=TRUE)': start tracking all untracked variables in
            the global environment

         *  'untrack(x)': stop tracking variable 'x' - the R object 'x'
            is put back as an ordinary object in the global environment

         *  'untrack(all=TRUE)': stop tracking all variables in the
            global environment (but tracking is still set up)

         *  'untrack(list=...)': stop tracking specified variables

         *  'track.summary()': print a summary of the basic
            characteristics of tracked variables: name, class, extent,
            and creation, modification and access times.

         *  'track.remove(x)': completely remove all traces of 'x' from
            the global environment, tracking environment and tracking
            directory.   Note that if variable 'x' in the global
            environment is tracked, 'remove(x)' will make 'x' an
            "orphaned" variable: 'remove(x)' will just remove the active
            binding from the global environment, and leave 'x' in the
            tracked environment and on file, and 'x' will reappear after
            restarting tracking.

Complete list of functions and common calling patterns:

      The 'trackObjs' package provides many additional functions for
      controlling how tracking is performed (e.g., whether or not
      tracked variables are cached in memory), examining the state of
      tracking (show which variables are tracked, untracked, orphaned,
      masked, etc.) and repairing tracking environments and databases
      that have become inconsistent or incomplete (this may result from
      resource limitiations, e.g., being unable to write a save file due
      to lack of disk space, or from manual tinkering, e.g., dropping a
      new save file into a tracking directory.)

[truncated here -- see ?trackObjs]

-- Tony Plate

PS: to give credit where due, the end of ?trackObjs says:

References:
      Roger D. Peng. Interacting with data using the filehash package. R
      News, 6(4):19-24, October 2006.
      'http://cran.r-project.org/doc/Rnews' and
      'http://sandybox.typepad.com/software'

      David E. Brahm. Delayed data packages. R News, 2(3):11-12,
      December 2002.  'http://cran.r-project.org/doc/Rnews'

See Also:
      [...]
      Inspriation from the packages 'g.data' and 'filehash'.



From adrian at maths.uwa.edu.au  Tue Sep 11 05:05:34 2007
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Tue, 11 Sep 2007 11:05:34 +0800 (WST)
Subject: [R-pkgs] scuba 1.1-8
Message-ID: <60074.124.182.61.237.1189479934.squirrel@124.182.61.237>

Version 1.1-8 of package 'scuba' has been uploaded to CRAN.

'scuba' is a package for scuba diving calculations and decompression
models. It supports dive profiles (tables, plotting etc), analysis of dive
profiles using decompression models, gas toxicity calculations, and gas
usage calculations.

New features in version 1.1-8:
     . support for dive profiles uploaded from a dive computer
     . new dataset: dive profile from a wreck dive on nitrox
     . bug fix in oxygen toxicity calculations

Adrian Baddeley



From mfay at niaid.nih.gov  Wed Sep 12 21:26:09 2007
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 12 Sep 2007 15:26:09 -0400
Subject: [R-pkgs] New package: hbim - Hill/Bliss Independence Model for
	Multicomponent Vaccines
Message-ID: <31DDB7BE4BF41D4888D41709C476B657062E780D@NIHCESMLBX5.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-packages/attachments/20070912/1a5d93f5/attachment-0001.pl>

From adrian at stats.gla.ac.uk  Thu Sep 27 11:40:39 2007
From: adrian at stats.gla.ac.uk (Adrian Bowman)
Date: Thu, 27 Sep 2007 10:40:39 +0100
Subject: [R-pkgs] New version (2.2) of the sm package
Message-ID: <1EA97626-87BD-4ED0-BD9B-25C350AE0CAB@stats.gla.ac.uk>

The sm package (by Adrian Bowman and Adelchi Azzalini) implements a
variety of nonparametric smoothing techniques, centred on nonparametric
regression for one or two covariates and density estimation for up to
three variables.  A new version of the package is now available on CRAN.

In an earlier unannounced version (2.1), a variety of methods of  
bandwidth
selection were added, with default settings to allow particularly simple
function calls.

In the new version (2.2), interactive control panels are available for
the main functions (sm.regression and sm.density), using the rpanel  
package
(which itself is based on tcltk).  In addition, the rgl package is used
to provide rotatable three-dimensional plots, where these are  
appropriate.
The details of how these functions operate are available in the help  
files
(including the help file for sm.options) and in the examples.  However,
the broad principle is that a control panel is activated by adding the
argument
       panel = TRUE
and an rgl plot is created by adding the argument
       display = "rgl"

Adrian Bowman



From antoinelucas at gmail.com  Thu Oct  4 19:00:09 2007
From: antoinelucas at gmail.com (Antoine)
Date: Thu, 4 Oct 2007 19:00:09 +0200
Subject: [R-pkgs] Amap new release
Message-ID: <20071004190009.1d47f726@antoine.domainelocal.fr>



A new major version of Amap package is available on CRAN.

For this major release, all clustering code has been rewritten in C++.

Amap implements several tools in the field of clustering and robust statistics.

New features are:
   * clustering possible in float precision (less memory needs)
   * new rank-based metric: Kendall distance, use for both matrix distance computation, K-means, and hierachical clustering.


Best.

	Antoine.



From pineda at zoology.ubc.ca  Thu Oct  4 22:34:24 2007
From: pineda at zoology.ubc.ca (Mario Pineda-Krch)
Date: Thu, 04 Oct 2007 13:34:24 -0700
Subject: [R-pkgs] New version of GillespieSSA package uploaded to CRAN
Message-ID: <47054E50.4030300@zoology.ubc.ca>

Dear useRs,

A new version of the package GillespieSSA (0.3-1) has been uploaded to 
CRAN.

The GillespieSSA package (Gillespie's Stochastic Simulation Algorithm) 
provides a simple to use, versatile, and extensible interface to a 
number of Monte Carlo implementations of the stochastic simulation 
algorithm (SSA) and is intended for scientists, teachers, and students 
alike.

The SSA is a numerical procedure for generating statistically correct 
trajectories of finite well-mixed populations in continuous time. The 
methods currently implemented are: the Direct method, Explicit 
tau-leaping, Binomial tau-leaping, and Optimized tau-leaping. The 
package also provides a library of molecular, ecological and 
epidemiological example models (as demos) that can easily be customized 
and extended. Currently the following models are included, 
Decaying-Dimerization Reaction Set, Linear Molecular Chain System, 
single-species logistic growth model, Lotka predator-prey model, 
Rosenzweig-MacArthur predator-prey model, and Kermack-McKendrick SIR model.

The release consists of several bug fixes, improved documentation, and a 
revised more 'R-like' management of model parameters.

A vignette providing a tutorial of basic SSA theory, usage of the 
package using additional example models is currently being finalized. 
Although it is not part of this release a preprint is available upon 
request.

Comments are welcome,
Mario Pineda-Krch

-----------------------------------------------------------
Mario Pineda-Krch, Post Doctoral Fellow

Center for Animal Disease Modeling and Surveillance (CADMS)
University Of California, Davis, CA 95616, U.S.A.

Phone: (530) 297-4621
Fax:   (530) 297-4618
Email: pineda at zoology.ubc.ca
URL :  http://pineda-krch.com



From Max.Kuhn at pfizer.com  Fri Oct  5 20:33:37 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Fri, 5 Oct 2007 14:33:37 -0400
Subject: [R-pkgs] new packages: caret, caretLSF and caretNWS
Message-ID: <71257D09F114DA4A8E134DEAC70F25D309B8C303@groamrexm03.amer.pfizer.com>

Three more packages will be showing up on your mirror soon.

The caret package (short for "Classification And REgression Training")
aims to simplify the model building process. The package has functions
for

  - data splitting: balanced train/test splits, cross-validation and
bootstrapping sampling functions. There is also a function for maximum
dissimilarity sampling.

  - pre-processing: simple centering/scaling, filter methods for highly
correlated predictors, identification of linear combinations, removal of
"near zero variance" predictors and the "spatial-sign" transformation
function for predictors.

  - model building: the train function provides a common interface to 27
model types. Models can be tuned over complexity parameters using
resampling methods. A few functions also exist for plotting the results
from the tuning process.

  - bagged versions of mars (via the earth package) and fda models.

  - partial least squares classification model (based on the pls
package).

  - yet another knn function (this one returns the vote proportions for
all the classes) based on the functions in MASS and ipred.

  - a variable importance class and methods for a variety of models
(e.g. trees, pls, mars, etc) in addition to model-free methods.

  - RMA-type normalization methods for oligo arrays that can be used on
a per sample basis. These functions are well suited for normalizing
chips individually using information from the training set samples.

Three vignettes come with the package and include several examples. A
few example data sets, mostly from quantitative structure-activity
relationship (QSAR) experiments, are also contained in the package.

The other two packages, caretLSF and caretNWS, provide alternate
versions of caret's train function that can be executed in parallel
using the Rlsf and nws packages, respectively. For example, if
bootstrapping is used to tune a model, the B models can be split over M
different nodes. For caretNWS, either the free nws package or the
commercial version (nwsPro) can be used. The commercial version offers
fault tolerance features (as well as support). Email
info at revolution-computing.com instead of me for more information about
nwsPro or nws.

Thanks to Steve Weston, Jed Wing and Andre Williams who contributed to
these packages.

Please send me emails at max dot kuhn at pfizer dot com for questions,
suggestions or bugs. 

Max



From nkraemer at cs.tu-berlin.de  Tue Oct  9 15:55:01 2007
From: nkraemer at cs.tu-berlin.de (=?ISO-8859-15?Q?Nicole_Kr=E4mer?=)
Date: Tue, 09 Oct 2007 15:55:01 +0200
Subject: [R-pkgs] new package ppls
Message-ID: <470B8835.1010204@cs.tu-berlin.de>

A new package ppls is now available on CRAN.

The ppls package implements penalized Partial Leasts Squares (PLS). In a 
nutshell, supervised dimensionality reduction via PLS is combined with 
penalization techniques. Features of the package include


* estimation of linear regression models with penalized PLS,
* estimation of generalized additive models with penalized PLS based on 
splines transformations,
* model selection for both methods based on cross validation.


For more information on penalized PLS, see

http://ml.cs.tu-berlin.de/~nkraemer/papers/preprint_penalizedPLS.pdf

Please send an email to nkraemer at cs dot tu-berlin dot de for any 
comments, suggestions, or reports on bugs.

Regards,

Nicole & Anne-Laure


-- 
Dr. Nicole Kr?mer
TU Berlin
Machine Learning/Intelligent Data Analysis	fon: (+49) 30 314 78627
Franklinstr. 28/29, 10587 Berlin, Germany	fax: (+49) 30 314 78622

web: http://ml.cs.tu-berlin.de/~nkraemer



From kate at few.vu.nl  Mon Oct 15 13:41:44 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Mon, 15 Oct 2007 13:41:44 +0200 (CEST)
Subject: [R-pkgs] new package 'nnls'
Message-ID: <Pine.GSO.4.56.0710151339320.9860@laurel.few.vu.nl>

A new package 'nnls' is now available on CRAN.

The package provides an R interface to the Lawson-Hanson NNLS algorithm
for non-negative least squares that solves the least squares problem A x =
b with the constraint x >= 0.

The Lawson-Hanson NNLS algorithm was published in

Lawson CL, Hanson RJ (1974). Solving Least Squares Problems. Prentice
Hall, Englewood Cliffs, NJ.

Lawson CL, Hanson RJ (1995). Solving Least Squares Problems. Classics in
Applied Mathematics. SIAM, Philadelphia.

and is available as Fortran77 code on Netlib (file lawson-hanson/all). The
'nnls' package interfaces to this code.

Included in the examples section of the function 'nnls' is a test problem
comparing NNLS to the L-BFGS-B method of 'optim' and to the 'solve.QP'
function of the package 'quadprog'.  NNLS is shown to be faster and
slightly more accurate than these more general purpose algorithms for the
test problem examined.

I do not have access to S-PLUS or the S-PLUS source, but the help page for
the S-SPLUS function 'nnls.fit' references Lawson and Hanson (1974), and
is probably close to the port here.  I have not written any methods for
printing or summaries, and only return the solution x. On request, I can
modify this behavior.

I would be interested in suggestions, bug reports, and other comments.

Kate Mullen

----
Katharine Mullen
mail: Department of Physics and Astronomy, Faculty of Sciences
Vrije Universiteit Amsterdam, de Boelelaan 1081
1081 HV Amsterdam, The Netherlands
room: T.1.06
tel: +31 205987870
fax: +31 205987992
e-mail: kate at nat.vu.nl
homepage: http://www.nat.vu.nl/~kate/



From david.meyer at wu-wien.ac.at  Tue Oct 16 13:16:12 2007
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Tue, 16 Oct 2007 13:16:12 +0200
Subject: [R-pkgs] New package: sets
Message-ID: <47149D7C.2070908@wu-wien.ac.at>

Dear useRs,

The new 'sets' package made it to CRAN, supporting:

o data structures for sets, fuzzy sets, multisets, and fuzzy multisets
o the use of (most) R objects as elements
o standard set operations (union, intersection, complement, Cartesian 
product, power set, ...)
o support for several fuzzy logic systems

An introductory vignette is also available.

David and Kurt.



From deleeuw at stat.ucla.edu  Thu Oct 18 03:19:29 2007
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Wed, 17 Oct 2007 18:19:29 -0700
Subject: [R-pkgs] homals-0.9.0
Message-ID: <8A098B38-DA56-40F8-91D2-D8FE34C955BC@stat.ucla.edu>

homals-0.9.0 is on CRAN -- by Jan de Leeuw and Patrick Mair

This package implements the methods discussed in Gifi, Nonlinear  
Multivariate
Analysis, Wiley, 1990. In the Gifi terminology it covers homals,  
princals,
canals, morals, criminals, and overals. The R implementation fills  
several
gaps in Gifi, adding multiple ordinal, numerical, and polynomial data
transformations. Differences with previous CRAN version:

a. More R-like with S3 classes, namespace, print, plot, plot3d,  
summary, predict methods

b. (Much) better documented functions and data sets

c. Dynamic three-d plot using rgl

d. Static three-d plot using scatterplot3d

e. Predict method that counts "correct" classifications

f. Many bugs fixed

A paper describing the technique and implementation, with many examples,
is almost ready. There is a preprint at http://gifi.stat.ucla.edu/homalsR.pdf
Intermediate updates by svn from http://r-forge.r-project.org/projects/psychor/

==========================================================
Jan de Leeuw, 11667 Steinhoff Rd, Frazier Park, CA 93225
home 661-245-1725 skype 661-347-0667 global 254-381-4905
.mac: jdeleeuw +++  aim: deleeuwjan +++ skype: j_deleeuw
==========================================================
                 Many nights on the road
        and not dead yet ---
                the end of autumn.       (Basho 1644-1694)



From david.meyer at wu-wien.ac.at  Thu Oct 18 11:44:47 2007
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Thu, 18 Oct 2007 11:44:47 +0200
Subject: [R-pkgs] upgrade: relations
Message-ID: <47172B0F.7090804@wu-wien.ac.at>

Dear useRs,


a new version of the 'relations' package has appeared on CRAN. New 
features include:

   o support for fuzzy relations added

   o support for sets moved to separate 'sets' package

   o new SD fitters for the S ("symmetric") and M ("matches") families

   o fitters for Cook-Seiford method and Euclidean consensus added

   o fitters can now use a sparse constraint matrix representation

   o relations are now subsettable

   o relation_choice() for choosing "winner" objects based on an ensemble
     of relations between these

   o new summary method for relations which computes all implemented
     predicates

Best,

David and Kurt.



From h.wickham at gmail.com  Mon Oct 22 00:07:01 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 21 Oct 2007 17:07:01 -0500
Subject: [R-pkgs] ggplot2 - version 0.5.6
Message-ID: <f8e6ff050710211507p40df755dtced3fa3158cebc8b@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the over 500
examples of ggplot in use.

Changes in version 0.5.6
----------------------------------------

Improved error messages and other notifications:
  * all geoms and position adjustments should now give an informative
error message when required aesthetics are missing
  * better error messages if data not a data frame, or mapping not
created by aes or aes_string
  * better errors for qplot when variables missing or data invalid
  * better error if somehow you are missing necessary scales
  * stat_bin informs you of the default choice of binwidth
  * stat_smooth gives helpful error messages for common problems
  * printing a geom now displays the data set that it uses (if not the default)

Other improvements:
  * colour and fill legends now surround by background plot colour
  * can now draw arrow heads with geom_segment, and have added an
example demonstrating drawing a vector field
  * density plots should always include 0 on y axis
  * default boxplot outlier changed colour to black
  * stat_smooth supports categorical variables a little better
  * implemented hash methods for all ggplot objects.  This is the
first step in making it easier for me to compare all examples between
versions for quality control purposes

New data:
  * seals, contributed by David Brillinger and Charlotte Wickham, used
for vector field example

Bug fixes:
  * geoms hline, vline and abline now all work correctly when a
grouping variable is used
  * block histograms (where individuals are identifiable) now work correctly
  * all ggplot objects should now print properly from the command line
  * fixed bug in geom_path when only 1 point
  * segments geom now works correctly for more coordinate systems
  * order variables in scatterplot matrix by order of variables in data.frame
  * geom_density deals with missing values correctly when displaying
scaled densities
  * fixed bug in calculating categorical ranges
  * fixed bug in drawing error bars

Subtractions
  * now relies on R 2.6
  * removed grid.gedit and grid.gremove, and code replaced by grid.ls


-- 
http://had.co.nz/



From pls at mevik.net  Fri Oct 26 13:28:05 2007
From: pls at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik_and_Ron_Wehrens?=)
Date: Fri, 26 Oct 2007 13:28:05 +0200
Subject: [R-pkgs] pls version 2.1-0
Message-ID: <m0tzoe2jzu.fsf@bar.nemo-project.org>


Version 2.1-0 of the pls package is now available on CRAN.

The pls package implements partial least squares regression (PLSR) and
principal component regression (PCR).  Features of the package include

- Several plsr algorithms: orthogonal scores, kernel pls, wide kernel
  pls, and simpls
- Flexible cross-validation
- A formula interface, with traditional methods like predict, coef,
  plot and summary
- Functions for extraction of scores and loadings, and calculation of
  (R)MSEP and R2
- Functions for plotting predictions, validation statistics,
  coefficients, scores, loadings, and correlation loadings.

The main changes since 2.0-0 are

- Jackknife variance estimation of regression coefficients has been added.

- The `wide kernel' PLS algorithm has been implemented.  It is faster than the
  other algorithms for very wide data.

- The definition of R^2 has been changed to  1 - SSE/SST for all estimators,
  so R2() will give different results for test sets and
  cross-validation compared to pls < 2.1-0.  Also, the internal
  calculations have been reorganised.

- The plot functions for coefficients, predictions and validation results
  (R2, (R)MSEP) have gained an argument `main' to set the main title of the
  plot.

- plots that go over several pages now only set `par(ask = TRUE)' if the plot
  device is interactive (suggested by Kevin Wright).

- mvr() and mvrCv() now check for near zero standard deviation when autoscaling
  (`scale = TRUE')


See the file CHANGES in the sources for all changes.

-- 
Bj?rn-Helge Mevik and Ron Wehrens



From gregory.warnes at mac.com  Thu Nov  1 19:05:44 2007
From: gregory.warnes at mac.com (Gregory Warnes)
Date: Thu, 1 Nov 2007 14:05:44 -0400
Subject: [R-pkgs] SASxport v. 1.2.0
In-Reply-To: <4722294E.30207@quantpharm.com>
References: <470E2BF5.7070307@metrumrg.com> <4722294E.30207@quantpharm.com>
Message-ID: <DF714C74-B5EC-475F-9E7D-CF035DDB36A4@mac.com>


SASxport Version 1.2.0 is now available
---------------------------------------

The SASxport package provides R with full support for reading
and writing SAS xport format files.

Version 1.2.0 corrects a critical issues with storage of negative
numbers, as well as adding additional improvements to the handling
of SAS display and input format specifications.  With these
enhancements, both reading and writing SAS transport files is
almost lossless*.

SASxport 1.2.0 is available _now_ at

	http://random-technologies-llc.com/products/SASxport/

and will become available on your favorite CRAN repository shortly.

For additional information and commercial support packages, please
visit the Random Technologies web site:

	http://random-technologies-llc.com/products/SASxport/

-Greg

Gregory R. Warnes, Ph.D
Chief Scientist
Random Technologies, LLC.

----

(*) Only information that cannot be stored in a SAS xport format file
     is lost: variable names are uppercased and truncated at 8
     characters, missing values for character string variables are
     converted to empty strings,  and numeric values outside of the SAS
     xport format numeric floating point range are converted to missing
     values.



From greg at warnes.net  Fri Nov  2 20:47:26 2007
From: greg at warnes.net (Gregory. R. Warnes)
Date: Fri, 2 Nov 2007 15:47:26 -0400
Subject: [R-pkgs] gplots 2.5.0
Message-ID: <AA61BDD3-CB47-441E-8E1E-372050754BA1@rochester.edu>


Announcing gplots 2.5.0
---------------------------------

gplots provides additional plotting functions, including several  
enhanced versions of base R functions.

Provided functions include:
	balloonplot, bandplot, barplot2, boxplot.n, colorpanel, heatmap.2,
	hist2d, lowess, ooplot, overplot, plot.lm2, plotCI, plotmeans,
	qqnorm.aov, residplot, rich.color, sinkplot, smartlegend, space,
         textplot, wapply


Changes in 2.5.0
-----------------------

New Features:

- textplot() now converts tab characters to spaces before processing to
   avoid problems with computing height and width of text that includes
   tabs.

- Add col2rgb() function to convert color names to rgb hex codes

Bug Fixes:

- Correct balloonplot.default to properly show specified x and y axis
   labels when explicitly provided

- R/balloonplot.R: Correct error in balloonplot when z contains NA  
values.

- Fix typos and code/doc mismatches identified by the latest R CMD check

Other:

- Clarify GPL version



From greg at random-technologies-llc.com  Sat Nov 10 00:05:07 2007
From: greg at random-technologies-llc.com (Gregory R. Warnes)
Date: Fri, 9 Nov 2007 18:05:07 -0500
Subject: [R-pkgs] SASxport v. 1.2.2
In-Reply-To: <4722294E.30207@quantpharm.com>
References: <470E2BF5.7070307@metrumrg.com> <4722294E.30207@quantpharm.com>
Message-ID: <DA158979-1950-4319-BB70-4B245D995090@random-technologies-llc.com>


SASxport Version 1.2.2 is now available
---------------------------------------

The SASxport package provides R with full support for reading
and writing SAS xport format files.

Version 1.2.2 corrects problems on 64 bit versions of R.

SASxport 1.2.2 is available _now_ at

	http://random-technologies-llc.com/products/SASxport/

and will become available on your favorite CRAN repository shortly.

For additional information and commercial support packages, please
visit the Random Technologies web site:

	http://random-technologies-llc.com/products/SASxport/

-Greg

Gregory R. Warnes, Ph.D
Chief Scientist
Random Technologies, LLC.



From vincent.goulet at act.ulaval.ca  Fri Nov 16 19:30:19 2007
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Fri, 16 Nov 2007 13:30:19 -0500
Subject: [R-pkgs] New version of actuar
Message-ID: <7F1B6E66-613E-4A93-AF0D-4F6D66BE4307@act.ulaval.ca>

UseRs,

Version 0.9-4 of actuar should be making its way to CRAN mirrors. The  
main highlights of this new version are speed enhancements for a few  
functions, support for phase-type distributions and functions for ruin  
theory.

The relevant section of the NEWS file follows

Version 0.9-4
=============

Maintenance and new features release.

NEW FEATURES -- LOSS DISTRIBUTIONS

   o Functions mgffoo() to compute the moment (or cumulant if 'log =
     TRUE') generating function of the following distributions:
     chi-square, exponential, gamma, inverse gaussian (from package
     SuppDists), inverse gamma, normal, uniform and phase-type (see
     below).

   o Functions mfoo() to compute the raw moments of all the probability
     distributions supported in the package and the following of base
     R: chi-square, exponential, gamma, inverse gaussian (from package
     SuppDists), inverse gamma, normal, uniform.

   o Functions {d,p,mgf,m,r}phtype() to compute the probability density
     function, cumulative distribution function, moment generating
     function, raw moments of, and to generate variates from,
     phase-type distributions.

NEW FEATURES -- RISK THEORY

   o Function VaR() with a method for objects of class "aggregateDist"
     to compute the Value at Risk of a distribution.

   o Function CTE() with a method for objects of class "aggregateDist"
     to compute the Conditional Tail Expectation of a distribution.

   o Function adjCoef() to compute the adjustment coefficient in ruin
     theory. If proportional or excess-of-loss reinsurance is included
     in the model, adjCoef() returns a function to compute the
     adjustment coefficient for given limits. A plot method is also
     included.

   o Function ruin() returns a function to compute the infinite time
     probability of ruin for given initial surpluses in the
     Cram?r-Lundberg and Sparre Andersen models. Most calculations are
     done using the cdf of phase-type distributions as per Asmussen and
     Rolski (1991).

   o Calculations of the aggregate claim distribution using the
     recursive method much faster now that recursions are done in C.

NEW FEATURES -- CREDIBILITY THEORY

   o Modular rewrite of cm(): the function now calls internal functions
     to carry calculations for each supported credibility model. This
     is more efficient.

   o Basic support for the regression model of Hachemeister in function
     cm().

   o For the hierarchical credibility model: support for the variance
     components estimators of B?hlmann and Gisler (2005) and Ohlsson
     (2005). Support remains for iterative pseudo-estimators.

   o Calculations of iterative pseudo-estimators in hierarchical
     credibility are much faster now that they are done in C.

OTHER NEW FEATURES

   o Four new vignettes: introduction to the package and presentation
     of the features in loss distributions, risk theory and credibility
     theory.

   o Portfolio simulation material of the "credibility" demo moved to
     demo "simulation".

USER-VISIBLE CHANGES

   o Argument 'approx.lin' of quantile.aggregateDist() renamed
     'smooth'.

   o Function aggregateDist() gains a 'maxit' argument for the maximum
     number of recursions when using Panjer's algorithm. This is to
     avoid infinite recursion when the cumulative distribution
     function does not converge to 1.

   o Function cm() gains a 'maxit' argument for the maximum number of
     iterations in pseudo-estimators calculations.

   o Methods of aggregate(), frequency(), severity() and weights() for
     objects of class "simpf" gain two new arguments:

     1. 'classification'; when TRUE, the columns giving the
        classification structure of the portfolio are excluded from the
        result. This eases calculation of loss ratios (aggregate claim
        amounts divided by the weights);

     2. 'prefix'; specifies a prefix to use in column names, with
         sensible defaults to avoid name clashes for data and weight
         columns.

BUG FIXES

   o The way weights had to be specified for the "chi-square" method of
     mde() to give expected results was very unintuitive. The fix has
     no effect when using the default weights.

   o The empirical step function returned by the "recursive" and
     "convolution" methods of aggregateDist() now correctly returns 1
     when evaluated past its largest knot.

DEPRECATED

   o Direct usage of bstraub() is now deprecated in favor of cm(). The
     function will remain in the package since it is used internally by
     cm(), but it will not be exported in future releases of the
     package. The current format of the results is also deprecated.


---
   Vincent Goulet, Associate Professor
   ?cole d'actuariat
   Universit? Laval, Qu?bec
   Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From groemping at tfh-berlin.de  Fri Nov 23 21:08:43 2007
From: groemping at tfh-berlin.de (=?ISO-8859-1?Q?Ulrike_Gr=F6mping?=)
Date: Fri, 23 Nov 2007 21:08:43 +0100
Subject: [R-pkgs] Major update to package relimpo: Version 2.0
Message-ID: <20071123195655.M80989@tfh-berlin.de>

Dear userRs,

Version 2.0 of package relaimpo is on CRAN (and on my homepage with an
additional metric for non-US users). It contains several major improvements: 
- usage of factors
- incorporation of interactions (for metric lmg only)
- incorporation of observation weights
- application to data from complex surveys
- processing of multiply imputed data
The latter two points are somewhat experimental - of course, feedback is very
welcome.

Regards, Ulrike

****************************** 
 Prof. Dr. Ulrike Gr?mping 
 Fachbereich II 
 TFH Berlin 
 Luxemburger Str. 10 
 13353 Berlin 
 mail: groemping at tfh-berlin.de 
 www: www.tfh-berlin.de/~groemp/



From GPetris at uark.edu  Wed Nov 28 19:14:22 2007
From: GPetris at uark.edu (Giovanni Petris)
Date: Wed, 28 Nov 2007 12:14:22 -0600 (CST)
Subject: [R-pkgs] Package dlm version 0.8-1
Message-ID: <200711281814.lASIEMYo009315@definetti.ddns.uark.edu>


I uploaded a new version of package dlm to CRAN. 

dlm provides functions for maximum likelihood, Kalman filtering and
smoothing, and Bayesian analysis of Gaussian linear state space
models, also known as Dynamic Linear Models.  

The most important visible changes from the previous version are the
following.

1) Missing values are now allowed in the observations.

2) Extractor and replacement functions for the matrices defining a dlm
   are now available.

3) The function for Kalman smoothing, "dlmSmooth", can take as
   arguments a data vector and a dlm object. Previously the argument
   had to be the output from "dlmFilter".

4) In addition to the "+" method function for objects of class "dlm",
   used to build complex models from simple components, all having the
   same dimensionality of the observation vector, there is now an
   outer sum, "%+%", which creates a joint model from independent
   dlm's. This is useful to specify models for multivariate
   observations. 

5) Minimal support for Markov chain Monte Carlo output analysis has
   been added, with functions "mcmcSD", "mcmcMean", "ergMean". 

Thanks to Michael Lavine for suggesting the outer sum in (4).

Please let me know of any problems. Comments and suggestions are
very welcome. 

Giovanni Petris

-- 

Giovanni Petris  <GPetris at uark.edu>
Department of Mathematical Sciences
University of Arkansas - Fayetteville
http://definetti.uark.edu/~gpetris/



From Max.Kuhn at pfizer.com  Thu Nov 29 15:25:26 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Thu, 29 Nov 2007 09:25:26 -0500
Subject: [R-pkgs] New versions of the caret (3.08) and caretLSF (1.12)
	packages
Message-ID: <71257D09F114DA4A8E134DEAC70F25D30A45AF33@groamrexm03.amer.pfizer.com>

New versions of the caret (3.08) and caretLSF (1.12) packages have been
released. 

caret (short for "Classification And REgression Training") aims to
simplify the model building process. The package has functions for data
splitting, pre-processing and model tuning, as well as other
miscellaneous functions. 

In the new versions:

   - The elasticnet and the lasso (from the enet package) have been
added

   - mars and fda models are now fit using the earth package. Instead of
using nk as a tuning parameter, these models now use the default nk from
the training set and tunes over nprune. This mimics the process used by
earth/mars/fda more closely.

   - A bug was fixed with leave-one-out cross-validation.

   - For some models, the calculations in the train function are much
more efficient. Wherever possible, caret tries to avoid re-fitting
models if it can get predictions from sub-models. For example, an object
for a boosted tree with 500 trees can often be used to get predictions
for any boosted tree with less than 500 trees. The affected models are:
pls, plsda, earth, rpart, gbm, gamboost, glmboost, blackboost, ctree,
pam, enet and lasso.


The caretLSF package is a parallel processing version of caret. The
other caret package, caretNWS, will be updated to work with the new
version of caret shortly.

Please email me at max dot kuhn at pfizer dot com with any questions or
comments

Max



From kate at few.vu.nl  Mon Dec  3 20:41:55 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Mon, 3 Dec 2007 20:41:55 +0100 (CET)
Subject: [R-pkgs] new package 'bvls', update of 'nnls'
Message-ID: <Pine.GSO.4.56.0712032032140.15974@laurel.few.vu.nl>

A new package 'bvls' is available on CRAN.

The package provides an R interface to the Stark-Parker algorithm for
bounded-variable least squares (BVLS) that solves A x = b with the
constraint l <= x <= u under least squares criteria, where l,x,u \in R^n,
b \in R^m and A is an m \times n matrix.

The Stark-Parker BVLS algorithm was published in

 Stark PB, Parker RL (1995). Bounded-variable least-squares: an
 algorithm and applications, Computational Statistics, 10, 129-141.

The packages interfaces the Fortran77 code distributed via the statlib
on-line software repository at Carnegie Mellon University
(http://lib.stat.cmu.edu/general/bvls), modified very slightly for
compatibility with the gfortran compiler.  Stark and Parker have agreed to
distribution under GPL version 2 or newer.

The function 'bvls::bvls' returns an object of (S3) class 'bvls', which
has methods for 'coefficients', 'fitted.values', 'deviance' and
'residuals'.

====

Version 1.1 of the package 'nnls' is available on CRAN.
Changes between Version 1.0 and 1.1:

	o The function 'nnls::nnls' returns an object of (S3) class
	  'nnls', which has methods for 'coefficients',
	  'fitted.values', 'deviance' and 'residuals'

	o The function 'nnnpls::nnnpls' allows each element of x to be
	  constrained to either a non-positive or a non-negative value

----
Katharine Mullen
mail: Department of Physics and Astronomy, Faculty of Sciences
Vrije Universiteit Amsterdam, de Boelelaan 1081
1081 HV Amsterdam, The Netherlands
room: T.1.06
tel: +31 205987870
fax: +31 205987992
e-mail: kate at nat.vu.nl
homepage: http://www.nat.vu.nl/~kate/



From h.wickham at gmail.com  Fri Dec  7 20:02:05 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 7 Dec 2007 13:02:05 -0600
Subject: [R-pkgs] fda, version 1.2.3
Message-ID: <f8e6ff050712071102o58d7de95iaf491b11e016652e@mail.gmail.com>

fda 1.2.3
========================

Version 1.2.3 of the fda package has just been released. This version adds to
previous versions a script to create most of the figures of chapter 6 of
"Applied Functional Data Analysis" by Ramsay and Silverman. Other changes
offer simpler calls to time warping / registration and functional principal
component functions.

The fda package supports the books "Functional Data Analysis" and "Applied
Functional Data Analysis" by Bernard Silverman and James Ramsay. Functional
data analysis, which lots of us like to call "FDA", is about the analysis of
information on curves or functions. FDA is a collection statistical techniques
for answering questions like, "What are the main ways in which the curves vary
from one to another?" In fact, most of the questions and problems associated
with multivariate data (PCA, LDA, clustering, ...) have functional
counterparts. More information about FDA can be found at
http://www.psych.mcgill.ca/misc/fda/.

Regards

Hadley Wickham
James Ramsey
Spencer Graves



From penel at biomserv.univ-lyon1.fr  Wed Dec 12 15:59:10 2007
From: penel at biomserv.univ-lyon1.fr (Simon Penel)
Date: Wed, 12 Dec 2007 15:59:10 +0100
Subject: [R-pkgs] New version of seqinR  released
Message-ID: <475FF73E.8080606@biomserv.univ-lyon1.fr>

Dear useRs,

the seqinR package contains utilities to import and analyze biological
sequence data. For a general introduction see this document:
http://pbil.univ-lyon1.fr/software/SeqinR//vignette.pdf

Please do not use r-help for questions about seqinR or r-bugs
for bug report about seqinR. Use instead the seqinR diffusion list:
http://pbil.univ-lyon1.fr/software/SeqinR//mailing.php?lang=eng

A new version of seqinR, seqinR 1.1-4, has been released on CRAN.
Here is a summary of changes:

o There is a new chapter to explain how to set up a
  local ACNUC server on Unix-like platforms.

o Function GC() has gained a new argument NA.GC
  defaulting to NA to say what should be returned when the
  GC content cannot be computed from data (for instance with a
  sequence like NNNNNNNNNNNN). The argument oldGC is now
  deprecated and a warning is issued. Functions GC1(),
  GC2(), GC3() are now simple wrappers for the
  more general GCpos() function. The new argument frame
  allows to take the frame into account for CDS.

o Function read.fasta() now supports comment lines
  starting by a semicolon character in FASTA files. An example
  of such a file is provided in sequences/legacy.fasta.
  The argument File is now deprecated. There is
  a new argument seqonly to import just the sequences
  without names, annotations and coercion attempts. There is
  a new argument strip.desc to remove the leading
  '>' character in annotations (as in function readFASTA
  from the Biostrings package). The FASTA file
  example someORF.fsa from Biostrings is also added
  for comparisons.

o Function read.alignment() has gained a new argument
  forceToLower defaulting to TRUE to force lower case in
  the character of the sequence (this is for a smoother interaction
  with the package ape). The argument File is now
  deprecated and a warning is issued when used instead of file.
  The example in the function kaks() has been corrected
  to avoid this warning when reading the example files.

o The details of the socket connection are no more stored in
  the slot socket for objects of class seqAcnucWeb:
  this slot is now deleted. As a consequence, the argument
  socket in function as.SeqAcnucWeb() has been
  removed and there is now a new
  argument socket = "auto" in functions getAnnot(),
  getFrag(), geyKeyword(), getLocation(),
  and getSequence(). The default value "auto" means
  that the details of the socket connection are taken automatically
  when necessary from the last opened bank. The size of local lists
  of sequences is reduced by about a third now as compared to the
  previous version.

o New dataset m16j and waterabs added.

o Generic functions getAnnot(), getFrag(), getKeyword(),
  getLength(), getLocation(), getName(), getSequence() and
  getTrans() have gained methods to handle objects from class list
  and class qaw.

o Functions getAttributsocket() and getNumber.socket()
  are now deprecated, a warning is issued.

o There is a new appendix in which all the examples protected
  by a dontrun statment are forced to be executed.

o New low level utility functions related to an ACNUC server:
  acnucclose(), quitacnuc(), clientid(), countfreelists(),
  knowndbs(), autosocket(), countsubseqs(), savelist(),
  ghelp(), modifylist(), getlistate(), setlistname(),
  residuecount(), isenum(), prettyseq(), gfrag(),
  print.seqAcnucWeb()

o Utility function parser.socket() has been optimized and
  is about four times faster now. This decreases the time
  needed by the query() function.

Best,

the seqinR team

-- 
Simon Penel
Laboratoire de Biometrie et Biologie Evolutive           Bat 711  -   CNRS UMR 5558  -    Universite Lyon 1              43 bd du 11 novembre 1918 69622 Villeurbanne Cedex       Tel:   04 72 43 29 04      Fax:  04 72 43 13 88
http://lbbe.univ-lyon1.fr/-Penel-Simon-.html?lang=fr
http://pbil.univ-lyon1.fr/members/penel



From KKIII at Indiana.Edu  Thu Dec 13 20:13:39 2007
From: KKIII at Indiana.Edu (Ken Kelley)
Date: Thu, 13 Dec 2007 14:13:39 -0500
Subject: [R-pkgs] New version of MBESS released
Message-ID: <86b533e90712131113y3104de23x9028456d2f7d8466@mail.gmail.com>

Hello useRs,

MBESS (Methods for the Behavioral, Educational, and Social Sciences)
has recently been released and should be on all of the mirrors by now
(with binaries for Mac and Windows:
http://cran.r-project.org/src/contrib/Descriptions/MBESS.html).

The major contribution of MBESS is confidence intervals for
noncentrality parameters (t, F, and chi-square) and standardized
effect sizes (e.g., the standardized mean and mean difference, R^2 for
random or fixed effects, the coefficient of variation, the root mean
square error of approximation, standardized regression coefficients)
as well as sample size planning from the accuracy in parameter
estimation (AIPE) approach, where the width of the observed confidence
intervals is of interest (in addition to or instead of the power
analytic approach to sample size planning).

This is the 10th release of MBESS and it is version number is now 1.0.0.

Detailed information about MBESS is available in the current issue of
Behavior Research Methods
(http://www.psychonomic.org/BRMIC/contents.htm) as well as Journal of
Statistical Software (http://www.jstatsoft.org/v20/i08).

Take care,
Ken

-- 
Ken Kelley, Ph.D.
Indiana University
Inquiry Methodology Program
201 North Rose Avenue, Suite 4000
Bloomington, Indiana 47405

Phone: 812-856-8330 / Fax: 812-856-8333
Email: KKIII at Indiana.Edu
Internet: http://www.indiana.edu/~kenkel



From ahenningsen at email.uni-kiel.de  Tue Dec 18 17:15:57 2007
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Tue, 18 Dec 2007 17:15:57 +0100
Subject: [R-pkgs] New version of systemfit (not backward compatible)
Message-ID: <200712181715.57597.ahenningsen@email.uni-kiel.de>

Dear R users,

the systemfit package contains functions for fitting systems of simultaneous 
equations by various estimation methods (e.g. OLS, SUR, 2SLS, 3SLS). 
Currently version 0.8 of systemfit is available on CRAN. However, shortly we 
will upload version 1.0, which is NOT BACKWARD COMPATIBLE. The changes that 
broke backward compatibility were necessary to make systemfit() more similar 
to standard regression tools in R such as lm(). We hope that the usage of 
systemfit() is more intuitive for R users now. We will continue to maintain 
the 0.8 branch so that users can still use the old version if they do not 
want to update their R scripts. Both versions are and will be available for 
download from systemfit's website:
   http://www.systemfit.org/
which is a shortcut to 
   http://www.uni-kiel.de/agrarpol/ahenningsen/systemfit/

A paper that describes the (new version of the) systemfit package is 
forthcoming in the Journal of Statistical Software (JSS). A preprint of this 
paper is available on systemfit's website:
   http://www.systemfit.org/systemfit_paper_1.0.pdf

The following list summarizes the most important changes 
from version 0.8 to 1.0:
- some names of systemfit()'s arguments have changed to make it more 
  similar to standard regression tools in R
- the order of systemfit()'s arguments has changed to make it more 
  similar to standard regression tools in R
- the names of the elements in the object returned by systemfit() have 
  changed to make it more similar to lm()
- added several methods for systemfit objects that are generally 
  available for standard regression tools in R
- restrictions on the coefficients can be specified symbolically now
- the functionality of systemfitClassic() has been integrated into systemfit()
- replaced ftest.systemfit() and waldtest.systemfit() by the method
  linear.hypothesis()
- systemfit now uses the "Matrix" package for matrix calculations (this 
  makes the estimation of large models and large data sets much faster)
- improved checking of the arguments so that error messages are more 
  helpful now

We thank two anonymous referees of the JSS, Achim Zeileis, John Fox, William 
H. Greene, Ott Toomet, Duncan Murdoch, Martin Maechler, Duglas Bates and 
several (other) systemfit users for their answers, comments, and/or 
suggestions that helped us to improve the systemfit package.

Feedback is always welcome!
Arne & Jeff

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445 or +49-4349-914871
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From racinej at mcmaster.ca  Tue Dec 18 21:30:03 2007
From: racinej at mcmaster.ca (Jeffrey S. Racine)
Date: Tue, 18 Dec 2007 15:30:03 -0500
Subject: [R-pkgs] Update of the np package (version 0.14-1)
Message-ID: <1198009803.37146.29.camel@pc-racine1.mcmaster.ca>

Dear R users,

An updated version of the np package has recently been uploaded to CRAN
(version 0.14-1). 

The package is briefly described in a recent issue of Rnews (October,
2007, http://cran.r-project.org/doc/Rnews/Rnews_2007-2.pdf) for those
who might be interested.

A somewhat more detailed paper that describes the np package is
forthcoming in the Journal of Statistical Software
(http://www.jstatsoft.org) for those might be interested.

A much more thorough treatment of the subject matter can be found in Li,
Q. and J. S. Racine (2007), Nonparametric Econometrics: Theory and
Practice, Princeton University Press, ISBN: 0691121613 (768 Pages) for
those who might be interested
(http://press.princeton.edu/titles/8355.html)

Information on the np package:

This package provides a variety of nonparametric (and semiparametric)
kernel methods that seamlessly handle a mix of continuous, unordered,
and ordered factor datatypes. We would like to gratefully acknowledge
support from  the Natural Sciences and Engineering Research Council of
Canada (NSERC:www.nserc.ca), the Social Sciences and Humanities Research
Council of Canada (SSHRC:www.sshrc.ca), and the Shared Hierarchical
Academic Research Computing Network (SHARCNET:www.sharcnet.ca).

Changes from version 0.13-1 to 0.14-1:

* now use optim rather than nlm for minimisation in single index and
smooth coefficient models
* fixed bug in klein-spady objective function
* regression standard errors are now available in the case of no
  continuous variables
* summary should look prettier, print additional information
* tidied up lingering issues with out-of-sample data and conditional
modes
* fixed error when plotting asymptotic errors with conditional densities
* fixed a bug in npplot with partially linear regressions and 
plot.behavior='data' or 'plot-data'
* maximum default number of multistarts is now set to 5
* least-squares cross-validation of conditional densities uses a new,
 faster algorithm
* new, faster algorithm for least-squares cross-validation for both 
local-constant and local linear regressions.
   The estimator has changed somewhat: both cross-validation and
   the estimator use a method of shrinking towards the local constant
   estimator rather than the standard ridge approach that shrinks
   towards zero
* optimised smooth coefficient code, added ridging
* fixed bug in uniform CDF kernel
* fixed bug where npindexbw would ignore bandwidth.compute = FALSE and
   compute bandwidths when supplied with a preexisting bw object
* now can handle estimation out of discrete support.
* summary would misreport the values of discrete scale factors which
   were computed with bwscaling = TRUE

We are grateful to John Fox, Achim Zeilies, Roger Koenker, and numerous
users for their valuable feedback which resulted in an improved version
of the package.

-- Jeffrey Racine & Tristen Hayfield.

-- 
Professor J. S. Racine         Phone:  (905) 525 9140 x 23825
Department of Economics        FAX:    (905) 521-8232
McMaster University            e-mail: racinej at mcmaster.ca
1280 Main St. W.,Hamilton,     URL:
http://www.economics.mcmaster.ca/racine/
Ontario, Canada. L8S 4M4

`The generation of random numbers is too important to be left to chance'



From tplate at acm.org  Sun Dec 23 02:33:06 2007
From: tplate at acm.org (Tony Plate)
Date: Sat, 22 Dec 2007 18:33:06 -0700
Subject: [R-pkgs] new version of trackObjs
Message-ID: <476DBAD2.1020700@acm.org>

The trackObjs package stores objects in files on disk so that files are
automatically rewritten when objects are changed, and so
that objects are accessible but do not occupy memory until
they are accessed. Also tracks times when objects are created
and modified, and caches some basic characteristics of objects
to allow for fast summaries of objects.

This version trackObjs_0.8-0 fixes some bugs:

     o   Fixed faulty detection of conflicting existing objects
         when starting to track to an existing directory.

     o   Replaced environment on function that is in the active
         binding for a tracked object.  Previously, that function
         could, if constructed via track(obj <- value), have a
         copy of the tracked object in its environment, which would
         stay present taking up memory even if the object was
         flushed out of the tracking environment.

     o   Fixed bug that stopped track.stop(all=TRUE) from working

-- Tony Plate



From deleeuw at stat.ucla.edu  Sun Dec 23 18:57:08 2007
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sun, 23 Dec 2007 09:57:08 -0800
Subject: [R-pkgs] anacor: yet another ca package
Message-ID: <E99D0798-917F-4C4B-A951-C25D86A3175F@stat.ucla.edu>

anacor-0.9.0 is on CRAN (by De Leeuw and Mair)

anacor does correspondence analysis and canonical correspondence
analysis. It can make row plots, column plots,
joint plots, Benz?cri plots, regression plots,
and transformation plots. Where appropriate, plots can
be in 3d using either rgl or scatterplot3d. Row and
column points can be in standard scaling, Benz?cri
scaling, Goodman scaling, row-centroid, or column-centroid
scaling.

The summary method writes out a table with the chi-square
(inertia) decomposition, it also writes out the singular
values, and their asymptotic standard errors under multinomial
sampling. Plots of the category quantifications (row scores
and column scores) can be made optionally with asymptotic
confidence ellipses, again based on multinomial sampling.

The package contain various utilities to switch data formats,
in particular to transform data frames to Burt matrices,
to indicator matrices, and even to fuzzy indicator matrices
using B-spline bases.

The vignette for the package (not added yet) is a paper
also submitted to the special psychoR issue of JSS. You
can get a preprint at

http://idisk.mac.com/jdeleeuw-Public/psychoR/anacor.zip

The psychoR directory also has the anacor package, the
homals package, and the homals paper. smacof (many forms
of multidimensional scaling) is next.

==========================================================
Jan de Leeuw, 11667 Steinhoff Rd, Frazier Park, CA 93225
home 661-245-1725 mobile 661-231-5416 work 310-825-9550
.mac: jdeleeuw +++  aim: deleeuwjan +++ skype: j_deleeuw
==========================================================
          There is no worse screen to block out
    the spirit than confidence in our own intelligence.
                                    ---- John Calvin.



